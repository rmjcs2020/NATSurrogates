{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(10)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "params = {\n",
    "    'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "    'image.origin': 'lower',\n",
    "    'image.interpolation': 'nearest',\n",
    "    'image.cmap': 'gray',\n",
    "    'axes.grid': False,\n",
    "    'savefig.dpi': 300,  # to adjust notebook inline plot size\n",
    "    'axes.labelsize': 16, # fontsize for x and y labels (was 10)\n",
    "    'axes.titlesize': 16,\n",
    "    'font.size': 16, # was 10\n",
    "    'legend.fontsize': 16, # was 10\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'text.usetex': True,\n",
    "    'figure.figsize': [3.39, 2.10],\n",
    "    'font.family': 'serif',\n",
    "}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training data that goes from initial condition location to PCA coefficient trajectory\n",
    "num_modes=40\n",
    "locs = np.load('../../SWE_Data/Data/Locations.npy')\n",
    "pca_coeffs = np.load('../../SWE_Data/PCA_Coefficients_q1.npy')[0:num_modes,:]\n",
    "\n",
    "coeff_scaler = MinMaxScaler()\n",
    "pca_coeffs_scaled = np.transpose(coeff_scaler.fit_transform(np.transpose(pca_coeffs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = np.shape(locs)[0]\n",
    "num_ivs = np.shape(locs)[1]\n",
    "num_coeffs = np.shape(pca_coeffs)[0]\n",
    "burn_in = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "raw_training_data = np.zeros(shape=(num_sims,num_coeffs+num_ivs,500),dtype='double')\n",
    "\n",
    "for sim in range(num_sims):\n",
    "    raw_training_data[sim,:-num_ivs,:] = pca_coeffs_scaled[:,500*sim:500*(sim+1)]\n",
    "    raw_training_data[sim,-num_ivs:,:] = locs[sim,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 42, 500)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(raw_training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "from tcn import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0127 14:54:32.439893 139866416793408 deprecation.py:506] From /home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 42, 20)]          0         \n",
      "_________________________________________________________________\n",
      "tcn (TCN)                    (None, 42, 88)            227920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 42, 88)            0         \n",
      "_________________________________________________________________\n",
      "tcn_1 (TCN)                  (None, 42, 88)            233904    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 42, 88)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 42, 480)           42720     \n",
      "=================================================================\n",
      "Total params: 504,544\n",
      "Trainable params: 504,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = None\n",
    "inputs = Input(batch_shape=(batch_size, 42, burn_in))\n",
    "tcn_output = TCN(88,return_sequences=True,activation='tanh')(inputs)  # The TCN layers are here.\n",
    "tcn_output = Dropout(0.2)(tcn_output,training=True)\n",
    "tcn_output = TCN(88,return_sequences=True,activation='tanh')(tcn_output)  # The TCN layers are here.\n",
    "tcn_output = Dropout(0.2)(tcn_output,training=True)\n",
    "output = Dense(500-burn_in,activation='linear')(tcn_output)\n",
    "m = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "my_adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "m.compile(optimizer=my_adam, loss='mse')\n",
    "\n",
    "filepath = \"NA_TCN.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "earlystopping = EarlyStopping(monitor='loss', min_delta=0, patience=100, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data into windowed input and windowed output\n",
    "input_window_length = burn_in\n",
    "output_window_length = 500-burn_in\n",
    "num_timesteps_per_simulation = 500\n",
    "state_len = 42\n",
    "num_sims = 20\n",
    "\n",
    "training_data_ip = np.zeros(shape=(num_sims,state_len,burn_in))\n",
    "training_data_op = np.zeros(shape=(num_sims,state_len,500-burn_in))\n",
    "\n",
    "for sim_num in range(num_sims):\n",
    "    training_data_ip[sim_num,:,:] = raw_training_data[sim_num,:,0:burn_in]\n",
    "    training_data_op[sim_num,:,:] = raw_training_data[sim_num,:,burn_in:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "\n",
      "Epoch 00001: loss improved from inf to 5.83731, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 2s 92ms/sample - loss: 5.8373\n",
      "Epoch 2/5000\n",
      "\n",
      "Epoch 00002: loss improved from 5.83731 to 2.96995, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 2.9699\n",
      "Epoch 3/5000\n",
      "\n",
      "Epoch 00003: loss improved from 2.96995 to 1.84267, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 1.8427\n",
      "Epoch 4/5000\n",
      "\n",
      "Epoch 00004: loss improved from 1.84267 to 1.34592, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 1.3459\n",
      "Epoch 5/5000\n",
      "\n",
      "Epoch 00005: loss improved from 1.34592 to 1.01302, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 1.0130\n",
      "Epoch 6/5000\n",
      "\n",
      "Epoch 00006: loss improved from 1.01302 to 0.78742, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.7874\n",
      "Epoch 7/5000\n",
      "\n",
      "Epoch 00007: loss improved from 0.78742 to 0.64475, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.6447\n",
      "Epoch 8/5000\n",
      "\n",
      "Epoch 00008: loss improved from 0.64475 to 0.52784, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.5278\n",
      "Epoch 9/5000\n",
      "\n",
      "Epoch 00009: loss improved from 0.52784 to 0.44776, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.4478\n",
      "Epoch 10/5000\n",
      "\n",
      "Epoch 00010: loss improved from 0.44776 to 0.39369, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.3937\n",
      "Epoch 11/5000\n",
      "\n",
      "Epoch 00011: loss improved from 0.39369 to 0.34908, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.3491\n",
      "Epoch 12/5000\n",
      "\n",
      "Epoch 00012: loss improved from 0.34908 to 0.31643, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.3164\n",
      "Epoch 13/5000\n",
      "\n",
      "Epoch 00013: loss improved from 0.31643 to 0.29008, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.2901\n",
      "Epoch 14/5000\n",
      "\n",
      "Epoch 00014: loss improved from 0.29008 to 0.27174, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.2717\n",
      "Epoch 15/5000\n",
      "\n",
      "Epoch 00015: loss improved from 0.27174 to 0.25293, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.2529\n",
      "Epoch 16/5000\n",
      "\n",
      "Epoch 00016: loss improved from 0.25293 to 0.24286, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.2429\n",
      "Epoch 17/5000\n",
      "\n",
      "Epoch 00017: loss improved from 0.24286 to 0.23252, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.2325\n",
      "Epoch 18/5000\n",
      "\n",
      "Epoch 00018: loss improved from 0.23252 to 0.22210, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.2221\n",
      "Epoch 19/5000\n",
      "\n",
      "Epoch 00019: loss improved from 0.22210 to 0.21443, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.2144\n",
      "Epoch 20/5000\n",
      "\n",
      "Epoch 00020: loss improved from 0.21443 to 0.20748, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.2075\n",
      "Epoch 21/5000\n",
      "\n",
      "Epoch 00021: loss improved from 0.20748 to 0.19992, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1999\n",
      "Epoch 22/5000\n",
      "\n",
      "Epoch 00022: loss improved from 0.19992 to 0.19482, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1948\n",
      "Epoch 23/5000\n",
      "\n",
      "Epoch 00023: loss improved from 0.19482 to 0.18998, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1900\n",
      "Epoch 24/5000\n",
      "\n",
      "Epoch 00024: loss improved from 0.18998 to 0.18395, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.1840\n",
      "Epoch 25/5000\n",
      "\n",
      "Epoch 00025: loss improved from 0.18395 to 0.18058, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1806\n",
      "Epoch 26/5000\n",
      "\n",
      "Epoch 00026: loss improved from 0.18058 to 0.17543, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1754\n",
      "Epoch 27/5000\n",
      "\n",
      "Epoch 00027: loss improved from 0.17543 to 0.17112, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1711\n",
      "Epoch 28/5000\n",
      "\n",
      "Epoch 00028: loss improved from 0.17112 to 0.16780, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.1678\n",
      "Epoch 29/5000\n",
      "\n",
      "Epoch 00029: loss improved from 0.16780 to 0.16202, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.1620\n",
      "Epoch 30/5000\n",
      "\n",
      "Epoch 00030: loss improved from 0.16202 to 0.15847, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1585\n",
      "Epoch 31/5000\n",
      "\n",
      "Epoch 00031: loss improved from 0.15847 to 0.15417, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.1542\n",
      "Epoch 32/5000\n",
      "\n",
      "Epoch 00032: loss improved from 0.15417 to 0.15006, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.1501\n",
      "Epoch 33/5000\n",
      "\n",
      "Epoch 00033: loss improved from 0.15006 to 0.14520, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1452\n",
      "Epoch 34/5000\n",
      "\n",
      "Epoch 00034: loss improved from 0.14520 to 0.14193, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1419\n",
      "Epoch 35/5000\n",
      "\n",
      "Epoch 00035: loss improved from 0.14193 to 0.13891, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1389\n",
      "Epoch 36/5000\n",
      "\n",
      "Epoch 00036: loss improved from 0.13891 to 0.13579, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1358\n",
      "Epoch 37/5000\n",
      "\n",
      "Epoch 00037: loss improved from 0.13579 to 0.13093, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.1309\n",
      "Epoch 38/5000\n",
      "\n",
      "Epoch 00038: loss improved from 0.13093 to 0.12877, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1288\n",
      "Epoch 39/5000\n",
      "\n",
      "Epoch 00039: loss improved from 0.12877 to 0.12427, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1243\n",
      "Epoch 40/5000\n",
      "\n",
      "Epoch 00040: loss improved from 0.12427 to 0.12114, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.1211\n",
      "Epoch 41/5000\n",
      "\n",
      "Epoch 00041: loss improved from 0.12114 to 0.11902, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1190\n",
      "Epoch 42/5000\n",
      "\n",
      "Epoch 00042: loss improved from 0.11902 to 0.11549, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.1155\n",
      "Epoch 43/5000\n",
      "\n",
      "Epoch 00043: loss improved from 0.11549 to 0.11344, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1134\n",
      "Epoch 44/5000\n",
      "\n",
      "Epoch 00044: loss improved from 0.11344 to 0.10924, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1092\n",
      "Epoch 45/5000\n",
      "\n",
      "Epoch 00045: loss improved from 0.10924 to 0.10641, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1064\n",
      "Epoch 46/5000\n",
      "\n",
      "Epoch 00046: loss improved from 0.10641 to 0.10432, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1043\n",
      "Epoch 47/5000\n",
      "\n",
      "Epoch 00047: loss improved from 0.10432 to 0.10310, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.1031\n",
      "Epoch 48/5000\n",
      "\n",
      "Epoch 00048: loss improved from 0.10310 to 0.10097, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.1010\n",
      "Epoch 49/5000\n",
      "\n",
      "Epoch 00049: loss improved from 0.10097 to 0.09874, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0987\n",
      "Epoch 50/5000\n",
      "\n",
      "Epoch 00050: loss improved from 0.09874 to 0.09586, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0959\n",
      "Epoch 51/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00051: loss improved from 0.09586 to 0.09417, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0942\n",
      "Epoch 52/5000\n",
      "\n",
      "Epoch 00052: loss improved from 0.09417 to 0.09250, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0925\n",
      "Epoch 53/5000\n",
      "\n",
      "Epoch 00053: loss improved from 0.09250 to 0.08977, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0898\n",
      "Epoch 54/5000\n",
      "\n",
      "Epoch 00054: loss improved from 0.08977 to 0.08716, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0872\n",
      "Epoch 55/5000\n",
      "\n",
      "Epoch 00055: loss improved from 0.08716 to 0.08691, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0869\n",
      "Epoch 56/5000\n",
      "\n",
      "Epoch 00056: loss improved from 0.08691 to 0.08365, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0837\n",
      "Epoch 57/5000\n",
      "\n",
      "Epoch 00057: loss improved from 0.08365 to 0.08216, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0822\n",
      "Epoch 58/5000\n",
      "\n",
      "Epoch 00058: loss improved from 0.08216 to 0.08192, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0819\n",
      "Epoch 59/5000\n",
      "\n",
      "Epoch 00059: loss improved from 0.08192 to 0.07794, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0779\n",
      "Epoch 60/5000\n",
      "\n",
      "Epoch 00060: loss improved from 0.07794 to 0.07793, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0779\n",
      "Epoch 61/5000\n",
      "\n",
      "Epoch 00061: loss improved from 0.07793 to 0.07612, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0761\n",
      "Epoch 62/5000\n",
      "\n",
      "Epoch 00062: loss improved from 0.07612 to 0.07580, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0758\n",
      "Epoch 63/5000\n",
      "\n",
      "Epoch 00063: loss improved from 0.07580 to 0.07269, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0727\n",
      "Epoch 64/5000\n",
      "\n",
      "Epoch 00064: loss improved from 0.07269 to 0.07124, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0712\n",
      "Epoch 65/5000\n",
      "\n",
      "Epoch 00065: loss improved from 0.07124 to 0.07084, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0708\n",
      "Epoch 66/5000\n",
      "\n",
      "Epoch 00066: loss improved from 0.07084 to 0.06836, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0684\n",
      "Epoch 67/5000\n",
      "\n",
      "Epoch 00067: loss improved from 0.06836 to 0.06805, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0680\n",
      "Epoch 68/5000\n",
      "\n",
      "Epoch 00068: loss improved from 0.06805 to 0.06741, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0674\n",
      "Epoch 69/5000\n",
      "\n",
      "Epoch 00069: loss improved from 0.06741 to 0.06638, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0664\n",
      "Epoch 70/5000\n",
      "\n",
      "Epoch 00070: loss improved from 0.06638 to 0.06511, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0651\n",
      "Epoch 71/5000\n",
      "\n",
      "Epoch 00071: loss improved from 0.06511 to 0.06391, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0639\n",
      "Epoch 72/5000\n",
      "\n",
      "Epoch 00072: loss improved from 0.06391 to 0.06287, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0629\n",
      "Epoch 73/5000\n",
      "\n",
      "Epoch 00073: loss improved from 0.06287 to 0.06235, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0623\n",
      "Epoch 74/5000\n",
      "\n",
      "Epoch 00074: loss improved from 0.06235 to 0.06130, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0613\n",
      "Epoch 75/5000\n",
      "\n",
      "Epoch 00075: loss improved from 0.06130 to 0.06037, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0604\n",
      "Epoch 76/5000\n",
      "\n",
      "Epoch 00076: loss improved from 0.06037 to 0.05877, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0588\n",
      "Epoch 77/5000\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.05877\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0594\n",
      "Epoch 78/5000\n",
      "\n",
      "Epoch 00078: loss improved from 0.05877 to 0.05799, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0580\n",
      "Epoch 79/5000\n",
      "\n",
      "Epoch 00079: loss improved from 0.05799 to 0.05703, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0570\n",
      "Epoch 80/5000\n",
      "\n",
      "Epoch 00080: loss improved from 0.05703 to 0.05634, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0563\n",
      "Epoch 81/5000\n",
      "\n",
      "Epoch 00081: loss improved from 0.05634 to 0.05630, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0563\n",
      "Epoch 82/5000\n",
      "\n",
      "Epoch 00082: loss improved from 0.05630 to 0.05523, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0552\n",
      "Epoch 83/5000\n",
      "\n",
      "Epoch 00083: loss improved from 0.05523 to 0.05430, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0543\n",
      "Epoch 84/5000\n",
      "\n",
      "Epoch 00084: loss improved from 0.05430 to 0.05359, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0536\n",
      "Epoch 85/5000\n",
      "\n",
      "Epoch 00085: loss improved from 0.05359 to 0.05330, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0533\n",
      "Epoch 86/5000\n",
      "\n",
      "Epoch 00086: loss improved from 0.05330 to 0.05212, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0521\n",
      "Epoch 87/5000\n",
      "\n",
      "Epoch 00087: loss did not improve from 0.05212\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0524\n",
      "Epoch 88/5000\n",
      "\n",
      "Epoch 00088: loss improved from 0.05212 to 0.05057, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0506\n",
      "Epoch 89/5000\n",
      "\n",
      "Epoch 00089: loss improved from 0.05057 to 0.05003, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0500\n",
      "Epoch 90/5000\n",
      "\n",
      "Epoch 00090: loss did not improve from 0.05003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0506\n",
      "Epoch 91/5000\n",
      "\n",
      "Epoch 00091: loss improved from 0.05003 to 0.04951, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0495\n",
      "Epoch 92/5000\n",
      "\n",
      "Epoch 00092: loss improved from 0.04951 to 0.04896, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0490\n",
      "Epoch 93/5000\n",
      "\n",
      "Epoch 00093: loss improved from 0.04896 to 0.04804, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0480\n",
      "Epoch 94/5000\n",
      "\n",
      "Epoch 00094: loss improved from 0.04804 to 0.04702, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0470\n",
      "Epoch 95/5000\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.04702\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0471\n",
      "Epoch 96/5000\n",
      "\n",
      "Epoch 00096: loss improved from 0.04702 to 0.04585, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0458\n",
      "Epoch 97/5000\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.04585\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0461\n",
      "Epoch 98/5000\n",
      "\n",
      "Epoch 00098: loss improved from 0.04585 to 0.04538, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0454\n",
      "Epoch 99/5000\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.04538\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0455\n",
      "Epoch 100/5000\n",
      "\n",
      "Epoch 00100: loss improved from 0.04538 to 0.04505, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0451\n",
      "Epoch 101/5000\n",
      "\n",
      "Epoch 00101: loss improved from 0.04505 to 0.04418, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0442\n",
      "Epoch 102/5000\n",
      "\n",
      "Epoch 00102: loss did not improve from 0.04418\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/5000\n",
      "\n",
      "Epoch 00103: loss improved from 0.04418 to 0.04299, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0430\n",
      "Epoch 104/5000\n",
      "\n",
      "Epoch 00104: loss did not improve from 0.04299\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0431\n",
      "Epoch 105/5000\n",
      "\n",
      "Epoch 00105: loss improved from 0.04299 to 0.04176, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0418\n",
      "Epoch 106/5000\n",
      "\n",
      "Epoch 00106: loss did not improve from 0.04176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0420\n",
      "Epoch 107/5000\n",
      "\n",
      "Epoch 00107: loss improved from 0.04176 to 0.04149, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0415\n",
      "Epoch 108/5000\n",
      "\n",
      "Epoch 00108: loss improved from 0.04149 to 0.04109, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0411\n",
      "Epoch 109/5000\n",
      "\n",
      "Epoch 00109: loss improved from 0.04109 to 0.04021, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0402\n",
      "Epoch 110/5000\n",
      "\n",
      "Epoch 00110: loss did not improve from 0.04021\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0406\n",
      "Epoch 111/5000\n",
      "\n",
      "Epoch 00111: loss did not improve from 0.04021\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0407\n",
      "Epoch 112/5000\n",
      "\n",
      "Epoch 00112: loss improved from 0.04021 to 0.03915, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0392\n",
      "Epoch 113/5000\n",
      "\n",
      "Epoch 00113: loss improved from 0.03915 to 0.03908, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0391\n",
      "Epoch 114/5000\n",
      "\n",
      "Epoch 00114: loss improved from 0.03908 to 0.03841, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0384\n",
      "Epoch 115/5000\n",
      "\n",
      "Epoch 00115: loss improved from 0.03841 to 0.03808, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0381\n",
      "Epoch 116/5000\n",
      "\n",
      "Epoch 00116: loss did not improve from 0.03808\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0383\n",
      "Epoch 117/5000\n",
      "\n",
      "Epoch 00117: loss improved from 0.03808 to 0.03739, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0374\n",
      "Epoch 118/5000\n",
      "\n",
      "Epoch 00118: loss improved from 0.03739 to 0.03737, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0374\n",
      "Epoch 119/5000\n",
      "\n",
      "Epoch 00119: loss improved from 0.03737 to 0.03654, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0365\n",
      "Epoch 120/5000\n",
      "\n",
      "Epoch 00120: loss did not improve from 0.03654\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0366\n",
      "Epoch 121/5000\n",
      "\n",
      "Epoch 00121: loss did not improve from 0.03654\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0370\n",
      "Epoch 122/5000\n",
      "\n",
      "Epoch 00122: loss improved from 0.03654 to 0.03624, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0362\n",
      "Epoch 123/5000\n",
      "\n",
      "Epoch 00123: loss improved from 0.03624 to 0.03579, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0358\n",
      "Epoch 124/5000\n",
      "\n",
      "Epoch 00124: loss did not improve from 0.03579\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0360\n",
      "Epoch 125/5000\n",
      "\n",
      "Epoch 00125: loss improved from 0.03579 to 0.03564, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0356\n",
      "Epoch 126/5000\n",
      "\n",
      "Epoch 00126: loss improved from 0.03564 to 0.03485, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0349\n",
      "Epoch 127/5000\n",
      "\n",
      "Epoch 00127: loss did not improve from 0.03485\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0349\n",
      "Epoch 128/5000\n",
      "\n",
      "Epoch 00128: loss improved from 0.03485 to 0.03448, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0345\n",
      "Epoch 129/5000\n",
      "\n",
      "Epoch 00129: loss improved from 0.03448 to 0.03414, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0341\n",
      "Epoch 130/5000\n",
      "\n",
      "Epoch 00130: loss improved from 0.03414 to 0.03400, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0340\n",
      "Epoch 131/5000\n",
      "\n",
      "Epoch 00131: loss improved from 0.03400 to 0.03382, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0338\n",
      "Epoch 132/5000\n",
      "\n",
      "Epoch 00132: loss improved from 0.03382 to 0.03379, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0338\n",
      "Epoch 133/5000\n",
      "\n",
      "Epoch 00133: loss improved from 0.03379 to 0.03358, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0336\n",
      "Epoch 134/5000\n",
      "\n",
      "Epoch 00134: loss improved from 0.03358 to 0.03323, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0332\n",
      "Epoch 135/5000\n",
      "\n",
      "Epoch 00135: loss improved from 0.03323 to 0.03300, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0330\n",
      "Epoch 136/5000\n",
      "\n",
      "Epoch 00136: loss improved from 0.03300 to 0.03258, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0326\n",
      "Epoch 137/5000\n",
      "\n",
      "Epoch 00137: loss improved from 0.03258 to 0.03252, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0325\n",
      "Epoch 138/5000\n",
      "\n",
      "Epoch 00138: loss improved from 0.03252 to 0.03220, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0322\n",
      "Epoch 139/5000\n",
      "\n",
      "Epoch 00139: loss improved from 0.03220 to 0.03178, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0318\n",
      "Epoch 140/5000\n",
      "\n",
      "Epoch 00140: loss did not improve from 0.03178\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0322\n",
      "Epoch 141/5000\n",
      "\n",
      "Epoch 00141: loss improved from 0.03178 to 0.03113, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0311\n",
      "Epoch 142/5000\n",
      "\n",
      "Epoch 00142: loss did not improve from 0.03113\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0315\n",
      "Epoch 143/5000\n",
      "\n",
      "Epoch 00143: loss did not improve from 0.03113\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0317\n",
      "Epoch 144/5000\n",
      "\n",
      "Epoch 00144: loss did not improve from 0.03113\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0312\n",
      "Epoch 145/5000\n",
      "\n",
      "Epoch 00145: loss did not improve from 0.03113\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0312\n",
      "Epoch 146/5000\n",
      "\n",
      "Epoch 00146: loss improved from 0.03113 to 0.03064, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0306\n",
      "Epoch 147/5000\n",
      "\n",
      "Epoch 00147: loss improved from 0.03064 to 0.03026, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0303\n",
      "Epoch 148/5000\n",
      "\n",
      "Epoch 00148: loss did not improve from 0.03026\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0309\n",
      "Epoch 149/5000\n",
      "\n",
      "Epoch 00149: loss did not improve from 0.03026\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0308\n",
      "Epoch 150/5000\n",
      "\n",
      "Epoch 00150: loss did not improve from 0.03026\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0304\n",
      "Epoch 151/5000\n",
      "\n",
      "Epoch 00151: loss improved from 0.03026 to 0.03011, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0301\n",
      "Epoch 152/5000\n",
      "\n",
      "Epoch 00152: loss did not improve from 0.03011\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0305\n",
      "Epoch 153/5000\n",
      "\n",
      "Epoch 00153: loss did not improve from 0.03011\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0306\n",
      "Epoch 154/5000\n",
      "\n",
      "Epoch 00154: loss improved from 0.03011 to 0.02991, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0299\n",
      "Epoch 155/5000\n",
      "\n",
      "Epoch 00155: loss improved from 0.02991 to 0.02971, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0297\n",
      "Epoch 156/5000\n",
      "\n",
      "Epoch 00156: loss improved from 0.02971 to 0.02907, saving model to CNN_NAT.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0291\n",
      "Epoch 157/5000\n",
      "\n",
      "Epoch 00157: loss did not improve from 0.02907\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0298\n",
      "Epoch 158/5000\n",
      "\n",
      "Epoch 00158: loss did not improve from 0.02907\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0294\n",
      "Epoch 159/5000\n",
      "\n",
      "Epoch 00159: loss improved from 0.02907 to 0.02904, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0290\n",
      "Epoch 160/5000\n",
      "\n",
      "Epoch 00160: loss did not improve from 0.02904\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0292\n",
      "Epoch 161/5000\n",
      "\n",
      "Epoch 00161: loss did not improve from 0.02904\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0291\n",
      "Epoch 162/5000\n",
      "\n",
      "Epoch 00162: loss improved from 0.02904 to 0.02866, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0287\n",
      "Epoch 163/5000\n",
      "\n",
      "Epoch 00163: loss improved from 0.02866 to 0.02851, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0285\n",
      "Epoch 164/5000\n",
      "\n",
      "Epoch 00164: loss improved from 0.02851 to 0.02816, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0282\n",
      "Epoch 165/5000\n",
      "\n",
      "Epoch 00165: loss did not improve from 0.02816\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0286\n",
      "Epoch 166/5000\n",
      "\n",
      "Epoch 00166: loss improved from 0.02816 to 0.02803, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0280\n",
      "Epoch 167/5000\n",
      "\n",
      "Epoch 00167: loss improved from 0.02803 to 0.02788, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0279\n",
      "Epoch 168/5000\n",
      "\n",
      "Epoch 00168: loss did not improve from 0.02788\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0281\n",
      "Epoch 169/5000\n",
      "\n",
      "Epoch 00169: loss did not improve from 0.02788\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0280\n",
      "Epoch 170/5000\n",
      "\n",
      "Epoch 00170: loss did not improve from 0.02788\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0282\n",
      "Epoch 171/5000\n",
      "\n",
      "Epoch 00171: loss did not improve from 0.02788\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0282\n",
      "Epoch 172/5000\n",
      "\n",
      "Epoch 00172: loss improved from 0.02788 to 0.02747, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0275\n",
      "Epoch 173/5000\n",
      "\n",
      "Epoch 00173: loss improved from 0.02747 to 0.02699, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0270\n",
      "Epoch 174/5000\n",
      "\n",
      "Epoch 00174: loss did not improve from 0.02699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0271\n",
      "Epoch 175/5000\n",
      "\n",
      "Epoch 00175: loss did not improve from 0.02699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0271\n",
      "Epoch 176/5000\n",
      "\n",
      "Epoch 00176: loss did not improve from 0.02699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0273\n",
      "Epoch 177/5000\n",
      "\n",
      "Epoch 00177: loss improved from 0.02699 to 0.02686, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0269\n",
      "Epoch 178/5000\n",
      "\n",
      "Epoch 00178: loss improved from 0.02686 to 0.02672, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0267\n",
      "Epoch 179/5000\n",
      "\n",
      "Epoch 00179: loss did not improve from 0.02672\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0271\n",
      "Epoch 180/5000\n",
      "\n",
      "Epoch 00180: loss did not improve from 0.02672\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0269\n",
      "Epoch 181/5000\n",
      "\n",
      "Epoch 00181: loss did not improve from 0.02672\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0270\n",
      "Epoch 182/5000\n",
      "\n",
      "Epoch 00182: loss improved from 0.02672 to 0.02650, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0265\n",
      "Epoch 183/5000\n",
      "\n",
      "Epoch 00183: loss improved from 0.02650 to 0.02636, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0264\n",
      "Epoch 184/5000\n",
      "\n",
      "Epoch 00184: loss improved from 0.02636 to 0.02626, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0263\n",
      "Epoch 185/5000\n",
      "\n",
      "Epoch 00185: loss did not improve from 0.02626\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0265\n",
      "Epoch 186/5000\n",
      "\n",
      "Epoch 00186: loss improved from 0.02626 to 0.02573, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0257\n",
      "Epoch 187/5000\n",
      "\n",
      "Epoch 00187: loss did not improve from 0.02573\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0261\n",
      "Epoch 188/5000\n",
      "\n",
      "Epoch 00188: loss improved from 0.02573 to 0.02561, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0256\n",
      "Epoch 189/5000\n",
      "\n",
      "Epoch 00189: loss did not improve from 0.02561\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0266\n",
      "Epoch 190/5000\n",
      "\n",
      "Epoch 00190: loss did not improve from 0.02561\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0265\n",
      "Epoch 191/5000\n",
      "\n",
      "Epoch 00191: loss improved from 0.02561 to 0.02543, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0254\n",
      "Epoch 192/5000\n",
      "\n",
      "Epoch 00192: loss did not improve from 0.02543\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0256\n",
      "Epoch 193/5000\n",
      "\n",
      "Epoch 00193: loss improved from 0.02543 to 0.02526, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0253\n",
      "Epoch 194/5000\n",
      "\n",
      "Epoch 00194: loss improved from 0.02526 to 0.02509, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0251\n",
      "Epoch 195/5000\n",
      "\n",
      "Epoch 00195: loss improved from 0.02509 to 0.02501, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0250\n",
      "Epoch 196/5000\n",
      "\n",
      "Epoch 00196: loss did not improve from 0.02501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0255\n",
      "Epoch 197/5000\n",
      "\n",
      "Epoch 00197: loss did not improve from 0.02501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0252\n",
      "Epoch 198/5000\n",
      "\n",
      "Epoch 00198: loss did not improve from 0.02501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0255\n",
      "Epoch 199/5000\n",
      "\n",
      "Epoch 00199: loss improved from 0.02501 to 0.02496, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0250\n",
      "Epoch 200/5000\n",
      "\n",
      "Epoch 00200: loss did not improve from 0.02496\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0250\n",
      "Epoch 201/5000\n",
      "\n",
      "Epoch 00201: loss did not improve from 0.02496\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0252\n",
      "Epoch 202/5000\n",
      "\n",
      "Epoch 00202: loss did not improve from 0.02496\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0250\n",
      "Epoch 203/5000\n",
      "\n",
      "Epoch 00203: loss improved from 0.02496 to 0.02468, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0247\n",
      "Epoch 204/5000\n",
      "\n",
      "Epoch 00204: loss did not improve from 0.02468\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0251\n",
      "Epoch 205/5000\n",
      "\n",
      "Epoch 00205: loss did not improve from 0.02468\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0248\n",
      "Epoch 206/5000\n",
      "\n",
      "Epoch 00206: loss did not improve from 0.02468\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0248\n",
      "Epoch 207/5000\n",
      "\n",
      "Epoch 00207: loss did not improve from 0.02468\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0250\n",
      "Epoch 208/5000\n",
      "\n",
      "Epoch 00208: loss did not improve from 0.02468\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0248\n",
      "Epoch 209/5000\n",
      "\n",
      "Epoch 00209: loss improved from 0.02468 to 0.02451, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0245\n",
      "Epoch 210/5000\n",
      "\n",
      "Epoch 00210: loss improved from 0.02451 to 0.02425, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0243\n",
      "Epoch 211/5000\n",
      "\n",
      "Epoch 00211: loss improved from 0.02425 to 0.02413, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0241\n",
      "Epoch 212/5000\n",
      "\n",
      "Epoch 00212: loss improved from 0.02413 to 0.02392, saving model to CNN_NAT.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0239\n",
      "Epoch 213/5000\n",
      "\n",
      "Epoch 00213: loss did not improve from 0.02392\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0242\n",
      "Epoch 214/5000\n",
      "\n",
      "Epoch 00214: loss did not improve from 0.02392\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0241\n",
      "Epoch 215/5000\n",
      "\n",
      "Epoch 00215: loss did not improve from 0.02392\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0241\n",
      "Epoch 216/5000\n",
      "\n",
      "Epoch 00216: loss did not improve from 0.02392\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0246\n",
      "Epoch 217/5000\n",
      "\n",
      "Epoch 00217: loss improved from 0.02392 to 0.02347, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0235\n",
      "Epoch 218/5000\n",
      "\n",
      "Epoch 00218: loss improved from 0.02347 to 0.02340, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0234\n",
      "Epoch 219/5000\n",
      "\n",
      "Epoch 00219: loss did not improve from 0.02340\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0238\n",
      "Epoch 220/5000\n",
      "\n",
      "Epoch 00220: loss did not improve from 0.02340\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0236\n",
      "Epoch 221/5000\n",
      "\n",
      "Epoch 00221: loss did not improve from 0.02340\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0235\n",
      "Epoch 222/5000\n",
      "\n",
      "Epoch 00222: loss did not improve from 0.02340\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0239\n",
      "Epoch 223/5000\n",
      "\n",
      "Epoch 00223: loss improved from 0.02340 to 0.02326, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0233\n",
      "Epoch 224/5000\n",
      "\n",
      "Epoch 00224: loss did not improve from 0.02326\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0237\n",
      "Epoch 225/5000\n",
      "\n",
      "Epoch 00225: loss did not improve from 0.02326\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0237\n",
      "Epoch 226/5000\n",
      "\n",
      "Epoch 00226: loss did not improve from 0.02326\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0236\n",
      "Epoch 227/5000\n",
      "\n",
      "Epoch 00227: loss did not improve from 0.02326\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0238\n",
      "Epoch 228/5000\n",
      "\n",
      "Epoch 00228: loss did not improve from 0.02326\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0234\n",
      "Epoch 229/5000\n",
      "\n",
      "Epoch 00229: loss did not improve from 0.02326\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0233\n",
      "Epoch 230/5000\n",
      "\n",
      "Epoch 00230: loss did not improve from 0.02326\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0238\n",
      "Epoch 231/5000\n",
      "\n",
      "Epoch 00231: loss improved from 0.02326 to 0.02310, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0231\n",
      "Epoch 232/5000\n",
      "\n",
      "Epoch 00232: loss improved from 0.02310 to 0.02264, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0226\n",
      "Epoch 233/5000\n",
      "\n",
      "Epoch 00233: loss did not improve from 0.02264\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0230\n",
      "Epoch 234/5000\n",
      "\n",
      "Epoch 00234: loss did not improve from 0.02264\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0234\n",
      "Epoch 235/5000\n",
      "\n",
      "Epoch 00235: loss did not improve from 0.02264\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0233\n",
      "Epoch 236/5000\n",
      "\n",
      "Epoch 00236: loss did not improve from 0.02264\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0227\n",
      "Epoch 237/5000\n",
      "\n",
      "Epoch 00237: loss did not improve from 0.02264\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0227\n",
      "Epoch 238/5000\n",
      "\n",
      "Epoch 00238: loss did not improve from 0.02264\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0230\n",
      "Epoch 239/5000\n",
      "\n",
      "Epoch 00239: loss did not improve from 0.02264\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0227\n",
      "Epoch 240/5000\n",
      "\n",
      "Epoch 00240: loss did not improve from 0.02264\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0231\n",
      "Epoch 241/5000\n",
      "\n",
      "Epoch 00241: loss did not improve from 0.02264\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0228\n",
      "Epoch 242/5000\n",
      "\n",
      "Epoch 00242: loss improved from 0.02264 to 0.02221, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0222\n",
      "Epoch 243/5000\n",
      "\n",
      "Epoch 00243: loss improved from 0.02221 to 0.02192, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0219\n",
      "Epoch 244/5000\n",
      "\n",
      "Epoch 00244: loss did not improve from 0.02192\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0220\n",
      "Epoch 245/5000\n",
      "\n",
      "Epoch 00245: loss did not improve from 0.02192\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0228\n",
      "Epoch 246/5000\n",
      "\n",
      "Epoch 00246: loss did not improve from 0.02192\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0224\n",
      "Epoch 247/5000\n",
      "\n",
      "Epoch 00247: loss did not improve from 0.02192\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0222\n",
      "Epoch 248/5000\n",
      "\n",
      "Epoch 00248: loss did not improve from 0.02192\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0226\n",
      "Epoch 249/5000\n",
      "\n",
      "Epoch 00249: loss improved from 0.02192 to 0.02188, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0219\n",
      "Epoch 250/5000\n",
      "\n",
      "Epoch 00250: loss did not improve from 0.02188\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0221\n",
      "Epoch 251/5000\n",
      "\n",
      "Epoch 00251: loss improved from 0.02188 to 0.02143, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0214\n",
      "Epoch 252/5000\n",
      "\n",
      "Epoch 00252: loss did not improve from 0.02143\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0221\n",
      "Epoch 253/5000\n",
      "\n",
      "Epoch 00253: loss did not improve from 0.02143\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0223\n",
      "Epoch 254/5000\n",
      "\n",
      "Epoch 00254: loss did not improve from 0.02143\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0219\n",
      "Epoch 255/5000\n",
      "\n",
      "Epoch 00255: loss did not improve from 0.02143\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0218\n",
      "Epoch 256/5000\n",
      "\n",
      "Epoch 00256: loss did not improve from 0.02143\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0224\n",
      "Epoch 257/5000\n",
      "\n",
      "Epoch 00257: loss did not improve from 0.02143\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0221\n",
      "Epoch 258/5000\n",
      "\n",
      "Epoch 00258: loss did not improve from 0.02143\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0215\n",
      "Epoch 259/5000\n",
      "\n",
      "Epoch 00259: loss did not improve from 0.02143\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0221\n",
      "Epoch 260/5000\n",
      "\n",
      "Epoch 00260: loss improved from 0.02143 to 0.02140, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0214\n",
      "Epoch 261/5000\n",
      "\n",
      "Epoch 00261: loss did not improve from 0.02140\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0221\n",
      "Epoch 262/5000\n",
      "\n",
      "Epoch 00262: loss did not improve from 0.02140\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0217\n",
      "Epoch 263/5000\n",
      "\n",
      "Epoch 00263: loss did not improve from 0.02140\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0216\n",
      "Epoch 264/5000\n",
      "\n",
      "Epoch 00264: loss improved from 0.02140 to 0.02137, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0214\n",
      "Epoch 265/5000\n",
      "\n",
      "Epoch 00265: loss improved from 0.02137 to 0.02128, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0213\n",
      "Epoch 266/5000\n",
      "\n",
      "Epoch 00266: loss improved from 0.02128 to 0.02121, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0212\n",
      "Epoch 267/5000\n",
      "\n",
      "Epoch 00267: loss did not improve from 0.02121\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0212\n",
      "Epoch 268/5000\n",
      "\n",
      "Epoch 00268: loss did not improve from 0.02121\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0221\n",
      "Epoch 269/5000\n",
      "\n",
      "Epoch 00269: loss did not improve from 0.02121\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0216\n",
      "Epoch 270/5000\n",
      "\n",
      "Epoch 00270: loss did not improve from 0.02121\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/5000\n",
      "\n",
      "Epoch 00271: loss improved from 0.02121 to 0.02066, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0207\n",
      "Epoch 272/5000\n",
      "\n",
      "Epoch 00272: loss did not improve from 0.02066\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0215\n",
      "Epoch 273/5000\n",
      "\n",
      "Epoch 00273: loss did not improve from 0.02066\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0209\n",
      "Epoch 274/5000\n",
      "\n",
      "Epoch 00274: loss did not improve from 0.02066\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0214\n",
      "Epoch 275/5000\n",
      "\n",
      "Epoch 00275: loss improved from 0.02066 to 0.02055, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0206\n",
      "Epoch 276/5000\n",
      "\n",
      "Epoch 00276: loss did not improve from 0.02055\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0213\n",
      "Epoch 277/5000\n",
      "\n",
      "Epoch 00277: loss did not improve from 0.02055\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0206\n",
      "Epoch 278/5000\n",
      "\n",
      "Epoch 00278: loss did not improve from 0.02055\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0215\n",
      "Epoch 279/5000\n",
      "\n",
      "Epoch 00279: loss did not improve from 0.02055\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0208\n",
      "Epoch 280/5000\n",
      "\n",
      "Epoch 00280: loss did not improve from 0.02055\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0211\n",
      "Epoch 281/5000\n",
      "\n",
      "Epoch 00281: loss did not improve from 0.02055\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0211\n",
      "Epoch 282/5000\n",
      "\n",
      "Epoch 00282: loss improved from 0.02055 to 0.02047, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0205\n",
      "Epoch 283/5000\n",
      "\n",
      "Epoch 00283: loss did not improve from 0.02047\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0205\n",
      "Epoch 284/5000\n",
      "\n",
      "Epoch 00284: loss did not improve from 0.02047\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0207\n",
      "Epoch 285/5000\n",
      "\n",
      "Epoch 00285: loss did not improve from 0.02047\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0208\n",
      "Epoch 286/5000\n",
      "\n",
      "Epoch 00286: loss did not improve from 0.02047\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0213\n",
      "Epoch 287/5000\n",
      "\n",
      "Epoch 00287: loss did not improve from 0.02047\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0208\n",
      "Epoch 288/5000\n",
      "\n",
      "Epoch 00288: loss did not improve from 0.02047\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0208\n",
      "Epoch 289/5000\n",
      "\n",
      "Epoch 00289: loss did not improve from 0.02047\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0207\n",
      "Epoch 290/5000\n",
      "\n",
      "Epoch 00290: loss improved from 0.02047 to 0.02047, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0205\n",
      "Epoch 291/5000\n",
      "\n",
      "Epoch 00291: loss did not improve from 0.02047\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0205\n",
      "Epoch 292/5000\n",
      "\n",
      "Epoch 00292: loss did not improve from 0.02047\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0206\n",
      "Epoch 293/5000\n",
      "\n",
      "Epoch 00293: loss did not improve from 0.02047\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0207\n",
      "Epoch 294/5000\n",
      "\n",
      "Epoch 00294: loss improved from 0.02047 to 0.02008, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0201\n",
      "Epoch 295/5000\n",
      "\n",
      "Epoch 00295: loss improved from 0.02008 to 0.01998, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0200\n",
      "Epoch 296/5000\n",
      "\n",
      "Epoch 00296: loss did not improve from 0.01998\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0205\n",
      "Epoch 297/5000\n",
      "\n",
      "Epoch 00297: loss did not improve from 0.01998\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0203\n",
      "Epoch 298/5000\n",
      "\n",
      "Epoch 00298: loss did not improve from 0.01998\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0206\n",
      "Epoch 299/5000\n",
      "\n",
      "Epoch 00299: loss did not improve from 0.01998\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0205\n",
      "Epoch 300/5000\n",
      "\n",
      "Epoch 00300: loss did not improve from 0.01998\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0203\n",
      "Epoch 301/5000\n",
      "\n",
      "Epoch 00301: loss did not improve from 0.01998\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0205\n",
      "Epoch 302/5000\n",
      "\n",
      "Epoch 00302: loss did not improve from 0.01998\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0202\n",
      "Epoch 303/5000\n",
      "\n",
      "Epoch 00303: loss did not improve from 0.01998\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0202\n",
      "Epoch 304/5000\n",
      "\n",
      "Epoch 00304: loss did not improve from 0.01998\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0201\n",
      "Epoch 305/5000\n",
      "\n",
      "Epoch 00305: loss did not improve from 0.01998\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0205\n",
      "Epoch 306/5000\n",
      "\n",
      "Epoch 00306: loss did not improve from 0.01998\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0206\n",
      "Epoch 307/5000\n",
      "\n",
      "Epoch 00307: loss did not improve from 0.01998\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0200\n",
      "Epoch 308/5000\n",
      "\n",
      "Epoch 00308: loss did not improve from 0.01998\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0202\n",
      "Epoch 309/5000\n",
      "\n",
      "Epoch 00309: loss improved from 0.01998 to 0.01963, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0196\n",
      "Epoch 310/5000\n",
      "\n",
      "Epoch 00310: loss did not improve from 0.01963\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0203\n",
      "Epoch 311/5000\n",
      "\n",
      "Epoch 00311: loss did not improve from 0.01963\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0203\n",
      "Epoch 312/5000\n",
      "\n",
      "Epoch 00312: loss did not improve from 0.01963\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0198\n",
      "Epoch 313/5000\n",
      "\n",
      "Epoch 00313: loss did not improve from 0.01963\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0199\n",
      "Epoch 314/5000\n",
      "\n",
      "Epoch 00314: loss did not improve from 0.01963\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0201\n",
      "Epoch 315/5000\n",
      "\n",
      "Epoch 00315: loss did not improve from 0.01963\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0202\n",
      "Epoch 316/5000\n",
      "\n",
      "Epoch 00316: loss did not improve from 0.01963\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0201\n",
      "Epoch 317/5000\n",
      "\n",
      "Epoch 00317: loss did not improve from 0.01963\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0200\n",
      "Epoch 318/5000\n",
      "\n",
      "Epoch 00318: loss did not improve from 0.01963\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0201\n",
      "Epoch 319/5000\n",
      "\n",
      "Epoch 00319: loss did not improve from 0.01963\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0197\n",
      "Epoch 320/5000\n",
      "\n",
      "Epoch 00320: loss did not improve from 0.01963\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0198\n",
      "Epoch 321/5000\n",
      "\n",
      "Epoch 00321: loss improved from 0.01963 to 0.01963, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0196\n",
      "Epoch 322/5000\n",
      "\n",
      "Epoch 00322: loss did not improve from 0.01963\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0197\n",
      "Epoch 323/5000\n",
      "\n",
      "Epoch 00323: loss did not improve from 0.01963\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0197\n",
      "Epoch 324/5000\n",
      "\n",
      "Epoch 00324: loss improved from 0.01963 to 0.01935, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0194\n",
      "Epoch 325/5000\n",
      "\n",
      "Epoch 00325: loss did not improve from 0.01935\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0197\n",
      "Epoch 326/5000\n",
      "\n",
      "Epoch 00326: loss did not improve from 0.01935\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0198\n",
      "Epoch 327/5000\n",
      "\n",
      "Epoch 00327: loss did not improve from 0.01935\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0197\n",
      "Epoch 328/5000\n",
      "\n",
      "Epoch 00328: loss did not improve from 0.01935\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0199\n",
      "Epoch 329/5000\n",
      "\n",
      "Epoch 00329: loss improved from 0.01935 to 0.01933, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0193\n",
      "Epoch 330/5000\n",
      "\n",
      "Epoch 00330: loss did not improve from 0.01933\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/5000\n",
      "\n",
      "Epoch 00331: loss improved from 0.01933 to 0.01926, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0193\n",
      "Epoch 332/5000\n",
      "\n",
      "Epoch 00332: loss did not improve from 0.01926\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0201\n",
      "Epoch 333/5000\n",
      "\n",
      "Epoch 00333: loss improved from 0.01926 to 0.01926, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0193\n",
      "Epoch 334/5000\n",
      "\n",
      "Epoch 00334: loss did not improve from 0.01926\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0197\n",
      "Epoch 335/5000\n",
      "\n",
      "Epoch 00335: loss did not improve from 0.01926\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0196\n",
      "Epoch 336/5000\n",
      "\n",
      "Epoch 00336: loss improved from 0.01926 to 0.01904, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0190\n",
      "Epoch 337/5000\n",
      "\n",
      "Epoch 00337: loss improved from 0.01904 to 0.01884, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0188\n",
      "Epoch 338/5000\n",
      "\n",
      "Epoch 00338: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0196\n",
      "Epoch 339/5000\n",
      "\n",
      "Epoch 00339: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0196\n",
      "Epoch 340/5000\n",
      "\n",
      "Epoch 00340: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0196\n",
      "Epoch 341/5000\n",
      "\n",
      "Epoch 00341: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0193\n",
      "Epoch 342/5000\n",
      "\n",
      "Epoch 00342: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0193\n",
      "Epoch 343/5000\n",
      "\n",
      "Epoch 00343: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0192\n",
      "Epoch 344/5000\n",
      "\n",
      "Epoch 00344: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0190\n",
      "Epoch 345/5000\n",
      "\n",
      "Epoch 00345: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0192\n",
      "Epoch 346/5000\n",
      "\n",
      "Epoch 00346: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0191\n",
      "Epoch 347/5000\n",
      "\n",
      "Epoch 00347: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0195\n",
      "Epoch 348/5000\n",
      "\n",
      "Epoch 00348: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0192\n",
      "Epoch 349/5000\n",
      "\n",
      "Epoch 00349: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0192\n",
      "Epoch 350/5000\n",
      "\n",
      "Epoch 00350: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0190\n",
      "Epoch 351/5000\n",
      "\n",
      "Epoch 00351: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0189\n",
      "Epoch 352/5000\n",
      "\n",
      "Epoch 00352: loss did not improve from 0.01884\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0189\n",
      "Epoch 353/5000\n",
      "\n",
      "Epoch 00353: loss improved from 0.01884 to 0.01869, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0187\n",
      "Epoch 354/5000\n",
      "\n",
      "Epoch 00354: loss did not improve from 0.01869\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0191\n",
      "Epoch 355/5000\n",
      "\n",
      "Epoch 00355: loss did not improve from 0.01869\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0190\n",
      "Epoch 356/5000\n",
      "\n",
      "Epoch 00356: loss did not improve from 0.01869\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0190\n",
      "Epoch 357/5000\n",
      "\n",
      "Epoch 00357: loss did not improve from 0.01869\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0191\n",
      "Epoch 358/5000\n",
      "\n",
      "Epoch 00358: loss did not improve from 0.01869\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0189\n",
      "Epoch 359/5000\n",
      "\n",
      "Epoch 00359: loss improved from 0.01869 to 0.01867, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0187\n",
      "Epoch 360/5000\n",
      "\n",
      "Epoch 00360: loss did not improve from 0.01867\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0189\n",
      "Epoch 361/5000\n",
      "\n",
      "Epoch 00361: loss did not improve from 0.01867\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0189\n",
      "Epoch 362/5000\n",
      "\n",
      "Epoch 00362: loss did not improve from 0.01867\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0188\n",
      "Epoch 363/5000\n",
      "\n",
      "Epoch 00363: loss improved from 0.01867 to 0.01857, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0186\n",
      "Epoch 364/5000\n",
      "\n",
      "Epoch 00364: loss did not improve from 0.01857\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0188\n",
      "Epoch 365/5000\n",
      "\n",
      "Epoch 00365: loss did not improve from 0.01857\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0188\n",
      "Epoch 366/5000\n",
      "\n",
      "Epoch 00366: loss did not improve from 0.01857\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0186\n",
      "Epoch 367/5000\n",
      "\n",
      "Epoch 00367: loss did not improve from 0.01857\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0188\n",
      "Epoch 368/5000\n",
      "\n",
      "Epoch 00368: loss did not improve from 0.01857\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0188\n",
      "Epoch 369/5000\n",
      "\n",
      "Epoch 00369: loss did not improve from 0.01857\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0187\n",
      "Epoch 370/5000\n",
      "\n",
      "Epoch 00370: loss did not improve from 0.01857\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0186\n",
      "Epoch 371/5000\n",
      "\n",
      "Epoch 00371: loss did not improve from 0.01857\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0191\n",
      "Epoch 372/5000\n",
      "\n",
      "Epoch 00372: loss improved from 0.01857 to 0.01836, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0184\n",
      "Epoch 373/5000\n",
      "\n",
      "Epoch 00373: loss did not improve from 0.01836\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0186\n",
      "Epoch 374/5000\n",
      "\n",
      "Epoch 00374: loss did not improve from 0.01836\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0186\n",
      "Epoch 375/5000\n",
      "\n",
      "Epoch 00375: loss did not improve from 0.01836\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0186\n",
      "Epoch 376/5000\n",
      "\n",
      "Epoch 00376: loss did not improve from 0.01836\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0189\n",
      "Epoch 377/5000\n",
      "\n",
      "Epoch 00377: loss did not improve from 0.01836\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0184\n",
      "Epoch 378/5000\n",
      "\n",
      "Epoch 00378: loss did not improve from 0.01836\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0185\n",
      "Epoch 379/5000\n",
      "\n",
      "Epoch 00379: loss did not improve from 0.01836\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0190\n",
      "Epoch 380/5000\n",
      "\n",
      "Epoch 00380: loss did not improve from 0.01836\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0186\n",
      "Epoch 381/5000\n",
      "\n",
      "Epoch 00381: loss did not improve from 0.01836\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0186\n",
      "Epoch 382/5000\n",
      "\n",
      "Epoch 00382: loss did not improve from 0.01836\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0184\n",
      "Epoch 383/5000\n",
      "\n",
      "Epoch 00383: loss improved from 0.01836 to 0.01799, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0180\n",
      "Epoch 384/5000\n",
      "\n",
      "Epoch 00384: loss did not improve from 0.01799\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0182\n",
      "Epoch 385/5000\n",
      "\n",
      "Epoch 00385: loss did not improve from 0.01799\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0186\n",
      "Epoch 386/5000\n",
      "\n",
      "Epoch 00386: loss did not improve from 0.01799\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0184\n",
      "Epoch 387/5000\n",
      "\n",
      "Epoch 00387: loss did not improve from 0.01799\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0182\n",
      "Epoch 388/5000\n",
      "\n",
      "Epoch 00388: loss did not improve from 0.01799\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0185\n",
      "Epoch 389/5000\n",
      "\n",
      "Epoch 00389: loss did not improve from 0.01799\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0182\n",
      "Epoch 390/5000\n",
      "\n",
      "Epoch 00390: loss did not improve from 0.01799\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/5000\n",
      "\n",
      "Epoch 00391: loss did not improve from 0.01799\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0184\n",
      "Epoch 392/5000\n",
      "\n",
      "Epoch 00392: loss did not improve from 0.01799\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0182\n",
      "Epoch 393/5000\n",
      "\n",
      "Epoch 00393: loss did not improve from 0.01799\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0183\n",
      "Epoch 394/5000\n",
      "\n",
      "Epoch 00394: loss did not improve from 0.01799\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0183\n",
      "Epoch 395/5000\n",
      "\n",
      "Epoch 00395: loss improved from 0.01799 to 0.01769, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0177\n",
      "Epoch 396/5000\n",
      "\n",
      "Epoch 00396: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0182\n",
      "Epoch 397/5000\n",
      "\n",
      "Epoch 00397: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0183\n",
      "Epoch 398/5000\n",
      "\n",
      "Epoch 00398: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0186\n",
      "Epoch 399/5000\n",
      "\n",
      "Epoch 00399: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0181\n",
      "Epoch 400/5000\n",
      "\n",
      "Epoch 00400: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0178\n",
      "Epoch 401/5000\n",
      "\n",
      "Epoch 00401: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0182\n",
      "Epoch 402/5000\n",
      "\n",
      "Epoch 00402: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0183\n",
      "Epoch 403/5000\n",
      "\n",
      "Epoch 00403: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0182\n",
      "Epoch 404/5000\n",
      "\n",
      "Epoch 00404: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0185\n",
      "Epoch 405/5000\n",
      "\n",
      "Epoch 00405: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0183\n",
      "Epoch 406/5000\n",
      "\n",
      "Epoch 00406: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0182\n",
      "Epoch 407/5000\n",
      "\n",
      "Epoch 00407: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0179\n",
      "Epoch 408/5000\n",
      "\n",
      "Epoch 00408: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0182\n",
      "Epoch 409/5000\n",
      "\n",
      "Epoch 00409: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0182\n",
      "Epoch 410/5000\n",
      "\n",
      "Epoch 00410: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0183\n",
      "Epoch 411/5000\n",
      "\n",
      "Epoch 00411: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0180\n",
      "Epoch 412/5000\n",
      "\n",
      "Epoch 00412: loss improved from 0.01769 to 0.01769, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0177\n",
      "Epoch 413/5000\n",
      "\n",
      "Epoch 00413: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0177\n",
      "Epoch 414/5000\n",
      "\n",
      "Epoch 00414: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0178\n",
      "Epoch 415/5000\n",
      "\n",
      "Epoch 00415: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0181\n",
      "Epoch 416/5000\n",
      "\n",
      "Epoch 00416: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0179\n",
      "Epoch 417/5000\n",
      "\n",
      "Epoch 00417: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0186\n",
      "Epoch 418/5000\n",
      "\n",
      "Epoch 00418: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0180\n",
      "Epoch 419/5000\n",
      "\n",
      "Epoch 00419: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0177\n",
      "Epoch 420/5000\n",
      "\n",
      "Epoch 00420: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0178\n",
      "Epoch 421/5000\n",
      "\n",
      "Epoch 00421: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0183\n",
      "Epoch 422/5000\n",
      "\n",
      "Epoch 00422: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0182\n",
      "Epoch 423/5000\n",
      "\n",
      "Epoch 00423: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0179\n",
      "Epoch 424/5000\n",
      "\n",
      "Epoch 00424: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0177\n",
      "Epoch 425/5000\n",
      "\n",
      "Epoch 00425: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0180\n",
      "Epoch 426/5000\n",
      "\n",
      "Epoch 00426: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0182\n",
      "Epoch 427/5000\n",
      "\n",
      "Epoch 00427: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0178\n",
      "Epoch 428/5000\n",
      "\n",
      "Epoch 00428: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0177\n",
      "Epoch 429/5000\n",
      "\n",
      "Epoch 00429: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0181\n",
      "Epoch 430/5000\n",
      "\n",
      "Epoch 00430: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0179\n",
      "Epoch 431/5000\n",
      "\n",
      "Epoch 00431: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0178\n",
      "Epoch 432/5000\n",
      "\n",
      "Epoch 00432: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0180\n",
      "Epoch 433/5000\n",
      "\n",
      "Epoch 00433: loss did not improve from 0.01769\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0179\n",
      "Epoch 434/5000\n",
      "\n",
      "Epoch 00434: loss improved from 0.01769 to 0.01727, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 8ms/sample - loss: 0.0173\n",
      "Epoch 435/5000\n",
      "\n",
      "Epoch 00435: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0181\n",
      "Epoch 436/5000\n",
      "\n",
      "Epoch 00436: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0177\n",
      "Epoch 437/5000\n",
      "\n",
      "Epoch 00437: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0178\n",
      "Epoch 438/5000\n",
      "\n",
      "Epoch 00438: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0176\n",
      "Epoch 439/5000\n",
      "\n",
      "Epoch 00439: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0176\n",
      "Epoch 440/5000\n",
      "\n",
      "Epoch 00440: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0177\n",
      "Epoch 441/5000\n",
      "\n",
      "Epoch 00441: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0177\n",
      "Epoch 442/5000\n",
      "\n",
      "Epoch 00442: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0173\n",
      "Epoch 443/5000\n",
      "\n",
      "Epoch 00443: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0176\n",
      "Epoch 444/5000\n",
      "\n",
      "Epoch 00444: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0177\n",
      "Epoch 445/5000\n",
      "\n",
      "Epoch 00445: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0176\n",
      "Epoch 446/5000\n",
      "\n",
      "Epoch 00446: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0176\n",
      "Epoch 447/5000\n",
      "\n",
      "Epoch 00447: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0178\n",
      "Epoch 448/5000\n",
      "\n",
      "Epoch 00448: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0174\n",
      "Epoch 449/5000\n",
      "\n",
      "Epoch 00449: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0175\n",
      "Epoch 450/5000\n",
      "\n",
      "Epoch 00450: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0175\n",
      "Epoch 451/5000\n",
      "\n",
      "Epoch 00451: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452/5000\n",
      "\n",
      "Epoch 00452: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0175\n",
      "Epoch 453/5000\n",
      "\n",
      "Epoch 00453: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0173\n",
      "Epoch 454/5000\n",
      "\n",
      "Epoch 00454: loss did not improve from 0.01727\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0174\n",
      "Epoch 455/5000\n",
      "\n",
      "Epoch 00455: loss improved from 0.01727 to 0.01715, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0172\n",
      "Epoch 456/5000\n",
      "\n",
      "Epoch 00456: loss did not improve from 0.01715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0175\n",
      "Epoch 457/5000\n",
      "\n",
      "Epoch 00457: loss did not improve from 0.01715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0173\n",
      "Epoch 458/5000\n",
      "\n",
      "Epoch 00458: loss did not improve from 0.01715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0175\n",
      "Epoch 459/5000\n",
      "\n",
      "Epoch 00459: loss improved from 0.01715 to 0.01702, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0170\n",
      "Epoch 460/5000\n",
      "\n",
      "Epoch 00460: loss did not improve from 0.01702\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0179\n",
      "Epoch 461/5000\n",
      "\n",
      "Epoch 00461: loss did not improve from 0.01702\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0176\n",
      "Epoch 462/5000\n",
      "\n",
      "Epoch 00462: loss did not improve from 0.01702\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0173\n",
      "Epoch 463/5000\n",
      "\n",
      "Epoch 00463: loss did not improve from 0.01702\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0173\n",
      "Epoch 464/5000\n",
      "\n",
      "Epoch 00464: loss improved from 0.01702 to 0.01702, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0170\n",
      "Epoch 465/5000\n",
      "\n",
      "Epoch 00465: loss did not improve from 0.01702\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0174\n",
      "Epoch 466/5000\n",
      "\n",
      "Epoch 00466: loss did not improve from 0.01702\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0174\n",
      "Epoch 467/5000\n",
      "\n",
      "Epoch 00467: loss did not improve from 0.01702\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0171\n",
      "Epoch 468/5000\n",
      "\n",
      "Epoch 00468: loss did not improve from 0.01702\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0173\n",
      "Epoch 469/5000\n",
      "\n",
      "Epoch 00469: loss did not improve from 0.01702\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0173\n",
      "Epoch 470/5000\n",
      "\n",
      "Epoch 00470: loss did not improve from 0.01702\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0171\n",
      "Epoch 471/5000\n",
      "\n",
      "Epoch 00471: loss improved from 0.01702 to 0.01694, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0169\n",
      "Epoch 472/5000\n",
      "\n",
      "Epoch 00472: loss improved from 0.01694 to 0.01683, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0168\n",
      "Epoch 473/5000\n",
      "\n",
      "Epoch 00473: loss did not improve from 0.01683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 474/5000\n",
      "\n",
      "Epoch 00474: loss did not improve from 0.01683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0172\n",
      "Epoch 475/5000\n",
      "\n",
      "Epoch 00475: loss did not improve from 0.01683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0173\n",
      "Epoch 476/5000\n",
      "\n",
      "Epoch 00476: loss did not improve from 0.01683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 477/5000\n",
      "\n",
      "Epoch 00477: loss did not improve from 0.01683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0171\n",
      "Epoch 478/5000\n",
      "\n",
      "Epoch 00478: loss did not improve from 0.01683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 479/5000\n",
      "\n",
      "Epoch 00479: loss did not improve from 0.01683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0168\n",
      "Epoch 480/5000\n",
      "\n",
      "Epoch 00480: loss did not improve from 0.01683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0173\n",
      "Epoch 481/5000\n",
      "\n",
      "Epoch 00481: loss improved from 0.01683 to 0.01681, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0168\n",
      "Epoch 482/5000\n",
      "\n",
      "Epoch 00482: loss did not improve from 0.01681\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0172\n",
      "Epoch 483/5000\n",
      "\n",
      "Epoch 00483: loss did not improve from 0.01681\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0172\n",
      "Epoch 484/5000\n",
      "\n",
      "Epoch 00484: loss did not improve from 0.01681\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0171\n",
      "Epoch 485/5000\n",
      "\n",
      "Epoch 00485: loss did not improve from 0.01681\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0173\n",
      "Epoch 486/5000\n",
      "\n",
      "Epoch 00486: loss did not improve from 0.01681\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0174\n",
      "Epoch 487/5000\n",
      "\n",
      "Epoch 00487: loss improved from 0.01681 to 0.01679, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0168\n",
      "Epoch 488/5000\n",
      "\n",
      "Epoch 00488: loss did not improve from 0.01679\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0172\n",
      "Epoch 489/5000\n",
      "\n",
      "Epoch 00489: loss did not improve from 0.01679\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0171\n",
      "Epoch 490/5000\n",
      "\n",
      "Epoch 00490: loss did not improve from 0.01679\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0171\n",
      "Epoch 491/5000\n",
      "\n",
      "Epoch 00491: loss did not improve from 0.01679\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0173\n",
      "Epoch 492/5000\n",
      "\n",
      "Epoch 00492: loss did not improve from 0.01679\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0170\n",
      "Epoch 493/5000\n",
      "\n",
      "Epoch 00493: loss did not improve from 0.01679\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0170\n",
      "Epoch 494/5000\n",
      "\n",
      "Epoch 00494: loss did not improve from 0.01679\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0172\n",
      "Epoch 495/5000\n",
      "\n",
      "Epoch 00495: loss did not improve from 0.01679\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 496/5000\n",
      "\n",
      "Epoch 00496: loss did not improve from 0.01679\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0172\n",
      "Epoch 497/5000\n",
      "\n",
      "Epoch 00497: loss did not improve from 0.01679\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0170\n",
      "Epoch 498/5000\n",
      "\n",
      "Epoch 00498: loss did not improve from 0.01679\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0170\n",
      "Epoch 499/5000\n",
      "\n",
      "Epoch 00499: loss did not improve from 0.01679\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0170\n",
      "Epoch 500/5000\n",
      "\n",
      "Epoch 00500: loss did not improve from 0.01679\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 501/5000\n",
      "\n",
      "Epoch 00501: loss improved from 0.01679 to 0.01657, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0166\n",
      "Epoch 502/5000\n",
      "\n",
      "Epoch 00502: loss did not improve from 0.01657\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 503/5000\n",
      "\n",
      "Epoch 00503: loss did not improve from 0.01657\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 504/5000\n",
      "\n",
      "Epoch 00504: loss did not improve from 0.01657\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 505/5000\n",
      "\n",
      "Epoch 00505: loss did not improve from 0.01657\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0170\n",
      "Epoch 506/5000\n",
      "\n",
      "Epoch 00506: loss did not improve from 0.01657\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0166\n",
      "Epoch 507/5000\n",
      "\n",
      "Epoch 00507: loss did not improve from 0.01657\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0172\n",
      "Epoch 508/5000\n",
      "\n",
      "Epoch 00508: loss improved from 0.01657 to 0.01656, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0166\n",
      "Epoch 509/5000\n",
      "\n",
      "Epoch 00509: loss did not improve from 0.01656\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 510/5000\n",
      "\n",
      "Epoch 00510: loss did not improve from 0.01656\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 511/5000\n",
      "\n",
      "Epoch 00511: loss did not improve from 0.01656\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512/5000\n",
      "\n",
      "Epoch 00512: loss did not improve from 0.01656\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0170\n",
      "Epoch 513/5000\n",
      "\n",
      "Epoch 00513: loss did not improve from 0.01656\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0166\n",
      "Epoch 514/5000\n",
      "\n",
      "Epoch 00514: loss did not improve from 0.01656\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 515/5000\n",
      "\n",
      "Epoch 00515: loss improved from 0.01656 to 0.01656, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0166\n",
      "Epoch 516/5000\n",
      "\n",
      "Epoch 00516: loss did not improve from 0.01656\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0170\n",
      "Epoch 517/5000\n",
      "\n",
      "Epoch 00517: loss did not improve from 0.01656\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0168\n",
      "Epoch 518/5000\n",
      "\n",
      "Epoch 00518: loss did not improve from 0.01656\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0166\n",
      "Epoch 519/5000\n",
      "\n",
      "Epoch 00519: loss did not improve from 0.01656\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0168\n",
      "Epoch 520/5000\n",
      "\n",
      "Epoch 00520: loss did not improve from 0.01656\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0166\n",
      "Epoch 521/5000\n",
      "\n",
      "Epoch 00521: loss did not improve from 0.01656\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0166\n",
      "Epoch 522/5000\n",
      "\n",
      "Epoch 00522: loss improved from 0.01656 to 0.01653, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0165\n",
      "Epoch 523/5000\n",
      "\n",
      "Epoch 00523: loss did not improve from 0.01653\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0170\n",
      "Epoch 524/5000\n",
      "\n",
      "Epoch 00524: loss improved from 0.01653 to 0.01640, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0164\n",
      "Epoch 525/5000\n",
      "\n",
      "Epoch 00525: loss improved from 0.01640 to 0.01633, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0163\n",
      "Epoch 526/5000\n",
      "\n",
      "Epoch 00526: loss did not improve from 0.01633\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0168\n",
      "Epoch 527/5000\n",
      "\n",
      "Epoch 00527: loss did not improve from 0.01633\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0166\n",
      "Epoch 528/5000\n",
      "\n",
      "Epoch 00528: loss did not improve from 0.01633\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0167\n",
      "Epoch 529/5000\n",
      "\n",
      "Epoch 00529: loss did not improve from 0.01633\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0167\n",
      "Epoch 530/5000\n",
      "\n",
      "Epoch 00530: loss did not improve from 0.01633\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 531/5000\n",
      "\n",
      "Epoch 00531: loss did not improve from 0.01633\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0167\n",
      "Epoch 532/5000\n",
      "\n",
      "Epoch 00532: loss improved from 0.01633 to 0.01627, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0163\n",
      "Epoch 533/5000\n",
      "\n",
      "Epoch 00533: loss did not improve from 0.01627\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0168\n",
      "Epoch 534/5000\n",
      "\n",
      "Epoch 00534: loss did not improve from 0.01627\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0164\n",
      "Epoch 535/5000\n",
      "\n",
      "Epoch 00535: loss did not improve from 0.01627\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0165\n",
      "Epoch 536/5000\n",
      "\n",
      "Epoch 00536: loss did not improve from 0.01627\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0166\n",
      "Epoch 537/5000\n",
      "\n",
      "Epoch 00537: loss did not improve from 0.01627\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0167\n",
      "Epoch 538/5000\n",
      "\n",
      "Epoch 00538: loss did not improve from 0.01627\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0167\n",
      "Epoch 539/5000\n",
      "\n",
      "Epoch 00539: loss did not improve from 0.01627\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0164\n",
      "Epoch 540/5000\n",
      "\n",
      "Epoch 00540: loss did not improve from 0.01627\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0166\n",
      "Epoch 541/5000\n",
      "\n",
      "Epoch 00541: loss improved from 0.01627 to 0.01619, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0162\n",
      "Epoch 542/5000\n",
      "\n",
      "Epoch 00542: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0165\n",
      "Epoch 543/5000\n",
      "\n",
      "Epoch 00543: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 544/5000\n",
      "\n",
      "Epoch 00544: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0165\n",
      "Epoch 545/5000\n",
      "\n",
      "Epoch 00545: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 546/5000\n",
      "\n",
      "Epoch 00546: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0162\n",
      "Epoch 547/5000\n",
      "\n",
      "Epoch 00547: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 548/5000\n",
      "\n",
      "Epoch 00548: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0162\n",
      "Epoch 549/5000\n",
      "\n",
      "Epoch 00549: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 550/5000\n",
      "\n",
      "Epoch 00550: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0162\n",
      "Epoch 551/5000\n",
      "\n",
      "Epoch 00551: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0164\n",
      "Epoch 552/5000\n",
      "\n",
      "Epoch 00552: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 553/5000\n",
      "\n",
      "Epoch 00553: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 554/5000\n",
      "\n",
      "Epoch 00554: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0164\n",
      "Epoch 555/5000\n",
      "\n",
      "Epoch 00555: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0162\n",
      "Epoch 556/5000\n",
      "\n",
      "Epoch 00556: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0164\n",
      "Epoch 557/5000\n",
      "\n",
      "Epoch 00557: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0163\n",
      "Epoch 558/5000\n",
      "\n",
      "Epoch 00558: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0164\n",
      "Epoch 559/5000\n",
      "\n",
      "Epoch 00559: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0162\n",
      "Epoch 560/5000\n",
      "\n",
      "Epoch 00560: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0164\n",
      "Epoch 561/5000\n",
      "\n",
      "Epoch 00561: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0164\n",
      "Epoch 562/5000\n",
      "\n",
      "Epoch 00562: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0166\n",
      "Epoch 563/5000\n",
      "\n",
      "Epoch 00563: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 564/5000\n",
      "\n",
      "Epoch 00564: loss did not improve from 0.01619\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0167\n",
      "Epoch 565/5000\n",
      "\n",
      "Epoch 00565: loss improved from 0.01619 to 0.01593, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0159\n",
      "Epoch 566/5000\n",
      "\n",
      "Epoch 00566: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 567/5000\n",
      "\n",
      "Epoch 00567: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 568/5000\n",
      "\n",
      "Epoch 00568: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 569/5000\n",
      "\n",
      "Epoch 00569: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 570/5000\n",
      "\n",
      "Epoch 00570: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0165\n",
      "Epoch 571/5000\n",
      "\n",
      "Epoch 00571: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 572/5000\n",
      "\n",
      "Epoch 00572: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 573/5000\n",
      "\n",
      "Epoch 00573: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0164\n",
      "Epoch 574/5000\n",
      "\n",
      "Epoch 00574: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 575/5000\n",
      "\n",
      "Epoch 00575: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0162\n",
      "Epoch 576/5000\n",
      "\n",
      "Epoch 00576: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 577/5000\n",
      "\n",
      "Epoch 00577: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 578/5000\n",
      "\n",
      "Epoch 00578: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0162\n",
      "Epoch 579/5000\n",
      "\n",
      "Epoch 00579: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 580/5000\n",
      "\n",
      "Epoch 00580: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 581/5000\n",
      "\n",
      "Epoch 00581: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 582/5000\n",
      "\n",
      "Epoch 00582: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 583/5000\n",
      "\n",
      "Epoch 00583: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 584/5000\n",
      "\n",
      "Epoch 00584: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 585/5000\n",
      "\n",
      "Epoch 00585: loss did not improve from 0.01593\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 586/5000\n",
      "\n",
      "Epoch 00586: loss improved from 0.01593 to 0.01591, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0159\n",
      "Epoch 587/5000\n",
      "\n",
      "Epoch 00587: loss did not improve from 0.01591\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 588/5000\n",
      "\n",
      "Epoch 00588: loss improved from 0.01591 to 0.01583, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0158\n",
      "Epoch 589/5000\n",
      "\n",
      "Epoch 00589: loss did not improve from 0.01583\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 590/5000\n",
      "\n",
      "Epoch 00590: loss did not improve from 0.01583\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 591/5000\n",
      "\n",
      "Epoch 00591: loss did not improve from 0.01583\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 592/5000\n",
      "\n",
      "Epoch 00592: loss did not improve from 0.01583\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 593/5000\n",
      "\n",
      "Epoch 00593: loss did not improve from 0.01583\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 594/5000\n",
      "\n",
      "Epoch 00594: loss did not improve from 0.01583\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 595/5000\n",
      "\n",
      "Epoch 00595: loss did not improve from 0.01583\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 596/5000\n",
      "\n",
      "Epoch 00596: loss did not improve from 0.01583\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 597/5000\n",
      "\n",
      "Epoch 00597: loss did not improve from 0.01583\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0162\n",
      "Epoch 598/5000\n",
      "\n",
      "Epoch 00598: loss did not improve from 0.01583\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 599/5000\n",
      "\n",
      "Epoch 00599: loss did not improve from 0.01583\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 600/5000\n",
      "\n",
      "Epoch 00600: loss did not improve from 0.01583\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 601/5000\n",
      "\n",
      "Epoch 00601: loss improved from 0.01583 to 0.01569, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0157\n",
      "Epoch 602/5000\n",
      "\n",
      "Epoch 00602: loss did not improve from 0.01569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 603/5000\n",
      "\n",
      "Epoch 00603: loss did not improve from 0.01569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 604/5000\n",
      "\n",
      "Epoch 00604: loss did not improve from 0.01569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0157\n",
      "Epoch 605/5000\n",
      "\n",
      "Epoch 00605: loss did not improve from 0.01569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0157\n",
      "Epoch 606/5000\n",
      "\n",
      "Epoch 00606: loss did not improve from 0.01569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 607/5000\n",
      "\n",
      "Epoch 00607: loss did not improve from 0.01569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 608/5000\n",
      "\n",
      "Epoch 00608: loss did not improve from 0.01569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 609/5000\n",
      "\n",
      "Epoch 00609: loss did not improve from 0.01569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 610/5000\n",
      "\n",
      "Epoch 00610: loss did not improve from 0.01569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 611/5000\n",
      "\n",
      "Epoch 00611: loss did not improve from 0.01569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 612/5000\n",
      "\n",
      "Epoch 00612: loss did not improve from 0.01569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 613/5000\n",
      "\n",
      "Epoch 00613: loss did not improve from 0.01569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 614/5000\n",
      "\n",
      "Epoch 00614: loss improved from 0.01569 to 0.01556, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0156\n",
      "Epoch 615/5000\n",
      "\n",
      "Epoch 00615: loss did not improve from 0.01556\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 616/5000\n",
      "\n",
      "Epoch 00616: loss did not improve from 0.01556\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 617/5000\n",
      "\n",
      "Epoch 00617: loss improved from 0.01556 to 0.01554, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0155\n",
      "Epoch 618/5000\n",
      "\n",
      "Epoch 00618: loss did not improve from 0.01554\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0162\n",
      "Epoch 619/5000\n",
      "\n",
      "Epoch 00619: loss did not improve from 0.01554\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 620/5000\n",
      "\n",
      "Epoch 00620: loss did not improve from 0.01554\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 621/5000\n",
      "\n",
      "Epoch 00621: loss did not improve from 0.01554\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0161\n",
      "Epoch 622/5000\n",
      "\n",
      "Epoch 00622: loss did not improve from 0.01554\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 623/5000\n",
      "\n",
      "Epoch 00623: loss did not improve from 0.01554\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0157\n",
      "Epoch 624/5000\n",
      "\n",
      "Epoch 00624: loss did not improve from 0.01554\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 625/5000\n",
      "\n",
      "Epoch 00625: loss did not improve from 0.01554\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 626/5000\n",
      "\n",
      "Epoch 00626: loss did not improve from 0.01554\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 627/5000\n",
      "\n",
      "Epoch 00627: loss did not improve from 0.01554\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0160\n",
      "Epoch 628/5000\n",
      "\n",
      "Epoch 00628: loss improved from 0.01554 to 0.01551, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0155\n",
      "Epoch 629/5000\n",
      "\n",
      "Epoch 00629: loss improved from 0.01551 to 0.01551, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0155\n",
      "Epoch 630/5000\n",
      "\n",
      "Epoch 00630: loss did not improve from 0.01551\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0157\n",
      "Epoch 631/5000\n",
      "\n",
      "Epoch 00631: loss did not improve from 0.01551\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 632/5000\n",
      "\n",
      "Epoch 00632: loss did not improve from 0.01551\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 633/5000\n",
      "\n",
      "Epoch 00633: loss did not improve from 0.01551\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 634/5000\n",
      "\n",
      "Epoch 00634: loss did not improve from 0.01551\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0161\n",
      "Epoch 635/5000\n",
      "\n",
      "Epoch 00635: loss did not improve from 0.01551\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 636/5000\n",
      "\n",
      "Epoch 00636: loss improved from 0.01551 to 0.01548, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0155\n",
      "Epoch 637/5000\n",
      "\n",
      "Epoch 00637: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0157\n",
      "Epoch 638/5000\n",
      "\n",
      "Epoch 00638: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0158\n",
      "Epoch 639/5000\n",
      "\n",
      "Epoch 00639: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0158\n",
      "Epoch 640/5000\n",
      "\n",
      "Epoch 00640: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 641/5000\n",
      "\n",
      "Epoch 00641: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0157\n",
      "Epoch 642/5000\n",
      "\n",
      "Epoch 00642: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0158\n",
      "Epoch 643/5000\n",
      "\n",
      "Epoch 00643: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0157\n",
      "Epoch 644/5000\n",
      "\n",
      "Epoch 00644: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 645/5000\n",
      "\n",
      "Epoch 00645: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0158\n",
      "Epoch 646/5000\n",
      "\n",
      "Epoch 00646: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 647/5000\n",
      "\n",
      "Epoch 00647: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 648/5000\n",
      "\n",
      "Epoch 00648: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 649/5000\n",
      "\n",
      "Epoch 00649: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0157\n",
      "Epoch 650/5000\n",
      "\n",
      "Epoch 00650: loss did not improve from 0.01548\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0158\n",
      "Epoch 651/5000\n",
      "\n",
      "Epoch 00651: loss improved from 0.01548 to 0.01545, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0154\n",
      "Epoch 652/5000\n",
      "\n",
      "Epoch 00652: loss did not improve from 0.01545\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0158\n",
      "Epoch 653/5000\n",
      "\n",
      "Epoch 00653: loss did not improve from 0.01545\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 654/5000\n",
      "\n",
      "Epoch 00654: loss did not improve from 0.01545\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 655/5000\n",
      "\n",
      "Epoch 00655: loss did not improve from 0.01545\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 656/5000\n",
      "\n",
      "Epoch 00656: loss improved from 0.01545 to 0.01526, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0153\n",
      "Epoch 657/5000\n",
      "\n",
      "Epoch 00657: loss did not improve from 0.01526\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0158\n",
      "Epoch 658/5000\n",
      "\n",
      "Epoch 00658: loss did not improve from 0.01526\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 659/5000\n",
      "\n",
      "Epoch 00659: loss did not improve from 0.01526\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 660/5000\n",
      "\n",
      "Epoch 00660: loss did not improve from 0.01526\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 661/5000\n",
      "\n",
      "Epoch 00661: loss did not improve from 0.01526\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0157\n",
      "Epoch 662/5000\n",
      "\n",
      "Epoch 00662: loss did not improve from 0.01526\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 663/5000\n",
      "\n",
      "Epoch 00663: loss did not improve from 0.01526\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 664/5000\n",
      "\n",
      "Epoch 00664: loss did not improve from 0.01526\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0157\n",
      "Epoch 665/5000\n",
      "\n",
      "Epoch 00665: loss did not improve from 0.01526\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0158\n",
      "Epoch 666/5000\n",
      "\n",
      "Epoch 00666: loss did not improve from 0.01526\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 667/5000\n",
      "\n",
      "Epoch 00667: loss improved from 0.01526 to 0.01524, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0152\n",
      "Epoch 668/5000\n",
      "\n",
      "Epoch 00668: loss did not improve from 0.01524\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 669/5000\n",
      "\n",
      "Epoch 00669: loss did not improve from 0.01524\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 670/5000\n",
      "\n",
      "Epoch 00670: loss did not improve from 0.01524\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 671/5000\n",
      "\n",
      "Epoch 00671: loss did not improve from 0.01524\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 672/5000\n",
      "\n",
      "Epoch 00672: loss did not improve from 0.01524\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 673/5000\n",
      "\n",
      "Epoch 00673: loss did not improve from 0.01524\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 674/5000\n",
      "\n",
      "Epoch 00674: loss did not improve from 0.01524\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 675/5000\n",
      "\n",
      "Epoch 00675: loss did not improve from 0.01524\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 676/5000\n",
      "\n",
      "Epoch 00676: loss did not improve from 0.01524\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 677/5000\n",
      "\n",
      "Epoch 00677: loss improved from 0.01524 to 0.01517, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0152\n",
      "Epoch 678/5000\n",
      "\n",
      "Epoch 00678: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 679/5000\n",
      "\n",
      "Epoch 00679: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0157\n",
      "Epoch 680/5000\n",
      "\n",
      "Epoch 00680: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 681/5000\n",
      "\n",
      "Epoch 00681: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 682/5000\n",
      "\n",
      "Epoch 00682: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0155\n",
      "Epoch 683/5000\n",
      "\n",
      "Epoch 00683: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 684/5000\n",
      "\n",
      "Epoch 00684: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0159\n",
      "Epoch 685/5000\n",
      "\n",
      "Epoch 00685: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 686/5000\n",
      "\n",
      "Epoch 00686: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 687/5000\n",
      "\n",
      "Epoch 00687: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0157\n",
      "Epoch 688/5000\n",
      "\n",
      "Epoch 00688: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 689/5000\n",
      "\n",
      "Epoch 00689: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 690/5000\n",
      "\n",
      "Epoch 00690: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 691/5000\n",
      "\n",
      "Epoch 00691: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 692/5000\n",
      "\n",
      "Epoch 00692: loss did not improve from 0.01517\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 693/5000\n",
      "\n",
      "Epoch 00693: loss improved from 0.01517 to 0.01515, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0152\n",
      "Epoch 694/5000\n",
      "\n",
      "Epoch 00694: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 695/5000\n",
      "\n",
      "Epoch 00695: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 696/5000\n",
      "\n",
      "Epoch 00696: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 697/5000\n",
      "\n",
      "Epoch 00697: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 698/5000\n",
      "\n",
      "Epoch 00698: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0158\n",
      "Epoch 699/5000\n",
      "\n",
      "Epoch 00699: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 700/5000\n",
      "\n",
      "Epoch 00700: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 701/5000\n",
      "\n",
      "Epoch 00701: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 702/5000\n",
      "\n",
      "Epoch 00702: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 703/5000\n",
      "\n",
      "Epoch 00703: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 704/5000\n",
      "\n",
      "Epoch 00704: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 705/5000\n",
      "\n",
      "Epoch 00705: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 706/5000\n",
      "\n",
      "Epoch 00706: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 707/5000\n",
      "\n",
      "Epoch 00707: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 708/5000\n",
      "\n",
      "Epoch 00708: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 709/5000\n",
      "\n",
      "Epoch 00709: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0156\n",
      "Epoch 710/5000\n",
      "\n",
      "Epoch 00710: loss did not improve from 0.01515\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 711/5000\n",
      "\n",
      "Epoch 00711: loss improved from 0.01515 to 0.01499, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 7ms/sample - loss: 0.0150\n",
      "Epoch 712/5000\n",
      "\n",
      "Epoch 00712: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 713/5000\n",
      "\n",
      "Epoch 00713: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 714/5000\n",
      "\n",
      "Epoch 00714: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 715/5000\n",
      "\n",
      "Epoch 00715: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 716/5000\n",
      "\n",
      "Epoch 00716: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 717/5000\n",
      "\n",
      "Epoch 00717: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 718/5000\n",
      "\n",
      "Epoch 00718: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 719/5000\n",
      "\n",
      "Epoch 00719: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 720/5000\n",
      "\n",
      "Epoch 00720: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 721/5000\n",
      "\n",
      "Epoch 00721: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 722/5000\n",
      "\n",
      "Epoch 00722: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 723/5000\n",
      "\n",
      "Epoch 00723: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 724/5000\n",
      "\n",
      "Epoch 00724: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 725/5000\n",
      "\n",
      "Epoch 00725: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 726/5000\n",
      "\n",
      "Epoch 00726: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 727/5000\n",
      "\n",
      "Epoch 00727: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 728/5000\n",
      "\n",
      "Epoch 00728: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 729/5000\n",
      "\n",
      "Epoch 00729: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 730/5000\n",
      "\n",
      "Epoch 00730: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 731/5000\n",
      "\n",
      "Epoch 00731: loss did not improve from 0.01499\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 732/5000\n",
      "\n",
      "Epoch 00732: loss improved from 0.01499 to 0.01485, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0149\n",
      "Epoch 733/5000\n",
      "\n",
      "Epoch 00733: loss improved from 0.01485 to 0.01455, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0146\n",
      "Epoch 734/5000\n",
      "\n",
      "Epoch 00734: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 735/5000\n",
      "\n",
      "Epoch 00735: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 736/5000\n",
      "\n",
      "Epoch 00736: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 737/5000\n",
      "\n",
      "Epoch 00737: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 738/5000\n",
      "\n",
      "Epoch 00738: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 739/5000\n",
      "\n",
      "Epoch 00739: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 740/5000\n",
      "\n",
      "Epoch 00740: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0155\n",
      "Epoch 741/5000\n",
      "\n",
      "Epoch 00741: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 742/5000\n",
      "\n",
      "Epoch 00742: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 743/5000\n",
      "\n",
      "Epoch 00743: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 744/5000\n",
      "\n",
      "Epoch 00744: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 745/5000\n",
      "\n",
      "Epoch 00745: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 746/5000\n",
      "\n",
      "Epoch 00746: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 747/5000\n",
      "\n",
      "Epoch 00747: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 748/5000\n",
      "\n",
      "Epoch 00748: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 749/5000\n",
      "\n",
      "Epoch 00749: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 750/5000\n",
      "\n",
      "Epoch 00750: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 751/5000\n",
      "\n",
      "Epoch 00751: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 752/5000\n",
      "\n",
      "Epoch 00752: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 753/5000\n",
      "\n",
      "Epoch 00753: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 754/5000\n",
      "\n",
      "Epoch 00754: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 755/5000\n",
      "\n",
      "Epoch 00755: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 756/5000\n",
      "\n",
      "Epoch 00756: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 757/5000\n",
      "\n",
      "Epoch 00757: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0154\n",
      "Epoch 758/5000\n",
      "\n",
      "Epoch 00758: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 759/5000\n",
      "\n",
      "Epoch 00759: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 760/5000\n",
      "\n",
      "Epoch 00760: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 761/5000\n",
      "\n",
      "Epoch 00761: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 762/5000\n",
      "\n",
      "Epoch 00762: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 763/5000\n",
      "\n",
      "Epoch 00763: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 764/5000\n",
      "\n",
      "Epoch 00764: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 765/5000\n",
      "\n",
      "Epoch 00765: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 766/5000\n",
      "\n",
      "Epoch 00766: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 767/5000\n",
      "\n",
      "Epoch 00767: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 768/5000\n",
      "\n",
      "Epoch 00768: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 769/5000\n",
      "\n",
      "Epoch 00769: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 770/5000\n",
      "\n",
      "Epoch 00770: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 771/5000\n",
      "\n",
      "Epoch 00771: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 772/5000\n",
      "\n",
      "Epoch 00772: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 773/5000\n",
      "\n",
      "Epoch 00773: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 774/5000\n",
      "\n",
      "Epoch 00774: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 775/5000\n",
      "\n",
      "Epoch 00775: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 776/5000\n",
      "\n",
      "Epoch 00776: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 777/5000\n",
      "\n",
      "Epoch 00777: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 778/5000\n",
      "\n",
      "Epoch 00778: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 779/5000\n",
      "\n",
      "Epoch 00779: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 780/5000\n",
      "\n",
      "Epoch 00780: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 781/5000\n",
      "\n",
      "Epoch 00781: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 782/5000\n",
      "\n",
      "Epoch 00782: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 783/5000\n",
      "\n",
      "Epoch 00783: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 784/5000\n",
      "\n",
      "Epoch 00784: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 785/5000\n",
      "\n",
      "Epoch 00785: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 786/5000\n",
      "\n",
      "Epoch 00786: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0153\n",
      "Epoch 787/5000\n",
      "\n",
      "Epoch 00787: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 788/5000\n",
      "\n",
      "Epoch 00788: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 789/5000\n",
      "\n",
      "Epoch 00789: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 790/5000\n",
      "\n",
      "Epoch 00790: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 791/5000\n",
      "\n",
      "Epoch 00791: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 792/5000\n",
      "\n",
      "Epoch 00792: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 793/5000\n",
      "\n",
      "Epoch 00793: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 794/5000\n",
      "\n",
      "Epoch 00794: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 795/5000\n",
      "\n",
      "Epoch 00795: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 796/5000\n",
      "\n",
      "Epoch 00796: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 797/5000\n",
      "\n",
      "Epoch 00797: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 798/5000\n",
      "\n",
      "Epoch 00798: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 799/5000\n",
      "\n",
      "Epoch 00799: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 800/5000\n",
      "\n",
      "Epoch 00800: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 801/5000\n",
      "\n",
      "Epoch 00801: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 802/5000\n",
      "\n",
      "Epoch 00802: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 803/5000\n",
      "\n",
      "Epoch 00803: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 804/5000\n",
      "\n",
      "Epoch 00804: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 805/5000\n",
      "\n",
      "Epoch 00805: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 806/5000\n",
      "\n",
      "Epoch 00806: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 807/5000\n",
      "\n",
      "Epoch 00807: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0152\n",
      "Epoch 808/5000\n",
      "\n",
      "Epoch 00808: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 809/5000\n",
      "\n",
      "Epoch 00809: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 810/5000\n",
      "\n",
      "Epoch 00810: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 811/5000\n",
      "\n",
      "Epoch 00811: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 812/5000\n",
      "\n",
      "Epoch 00812: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 813/5000\n",
      "\n",
      "Epoch 00813: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 814/5000\n",
      "\n",
      "Epoch 00814: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 815/5000\n",
      "\n",
      "Epoch 00815: loss did not improve from 0.01455\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 816/5000\n",
      "\n",
      "Epoch 00816: loss improved from 0.01455 to 0.01450, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 7ms/sample - loss: 0.0145\n",
      "Epoch 817/5000\n",
      "\n",
      "Epoch 00817: loss did not improve from 0.01450\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 818/5000\n",
      "\n",
      "Epoch 00818: loss did not improve from 0.01450\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 819/5000\n",
      "\n",
      "Epoch 00819: loss did not improve from 0.01450\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 820/5000\n",
      "\n",
      "Epoch 00820: loss did not improve from 0.01450\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 821/5000\n",
      "\n",
      "Epoch 00821: loss did not improve from 0.01450\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 822/5000\n",
      "\n",
      "Epoch 00822: loss did not improve from 0.01450\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 823/5000\n",
      "\n",
      "Epoch 00823: loss improved from 0.01450 to 0.01438, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0144\n",
      "Epoch 824/5000\n",
      "\n",
      "Epoch 00824: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 825/5000\n",
      "\n",
      "Epoch 00825: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 826/5000\n",
      "\n",
      "Epoch 00826: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 827/5000\n",
      "\n",
      "Epoch 00827: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 828/5000\n",
      "\n",
      "Epoch 00828: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 829/5000\n",
      "\n",
      "Epoch 00829: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 830/5000\n",
      "\n",
      "Epoch 00830: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 831/5000\n",
      "\n",
      "Epoch 00831: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0151\n",
      "Epoch 832/5000\n",
      "\n",
      "Epoch 00832: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 833/5000\n",
      "\n",
      "Epoch 00833: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 834/5000\n",
      "\n",
      "Epoch 00834: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 835/5000\n",
      "\n",
      "Epoch 00835: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 836/5000\n",
      "\n",
      "Epoch 00836: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 837/5000\n",
      "\n",
      "Epoch 00837: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 838/5000\n",
      "\n",
      "Epoch 00838: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 839/5000\n",
      "\n",
      "Epoch 00839: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0150\n",
      "Epoch 840/5000\n",
      "\n",
      "Epoch 00840: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 841/5000\n",
      "\n",
      "Epoch 00841: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 842/5000\n",
      "\n",
      "Epoch 00842: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 843/5000\n",
      "\n",
      "Epoch 00843: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 844/5000\n",
      "\n",
      "Epoch 00844: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 845/5000\n",
      "\n",
      "Epoch 00845: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 846/5000\n",
      "\n",
      "Epoch 00846: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 847/5000\n",
      "\n",
      "Epoch 00847: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 848/5000\n",
      "\n",
      "Epoch 00848: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 849/5000\n",
      "\n",
      "Epoch 00849: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 850/5000\n",
      "\n",
      "Epoch 00850: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 851/5000\n",
      "\n",
      "Epoch 00851: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 852/5000\n",
      "\n",
      "Epoch 00852: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 853/5000\n",
      "\n",
      "Epoch 00853: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 854/5000\n",
      "\n",
      "Epoch 00854: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 855/5000\n",
      "\n",
      "Epoch 00855: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 856/5000\n",
      "\n",
      "Epoch 00856: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 857/5000\n",
      "\n",
      "Epoch 00857: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 858/5000\n",
      "\n",
      "Epoch 00858: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 859/5000\n",
      "\n",
      "Epoch 00859: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 860/5000\n",
      "\n",
      "Epoch 00860: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 861/5000\n",
      "\n",
      "Epoch 00861: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 862/5000\n",
      "\n",
      "Epoch 00862: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 863/5000\n",
      "\n",
      "Epoch 00863: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 864/5000\n",
      "\n",
      "Epoch 00864: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 865/5000\n",
      "\n",
      "Epoch 00865: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 866/5000\n",
      "\n",
      "Epoch 00866: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 867/5000\n",
      "\n",
      "Epoch 00867: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 868/5000\n",
      "\n",
      "Epoch 00868: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 869/5000\n",
      "\n",
      "Epoch 00869: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 870/5000\n",
      "\n",
      "Epoch 00870: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 871/5000\n",
      "\n",
      "Epoch 00871: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 872/5000\n",
      "\n",
      "Epoch 00872: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 873/5000\n",
      "\n",
      "Epoch 00873: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 874/5000\n",
      "\n",
      "Epoch 00874: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 875/5000\n",
      "\n",
      "Epoch 00875: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 876/5000\n",
      "\n",
      "Epoch 00876: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 877/5000\n",
      "\n",
      "Epoch 00877: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 878/5000\n",
      "\n",
      "Epoch 00878: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 879/5000\n",
      "\n",
      "Epoch 00879: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 880/5000\n",
      "\n",
      "Epoch 00880: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 881/5000\n",
      "\n",
      "Epoch 00881: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 882/5000\n",
      "\n",
      "Epoch 00882: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 883/5000\n",
      "\n",
      "Epoch 00883: loss did not improve from 0.01438\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 884/5000\n",
      "\n",
      "Epoch 00884: loss improved from 0.01438 to 0.01434, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0143\n",
      "Epoch 885/5000\n",
      "\n",
      "Epoch 00885: loss improved from 0.01434 to 0.01429, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0143\n",
      "Epoch 886/5000\n",
      "\n",
      "Epoch 00886: loss did not improve from 0.01429\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 887/5000\n",
      "\n",
      "Epoch 00887: loss did not improve from 0.01429\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 888/5000\n",
      "\n",
      "Epoch 00888: loss did not improve from 0.01429\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 889/5000\n",
      "\n",
      "Epoch 00889: loss did not improve from 0.01429\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 890/5000\n",
      "\n",
      "Epoch 00890: loss did not improve from 0.01429\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 891/5000\n",
      "\n",
      "Epoch 00891: loss did not improve from 0.01429\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 892/5000\n",
      "\n",
      "Epoch 00892: loss did not improve from 0.01429\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 893/5000\n",
      "\n",
      "Epoch 00893: loss did not improve from 0.01429\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 894/5000\n",
      "\n",
      "Epoch 00894: loss did not improve from 0.01429\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 895/5000\n",
      "\n",
      "Epoch 00895: loss did not improve from 0.01429\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 896/5000\n",
      "\n",
      "Epoch 00896: loss improved from 0.01429 to 0.01421, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0142\n",
      "Epoch 897/5000\n",
      "\n",
      "Epoch 00897: loss did not improve from 0.01421\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 898/5000\n",
      "\n",
      "Epoch 00898: loss did not improve from 0.01421\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 899/5000\n",
      "\n",
      "Epoch 00899: loss did not improve from 0.01421\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 900/5000\n",
      "\n",
      "Epoch 00900: loss did not improve from 0.01421\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 901/5000\n",
      "\n",
      "Epoch 00901: loss did not improve from 0.01421\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 902/5000\n",
      "\n",
      "Epoch 00902: loss did not improve from 0.01421\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 903/5000\n",
      "\n",
      "Epoch 00903: loss did not improve from 0.01421\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 904/5000\n",
      "\n",
      "Epoch 00904: loss did not improve from 0.01421\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 905/5000\n",
      "\n",
      "Epoch 00905: loss improved from 0.01421 to 0.01419, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0142\n",
      "Epoch 906/5000\n",
      "\n",
      "Epoch 00906: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 907/5000\n",
      "\n",
      "Epoch 00907: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 908/5000\n",
      "\n",
      "Epoch 00908: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 909/5000\n",
      "\n",
      "Epoch 00909: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 910/5000\n",
      "\n",
      "Epoch 00910: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 911/5000\n",
      "\n",
      "Epoch 00911: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 912/5000\n",
      "\n",
      "Epoch 00912: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0148\n",
      "Epoch 913/5000\n",
      "\n",
      "Epoch 00913: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 914/5000\n",
      "\n",
      "Epoch 00914: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 915/5000\n",
      "\n",
      "Epoch 00915: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 916/5000\n",
      "\n",
      "Epoch 00916: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 917/5000\n",
      "\n",
      "Epoch 00917: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 918/5000\n",
      "\n",
      "Epoch 00918: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 919/5000\n",
      "\n",
      "Epoch 00919: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 920/5000\n",
      "\n",
      "Epoch 00920: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 921/5000\n",
      "\n",
      "Epoch 00921: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 922/5000\n",
      "\n",
      "Epoch 00922: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 923/5000\n",
      "\n",
      "Epoch 00923: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 924/5000\n",
      "\n",
      "Epoch 00924: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 925/5000\n",
      "\n",
      "Epoch 00925: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 926/5000\n",
      "\n",
      "Epoch 00926: loss did not improve from 0.01419\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 927/5000\n",
      "\n",
      "Epoch 00927: loss improved from 0.01419 to 0.01397, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0140\n",
      "Epoch 928/5000\n",
      "\n",
      "Epoch 00928: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 929/5000\n",
      "\n",
      "Epoch 00929: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 930/5000\n",
      "\n",
      "Epoch 00930: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 931/5000\n",
      "\n",
      "Epoch 00931: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 932/5000\n",
      "\n",
      "Epoch 00932: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 933/5000\n",
      "\n",
      "Epoch 00933: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 934/5000\n",
      "\n",
      "Epoch 00934: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 935/5000\n",
      "\n",
      "Epoch 00935: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 936/5000\n",
      "\n",
      "Epoch 00936: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 937/5000\n",
      "\n",
      "Epoch 00937: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0149\n",
      "Epoch 938/5000\n",
      "\n",
      "Epoch 00938: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 939/5000\n",
      "\n",
      "Epoch 00939: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 940/5000\n",
      "\n",
      "Epoch 00940: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 941/5000\n",
      "\n",
      "Epoch 00941: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 942/5000\n",
      "\n",
      "Epoch 00942: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 943/5000\n",
      "\n",
      "Epoch 00943: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 944/5000\n",
      "\n",
      "Epoch 00944: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 945/5000\n",
      "\n",
      "Epoch 00945: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 946/5000\n",
      "\n",
      "Epoch 00946: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 947/5000\n",
      "\n",
      "Epoch 00947: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 948/5000\n",
      "\n",
      "Epoch 00948: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 949/5000\n",
      "\n",
      "Epoch 00949: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 950/5000\n",
      "\n",
      "Epoch 00950: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 951/5000\n",
      "\n",
      "Epoch 00951: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 952/5000\n",
      "\n",
      "Epoch 00952: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 953/5000\n",
      "\n",
      "Epoch 00953: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 954/5000\n",
      "\n",
      "Epoch 00954: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 955/5000\n",
      "\n",
      "Epoch 00955: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 956/5000\n",
      "\n",
      "Epoch 00956: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 957/5000\n",
      "\n",
      "Epoch 00957: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 958/5000\n",
      "\n",
      "Epoch 00958: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 959/5000\n",
      "\n",
      "Epoch 00959: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 960/5000\n",
      "\n",
      "Epoch 00960: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0147\n",
      "Epoch 961/5000\n",
      "\n",
      "Epoch 00961: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 962/5000\n",
      "\n",
      "Epoch 00962: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 963/5000\n",
      "\n",
      "Epoch 00963: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 964/5000\n",
      "\n",
      "Epoch 00964: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 965/5000\n",
      "\n",
      "Epoch 00965: loss did not improve from 0.01397\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 966/5000\n",
      "\n",
      "Epoch 00966: loss improved from 0.01397 to 0.01395, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0139\n",
      "Epoch 967/5000\n",
      "\n",
      "Epoch 00967: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 968/5000\n",
      "\n",
      "Epoch 00968: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 969/5000\n",
      "\n",
      "Epoch 00969: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 970/5000\n",
      "\n",
      "Epoch 00970: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 971/5000\n",
      "\n",
      "Epoch 00971: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 972/5000\n",
      "\n",
      "Epoch 00972: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 973/5000\n",
      "\n",
      "Epoch 00973: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 974/5000\n",
      "\n",
      "Epoch 00974: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 975/5000\n",
      "\n",
      "Epoch 00975: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 976/5000\n",
      "\n",
      "Epoch 00976: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 977/5000\n",
      "\n",
      "Epoch 00977: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 978/5000\n",
      "\n",
      "Epoch 00978: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 979/5000\n",
      "\n",
      "Epoch 00979: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 980/5000\n",
      "\n",
      "Epoch 00980: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 981/5000\n",
      "\n",
      "Epoch 00981: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 982/5000\n",
      "\n",
      "Epoch 00982: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 983/5000\n",
      "\n",
      "Epoch 00983: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 984/5000\n",
      "\n",
      "Epoch 00984: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 985/5000\n",
      "\n",
      "Epoch 00985: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 986/5000\n",
      "\n",
      "Epoch 00986: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 987/5000\n",
      "\n",
      "Epoch 00987: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 988/5000\n",
      "\n",
      "Epoch 00988: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 989/5000\n",
      "\n",
      "Epoch 00989: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 990/5000\n",
      "\n",
      "Epoch 00990: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 991/5000\n",
      "\n",
      "Epoch 00991: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 992/5000\n",
      "\n",
      "Epoch 00992: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 993/5000\n",
      "\n",
      "Epoch 00993: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 994/5000\n",
      "\n",
      "Epoch 00994: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 995/5000\n",
      "\n",
      "Epoch 00995: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 996/5000\n",
      "\n",
      "Epoch 00996: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0145\n",
      "Epoch 997/5000\n",
      "\n",
      "Epoch 00997: loss did not improve from 0.01395\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 998/5000\n",
      "\n",
      "Epoch 00998: loss improved from 0.01395 to 0.01394, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0139\n",
      "Epoch 999/5000\n",
      "\n",
      "Epoch 00999: loss did not improve from 0.01394\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1000/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01000: loss did not improve from 0.01394\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 1001/5000\n",
      "\n",
      "Epoch 01001: loss did not improve from 0.01394\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 1002/5000\n",
      "\n",
      "Epoch 01002: loss improved from 0.01394 to 0.01393, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0139\n",
      "Epoch 1003/5000\n",
      "\n",
      "Epoch 01003: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1004/5000\n",
      "\n",
      "Epoch 01004: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1005/5000\n",
      "\n",
      "Epoch 01005: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1006/5000\n",
      "\n",
      "Epoch 01006: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1007/5000\n",
      "\n",
      "Epoch 01007: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1008/5000\n",
      "\n",
      "Epoch 01008: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1009/5000\n",
      "\n",
      "Epoch 01009: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1010/5000\n",
      "\n",
      "Epoch 01010: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1011/5000\n",
      "\n",
      "Epoch 01011: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1012/5000\n",
      "\n",
      "Epoch 01012: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1013/5000\n",
      "\n",
      "Epoch 01013: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1014/5000\n",
      "\n",
      "Epoch 01014: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1015/5000\n",
      "\n",
      "Epoch 01015: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1016/5000\n",
      "\n",
      "Epoch 01016: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1017/5000\n",
      "\n",
      "Epoch 01017: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1018/5000\n",
      "\n",
      "Epoch 01018: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 1019/5000\n",
      "\n",
      "Epoch 01019: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1020/5000\n",
      "\n",
      "Epoch 01020: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 1021/5000\n",
      "\n",
      "Epoch 01021: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1022/5000\n",
      "\n",
      "Epoch 01022: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1023/5000\n",
      "\n",
      "Epoch 01023: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1024/5000\n",
      "\n",
      "Epoch 01024: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 1025/5000\n",
      "\n",
      "Epoch 01025: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1026/5000\n",
      "\n",
      "Epoch 01026: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1027/5000\n",
      "\n",
      "Epoch 01027: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 1028/5000\n",
      "\n",
      "Epoch 01028: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1029/5000\n",
      "\n",
      "Epoch 01029: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1030/5000\n",
      "\n",
      "Epoch 01030: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1031/5000\n",
      "\n",
      "Epoch 01031: loss did not improve from 0.01393\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1032/5000\n",
      "\n",
      "Epoch 01032: loss improved from 0.01393 to 0.01382, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0138\n",
      "Epoch 1033/5000\n",
      "\n",
      "Epoch 01033: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1034/5000\n",
      "\n",
      "Epoch 01034: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 1035/5000\n",
      "\n",
      "Epoch 01035: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1036/5000\n",
      "\n",
      "Epoch 01036: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1037/5000\n",
      "\n",
      "Epoch 01037: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1038/5000\n",
      "\n",
      "Epoch 01038: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1039/5000\n",
      "\n",
      "Epoch 01039: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1040/5000\n",
      "\n",
      "Epoch 01040: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1041/5000\n",
      "\n",
      "Epoch 01041: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1042/5000\n",
      "\n",
      "Epoch 01042: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 1043/5000\n",
      "\n",
      "Epoch 01043: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1044/5000\n",
      "\n",
      "Epoch 01044: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1045/5000\n",
      "\n",
      "Epoch 01045: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1046/5000\n",
      "\n",
      "Epoch 01046: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1047/5000\n",
      "\n",
      "Epoch 01047: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1048/5000\n",
      "\n",
      "Epoch 01048: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1049/5000\n",
      "\n",
      "Epoch 01049: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1050/5000\n",
      "\n",
      "Epoch 01050: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1051/5000\n",
      "\n",
      "Epoch 01051: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0141\n",
      "Epoch 1052/5000\n",
      "\n",
      "Epoch 01052: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1053/5000\n",
      "\n",
      "Epoch 01053: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1054/5000\n",
      "\n",
      "Epoch 01054: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1055/5000\n",
      "\n",
      "Epoch 01055: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0141\n",
      "Epoch 1056/5000\n",
      "\n",
      "Epoch 01056: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1057/5000\n",
      "\n",
      "Epoch 01057: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1058/5000\n",
      "\n",
      "Epoch 01058: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 1059/5000\n",
      "\n",
      "Epoch 01059: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1060/5000\n",
      "\n",
      "Epoch 01060: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1061/5000\n",
      "\n",
      "Epoch 01061: loss did not improve from 0.01382\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1062/5000\n",
      "\n",
      "Epoch 01062: loss improved from 0.01382 to 0.01370, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0137\n",
      "Epoch 1063/5000\n",
      "\n",
      "Epoch 01063: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1064/5000\n",
      "\n",
      "Epoch 01064: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1065/5000\n",
      "\n",
      "Epoch 01065: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1066/5000\n",
      "\n",
      "Epoch 01066: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 1067/5000\n",
      "\n",
      "Epoch 01067: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1068/5000\n",
      "\n",
      "Epoch 01068: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1069/5000\n",
      "\n",
      "Epoch 01069: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1070/5000\n",
      "\n",
      "Epoch 01070: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1071/5000\n",
      "\n",
      "Epoch 01071: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1072/5000\n",
      "\n",
      "Epoch 01072: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1073/5000\n",
      "\n",
      "Epoch 01073: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1074/5000\n",
      "\n",
      "Epoch 01074: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1075/5000\n",
      "\n",
      "Epoch 01075: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1076/5000\n",
      "\n",
      "Epoch 01076: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1077/5000\n",
      "\n",
      "Epoch 01077: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1078/5000\n",
      "\n",
      "Epoch 01078: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1079/5000\n",
      "\n",
      "Epoch 01079: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1080/5000\n",
      "\n",
      "Epoch 01080: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1081/5000\n",
      "\n",
      "Epoch 01081: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1082/5000\n",
      "\n",
      "Epoch 01082: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1083/5000\n",
      "\n",
      "Epoch 01083: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1084/5000\n",
      "\n",
      "Epoch 01084: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0144\n",
      "Epoch 1085/5000\n",
      "\n",
      "Epoch 01085: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1086/5000\n",
      "\n",
      "Epoch 01086: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0137\n",
      "Epoch 1087/5000\n",
      "\n",
      "Epoch 01087: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1088/5000\n",
      "\n",
      "Epoch 01088: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1089/5000\n",
      "\n",
      "Epoch 01089: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1090/5000\n",
      "\n",
      "Epoch 01090: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1091/5000\n",
      "\n",
      "Epoch 01091: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 1092/5000\n",
      "\n",
      "Epoch 01092: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1093/5000\n",
      "\n",
      "Epoch 01093: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1094/5000\n",
      "\n",
      "Epoch 01094: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1095/5000\n",
      "\n",
      "Epoch 01095: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1096/5000\n",
      "\n",
      "Epoch 01096: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0139\n",
      "Epoch 1097/5000\n",
      "\n",
      "Epoch 01097: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1098/5000\n",
      "\n",
      "Epoch 01098: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0141\n",
      "Epoch 1099/5000\n",
      "\n",
      "Epoch 01099: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1100/5000\n",
      "\n",
      "Epoch 01100: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1101/5000\n",
      "\n",
      "Epoch 01101: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1102/5000\n",
      "\n",
      "Epoch 01102: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1103/5000\n",
      "\n",
      "Epoch 01103: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1104/5000\n",
      "\n",
      "Epoch 01104: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1105/5000\n",
      "\n",
      "Epoch 01105: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1106/5000\n",
      "\n",
      "Epoch 01106: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1107/5000\n",
      "\n",
      "Epoch 01107: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1108/5000\n",
      "\n",
      "Epoch 01108: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1109/5000\n",
      "\n",
      "Epoch 01109: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1110/5000\n",
      "\n",
      "Epoch 01110: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1111/5000\n",
      "\n",
      "Epoch 01111: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1112/5000\n",
      "\n",
      "Epoch 01112: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 1113/5000\n",
      "\n",
      "Epoch 01113: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1114/5000\n",
      "\n",
      "Epoch 01114: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0143\n",
      "Epoch 1115/5000\n",
      "\n",
      "Epoch 01115: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0142\n",
      "Epoch 1116/5000\n",
      "\n",
      "Epoch 01116: loss did not improve from 0.01370\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1117/5000\n",
      "\n",
      "Epoch 01117: loss improved from 0.01370 to 0.01363, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0136\n",
      "Epoch 1118/5000\n",
      "\n",
      "Epoch 01118: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1119/5000\n",
      "\n",
      "Epoch 01119: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1120/5000\n",
      "\n",
      "Epoch 01120: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1121/5000\n",
      "\n",
      "Epoch 01121: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1122/5000\n",
      "\n",
      "Epoch 01122: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1123/5000\n",
      "\n",
      "Epoch 01123: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1124/5000\n",
      "\n",
      "Epoch 01124: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1125/5000\n",
      "\n",
      "Epoch 01125: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1126/5000\n",
      "\n",
      "Epoch 01126: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1127/5000\n",
      "\n",
      "Epoch 01127: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1128/5000\n",
      "\n",
      "Epoch 01128: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1129/5000\n",
      "\n",
      "Epoch 01129: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1130/5000\n",
      "\n",
      "Epoch 01130: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1131/5000\n",
      "\n",
      "Epoch 01131: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1132/5000\n",
      "\n",
      "Epoch 01132: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1133/5000\n",
      "\n",
      "Epoch 01133: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1134/5000\n",
      "\n",
      "Epoch 01134: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1135/5000\n",
      "\n",
      "Epoch 01135: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1136/5000\n",
      "\n",
      "Epoch 01136: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1137/5000\n",
      "\n",
      "Epoch 01137: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1138/5000\n",
      "\n",
      "Epoch 01138: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1139/5000\n",
      "\n",
      "Epoch 01139: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1140/5000\n",
      "\n",
      "Epoch 01140: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1141/5000\n",
      "\n",
      "Epoch 01141: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1142/5000\n",
      "\n",
      "Epoch 01142: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1143/5000\n",
      "\n",
      "Epoch 01143: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1144/5000\n",
      "\n",
      "Epoch 01144: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1145/5000\n",
      "\n",
      "Epoch 01145: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1146/5000\n",
      "\n",
      "Epoch 01146: loss did not improve from 0.01363\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1147/5000\n",
      "\n",
      "Epoch 01147: loss improved from 0.01363 to 0.01359, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0136\n",
      "Epoch 1148/5000\n",
      "\n",
      "Epoch 01148: loss did not improve from 0.01359\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1149/5000\n",
      "\n",
      "Epoch 01149: loss did not improve from 0.01359\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1150/5000\n",
      "\n",
      "Epoch 01150: loss did not improve from 0.01359\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1151/5000\n",
      "\n",
      "Epoch 01151: loss did not improve from 0.01359\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1152/5000\n",
      "\n",
      "Epoch 01152: loss did not improve from 0.01359\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1153/5000\n",
      "\n",
      "Epoch 01153: loss did not improve from 0.01359\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1154/5000\n",
      "\n",
      "Epoch 01154: loss improved from 0.01359 to 0.01337, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0134\n",
      "Epoch 1155/5000\n",
      "\n",
      "Epoch 01155: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1156/5000\n",
      "\n",
      "Epoch 01156: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1157/5000\n",
      "\n",
      "Epoch 01157: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1158/5000\n",
      "\n",
      "Epoch 01158: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1159/5000\n",
      "\n",
      "Epoch 01159: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1160/5000\n",
      "\n",
      "Epoch 01160: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1161/5000\n",
      "\n",
      "Epoch 01161: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1162/5000\n",
      "\n",
      "Epoch 01162: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1163/5000\n",
      "\n",
      "Epoch 01163: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1164/5000\n",
      "\n",
      "Epoch 01164: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1165/5000\n",
      "\n",
      "Epoch 01165: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1166/5000\n",
      "\n",
      "Epoch 01166: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1167/5000\n",
      "\n",
      "Epoch 01167: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1168/5000\n",
      "\n",
      "Epoch 01168: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1169/5000\n",
      "\n",
      "Epoch 01169: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1170/5000\n",
      "\n",
      "Epoch 01170: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1171/5000\n",
      "\n",
      "Epoch 01171: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1172/5000\n",
      "\n",
      "Epoch 01172: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1173/5000\n",
      "\n",
      "Epoch 01173: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1174/5000\n",
      "\n",
      "Epoch 01174: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1175/5000\n",
      "\n",
      "Epoch 01175: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1176/5000\n",
      "\n",
      "Epoch 01176: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0141\n",
      "Epoch 1177/5000\n",
      "\n",
      "Epoch 01177: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1178/5000\n",
      "\n",
      "Epoch 01178: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1179/5000\n",
      "\n",
      "Epoch 01179: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1180/5000\n",
      "\n",
      "Epoch 01180: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1181/5000\n",
      "\n",
      "Epoch 01181: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1182/5000\n",
      "\n",
      "Epoch 01182: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1183/5000\n",
      "\n",
      "Epoch 01183: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1184/5000\n",
      "\n",
      "Epoch 01184: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1185/5000\n",
      "\n",
      "Epoch 01185: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1186/5000\n",
      "\n",
      "Epoch 01186: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1187/5000\n",
      "\n",
      "Epoch 01187: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1188/5000\n",
      "\n",
      "Epoch 01188: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1189/5000\n",
      "\n",
      "Epoch 01189: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1190/5000\n",
      "\n",
      "Epoch 01190: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1191/5000\n",
      "\n",
      "Epoch 01191: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1192/5000\n",
      "\n",
      "Epoch 01192: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1193/5000\n",
      "\n",
      "Epoch 01193: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1194/5000\n",
      "\n",
      "Epoch 01194: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1195/5000\n",
      "\n",
      "Epoch 01195: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1196/5000\n",
      "\n",
      "Epoch 01196: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1197/5000\n",
      "\n",
      "Epoch 01197: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1198/5000\n",
      "\n",
      "Epoch 01198: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1199/5000\n",
      "\n",
      "Epoch 01199: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1200/5000\n",
      "\n",
      "Epoch 01200: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1201/5000\n",
      "\n",
      "Epoch 01201: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1202/5000\n",
      "\n",
      "Epoch 01202: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1203/5000\n",
      "\n",
      "Epoch 01203: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1204/5000\n",
      "\n",
      "Epoch 01204: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1205/5000\n",
      "\n",
      "Epoch 01205: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1206/5000\n",
      "\n",
      "Epoch 01206: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1207/5000\n",
      "\n",
      "Epoch 01207: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1208/5000\n",
      "\n",
      "Epoch 01208: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1209/5000\n",
      "\n",
      "Epoch 01209: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1210/5000\n",
      "\n",
      "Epoch 01210: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1211/5000\n",
      "\n",
      "Epoch 01211: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1212/5000\n",
      "\n",
      "Epoch 01212: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1213/5000\n",
      "\n",
      "Epoch 01213: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1214/5000\n",
      "\n",
      "Epoch 01214: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1215/5000\n",
      "\n",
      "Epoch 01215: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1216/5000\n",
      "\n",
      "Epoch 01216: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1217/5000\n",
      "\n",
      "Epoch 01217: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1218/5000\n",
      "\n",
      "Epoch 01218: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1219/5000\n",
      "\n",
      "Epoch 01219: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1220/5000\n",
      "\n",
      "Epoch 01220: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1221/5000\n",
      "\n",
      "Epoch 01221: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1222/5000\n",
      "\n",
      "Epoch 01222: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1223/5000\n",
      "\n",
      "Epoch 01223: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1224/5000\n",
      "\n",
      "Epoch 01224: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1225/5000\n",
      "\n",
      "Epoch 01225: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1226/5000\n",
      "\n",
      "Epoch 01226: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1227/5000\n",
      "\n",
      "Epoch 01227: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1228/5000\n",
      "\n",
      "Epoch 01228: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1229/5000\n",
      "\n",
      "Epoch 01229: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1230/5000\n",
      "\n",
      "Epoch 01230: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1231/5000\n",
      "\n",
      "Epoch 01231: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1232/5000\n",
      "\n",
      "Epoch 01232: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1233/5000\n",
      "\n",
      "Epoch 01233: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1234/5000\n",
      "\n",
      "Epoch 01234: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1235/5000\n",
      "\n",
      "Epoch 01235: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1236/5000\n",
      "\n",
      "Epoch 01236: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1237/5000\n",
      "\n",
      "Epoch 01237: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1238/5000\n",
      "\n",
      "Epoch 01238: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1239/5000\n",
      "\n",
      "Epoch 01239: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1240/5000\n",
      "\n",
      "Epoch 01240: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1241/5000\n",
      "\n",
      "Epoch 01241: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1242/5000\n",
      "\n",
      "Epoch 01242: loss did not improve from 0.01337\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1243/5000\n",
      "\n",
      "Epoch 01243: loss improved from 0.01337 to 0.01332, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1244/5000\n",
      "\n",
      "Epoch 01244: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1245/5000\n",
      "\n",
      "Epoch 01245: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1246/5000\n",
      "\n",
      "Epoch 01246: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1247/5000\n",
      "\n",
      "Epoch 01247: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1248/5000\n",
      "\n",
      "Epoch 01248: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1249/5000\n",
      "\n",
      "Epoch 01249: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1250/5000\n",
      "\n",
      "Epoch 01250: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1251/5000\n",
      "\n",
      "Epoch 01251: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1252/5000\n",
      "\n",
      "Epoch 01252: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1253/5000\n",
      "\n",
      "Epoch 01253: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1254/5000\n",
      "\n",
      "Epoch 01254: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1255/5000\n",
      "\n",
      "Epoch 01255: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1256/5000\n",
      "\n",
      "Epoch 01256: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1257/5000\n",
      "\n",
      "Epoch 01257: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1258/5000\n",
      "\n",
      "Epoch 01258: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1259/5000\n",
      "\n",
      "Epoch 01259: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1260/5000\n",
      "\n",
      "Epoch 01260: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1261/5000\n",
      "\n",
      "Epoch 01261: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1262/5000\n",
      "\n",
      "Epoch 01262: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1263/5000\n",
      "\n",
      "Epoch 01263: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1264/5000\n",
      "\n",
      "Epoch 01264: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1265/5000\n",
      "\n",
      "Epoch 01265: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1266/5000\n",
      "\n",
      "Epoch 01266: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1267/5000\n",
      "\n",
      "Epoch 01267: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1268/5000\n",
      "\n",
      "Epoch 01268: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1269/5000\n",
      "\n",
      "Epoch 01269: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1270/5000\n",
      "\n",
      "Epoch 01270: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1271/5000\n",
      "\n",
      "Epoch 01271: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1272/5000\n",
      "\n",
      "Epoch 01272: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1273/5000\n",
      "\n",
      "Epoch 01273: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1274/5000\n",
      "\n",
      "Epoch 01274: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1275/5000\n",
      "\n",
      "Epoch 01275: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1276/5000\n",
      "\n",
      "Epoch 01276: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1277/5000\n",
      "\n",
      "Epoch 01277: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1278/5000\n",
      "\n",
      "Epoch 01278: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1279/5000\n",
      "\n",
      "Epoch 01279: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1280/5000\n",
      "\n",
      "Epoch 01280: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1281/5000\n",
      "\n",
      "Epoch 01281: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1282/5000\n",
      "\n",
      "Epoch 01282: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1283/5000\n",
      "\n",
      "Epoch 01283: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1284/5000\n",
      "\n",
      "Epoch 01284: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1285/5000\n",
      "\n",
      "Epoch 01285: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1286/5000\n",
      "\n",
      "Epoch 01286: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1287/5000\n",
      "\n",
      "Epoch 01287: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1288/5000\n",
      "\n",
      "Epoch 01288: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1289/5000\n",
      "\n",
      "Epoch 01289: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1290/5000\n",
      "\n",
      "Epoch 01290: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1291/5000\n",
      "\n",
      "Epoch 01291: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1292/5000\n",
      "\n",
      "Epoch 01292: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1293/5000\n",
      "\n",
      "Epoch 01293: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1294/5000\n",
      "\n",
      "Epoch 01294: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1295/5000\n",
      "\n",
      "Epoch 01295: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1296/5000\n",
      "\n",
      "Epoch 01296: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1297/5000\n",
      "\n",
      "Epoch 01297: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1298/5000\n",
      "\n",
      "Epoch 01298: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1299/5000\n",
      "\n",
      "Epoch 01299: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1300/5000\n",
      "\n",
      "Epoch 01300: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1301/5000\n",
      "\n",
      "Epoch 01301: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1302/5000\n",
      "\n",
      "Epoch 01302: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1303/5000\n",
      "\n",
      "Epoch 01303: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1304/5000\n",
      "\n",
      "Epoch 01304: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0140\n",
      "Epoch 1305/5000\n",
      "\n",
      "Epoch 01305: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1306/5000\n",
      "\n",
      "Epoch 01306: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1307/5000\n",
      "\n",
      "Epoch 01307: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1308/5000\n",
      "\n",
      "Epoch 01308: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1309/5000\n",
      "\n",
      "Epoch 01309: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1310/5000\n",
      "\n",
      "Epoch 01310: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1311/5000\n",
      "\n",
      "Epoch 01311: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1312/5000\n",
      "\n",
      "Epoch 01312: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1313/5000\n",
      "\n",
      "Epoch 01313: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1314/5000\n",
      "\n",
      "Epoch 01314: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1315/5000\n",
      "\n",
      "Epoch 01315: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1316/5000\n",
      "\n",
      "Epoch 01316: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1317/5000\n",
      "\n",
      "Epoch 01317: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1318/5000\n",
      "\n",
      "Epoch 01318: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1319/5000\n",
      "\n",
      "Epoch 01319: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1320/5000\n",
      "\n",
      "Epoch 01320: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1321/5000\n",
      "\n",
      "Epoch 01321: loss improved from 0.01332 to 0.01332, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0133\n",
      "Epoch 1322/5000\n",
      "\n",
      "Epoch 01322: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1323/5000\n",
      "\n",
      "Epoch 01323: loss did not improve from 0.01332\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1324/5000\n",
      "\n",
      "Epoch 01324: loss improved from 0.01332 to 0.01321, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0132\n",
      "Epoch 1325/5000\n",
      "\n",
      "Epoch 01325: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1326/5000\n",
      "\n",
      "Epoch 01326: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1327/5000\n",
      "\n",
      "Epoch 01327: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1328/5000\n",
      "\n",
      "Epoch 01328: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1329/5000\n",
      "\n",
      "Epoch 01329: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1330/5000\n",
      "\n",
      "Epoch 01330: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1331/5000\n",
      "\n",
      "Epoch 01331: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1332/5000\n",
      "\n",
      "Epoch 01332: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1333/5000\n",
      "\n",
      "Epoch 01333: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1334/5000\n",
      "\n",
      "Epoch 01334: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1335/5000\n",
      "\n",
      "Epoch 01335: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1336/5000\n",
      "\n",
      "Epoch 01336: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1337/5000\n",
      "\n",
      "Epoch 01337: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1338/5000\n",
      "\n",
      "Epoch 01338: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1339/5000\n",
      "\n",
      "Epoch 01339: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1340/5000\n",
      "\n",
      "Epoch 01340: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1341/5000\n",
      "\n",
      "Epoch 01341: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1342/5000\n",
      "\n",
      "Epoch 01342: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1343/5000\n",
      "\n",
      "Epoch 01343: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1344/5000\n",
      "\n",
      "Epoch 01344: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1345/5000\n",
      "\n",
      "Epoch 01345: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1346/5000\n",
      "\n",
      "Epoch 01346: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1347/5000\n",
      "\n",
      "Epoch 01347: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1348/5000\n",
      "\n",
      "Epoch 01348: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1349/5000\n",
      "\n",
      "Epoch 01349: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1350/5000\n",
      "\n",
      "Epoch 01350: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1351/5000\n",
      "\n",
      "Epoch 01351: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1352/5000\n",
      "\n",
      "Epoch 01352: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1353/5000\n",
      "\n",
      "Epoch 01353: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1354/5000\n",
      "\n",
      "Epoch 01354: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1355/5000\n",
      "\n",
      "Epoch 01355: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1356/5000\n",
      "\n",
      "Epoch 01356: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1357/5000\n",
      "\n",
      "Epoch 01357: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1358/5000\n",
      "\n",
      "Epoch 01358: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1359/5000\n",
      "\n",
      "Epoch 01359: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1360/5000\n",
      "\n",
      "Epoch 01360: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1361/5000\n",
      "\n",
      "Epoch 01361: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1362/5000\n",
      "\n",
      "Epoch 01362: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1363/5000\n",
      "\n",
      "Epoch 01363: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1364/5000\n",
      "\n",
      "Epoch 01364: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1365/5000\n",
      "\n",
      "Epoch 01365: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1366/5000\n",
      "\n",
      "Epoch 01366: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1367/5000\n",
      "\n",
      "Epoch 01367: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1368/5000\n",
      "\n",
      "Epoch 01368: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1369/5000\n",
      "\n",
      "Epoch 01369: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1370/5000\n",
      "\n",
      "Epoch 01370: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1371/5000\n",
      "\n",
      "Epoch 01371: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1372/5000\n",
      "\n",
      "Epoch 01372: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1373/5000\n",
      "\n",
      "Epoch 01373: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1374/5000\n",
      "\n",
      "Epoch 01374: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1375/5000\n",
      "\n",
      "Epoch 01375: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1376/5000\n",
      "\n",
      "Epoch 01376: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1377/5000\n",
      "\n",
      "Epoch 01377: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1378/5000\n",
      "\n",
      "Epoch 01378: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1379/5000\n",
      "\n",
      "Epoch 01379: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1380/5000\n",
      "\n",
      "Epoch 01380: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1381/5000\n",
      "\n",
      "Epoch 01381: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1382/5000\n",
      "\n",
      "Epoch 01382: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1383/5000\n",
      "\n",
      "Epoch 01383: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1384/5000\n",
      "\n",
      "Epoch 01384: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1385/5000\n",
      "\n",
      "Epoch 01385: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1386/5000\n",
      "\n",
      "Epoch 01386: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1387/5000\n",
      "\n",
      "Epoch 01387: loss did not improve from 0.01321\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1388/5000\n",
      "\n",
      "Epoch 01388: loss improved from 0.01321 to 0.01312, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0131\n",
      "Epoch 1389/5000\n",
      "\n",
      "Epoch 01389: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1390/5000\n",
      "\n",
      "Epoch 01390: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1391/5000\n",
      "\n",
      "Epoch 01391: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1392/5000\n",
      "\n",
      "Epoch 01392: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1393/5000\n",
      "\n",
      "Epoch 01393: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1394/5000\n",
      "\n",
      "Epoch 01394: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1395/5000\n",
      "\n",
      "Epoch 01395: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1396/5000\n",
      "\n",
      "Epoch 01396: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1397/5000\n",
      "\n",
      "Epoch 01397: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1398/5000\n",
      "\n",
      "Epoch 01398: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1399/5000\n",
      "\n",
      "Epoch 01399: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1400/5000\n",
      "\n",
      "Epoch 01400: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1401/5000\n",
      "\n",
      "Epoch 01401: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1402/5000\n",
      "\n",
      "Epoch 01402: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1403/5000\n",
      "\n",
      "Epoch 01403: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1404/5000\n",
      "\n",
      "Epoch 01404: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0137\n",
      "Epoch 1405/5000\n",
      "\n",
      "Epoch 01405: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1406/5000\n",
      "\n",
      "Epoch 01406: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1407/5000\n",
      "\n",
      "Epoch 01407: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1408/5000\n",
      "\n",
      "Epoch 01408: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1409/5000\n",
      "\n",
      "Epoch 01409: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1410/5000\n",
      "\n",
      "Epoch 01410: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1411/5000\n",
      "\n",
      "Epoch 01411: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1412/5000\n",
      "\n",
      "Epoch 01412: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1413/5000\n",
      "\n",
      "Epoch 01413: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1414/5000\n",
      "\n",
      "Epoch 01414: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1415/5000\n",
      "\n",
      "Epoch 01415: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 1416/5000\n",
      "\n",
      "Epoch 01416: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1417/5000\n",
      "\n",
      "Epoch 01417: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1418/5000\n",
      "\n",
      "Epoch 01418: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1419/5000\n",
      "\n",
      "Epoch 01419: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0138\n",
      "Epoch 1420/5000\n",
      "\n",
      "Epoch 01420: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0132\n",
      "Epoch 1421/5000\n",
      "\n",
      "Epoch 01421: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1422/5000\n",
      "\n",
      "Epoch 01422: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1423/5000\n",
      "\n",
      "Epoch 01423: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0139\n",
      "Epoch 1424/5000\n",
      "\n",
      "Epoch 01424: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0133\n",
      "Epoch 1425/5000\n",
      "\n",
      "Epoch 01425: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1426/5000\n",
      "\n",
      "Epoch 01426: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1427/5000\n",
      "\n",
      "Epoch 01427: loss did not improve from 0.01312\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1428/5000\n",
      "\n",
      "Epoch 01428: loss improved from 0.01312 to 0.01310, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0131\n",
      "Epoch 1429/5000\n",
      "\n",
      "Epoch 01429: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1430/5000\n",
      "\n",
      "Epoch 01430: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1431/5000\n",
      "\n",
      "Epoch 01431: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1432/5000\n",
      "\n",
      "Epoch 01432: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1433/5000\n",
      "\n",
      "Epoch 01433: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1434/5000\n",
      "\n",
      "Epoch 01434: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1435/5000\n",
      "\n",
      "Epoch 01435: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1436/5000\n",
      "\n",
      "Epoch 01436: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1437/5000\n",
      "\n",
      "Epoch 01437: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1438/5000\n",
      "\n",
      "Epoch 01438: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1439/5000\n",
      "\n",
      "Epoch 01439: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1440/5000\n",
      "\n",
      "Epoch 01440: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1441/5000\n",
      "\n",
      "Epoch 01441: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1442/5000\n",
      "\n",
      "Epoch 01442: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1443/5000\n",
      "\n",
      "Epoch 01443: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1444/5000\n",
      "\n",
      "Epoch 01444: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1445/5000\n",
      "\n",
      "Epoch 01445: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1446/5000\n",
      "\n",
      "Epoch 01446: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1447/5000\n",
      "\n",
      "Epoch 01447: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1448/5000\n",
      "\n",
      "Epoch 01448: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1449/5000\n",
      "\n",
      "Epoch 01449: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1450/5000\n",
      "\n",
      "Epoch 01450: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1451/5000\n",
      "\n",
      "Epoch 01451: loss did not improve from 0.01310\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1452/5000\n",
      "\n",
      "Epoch 01452: loss improved from 0.01310 to 0.01309, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0131\n",
      "Epoch 1453/5000\n",
      "\n",
      "Epoch 01453: loss did not improve from 0.01309\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1454/5000\n",
      "\n",
      "Epoch 01454: loss improved from 0.01309 to 0.01307, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0131\n",
      "Epoch 1455/5000\n",
      "\n",
      "Epoch 01455: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1456/5000\n",
      "\n",
      "Epoch 01456: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1457/5000\n",
      "\n",
      "Epoch 01457: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1458/5000\n",
      "\n",
      "Epoch 01458: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1459/5000\n",
      "\n",
      "Epoch 01459: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1460/5000\n",
      "\n",
      "Epoch 01460: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1461/5000\n",
      "\n",
      "Epoch 01461: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1462/5000\n",
      "\n",
      "Epoch 01462: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1463/5000\n",
      "\n",
      "Epoch 01463: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1464/5000\n",
      "\n",
      "Epoch 01464: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1465/5000\n",
      "\n",
      "Epoch 01465: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1466/5000\n",
      "\n",
      "Epoch 01466: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1467/5000\n",
      "\n",
      "Epoch 01467: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1468/5000\n",
      "\n",
      "Epoch 01468: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1469/5000\n",
      "\n",
      "Epoch 01469: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1470/5000\n",
      "\n",
      "Epoch 01470: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1471/5000\n",
      "\n",
      "Epoch 01471: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1472/5000\n",
      "\n",
      "Epoch 01472: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1473/5000\n",
      "\n",
      "Epoch 01473: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0133\n",
      "Epoch 1474/5000\n",
      "\n",
      "Epoch 01474: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1475/5000\n",
      "\n",
      "Epoch 01475: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0136\n",
      "Epoch 1476/5000\n",
      "\n",
      "Epoch 01476: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1477/5000\n",
      "\n",
      "Epoch 01477: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1478/5000\n",
      "\n",
      "Epoch 01478: loss did not improve from 0.01307\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1479/5000\n",
      "\n",
      "Epoch 01479: loss improved from 0.01307 to 0.01297, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0130\n",
      "Epoch 1480/5000\n",
      "\n",
      "Epoch 01480: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1481/5000\n",
      "\n",
      "Epoch 01481: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1482/5000\n",
      "\n",
      "Epoch 01482: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1483/5000\n",
      "\n",
      "Epoch 01483: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1484/5000\n",
      "\n",
      "Epoch 01484: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1485/5000\n",
      "\n",
      "Epoch 01485: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1486/5000\n",
      "\n",
      "Epoch 01486: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1487/5000\n",
      "\n",
      "Epoch 01487: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1488/5000\n",
      "\n",
      "Epoch 01488: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1489/5000\n",
      "\n",
      "Epoch 01489: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1490/5000\n",
      "\n",
      "Epoch 01490: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1491/5000\n",
      "\n",
      "Epoch 01491: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1492/5000\n",
      "\n",
      "Epoch 01492: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1493/5000\n",
      "\n",
      "Epoch 01493: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1494/5000\n",
      "\n",
      "Epoch 01494: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1495/5000\n",
      "\n",
      "Epoch 01495: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1496/5000\n",
      "\n",
      "Epoch 01496: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1497/5000\n",
      "\n",
      "Epoch 01497: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1498/5000\n",
      "\n",
      "Epoch 01498: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1499/5000\n",
      "\n",
      "Epoch 01499: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1500/5000\n",
      "\n",
      "Epoch 01500: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1501/5000\n",
      "\n",
      "Epoch 01501: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1502/5000\n",
      "\n",
      "Epoch 01502: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1503/5000\n",
      "\n",
      "Epoch 01503: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1504/5000\n",
      "\n",
      "Epoch 01504: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1505/5000\n",
      "\n",
      "Epoch 01505: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1506/5000\n",
      "\n",
      "Epoch 01506: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1507/5000\n",
      "\n",
      "Epoch 01507: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1508/5000\n",
      "\n",
      "Epoch 01508: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1509/5000\n",
      "\n",
      "Epoch 01509: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1510/5000\n",
      "\n",
      "Epoch 01510: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1511/5000\n",
      "\n",
      "Epoch 01511: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1512/5000\n",
      "\n",
      "Epoch 01512: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1513/5000\n",
      "\n",
      "Epoch 01513: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1514/5000\n",
      "\n",
      "Epoch 01514: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1515/5000\n",
      "\n",
      "Epoch 01515: loss did not improve from 0.01297\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1516/5000\n",
      "\n",
      "Epoch 01516: loss improved from 0.01297 to 0.01288, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0129\n",
      "Epoch 1517/5000\n",
      "\n",
      "Epoch 01517: loss improved from 0.01288 to 0.01279, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0128\n",
      "Epoch 1518/5000\n",
      "\n",
      "Epoch 01518: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1519/5000\n",
      "\n",
      "Epoch 01519: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1520/5000\n",
      "\n",
      "Epoch 01520: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1521/5000\n",
      "\n",
      "Epoch 01521: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1522/5000\n",
      "\n",
      "Epoch 01522: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1523/5000\n",
      "\n",
      "Epoch 01523: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1524/5000\n",
      "\n",
      "Epoch 01524: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1525/5000\n",
      "\n",
      "Epoch 01525: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1526/5000\n",
      "\n",
      "Epoch 01526: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1527/5000\n",
      "\n",
      "Epoch 01527: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1528/5000\n",
      "\n",
      "Epoch 01528: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1529/5000\n",
      "\n",
      "Epoch 01529: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1530/5000\n",
      "\n",
      "Epoch 01530: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1531/5000\n",
      "\n",
      "Epoch 01531: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1532/5000\n",
      "\n",
      "Epoch 01532: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1533/5000\n",
      "\n",
      "Epoch 01533: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1534/5000\n",
      "\n",
      "Epoch 01534: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1535/5000\n",
      "\n",
      "Epoch 01535: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1536/5000\n",
      "\n",
      "Epoch 01536: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0130\n",
      "Epoch 1537/5000\n",
      "\n",
      "Epoch 01537: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0132\n",
      "Epoch 1538/5000\n",
      "\n",
      "Epoch 01538: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1539/5000\n",
      "\n",
      "Epoch 01539: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1540/5000\n",
      "\n",
      "Epoch 01540: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1541/5000\n",
      "\n",
      "Epoch 01541: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1542/5000\n",
      "\n",
      "Epoch 01542: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1543/5000\n",
      "\n",
      "Epoch 01543: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0135\n",
      "Epoch 1544/5000\n",
      "\n",
      "Epoch 01544: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0130\n",
      "Epoch 1545/5000\n",
      "\n",
      "Epoch 01545: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1546/5000\n",
      "\n",
      "Epoch 01546: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1547/5000\n",
      "\n",
      "Epoch 01547: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1548/5000\n",
      "\n",
      "Epoch 01548: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1549/5000\n",
      "\n",
      "Epoch 01549: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1550/5000\n",
      "\n",
      "Epoch 01550: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1551/5000\n",
      "\n",
      "Epoch 01551: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1552/5000\n",
      "\n",
      "Epoch 01552: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1553/5000\n",
      "\n",
      "Epoch 01553: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1554/5000\n",
      "\n",
      "Epoch 01554: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1555/5000\n",
      "\n",
      "Epoch 01555: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1556/5000\n",
      "\n",
      "Epoch 01556: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1557/5000\n",
      "\n",
      "Epoch 01557: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1558/5000\n",
      "\n",
      "Epoch 01558: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1559/5000\n",
      "\n",
      "Epoch 01559: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1560/5000\n",
      "\n",
      "Epoch 01560: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1561/5000\n",
      "\n",
      "Epoch 01561: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1562/5000\n",
      "\n",
      "Epoch 01562: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1563/5000\n",
      "\n",
      "Epoch 01563: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1564/5000\n",
      "\n",
      "Epoch 01564: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1565/5000\n",
      "\n",
      "Epoch 01565: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1566/5000\n",
      "\n",
      "Epoch 01566: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1567/5000\n",
      "\n",
      "Epoch 01567: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1568/5000\n",
      "\n",
      "Epoch 01568: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1569/5000\n",
      "\n",
      "Epoch 01569: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1570/5000\n",
      "\n",
      "Epoch 01570: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1571/5000\n",
      "\n",
      "Epoch 01571: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1572/5000\n",
      "\n",
      "Epoch 01572: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1573/5000\n",
      "\n",
      "Epoch 01573: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1574/5000\n",
      "\n",
      "Epoch 01574: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1575/5000\n",
      "\n",
      "Epoch 01575: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0134\n",
      "Epoch 1576/5000\n",
      "\n",
      "Epoch 01576: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1577/5000\n",
      "\n",
      "Epoch 01577: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1578/5000\n",
      "\n",
      "Epoch 01578: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1579/5000\n",
      "\n",
      "Epoch 01579: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1580/5000\n",
      "\n",
      "Epoch 01580: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1581/5000\n",
      "\n",
      "Epoch 01581: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1582/5000\n",
      "\n",
      "Epoch 01582: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1583/5000\n",
      "\n",
      "Epoch 01583: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1584/5000\n",
      "\n",
      "Epoch 01584: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1585/5000\n",
      "\n",
      "Epoch 01585: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1586/5000\n",
      "\n",
      "Epoch 01586: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0130\n",
      "Epoch 1587/5000\n",
      "\n",
      "Epoch 01587: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1588/5000\n",
      "\n",
      "Epoch 01588: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1589/5000\n",
      "\n",
      "Epoch 01589: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1590/5000\n",
      "\n",
      "Epoch 01590: loss did not improve from 0.01279\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1591/5000\n",
      "\n",
      "Epoch 01591: loss improved from 0.01279 to 0.01276, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0128\n",
      "Epoch 1592/5000\n",
      "\n",
      "Epoch 01592: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1593/5000\n",
      "\n",
      "Epoch 01593: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1594/5000\n",
      "\n",
      "Epoch 01594: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1595/5000\n",
      "\n",
      "Epoch 01595: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1596/5000\n",
      "\n",
      "Epoch 01596: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1597/5000\n",
      "\n",
      "Epoch 01597: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1598/5000\n",
      "\n",
      "Epoch 01598: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1599/5000\n",
      "\n",
      "Epoch 01599: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1600/5000\n",
      "\n",
      "Epoch 01600: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1601/5000\n",
      "\n",
      "Epoch 01601: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1602/5000\n",
      "\n",
      "Epoch 01602: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0133\n",
      "Epoch 1603/5000\n",
      "\n",
      "Epoch 01603: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1604/5000\n",
      "\n",
      "Epoch 01604: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1605/5000\n",
      "\n",
      "Epoch 01605: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1606/5000\n",
      "\n",
      "Epoch 01606: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1607/5000\n",
      "\n",
      "Epoch 01607: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1608/5000\n",
      "\n",
      "Epoch 01608: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1609/5000\n",
      "\n",
      "Epoch 01609: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1610/5000\n",
      "\n",
      "Epoch 01610: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1611/5000\n",
      "\n",
      "Epoch 01611: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1612/5000\n",
      "\n",
      "Epoch 01612: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1613/5000\n",
      "\n",
      "Epoch 01613: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1614/5000\n",
      "\n",
      "Epoch 01614: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1615/5000\n",
      "\n",
      "Epoch 01615: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 1616/5000\n",
      "\n",
      "Epoch 01616: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1617/5000\n",
      "\n",
      "Epoch 01617: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1618/5000\n",
      "\n",
      "Epoch 01618: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1619/5000\n",
      "\n",
      "Epoch 01619: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1620/5000\n",
      "\n",
      "Epoch 01620: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1621/5000\n",
      "\n",
      "Epoch 01621: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1622/5000\n",
      "\n",
      "Epoch 01622: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1623/5000\n",
      "\n",
      "Epoch 01623: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1624/5000\n",
      "\n",
      "Epoch 01624: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1625/5000\n",
      "\n",
      "Epoch 01625: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1626/5000\n",
      "\n",
      "Epoch 01626: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1627/5000\n",
      "\n",
      "Epoch 01627: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1628/5000\n",
      "\n",
      "Epoch 01628: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1629/5000\n",
      "\n",
      "Epoch 01629: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1630/5000\n",
      "\n",
      "Epoch 01630: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1631/5000\n",
      "\n",
      "Epoch 01631: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1632/5000\n",
      "\n",
      "Epoch 01632: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1633/5000\n",
      "\n",
      "Epoch 01633: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1634/5000\n",
      "\n",
      "Epoch 01634: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1635/5000\n",
      "\n",
      "Epoch 01635: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1636/5000\n",
      "\n",
      "Epoch 01636: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1637/5000\n",
      "\n",
      "Epoch 01637: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1638/5000\n",
      "\n",
      "Epoch 01638: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1639/5000\n",
      "\n",
      "Epoch 01639: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1640/5000\n",
      "\n",
      "Epoch 01640: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1641/5000\n",
      "\n",
      "Epoch 01641: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1642/5000\n",
      "\n",
      "Epoch 01642: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1643/5000\n",
      "\n",
      "Epoch 01643: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1644/5000\n",
      "\n",
      "Epoch 01644: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1645/5000\n",
      "\n",
      "Epoch 01645: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1646/5000\n",
      "\n",
      "Epoch 01646: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1647/5000\n",
      "\n",
      "Epoch 01647: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1648/5000\n",
      "\n",
      "Epoch 01648: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1649/5000\n",
      "\n",
      "Epoch 01649: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1650/5000\n",
      "\n",
      "Epoch 01650: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1651/5000\n",
      "\n",
      "Epoch 01651: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1652/5000\n",
      "\n",
      "Epoch 01652: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1653/5000\n",
      "\n",
      "Epoch 01653: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1654/5000\n",
      "\n",
      "Epoch 01654: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1655/5000\n",
      "\n",
      "Epoch 01655: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1656/5000\n",
      "\n",
      "Epoch 01656: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1657/5000\n",
      "\n",
      "Epoch 01657: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1658/5000\n",
      "\n",
      "Epoch 01658: loss did not improve from 0.01276\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1659/5000\n",
      "\n",
      "Epoch 01659: loss improved from 0.01276 to 0.01272, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 7ms/sample - loss: 0.0127\n",
      "Epoch 1660/5000\n",
      "\n",
      "Epoch 01660: loss did not improve from 0.01272\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1661/5000\n",
      "\n",
      "Epoch 01661: loss did not improve from 0.01272\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1662/5000\n",
      "\n",
      "Epoch 01662: loss did not improve from 0.01272\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1663/5000\n",
      "\n",
      "Epoch 01663: loss did not improve from 0.01272\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1664/5000\n",
      "\n",
      "Epoch 01664: loss did not improve from 0.01272\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1665/5000\n",
      "\n",
      "Epoch 01665: loss improved from 0.01272 to 0.01271, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0127\n",
      "Epoch 1666/5000\n",
      "\n",
      "Epoch 01666: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1667/5000\n",
      "\n",
      "Epoch 01667: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1668/5000\n",
      "\n",
      "Epoch 01668: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1669/5000\n",
      "\n",
      "Epoch 01669: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1670/5000\n",
      "\n",
      "Epoch 01670: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1671/5000\n",
      "\n",
      "Epoch 01671: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1672/5000\n",
      "\n",
      "Epoch 01672: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1673/5000\n",
      "\n",
      "Epoch 01673: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1674/5000\n",
      "\n",
      "Epoch 01674: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1675/5000\n",
      "\n",
      "Epoch 01675: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1676/5000\n",
      "\n",
      "Epoch 01676: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1677/5000\n",
      "\n",
      "Epoch 01677: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1678/5000\n",
      "\n",
      "Epoch 01678: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1679/5000\n",
      "\n",
      "Epoch 01679: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1680/5000\n",
      "\n",
      "Epoch 01680: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1681/5000\n",
      "\n",
      "Epoch 01681: loss did not improve from 0.01271\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1682/5000\n",
      "\n",
      "Epoch 01682: loss improved from 0.01271 to 0.01267, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0127\n",
      "Epoch 1683/5000\n",
      "\n",
      "Epoch 01683: loss did not improve from 0.01267\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1684/5000\n",
      "\n",
      "Epoch 01684: loss improved from 0.01267 to 0.01259, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0126\n",
      "Epoch 1685/5000\n",
      "\n",
      "Epoch 01685: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1686/5000\n",
      "\n",
      "Epoch 01686: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1687/5000\n",
      "\n",
      "Epoch 01687: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1688/5000\n",
      "\n",
      "Epoch 01688: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1689/5000\n",
      "\n",
      "Epoch 01689: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1690/5000\n",
      "\n",
      "Epoch 01690: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1691/5000\n",
      "\n",
      "Epoch 01691: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1692/5000\n",
      "\n",
      "Epoch 01692: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1693/5000\n",
      "\n",
      "Epoch 01693: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1694/5000\n",
      "\n",
      "Epoch 01694: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1695/5000\n",
      "\n",
      "Epoch 01695: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0131\n",
      "Epoch 1696/5000\n",
      "\n",
      "Epoch 01696: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1697/5000\n",
      "\n",
      "Epoch 01697: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1698/5000\n",
      "\n",
      "Epoch 01698: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1699/5000\n",
      "\n",
      "Epoch 01699: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1700/5000\n",
      "\n",
      "Epoch 01700: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1701/5000\n",
      "\n",
      "Epoch 01701: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1702/5000\n",
      "\n",
      "Epoch 01702: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1703/5000\n",
      "\n",
      "Epoch 01703: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1704/5000\n",
      "\n",
      "Epoch 01704: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1705/5000\n",
      "\n",
      "Epoch 01705: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1706/5000\n",
      "\n",
      "Epoch 01706: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1707/5000\n",
      "\n",
      "Epoch 01707: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1708/5000\n",
      "\n",
      "Epoch 01708: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1709/5000\n",
      "\n",
      "Epoch 01709: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1710/5000\n",
      "\n",
      "Epoch 01710: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1711/5000\n",
      "\n",
      "Epoch 01711: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1712/5000\n",
      "\n",
      "Epoch 01712: loss did not improve from 0.01259\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1713/5000\n",
      "\n",
      "Epoch 01713: loss improved from 0.01259 to 0.01254, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0125\n",
      "Epoch 1714/5000\n",
      "\n",
      "Epoch 01714: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1715/5000\n",
      "\n",
      "Epoch 01715: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1716/5000\n",
      "\n",
      "Epoch 01716: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1717/5000\n",
      "\n",
      "Epoch 01717: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1718/5000\n",
      "\n",
      "Epoch 01718: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1719/5000\n",
      "\n",
      "Epoch 01719: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1720/5000\n",
      "\n",
      "Epoch 01720: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0130\n",
      "Epoch 1721/5000\n",
      "\n",
      "Epoch 01721: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1722/5000\n",
      "\n",
      "Epoch 01722: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1723/5000\n",
      "\n",
      "Epoch 01723: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1724/5000\n",
      "\n",
      "Epoch 01724: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1725/5000\n",
      "\n",
      "Epoch 01725: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1726/5000\n",
      "\n",
      "Epoch 01726: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1727/5000\n",
      "\n",
      "Epoch 01727: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1728/5000\n",
      "\n",
      "Epoch 01728: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1729/5000\n",
      "\n",
      "Epoch 01729: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1730/5000\n",
      "\n",
      "Epoch 01730: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1731/5000\n",
      "\n",
      "Epoch 01731: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1732/5000\n",
      "\n",
      "Epoch 01732: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1733/5000\n",
      "\n",
      "Epoch 01733: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1734/5000\n",
      "\n",
      "Epoch 01734: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1735/5000\n",
      "\n",
      "Epoch 01735: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1736/5000\n",
      "\n",
      "Epoch 01736: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1737/5000\n",
      "\n",
      "Epoch 01737: loss did not improve from 0.01254\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1738/5000\n",
      "\n",
      "Epoch 01738: loss improved from 0.01254 to 0.01251, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0125\n",
      "Epoch 1739/5000\n",
      "\n",
      "Epoch 01739: loss did not improve from 0.01251\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1740/5000\n",
      "\n",
      "Epoch 01740: loss did not improve from 0.01251\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0126\n",
      "Epoch 1741/5000\n",
      "\n",
      "Epoch 01741: loss did not improve from 0.01251\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1742/5000\n",
      "\n",
      "Epoch 01742: loss did not improve from 0.01251\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1743/5000\n",
      "\n",
      "Epoch 01743: loss did not improve from 0.01251\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1744/5000\n",
      "\n",
      "Epoch 01744: loss did not improve from 0.01251\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1745/5000\n",
      "\n",
      "Epoch 01745: loss did not improve from 0.01251\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1746/5000\n",
      "\n",
      "Epoch 01746: loss did not improve from 0.01251\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1747/5000\n",
      "\n",
      "Epoch 01747: loss improved from 0.01251 to 0.01246, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0125\n",
      "Epoch 1748/5000\n",
      "\n",
      "Epoch 01748: loss did not improve from 0.01246\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1749/5000\n",
      "\n",
      "Epoch 01749: loss did not improve from 0.01246\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1750/5000\n",
      "\n",
      "Epoch 01750: loss did not improve from 0.01246\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1751/5000\n",
      "\n",
      "Epoch 01751: loss did not improve from 0.01246\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1752/5000\n",
      "\n",
      "Epoch 01752: loss did not improve from 0.01246\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1753/5000\n",
      "\n",
      "Epoch 01753: loss did not improve from 0.01246\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1754/5000\n",
      "\n",
      "Epoch 01754: loss did not improve from 0.01246\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1755/5000\n",
      "\n",
      "Epoch 01755: loss did not improve from 0.01246\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1756/5000\n",
      "\n",
      "Epoch 01756: loss did not improve from 0.01246\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1757/5000\n",
      "\n",
      "Epoch 01757: loss did not improve from 0.01246\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1758/5000\n",
      "\n",
      "Epoch 01758: loss improved from 0.01246 to 0.01242, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0124\n",
      "Epoch 1759/5000\n",
      "\n",
      "Epoch 01759: loss did not improve from 0.01242\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1760/5000\n",
      "\n",
      "Epoch 01760: loss did not improve from 0.01242\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1761/5000\n",
      "\n",
      "Epoch 01761: loss did not improve from 0.01242\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1762/5000\n",
      "\n",
      "Epoch 01762: loss did not improve from 0.01242\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1763/5000\n",
      "\n",
      "Epoch 01763: loss did not improve from 0.01242\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1764/5000\n",
      "\n",
      "Epoch 01764: loss did not improve from 0.01242\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1765/5000\n",
      "\n",
      "Epoch 01765: loss did not improve from 0.01242\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1766/5000\n",
      "\n",
      "Epoch 01766: loss did not improve from 0.01242\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1767/5000\n",
      "\n",
      "Epoch 01767: loss did not improve from 0.01242\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1768/5000\n",
      "\n",
      "Epoch 01768: loss did not improve from 0.01242\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1769/5000\n",
      "\n",
      "Epoch 01769: loss did not improve from 0.01242\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1770/5000\n",
      "\n",
      "Epoch 01770: loss did not improve from 0.01242\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1771/5000\n",
      "\n",
      "Epoch 01771: loss improved from 0.01242 to 0.01240, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 7ms/sample - loss: 0.0124\n",
      "Epoch 1772/5000\n",
      "\n",
      "Epoch 01772: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1773/5000\n",
      "\n",
      "Epoch 01773: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1774/5000\n",
      "\n",
      "Epoch 01774: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1775/5000\n",
      "\n",
      "Epoch 01775: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1776/5000\n",
      "\n",
      "Epoch 01776: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1777/5000\n",
      "\n",
      "Epoch 01777: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1778/5000\n",
      "\n",
      "Epoch 01778: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1779/5000\n",
      "\n",
      "Epoch 01779: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1780/5000\n",
      "\n",
      "Epoch 01780: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1781/5000\n",
      "\n",
      "Epoch 01781: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1782/5000\n",
      "\n",
      "Epoch 01782: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1783/5000\n",
      "\n",
      "Epoch 01783: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0129\n",
      "Epoch 1784/5000\n",
      "\n",
      "Epoch 01784: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1785/5000\n",
      "\n",
      "Epoch 01785: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1786/5000\n",
      "\n",
      "Epoch 01786: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1787/5000\n",
      "\n",
      "Epoch 01787: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1788/5000\n",
      "\n",
      "Epoch 01788: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1789/5000\n",
      "\n",
      "Epoch 01789: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1790/5000\n",
      "\n",
      "Epoch 01790: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1791/5000\n",
      "\n",
      "Epoch 01791: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1792/5000\n",
      "\n",
      "Epoch 01792: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1793/5000\n",
      "\n",
      "Epoch 01793: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1794/5000\n",
      "\n",
      "Epoch 01794: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1795/5000\n",
      "\n",
      "Epoch 01795: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1796/5000\n",
      "\n",
      "Epoch 01796: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1797/5000\n",
      "\n",
      "Epoch 01797: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1798/5000\n",
      "\n",
      "Epoch 01798: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1799/5000\n",
      "\n",
      "Epoch 01799: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1800/5000\n",
      "\n",
      "Epoch 01800: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1801/5000\n",
      "\n",
      "Epoch 01801: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1802/5000\n",
      "\n",
      "Epoch 01802: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1803/5000\n",
      "\n",
      "Epoch 01803: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1804/5000\n",
      "\n",
      "Epoch 01804: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1805/5000\n",
      "\n",
      "Epoch 01805: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1806/5000\n",
      "\n",
      "Epoch 01806: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1807/5000\n",
      "\n",
      "Epoch 01807: loss did not improve from 0.01240\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1808/5000\n",
      "\n",
      "Epoch 01808: loss improved from 0.01240 to 0.01233, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0123\n",
      "Epoch 1809/5000\n",
      "\n",
      "Epoch 01809: loss did not improve from 0.01233\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1810/5000\n",
      "\n",
      "Epoch 01810: loss did not improve from 0.01233\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1811/5000\n",
      "\n",
      "Epoch 01811: loss did not improve from 0.01233\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1812/5000\n",
      "\n",
      "Epoch 01812: loss improved from 0.01233 to 0.01226, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0123\n",
      "Epoch 1813/5000\n",
      "\n",
      "Epoch 01813: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1814/5000\n",
      "\n",
      "Epoch 01814: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1815/5000\n",
      "\n",
      "Epoch 01815: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1816/5000\n",
      "\n",
      "Epoch 01816: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1817/5000\n",
      "\n",
      "Epoch 01817: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1818/5000\n",
      "\n",
      "Epoch 01818: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1819/5000\n",
      "\n",
      "Epoch 01819: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1820/5000\n",
      "\n",
      "Epoch 01820: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1821/5000\n",
      "\n",
      "Epoch 01821: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1822/5000\n",
      "\n",
      "Epoch 01822: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1823/5000\n",
      "\n",
      "Epoch 01823: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1824/5000\n",
      "\n",
      "Epoch 01824: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1825/5000\n",
      "\n",
      "Epoch 01825: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1826/5000\n",
      "\n",
      "Epoch 01826: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1827/5000\n",
      "\n",
      "Epoch 01827: loss did not improve from 0.01226\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1828/5000\n",
      "\n",
      "Epoch 01828: loss improved from 0.01226 to 0.01220, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0122\n",
      "Epoch 1829/5000\n",
      "\n",
      "Epoch 01829: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1830/5000\n",
      "\n",
      "Epoch 01830: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1831/5000\n",
      "\n",
      "Epoch 01831: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1832/5000\n",
      "\n",
      "Epoch 01832: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1833/5000\n",
      "\n",
      "Epoch 01833: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1834/5000\n",
      "\n",
      "Epoch 01834: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1835/5000\n",
      "\n",
      "Epoch 01835: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1836/5000\n",
      "\n",
      "Epoch 01836: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1837/5000\n",
      "\n",
      "Epoch 01837: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1838/5000\n",
      "\n",
      "Epoch 01838: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1839/5000\n",
      "\n",
      "Epoch 01839: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1840/5000\n",
      "\n",
      "Epoch 01840: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1841/5000\n",
      "\n",
      "Epoch 01841: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1842/5000\n",
      "\n",
      "Epoch 01842: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1843/5000\n",
      "\n",
      "Epoch 01843: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1844/5000\n",
      "\n",
      "Epoch 01844: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1845/5000\n",
      "\n",
      "Epoch 01845: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1846/5000\n",
      "\n",
      "Epoch 01846: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1847/5000\n",
      "\n",
      "Epoch 01847: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1848/5000\n",
      "\n",
      "Epoch 01848: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0127\n",
      "Epoch 1849/5000\n",
      "\n",
      "Epoch 01849: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1850/5000\n",
      "\n",
      "Epoch 01850: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1851/5000\n",
      "\n",
      "Epoch 01851: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0126\n",
      "Epoch 1852/5000\n",
      "\n",
      "Epoch 01852: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1853/5000\n",
      "\n",
      "Epoch 01853: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0128\n",
      "Epoch 1854/5000\n",
      "\n",
      "Epoch 01854: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1855/5000\n",
      "\n",
      "Epoch 01855: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1856/5000\n",
      "\n",
      "Epoch 01856: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1857/5000\n",
      "\n",
      "Epoch 01857: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1858/5000\n",
      "\n",
      "Epoch 01858: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1859/5000\n",
      "\n",
      "Epoch 01859: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1860/5000\n",
      "\n",
      "Epoch 01860: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1861/5000\n",
      "\n",
      "Epoch 01861: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1862/5000\n",
      "\n",
      "Epoch 01862: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1863/5000\n",
      "\n",
      "Epoch 01863: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1864/5000\n",
      "\n",
      "Epoch 01864: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1865/5000\n",
      "\n",
      "Epoch 01865: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1866/5000\n",
      "\n",
      "Epoch 01866: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1867/5000\n",
      "\n",
      "Epoch 01867: loss did not improve from 0.01220\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1868/5000\n",
      "\n",
      "Epoch 01868: loss improved from 0.01220 to 0.01218, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0122\n",
      "Epoch 1869/5000\n",
      "\n",
      "Epoch 01869: loss did not improve from 0.01218\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1870/5000\n",
      "\n",
      "Epoch 01870: loss did not improve from 0.01218\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1871/5000\n",
      "\n",
      "Epoch 01871: loss did not improve from 0.01218\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1872/5000\n",
      "\n",
      "Epoch 01872: loss did not improve from 0.01218\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1873/5000\n",
      "\n",
      "Epoch 01873: loss did not improve from 0.01218\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1874/5000\n",
      "\n",
      "Epoch 01874: loss improved from 0.01218 to 0.01211, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0121\n",
      "Epoch 1875/5000\n",
      "\n",
      "Epoch 01875: loss did not improve from 0.01211\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1876/5000\n",
      "\n",
      "Epoch 01876: loss did not improve from 0.01211\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1877/5000\n",
      "\n",
      "Epoch 01877: loss improved from 0.01211 to 0.01204, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0120\n",
      "Epoch 1878/5000\n",
      "\n",
      "Epoch 01878: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1879/5000\n",
      "\n",
      "Epoch 01879: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1880/5000\n",
      "\n",
      "Epoch 01880: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1881/5000\n",
      "\n",
      "Epoch 01881: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1882/5000\n",
      "\n",
      "Epoch 01882: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1883/5000\n",
      "\n",
      "Epoch 01883: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1884/5000\n",
      "\n",
      "Epoch 01884: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1885/5000\n",
      "\n",
      "Epoch 01885: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1886/5000\n",
      "\n",
      "Epoch 01886: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1887/5000\n",
      "\n",
      "Epoch 01887: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1888/5000\n",
      "\n",
      "Epoch 01888: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1889/5000\n",
      "\n",
      "Epoch 01889: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1890/5000\n",
      "\n",
      "Epoch 01890: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1891/5000\n",
      "\n",
      "Epoch 01891: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1892/5000\n",
      "\n",
      "Epoch 01892: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1893/5000\n",
      "\n",
      "Epoch 01893: loss did not improve from 0.01204\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1894/5000\n",
      "\n",
      "Epoch 01894: loss improved from 0.01204 to 0.01193, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0119\n",
      "Epoch 1895/5000\n",
      "\n",
      "Epoch 01895: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1896/5000\n",
      "\n",
      "Epoch 01896: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1897/5000\n",
      "\n",
      "Epoch 01897: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1898/5000\n",
      "\n",
      "Epoch 01898: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1899/5000\n",
      "\n",
      "Epoch 01899: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1900/5000\n",
      "\n",
      "Epoch 01900: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1901/5000\n",
      "\n",
      "Epoch 01901: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1902/5000\n",
      "\n",
      "Epoch 01902: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1903/5000\n",
      "\n",
      "Epoch 01903: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0122\n",
      "Epoch 1904/5000\n",
      "\n",
      "Epoch 01904: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1905/5000\n",
      "\n",
      "Epoch 01905: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0123\n",
      "Epoch 1906/5000\n",
      "\n",
      "Epoch 01906: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1907/5000\n",
      "\n",
      "Epoch 01907: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1908/5000\n",
      "\n",
      "Epoch 01908: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1909/5000\n",
      "\n",
      "Epoch 01909: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1910/5000\n",
      "\n",
      "Epoch 01910: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1911/5000\n",
      "\n",
      "Epoch 01911: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1912/5000\n",
      "\n",
      "Epoch 01912: loss did not improve from 0.01193\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0122\n",
      "Epoch 1913/5000\n",
      "\n",
      "Epoch 01913: loss improved from 0.01193 to 0.01189, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0119\n",
      "Epoch 1914/5000\n",
      "\n",
      "Epoch 01914: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1915/5000\n",
      "\n",
      "Epoch 01915: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1916/5000\n",
      "\n",
      "Epoch 01916: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1917/5000\n",
      "\n",
      "Epoch 01917: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1918/5000\n",
      "\n",
      "Epoch 01918: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1919/5000\n",
      "\n",
      "Epoch 01919: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1920/5000\n",
      "\n",
      "Epoch 01920: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1921/5000\n",
      "\n",
      "Epoch 01921: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1922/5000\n",
      "\n",
      "Epoch 01922: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1923/5000\n",
      "\n",
      "Epoch 01923: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1924/5000\n",
      "\n",
      "Epoch 01924: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1925/5000\n",
      "\n",
      "Epoch 01925: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1926/5000\n",
      "\n",
      "Epoch 01926: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1927/5000\n",
      "\n",
      "Epoch 01927: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 1928/5000\n",
      "\n",
      "Epoch 01928: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1929/5000\n",
      "\n",
      "Epoch 01929: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1930/5000\n",
      "\n",
      "Epoch 01930: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1931/5000\n",
      "\n",
      "Epoch 01931: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1932/5000\n",
      "\n",
      "Epoch 01932: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1933/5000\n",
      "\n",
      "Epoch 01933: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1934/5000\n",
      "\n",
      "Epoch 01934: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1935/5000\n",
      "\n",
      "Epoch 01935: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1936/5000\n",
      "\n",
      "Epoch 01936: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1937/5000\n",
      "\n",
      "Epoch 01937: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1938/5000\n",
      "\n",
      "Epoch 01938: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1939/5000\n",
      "\n",
      "Epoch 01939: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1940/5000\n",
      "\n",
      "Epoch 01940: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1941/5000\n",
      "\n",
      "Epoch 01941: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1942/5000\n",
      "\n",
      "Epoch 01942: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1943/5000\n",
      "\n",
      "Epoch 01943: loss did not improve from 0.01189\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1944/5000\n",
      "\n",
      "Epoch 01944: loss improved from 0.01189 to 0.01180, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0118\n",
      "Epoch 1945/5000\n",
      "\n",
      "Epoch 01945: loss did not improve from 0.01180\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 1946/5000\n",
      "\n",
      "Epoch 01946: loss did not improve from 0.01180\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1947/5000\n",
      "\n",
      "Epoch 01947: loss did not improve from 0.01180\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1948/5000\n",
      "\n",
      "Epoch 01948: loss did not improve from 0.01180\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0119\n",
      "Epoch 1949/5000\n",
      "\n",
      "Epoch 01949: loss did not improve from 0.01180\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1950/5000\n",
      "\n",
      "Epoch 01950: loss did not improve from 0.01180\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1951/5000\n",
      "\n",
      "Epoch 01951: loss did not improve from 0.01180\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1952/5000\n",
      "\n",
      "Epoch 01952: loss did not improve from 0.01180\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 1953/5000\n",
      "\n",
      "Epoch 01953: loss did not improve from 0.01180\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 1954/5000\n",
      "\n",
      "Epoch 01954: loss did not improve from 0.01180\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1955/5000\n",
      "\n",
      "Epoch 01955: loss improved from 0.01180 to 0.01178, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0118\n",
      "Epoch 1956/5000\n",
      "\n",
      "Epoch 01956: loss improved from 0.01178 to 0.01176, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0118\n",
      "Epoch 1957/5000\n",
      "\n",
      "Epoch 01957: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1958/5000\n",
      "\n",
      "Epoch 01958: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1959/5000\n",
      "\n",
      "Epoch 01959: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1960/5000\n",
      "\n",
      "Epoch 01960: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 1961/5000\n",
      "\n",
      "Epoch 01961: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 1962/5000\n",
      "\n",
      "Epoch 01962: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 1963/5000\n",
      "\n",
      "Epoch 01963: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 1964/5000\n",
      "\n",
      "Epoch 01964: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 1965/5000\n",
      "\n",
      "Epoch 01965: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 1966/5000\n",
      "\n",
      "Epoch 01966: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1967/5000\n",
      "\n",
      "Epoch 01967: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1968/5000\n",
      "\n",
      "Epoch 01968: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1969/5000\n",
      "\n",
      "Epoch 01969: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1970/5000\n",
      "\n",
      "Epoch 01970: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 1971/5000\n",
      "\n",
      "Epoch 01971: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 1972/5000\n",
      "\n",
      "Epoch 01972: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 1973/5000\n",
      "\n",
      "Epoch 01973: loss did not improve from 0.01176\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 1974/5000\n",
      "\n",
      "Epoch 01974: loss improved from 0.01176 to 0.01174, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0117\n",
      "Epoch 1975/5000\n",
      "\n",
      "Epoch 01975: loss did not improve from 0.01174\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1976/5000\n",
      "\n",
      "Epoch 01976: loss did not improve from 0.01174\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 1977/5000\n",
      "\n",
      "Epoch 01977: loss did not improve from 0.01174\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1978/5000\n",
      "\n",
      "Epoch 01978: loss did not improve from 0.01174\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 1979/5000\n",
      "\n",
      "Epoch 01979: loss did not improve from 0.01174\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1980/5000\n",
      "\n",
      "Epoch 01980: loss improved from 0.01174 to 0.01167, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0117\n",
      "Epoch 1981/5000\n",
      "\n",
      "Epoch 01981: loss did not improve from 0.01167\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 1982/5000\n",
      "\n",
      "Epoch 01982: loss improved from 0.01167 to 0.01154, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0115\n",
      "Epoch 1983/5000\n",
      "\n",
      "Epoch 01983: loss did not improve from 0.01154\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 1984/5000\n",
      "\n",
      "Epoch 01984: loss did not improve from 0.01154\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 1985/5000\n",
      "\n",
      "Epoch 01985: loss did not improve from 0.01154\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 1986/5000\n",
      "\n",
      "Epoch 01986: loss did not improve from 0.01154\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1987/5000\n",
      "\n",
      "Epoch 01987: loss did not improve from 0.01154\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 1988/5000\n",
      "\n",
      "Epoch 01988: loss did not improve from 0.01154\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1989/5000\n",
      "\n",
      "Epoch 01989: loss improved from 0.01154 to 0.01153, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0115\n",
      "Epoch 1990/5000\n",
      "\n",
      "Epoch 01990: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 1991/5000\n",
      "\n",
      "Epoch 01991: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 1992/5000\n",
      "\n",
      "Epoch 01992: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 1993/5000\n",
      "\n",
      "Epoch 01993: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 1994/5000\n",
      "\n",
      "Epoch 01994: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1995/5000\n",
      "\n",
      "Epoch 01995: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0124\n",
      "Epoch 1996/5000\n",
      "\n",
      "Epoch 01996: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 1997/5000\n",
      "\n",
      "Epoch 01997: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 1998/5000\n",
      "\n",
      "Epoch 01998: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 1999/5000\n",
      "\n",
      "Epoch 01999: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2000/5000\n",
      "\n",
      "Epoch 02000: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 2001/5000\n",
      "\n",
      "Epoch 02001: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 2002/5000\n",
      "\n",
      "Epoch 02002: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2003/5000\n",
      "\n",
      "Epoch 02003: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 2004/5000\n",
      "\n",
      "Epoch 02004: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 2005/5000\n",
      "\n",
      "Epoch 02005: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0122\n",
      "Epoch 2006/5000\n",
      "\n",
      "Epoch 02006: loss did not improve from 0.01153\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 2007/5000\n",
      "\n",
      "Epoch 02007: loss improved from 0.01153 to 0.01138, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0114\n",
      "Epoch 2008/5000\n",
      "\n",
      "Epoch 02008: loss did not improve from 0.01138\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2009/5000\n",
      "\n",
      "Epoch 02009: loss did not improve from 0.01138\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2010/5000\n",
      "\n",
      "Epoch 02010: loss did not improve from 0.01138\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 2011/5000\n",
      "\n",
      "Epoch 02011: loss did not improve from 0.01138\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 2012/5000\n",
      "\n",
      "Epoch 02012: loss did not improve from 0.01138\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2013/5000\n",
      "\n",
      "Epoch 02013: loss did not improve from 0.01138\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 2014/5000\n",
      "\n",
      "Epoch 02014: loss did not improve from 0.01138\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 2015/5000\n",
      "\n",
      "Epoch 02015: loss did not improve from 0.01138\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 2016/5000\n",
      "\n",
      "Epoch 02016: loss did not improve from 0.01138\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 2017/5000\n",
      "\n",
      "Epoch 02017: loss did not improve from 0.01138\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 2018/5000\n",
      "\n",
      "Epoch 02018: loss did not improve from 0.01138\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 2019/5000\n",
      "\n",
      "Epoch 02019: loss did not improve from 0.01138\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0123\n",
      "Epoch 2020/5000\n",
      "\n",
      "Epoch 02020: loss improved from 0.01138 to 0.01133, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0113\n",
      "Epoch 2021/5000\n",
      "\n",
      "Epoch 02021: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 2022/5000\n",
      "\n",
      "Epoch 02022: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 2023/5000\n",
      "\n",
      "Epoch 02023: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 2024/5000\n",
      "\n",
      "Epoch 02024: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2025/5000\n",
      "\n",
      "Epoch 02025: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2026/5000\n",
      "\n",
      "Epoch 02026: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2027/5000\n",
      "\n",
      "Epoch 02027: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 2028/5000\n",
      "\n",
      "Epoch 02028: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2029/5000\n",
      "\n",
      "Epoch 02029: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2030/5000\n",
      "\n",
      "Epoch 02030: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2031/5000\n",
      "\n",
      "Epoch 02031: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2032/5000\n",
      "\n",
      "Epoch 02032: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2033/5000\n",
      "\n",
      "Epoch 02033: loss improved from 0.01133 to 0.01133, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0113\n",
      "Epoch 2034/5000\n",
      "\n",
      "Epoch 02034: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 2035/5000\n",
      "\n",
      "Epoch 02035: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2036/5000\n",
      "\n",
      "Epoch 02036: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 2037/5000\n",
      "\n",
      "Epoch 02037: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2038/5000\n",
      "\n",
      "Epoch 02038: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2039/5000\n",
      "\n",
      "Epoch 02039: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2040/5000\n",
      "\n",
      "Epoch 02040: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 2041/5000\n",
      "\n",
      "Epoch 02041: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2042/5000\n",
      "\n",
      "Epoch 02042: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2043/5000\n",
      "\n",
      "Epoch 02043: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0121\n",
      "Epoch 2044/5000\n",
      "\n",
      "Epoch 02044: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2045/5000\n",
      "\n",
      "Epoch 02045: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2046/5000\n",
      "\n",
      "Epoch 02046: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 2047/5000\n",
      "\n",
      "Epoch 02047: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2048/5000\n",
      "\n",
      "Epoch 02048: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 2049/5000\n",
      "\n",
      "Epoch 02049: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 2050/5000\n",
      "\n",
      "Epoch 02050: loss did not improve from 0.01133\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2051/5000\n",
      "\n",
      "Epoch 02051: loss improved from 0.01133 to 0.01127, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0113\n",
      "Epoch 2052/5000\n",
      "\n",
      "Epoch 02052: loss did not improve from 0.01127\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2053/5000\n",
      "\n",
      "Epoch 02053: loss did not improve from 0.01127\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 2054/5000\n",
      "\n",
      "Epoch 02054: loss improved from 0.01127 to 0.01111, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0111\n",
      "Epoch 2055/5000\n",
      "\n",
      "Epoch 02055: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2056/5000\n",
      "\n",
      "Epoch 02056: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2057/5000\n",
      "\n",
      "Epoch 02057: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2058/5000\n",
      "\n",
      "Epoch 02058: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2059/5000\n",
      "\n",
      "Epoch 02059: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2060/5000\n",
      "\n",
      "Epoch 02060: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2061/5000\n",
      "\n",
      "Epoch 02061: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 2062/5000\n",
      "\n",
      "Epoch 02062: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 2063/5000\n",
      "\n",
      "Epoch 02063: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 2064/5000\n",
      "\n",
      "Epoch 02064: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2065/5000\n",
      "\n",
      "Epoch 02065: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 2066/5000\n",
      "\n",
      "Epoch 02066: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2067/5000\n",
      "\n",
      "Epoch 02067: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 2068/5000\n",
      "\n",
      "Epoch 02068: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2069/5000\n",
      "\n",
      "Epoch 02069: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 2070/5000\n",
      "\n",
      "Epoch 02070: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2071/5000\n",
      "\n",
      "Epoch 02071: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 2072/5000\n",
      "\n",
      "Epoch 02072: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 2073/5000\n",
      "\n",
      "Epoch 02073: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 2074/5000\n",
      "\n",
      "Epoch 02074: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2075/5000\n",
      "\n",
      "Epoch 02075: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2076/5000\n",
      "\n",
      "Epoch 02076: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 2077/5000\n",
      "\n",
      "Epoch 02077: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2078/5000\n",
      "\n",
      "Epoch 02078: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2079/5000\n",
      "\n",
      "Epoch 02079: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2080/5000\n",
      "\n",
      "Epoch 02080: loss did not improve from 0.01111\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 2081/5000\n",
      "\n",
      "Epoch 02081: loss improved from 0.01111 to 0.01109, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0111\n",
      "Epoch 2082/5000\n",
      "\n",
      "Epoch 02082: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2083/5000\n",
      "\n",
      "Epoch 02083: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 2084/5000\n",
      "\n",
      "Epoch 02084: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2085/5000\n",
      "\n",
      "Epoch 02085: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2086/5000\n",
      "\n",
      "Epoch 02086: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2087/5000\n",
      "\n",
      "Epoch 02087: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 2088/5000\n",
      "\n",
      "Epoch 02088: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2089/5000\n",
      "\n",
      "Epoch 02089: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2090/5000\n",
      "\n",
      "Epoch 02090: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2091/5000\n",
      "\n",
      "Epoch 02091: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2092/5000\n",
      "\n",
      "Epoch 02092: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2093/5000\n",
      "\n",
      "Epoch 02093: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0119\n",
      "Epoch 2094/5000\n",
      "\n",
      "Epoch 02094: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2095/5000\n",
      "\n",
      "Epoch 02095: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2096/5000\n",
      "\n",
      "Epoch 02096: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2097/5000\n",
      "\n",
      "Epoch 02097: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2098/5000\n",
      "\n",
      "Epoch 02098: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2099/5000\n",
      "\n",
      "Epoch 02099: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2100/5000\n",
      "\n",
      "Epoch 02100: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2101/5000\n",
      "\n",
      "Epoch 02101: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2102/5000\n",
      "\n",
      "Epoch 02102: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2103/5000\n",
      "\n",
      "Epoch 02103: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 2104/5000\n",
      "\n",
      "Epoch 02104: loss did not improve from 0.01109\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2105/5000\n",
      "\n",
      "Epoch 02105: loss improved from 0.01109 to 0.01103, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0110\n",
      "Epoch 2106/5000\n",
      "\n",
      "Epoch 02106: loss did not improve from 0.01103\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2107/5000\n",
      "\n",
      "Epoch 02107: loss did not improve from 0.01103\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2108/5000\n",
      "\n",
      "Epoch 02108: loss did not improve from 0.01103\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2109/5000\n",
      "\n",
      "Epoch 02109: loss did not improve from 0.01103\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2110/5000\n",
      "\n",
      "Epoch 02110: loss did not improve from 0.01103\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2111/5000\n",
      "\n",
      "Epoch 02111: loss did not improve from 0.01103\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 2112/5000\n",
      "\n",
      "Epoch 02112: loss did not improve from 0.01103\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2113/5000\n",
      "\n",
      "Epoch 02113: loss improved from 0.01103 to 0.01101, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0110\n",
      "Epoch 2114/5000\n",
      "\n",
      "Epoch 02114: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2115/5000\n",
      "\n",
      "Epoch 02115: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2116/5000\n",
      "\n",
      "Epoch 02116: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2117/5000\n",
      "\n",
      "Epoch 02117: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2118/5000\n",
      "\n",
      "Epoch 02118: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0120\n",
      "Epoch 2119/5000\n",
      "\n",
      "Epoch 02119: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2120/5000\n",
      "\n",
      "Epoch 02120: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2121/5000\n",
      "\n",
      "Epoch 02121: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2122/5000\n",
      "\n",
      "Epoch 02122: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2123/5000\n",
      "\n",
      "Epoch 02123: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2124/5000\n",
      "\n",
      "Epoch 02124: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2125/5000\n",
      "\n",
      "Epoch 02125: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2126/5000\n",
      "\n",
      "Epoch 02126: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2127/5000\n",
      "\n",
      "Epoch 02127: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2128/5000\n",
      "\n",
      "Epoch 02128: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2129/5000\n",
      "\n",
      "Epoch 02129: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2130/5000\n",
      "\n",
      "Epoch 02130: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2131/5000\n",
      "\n",
      "Epoch 02131: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2132/5000\n",
      "\n",
      "Epoch 02132: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2133/5000\n",
      "\n",
      "Epoch 02133: loss did not improve from 0.01101\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2134/5000\n",
      "\n",
      "Epoch 02134: loss improved from 0.01101 to 0.01095, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 7ms/sample - loss: 0.0109\n",
      "Epoch 2135/5000\n",
      "\n",
      "Epoch 02135: loss did not improve from 0.01095\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2136/5000\n",
      "\n",
      "Epoch 02136: loss did not improve from 0.01095\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2137/5000\n",
      "\n",
      "Epoch 02137: loss did not improve from 0.01095\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2138/5000\n",
      "\n",
      "Epoch 02138: loss did not improve from 0.01095\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2139/5000\n",
      "\n",
      "Epoch 02139: loss did not improve from 0.01095\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2140/5000\n",
      "\n",
      "Epoch 02140: loss did not improve from 0.01095\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2141/5000\n",
      "\n",
      "Epoch 02141: loss did not improve from 0.01095\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2142/5000\n",
      "\n",
      "Epoch 02142: loss did not improve from 0.01095\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2143/5000\n",
      "\n",
      "Epoch 02143: loss improved from 0.01095 to 0.01094, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0109\n",
      "Epoch 2144/5000\n",
      "\n",
      "Epoch 02144: loss did not improve from 0.01094\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0116\n",
      "Epoch 2145/5000\n",
      "\n",
      "Epoch 02145: loss did not improve from 0.01094\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2146/5000\n",
      "\n",
      "Epoch 02146: loss did not improve from 0.01094\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2147/5000\n",
      "\n",
      "Epoch 02147: loss did not improve from 0.01094\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2148/5000\n",
      "\n",
      "Epoch 02148: loss did not improve from 0.01094\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2149/5000\n",
      "\n",
      "Epoch 02149: loss did not improve from 0.01094\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2150/5000\n",
      "\n",
      "Epoch 02150: loss improved from 0.01094 to 0.01089, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0109\n",
      "Epoch 2151/5000\n",
      "\n",
      "Epoch 02151: loss did not improve from 0.01089\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2152/5000\n",
      "\n",
      "Epoch 02152: loss did not improve from 0.01089\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2153/5000\n",
      "\n",
      "Epoch 02153: loss did not improve from 0.01089\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2154/5000\n",
      "\n",
      "Epoch 02154: loss did not improve from 0.01089\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2155/5000\n",
      "\n",
      "Epoch 02155: loss did not improve from 0.01089\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2156/5000\n",
      "\n",
      "Epoch 02156: loss improved from 0.01089 to 0.01086, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2157/5000\n",
      "\n",
      "Epoch 02157: loss did not improve from 0.01086\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2158/5000\n",
      "\n",
      "Epoch 02158: loss did not improve from 0.01086\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2159/5000\n",
      "\n",
      "Epoch 02159: loss did not improve from 0.01086\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2160/5000\n",
      "\n",
      "Epoch 02160: loss did not improve from 0.01086\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2161/5000\n",
      "\n",
      "Epoch 02161: loss did not improve from 0.01086\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2162/5000\n",
      "\n",
      "Epoch 02162: loss did not improve from 0.01086\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2163/5000\n",
      "\n",
      "Epoch 02163: loss did not improve from 0.01086\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2164/5000\n",
      "\n",
      "Epoch 02164: loss did not improve from 0.01086\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2165/5000\n",
      "\n",
      "Epoch 02165: loss did not improve from 0.01086\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0118\n",
      "Epoch 2166/5000\n",
      "\n",
      "Epoch 02166: loss did not improve from 0.01086\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2167/5000\n",
      "\n",
      "Epoch 02167: loss did not improve from 0.01086\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2168/5000\n",
      "\n",
      "Epoch 02168: loss improved from 0.01086 to 0.01084, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0108\n",
      "Epoch 2169/5000\n",
      "\n",
      "Epoch 02169: loss did not improve from 0.01084\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2170/5000\n",
      "\n",
      "Epoch 02170: loss did not improve from 0.01084\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2171/5000\n",
      "\n",
      "Epoch 02171: loss did not improve from 0.01084\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2172/5000\n",
      "\n",
      "Epoch 02172: loss did not improve from 0.01084\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2173/5000\n",
      "\n",
      "Epoch 02173: loss did not improve from 0.01084\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2174/5000\n",
      "\n",
      "Epoch 02174: loss did not improve from 0.01084\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2175/5000\n",
      "\n",
      "Epoch 02175: loss improved from 0.01084 to 0.01073, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0107\n",
      "Epoch 2176/5000\n",
      "\n",
      "Epoch 02176: loss improved from 0.01073 to 0.01064, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0106\n",
      "Epoch 2177/5000\n",
      "\n",
      "Epoch 02177: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2178/5000\n",
      "\n",
      "Epoch 02178: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0116\n",
      "Epoch 2179/5000\n",
      "\n",
      "Epoch 02179: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2180/5000\n",
      "\n",
      "Epoch 02180: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2181/5000\n",
      "\n",
      "Epoch 02181: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2182/5000\n",
      "\n",
      "Epoch 02182: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2183/5000\n",
      "\n",
      "Epoch 02183: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2184/5000\n",
      "\n",
      "Epoch 02184: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2185/5000\n",
      "\n",
      "Epoch 02185: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2186/5000\n",
      "\n",
      "Epoch 02186: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2187/5000\n",
      "\n",
      "Epoch 02187: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0117\n",
      "Epoch 2188/5000\n",
      "\n",
      "Epoch 02188: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2189/5000\n",
      "\n",
      "Epoch 02189: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2190/5000\n",
      "\n",
      "Epoch 02190: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2191/5000\n",
      "\n",
      "Epoch 02191: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2192/5000\n",
      "\n",
      "Epoch 02192: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2193/5000\n",
      "\n",
      "Epoch 02193: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2194/5000\n",
      "\n",
      "Epoch 02194: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2195/5000\n",
      "\n",
      "Epoch 02195: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2196/5000\n",
      "\n",
      "Epoch 02196: loss did not improve from 0.01064\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2197/5000\n",
      "\n",
      "Epoch 02197: loss improved from 0.01064 to 0.01061, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0106\n",
      "Epoch 2198/5000\n",
      "\n",
      "Epoch 02198: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2199/5000\n",
      "\n",
      "Epoch 02199: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2200/5000\n",
      "\n",
      "Epoch 02200: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2201/5000\n",
      "\n",
      "Epoch 02201: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2202/5000\n",
      "\n",
      "Epoch 02202: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2203/5000\n",
      "\n",
      "Epoch 02203: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2204/5000\n",
      "\n",
      "Epoch 02204: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2205/5000\n",
      "\n",
      "Epoch 02205: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2206/5000\n",
      "\n",
      "Epoch 02206: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2207/5000\n",
      "\n",
      "Epoch 02207: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2208/5000\n",
      "\n",
      "Epoch 02208: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2209/5000\n",
      "\n",
      "Epoch 02209: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2210/5000\n",
      "\n",
      "Epoch 02210: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2211/5000\n",
      "\n",
      "Epoch 02211: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2212/5000\n",
      "\n",
      "Epoch 02212: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2213/5000\n",
      "\n",
      "Epoch 02213: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2214/5000\n",
      "\n",
      "Epoch 02214: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2215/5000\n",
      "\n",
      "Epoch 02215: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2216/5000\n",
      "\n",
      "Epoch 02216: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2217/5000\n",
      "\n",
      "Epoch 02217: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2218/5000\n",
      "\n",
      "Epoch 02218: loss did not improve from 0.01061\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2219/5000\n",
      "\n",
      "Epoch 02219: loss improved from 0.01061 to 0.01059, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0106\n",
      "Epoch 2220/5000\n",
      "\n",
      "Epoch 02220: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2221/5000\n",
      "\n",
      "Epoch 02221: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2222/5000\n",
      "\n",
      "Epoch 02222: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2223/5000\n",
      "\n",
      "Epoch 02223: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2224/5000\n",
      "\n",
      "Epoch 02224: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2225/5000\n",
      "\n",
      "Epoch 02225: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2226/5000\n",
      "\n",
      "Epoch 02226: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2227/5000\n",
      "\n",
      "Epoch 02227: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2228/5000\n",
      "\n",
      "Epoch 02228: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2229/5000\n",
      "\n",
      "Epoch 02229: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2230/5000\n",
      "\n",
      "Epoch 02230: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2231/5000\n",
      "\n",
      "Epoch 02231: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2232/5000\n",
      "\n",
      "Epoch 02232: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2233/5000\n",
      "\n",
      "Epoch 02233: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2234/5000\n",
      "\n",
      "Epoch 02234: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2235/5000\n",
      "\n",
      "Epoch 02235: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2236/5000\n",
      "\n",
      "Epoch 02236: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2237/5000\n",
      "\n",
      "Epoch 02237: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2238/5000\n",
      "\n",
      "Epoch 02238: loss did not improve from 0.01059\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2239/5000\n",
      "\n",
      "Epoch 02239: loss improved from 0.01059 to 0.01033, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0103\n",
      "Epoch 2240/5000\n",
      "\n",
      "Epoch 02240: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2241/5000\n",
      "\n",
      "Epoch 02241: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2242/5000\n",
      "\n",
      "Epoch 02242: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2243/5000\n",
      "\n",
      "Epoch 02243: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2244/5000\n",
      "\n",
      "Epoch 02244: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2245/5000\n",
      "\n",
      "Epoch 02245: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2246/5000\n",
      "\n",
      "Epoch 02246: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0115\n",
      "Epoch 2247/5000\n",
      "\n",
      "Epoch 02247: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2248/5000\n",
      "\n",
      "Epoch 02248: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2249/5000\n",
      "\n",
      "Epoch 02249: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2250/5000\n",
      "\n",
      "Epoch 02250: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2251/5000\n",
      "\n",
      "Epoch 02251: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2252/5000\n",
      "\n",
      "Epoch 02252: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0113\n",
      "Epoch 2253/5000\n",
      "\n",
      "Epoch 02253: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2254/5000\n",
      "\n",
      "Epoch 02254: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2255/5000\n",
      "\n",
      "Epoch 02255: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2256/5000\n",
      "\n",
      "Epoch 02256: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2257/5000\n",
      "\n",
      "Epoch 02257: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2258/5000\n",
      "\n",
      "Epoch 02258: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2259/5000\n",
      "\n",
      "Epoch 02259: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2260/5000\n",
      "\n",
      "Epoch 02260: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2261/5000\n",
      "\n",
      "Epoch 02261: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2262/5000\n",
      "\n",
      "Epoch 02262: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2263/5000\n",
      "\n",
      "Epoch 02263: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2264/5000\n",
      "\n",
      "Epoch 02264: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2265/5000\n",
      "\n",
      "Epoch 02265: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2266/5000\n",
      "\n",
      "Epoch 02266: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2267/5000\n",
      "\n",
      "Epoch 02267: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2268/5000\n",
      "\n",
      "Epoch 02268: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0114\n",
      "Epoch 2269/5000\n",
      "\n",
      "Epoch 02269: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2270/5000\n",
      "\n",
      "Epoch 02270: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2271/5000\n",
      "\n",
      "Epoch 02271: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2272/5000\n",
      "\n",
      "Epoch 02272: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2273/5000\n",
      "\n",
      "Epoch 02273: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2274/5000\n",
      "\n",
      "Epoch 02274: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2275/5000\n",
      "\n",
      "Epoch 02275: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2276/5000\n",
      "\n",
      "Epoch 02276: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2277/5000\n",
      "\n",
      "Epoch 02277: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2278/5000\n",
      "\n",
      "Epoch 02278: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2279/5000\n",
      "\n",
      "Epoch 02279: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2280/5000\n",
      "\n",
      "Epoch 02280: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0111\n",
      "Epoch 2281/5000\n",
      "\n",
      "Epoch 02281: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2282/5000\n",
      "\n",
      "Epoch 02282: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2283/5000\n",
      "\n",
      "Epoch 02283: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2284/5000\n",
      "\n",
      "Epoch 02284: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2285/5000\n",
      "\n",
      "Epoch 02285: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2286/5000\n",
      "\n",
      "Epoch 02286: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2287/5000\n",
      "\n",
      "Epoch 02287: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2288/5000\n",
      "\n",
      "Epoch 02288: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2289/5000\n",
      "\n",
      "Epoch 02289: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2290/5000\n",
      "\n",
      "Epoch 02290: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2291/5000\n",
      "\n",
      "Epoch 02291: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2292/5000\n",
      "\n",
      "Epoch 02292: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2293/5000\n",
      "\n",
      "Epoch 02293: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2294/5000\n",
      "\n",
      "Epoch 02294: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2295/5000\n",
      "\n",
      "Epoch 02295: loss did not improve from 0.01033\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2296/5000\n",
      "\n",
      "Epoch 02296: loss improved from 0.01033 to 0.01028, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0103\n",
      "Epoch 2297/5000\n",
      "\n",
      "Epoch 02297: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2298/5000\n",
      "\n",
      "Epoch 02298: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2299/5000\n",
      "\n",
      "Epoch 02299: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2300/5000\n",
      "\n",
      "Epoch 02300: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2301/5000\n",
      "\n",
      "Epoch 02301: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2302/5000\n",
      "\n",
      "Epoch 02302: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2303/5000\n",
      "\n",
      "Epoch 02303: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2304/5000\n",
      "\n",
      "Epoch 02304: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2305/5000\n",
      "\n",
      "Epoch 02305: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2306/5000\n",
      "\n",
      "Epoch 02306: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2307/5000\n",
      "\n",
      "Epoch 02307: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2308/5000\n",
      "\n",
      "Epoch 02308: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2309/5000\n",
      "\n",
      "Epoch 02309: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2310/5000\n",
      "\n",
      "Epoch 02310: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2311/5000\n",
      "\n",
      "Epoch 02311: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2312/5000\n",
      "\n",
      "Epoch 02312: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2313/5000\n",
      "\n",
      "Epoch 02313: loss did not improve from 0.01028\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2314/5000\n",
      "\n",
      "Epoch 02314: loss improved from 0.01028 to 0.01018, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0102\n",
      "Epoch 2315/5000\n",
      "\n",
      "Epoch 02315: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2316/5000\n",
      "\n",
      "Epoch 02316: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2317/5000\n",
      "\n",
      "Epoch 02317: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2318/5000\n",
      "\n",
      "Epoch 02318: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2319/5000\n",
      "\n",
      "Epoch 02319: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2320/5000\n",
      "\n",
      "Epoch 02320: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2321/5000\n",
      "\n",
      "Epoch 02321: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2322/5000\n",
      "\n",
      "Epoch 02322: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2323/5000\n",
      "\n",
      "Epoch 02323: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2324/5000\n",
      "\n",
      "Epoch 02324: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2325/5000\n",
      "\n",
      "Epoch 02325: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2326/5000\n",
      "\n",
      "Epoch 02326: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2327/5000\n",
      "\n",
      "Epoch 02327: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2328/5000\n",
      "\n",
      "Epoch 02328: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2329/5000\n",
      "\n",
      "Epoch 02329: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2330/5000\n",
      "\n",
      "Epoch 02330: loss did not improve from 0.01018\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2331/5000\n",
      "\n",
      "Epoch 02331: loss improved from 0.01018 to 0.01010, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0101\n",
      "Epoch 2332/5000\n",
      "\n",
      "Epoch 02332: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2333/5000\n",
      "\n",
      "Epoch 02333: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2334/5000\n",
      "\n",
      "Epoch 02334: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2335/5000\n",
      "\n",
      "Epoch 02335: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2336/5000\n",
      "\n",
      "Epoch 02336: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2337/5000\n",
      "\n",
      "Epoch 02337: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2338/5000\n",
      "\n",
      "Epoch 02338: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2339/5000\n",
      "\n",
      "Epoch 02339: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2340/5000\n",
      "\n",
      "Epoch 02340: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2341/5000\n",
      "\n",
      "Epoch 02341: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2342/5000\n",
      "\n",
      "Epoch 02342: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2343/5000\n",
      "\n",
      "Epoch 02343: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2344/5000\n",
      "\n",
      "Epoch 02344: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2345/5000\n",
      "\n",
      "Epoch 02345: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2346/5000\n",
      "\n",
      "Epoch 02346: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2347/5000\n",
      "\n",
      "Epoch 02347: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2348/5000\n",
      "\n",
      "Epoch 02348: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0106\n",
      "Epoch 2349/5000\n",
      "\n",
      "Epoch 02349: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2350/5000\n",
      "\n",
      "Epoch 02350: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2351/5000\n",
      "\n",
      "Epoch 02351: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2352/5000\n",
      "\n",
      "Epoch 02352: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2353/5000\n",
      "\n",
      "Epoch 02353: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2354/5000\n",
      "\n",
      "Epoch 02354: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2355/5000\n",
      "\n",
      "Epoch 02355: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2356/5000\n",
      "\n",
      "Epoch 02356: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2357/5000\n",
      "\n",
      "Epoch 02357: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2358/5000\n",
      "\n",
      "Epoch 02358: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2359/5000\n",
      "\n",
      "Epoch 02359: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2360/5000\n",
      "\n",
      "Epoch 02360: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2361/5000\n",
      "\n",
      "Epoch 02361: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2362/5000\n",
      "\n",
      "Epoch 02362: loss did not improve from 0.01010\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2363/5000\n",
      "\n",
      "Epoch 02363: loss improved from 0.01010 to 0.01003, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0100\n",
      "Epoch 2364/5000\n",
      "\n",
      "Epoch 02364: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2365/5000\n",
      "\n",
      "Epoch 02365: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2366/5000\n",
      "\n",
      "Epoch 02366: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0109\n",
      "Epoch 2367/5000\n",
      "\n",
      "Epoch 02367: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2368/5000\n",
      "\n",
      "Epoch 02368: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2369/5000\n",
      "\n",
      "Epoch 02369: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0109\n",
      "Epoch 2370/5000\n",
      "\n",
      "Epoch 02370: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2371/5000\n",
      "\n",
      "Epoch 02371: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2372/5000\n",
      "\n",
      "Epoch 02372: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2373/5000\n",
      "\n",
      "Epoch 02373: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2374/5000\n",
      "\n",
      "Epoch 02374: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2375/5000\n",
      "\n",
      "Epoch 02375: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2376/5000\n",
      "\n",
      "Epoch 02376: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2377/5000\n",
      "\n",
      "Epoch 02377: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2378/5000\n",
      "\n",
      "Epoch 02378: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2379/5000\n",
      "\n",
      "Epoch 02379: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2380/5000\n",
      "\n",
      "Epoch 02380: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2381/5000\n",
      "\n",
      "Epoch 02381: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0110\n",
      "Epoch 2382/5000\n",
      "\n",
      "Epoch 02382: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0104\n",
      "Epoch 2383/5000\n",
      "\n",
      "Epoch 02383: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2384/5000\n",
      "\n",
      "Epoch 02384: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0104\n",
      "Epoch 2385/5000\n",
      "\n",
      "Epoch 02385: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2386/5000\n",
      "\n",
      "Epoch 02386: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2387/5000\n",
      "\n",
      "Epoch 02387: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2388/5000\n",
      "\n",
      "Epoch 02388: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2389/5000\n",
      "\n",
      "Epoch 02389: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2390/5000\n",
      "\n",
      "Epoch 02390: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2391/5000\n",
      "\n",
      "Epoch 02391: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2392/5000\n",
      "\n",
      "Epoch 02392: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2393/5000\n",
      "\n",
      "Epoch 02393: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0107\n",
      "Epoch 2394/5000\n",
      "\n",
      "Epoch 02394: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2395/5000\n",
      "\n",
      "Epoch 02395: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2396/5000\n",
      "\n",
      "Epoch 02396: loss did not improve from 0.01003\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2397/5000\n",
      "\n",
      "Epoch 02397: loss improved from 0.01003 to 0.00977, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0098\n",
      "Epoch 2398/5000\n",
      "\n",
      "Epoch 02398: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2399/5000\n",
      "\n",
      "Epoch 02399: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2400/5000\n",
      "\n",
      "Epoch 02400: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2401/5000\n",
      "\n",
      "Epoch 02401: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2402/5000\n",
      "\n",
      "Epoch 02402: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2403/5000\n",
      "\n",
      "Epoch 02403: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2404/5000\n",
      "\n",
      "Epoch 02404: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2405/5000\n",
      "\n",
      "Epoch 02405: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2406/5000\n",
      "\n",
      "Epoch 02406: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2407/5000\n",
      "\n",
      "Epoch 02407: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2408/5000\n",
      "\n",
      "Epoch 02408: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2409/5000\n",
      "\n",
      "Epoch 02409: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2410/5000\n",
      "\n",
      "Epoch 02410: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2411/5000\n",
      "\n",
      "Epoch 02411: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2412/5000\n",
      "\n",
      "Epoch 02412: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2413/5000\n",
      "\n",
      "Epoch 02413: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2414/5000\n",
      "\n",
      "Epoch 02414: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2415/5000\n",
      "\n",
      "Epoch 02415: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2416/5000\n",
      "\n",
      "Epoch 02416: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2417/5000\n",
      "\n",
      "Epoch 02417: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2418/5000\n",
      "\n",
      "Epoch 02418: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2419/5000\n",
      "\n",
      "Epoch 02419: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2420/5000\n",
      "\n",
      "Epoch 02420: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2421/5000\n",
      "\n",
      "Epoch 02421: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2422/5000\n",
      "\n",
      "Epoch 02422: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2423/5000\n",
      "\n",
      "Epoch 02423: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2424/5000\n",
      "\n",
      "Epoch 02424: loss did not improve from 0.00977\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2425/5000\n",
      "\n",
      "Epoch 02425: loss improved from 0.00977 to 0.00970, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0097\n",
      "Epoch 2426/5000\n",
      "\n",
      "Epoch 02426: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2427/5000\n",
      "\n",
      "Epoch 02427: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2428/5000\n",
      "\n",
      "Epoch 02428: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2429/5000\n",
      "\n",
      "Epoch 02429: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2430/5000\n",
      "\n",
      "Epoch 02430: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2431/5000\n",
      "\n",
      "Epoch 02431: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2432/5000\n",
      "\n",
      "Epoch 02432: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2433/5000\n",
      "\n",
      "Epoch 02433: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2434/5000\n",
      "\n",
      "Epoch 02434: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2435/5000\n",
      "\n",
      "Epoch 02435: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2436/5000\n",
      "\n",
      "Epoch 02436: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2437/5000\n",
      "\n",
      "Epoch 02437: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2438/5000\n",
      "\n",
      "Epoch 02438: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2439/5000\n",
      "\n",
      "Epoch 02439: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2440/5000\n",
      "\n",
      "Epoch 02440: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2441/5000\n",
      "\n",
      "Epoch 02441: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2442/5000\n",
      "\n",
      "Epoch 02442: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2443/5000\n",
      "\n",
      "Epoch 02443: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2444/5000\n",
      "\n",
      "Epoch 02444: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2445/5000\n",
      "\n",
      "Epoch 02445: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2446/5000\n",
      "\n",
      "Epoch 02446: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2447/5000\n",
      "\n",
      "Epoch 02447: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2448/5000\n",
      "\n",
      "Epoch 02448: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2449/5000\n",
      "\n",
      "Epoch 02449: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2450/5000\n",
      "\n",
      "Epoch 02450: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2451/5000\n",
      "\n",
      "Epoch 02451: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2452/5000\n",
      "\n",
      "Epoch 02452: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2453/5000\n",
      "\n",
      "Epoch 02453: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2454/5000\n",
      "\n",
      "Epoch 02454: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2455/5000\n",
      "\n",
      "Epoch 02455: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2456/5000\n",
      "\n",
      "Epoch 02456: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2457/5000\n",
      "\n",
      "Epoch 02457: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2458/5000\n",
      "\n",
      "Epoch 02458: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2459/5000\n",
      "\n",
      "Epoch 02459: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2460/5000\n",
      "\n",
      "Epoch 02460: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2461/5000\n",
      "\n",
      "Epoch 02461: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2462/5000\n",
      "\n",
      "Epoch 02462: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2463/5000\n",
      "\n",
      "Epoch 02463: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2464/5000\n",
      "\n",
      "Epoch 02464: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2465/5000\n",
      "\n",
      "Epoch 02465: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2466/5000\n",
      "\n",
      "Epoch 02466: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0112\n",
      "Epoch 2467/5000\n",
      "\n",
      "Epoch 02467: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2468/5000\n",
      "\n",
      "Epoch 02468: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2469/5000\n",
      "\n",
      "Epoch 02469: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2470/5000\n",
      "\n",
      "Epoch 02470: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2471/5000\n",
      "\n",
      "Epoch 02471: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2472/5000\n",
      "\n",
      "Epoch 02472: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2473/5000\n",
      "\n",
      "Epoch 02473: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2474/5000\n",
      "\n",
      "Epoch 02474: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2475/5000\n",
      "\n",
      "Epoch 02475: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2476/5000\n",
      "\n",
      "Epoch 02476: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2477/5000\n",
      "\n",
      "Epoch 02477: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2478/5000\n",
      "\n",
      "Epoch 02478: loss did not improve from 0.00970\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2479/5000\n",
      "\n",
      "Epoch 02479: loss improved from 0.00970 to 0.00965, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0097\n",
      "Epoch 2480/5000\n",
      "\n",
      "Epoch 02480: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2481/5000\n",
      "\n",
      "Epoch 02481: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2482/5000\n",
      "\n",
      "Epoch 02482: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2483/5000\n",
      "\n",
      "Epoch 02483: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2484/5000\n",
      "\n",
      "Epoch 02484: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2485/5000\n",
      "\n",
      "Epoch 02485: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2486/5000\n",
      "\n",
      "Epoch 02486: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2487/5000\n",
      "\n",
      "Epoch 02487: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2488/5000\n",
      "\n",
      "Epoch 02488: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2489/5000\n",
      "\n",
      "Epoch 02489: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2490/5000\n",
      "\n",
      "Epoch 02490: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2491/5000\n",
      "\n",
      "Epoch 02491: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2492/5000\n",
      "\n",
      "Epoch 02492: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2493/5000\n",
      "\n",
      "Epoch 02493: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2494/5000\n",
      "\n",
      "Epoch 02494: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2495/5000\n",
      "\n",
      "Epoch 02495: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2496/5000\n",
      "\n",
      "Epoch 02496: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0111\n",
      "Epoch 2497/5000\n",
      "\n",
      "Epoch 02497: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2498/5000\n",
      "\n",
      "Epoch 02498: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2499/5000\n",
      "\n",
      "Epoch 02499: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2500/5000\n",
      "\n",
      "Epoch 02500: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2501/5000\n",
      "\n",
      "Epoch 02501: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2502/5000\n",
      "\n",
      "Epoch 02502: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2503/5000\n",
      "\n",
      "Epoch 02503: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2504/5000\n",
      "\n",
      "Epoch 02504: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2505/5000\n",
      "\n",
      "Epoch 02505: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2506/5000\n",
      "\n",
      "Epoch 02506: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2507/5000\n",
      "\n",
      "Epoch 02507: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2508/5000\n",
      "\n",
      "Epoch 02508: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2509/5000\n",
      "\n",
      "Epoch 02509: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2510/5000\n",
      "\n",
      "Epoch 02510: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2511/5000\n",
      "\n",
      "Epoch 02511: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2512/5000\n",
      "\n",
      "Epoch 02512: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2513/5000\n",
      "\n",
      "Epoch 02513: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2514/5000\n",
      "\n",
      "Epoch 02514: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2515/5000\n",
      "\n",
      "Epoch 02515: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2516/5000\n",
      "\n",
      "Epoch 02516: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2517/5000\n",
      "\n",
      "Epoch 02517: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2518/5000\n",
      "\n",
      "Epoch 02518: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2519/5000\n",
      "\n",
      "Epoch 02519: loss did not improve from 0.00965\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2520/5000\n",
      "\n",
      "Epoch 02520: loss improved from 0.00965 to 0.00951, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0095\n",
      "Epoch 2521/5000\n",
      "\n",
      "Epoch 02521: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2522/5000\n",
      "\n",
      "Epoch 02522: loss did not improve from 0.00951\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2523/5000\n",
      "\n",
      "Epoch 02523: loss improved from 0.00951 to 0.00949, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0095\n",
      "Epoch 2524/5000\n",
      "\n",
      "Epoch 02524: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2525/5000\n",
      "\n",
      "Epoch 02525: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2526/5000\n",
      "\n",
      "Epoch 02526: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2527/5000\n",
      "\n",
      "Epoch 02527: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2528/5000\n",
      "\n",
      "Epoch 02528: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2529/5000\n",
      "\n",
      "Epoch 02529: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2530/5000\n",
      "\n",
      "Epoch 02530: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2531/5000\n",
      "\n",
      "Epoch 02531: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2532/5000\n",
      "\n",
      "Epoch 02532: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2533/5000\n",
      "\n",
      "Epoch 02533: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2534/5000\n",
      "\n",
      "Epoch 02534: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2535/5000\n",
      "\n",
      "Epoch 02535: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2536/5000\n",
      "\n",
      "Epoch 02536: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2537/5000\n",
      "\n",
      "Epoch 02537: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2538/5000\n",
      "\n",
      "Epoch 02538: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2539/5000\n",
      "\n",
      "Epoch 02539: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2540/5000\n",
      "\n",
      "Epoch 02540: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2541/5000\n",
      "\n",
      "Epoch 02541: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2542/5000\n",
      "\n",
      "Epoch 02542: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2543/5000\n",
      "\n",
      "Epoch 02543: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2544/5000\n",
      "\n",
      "Epoch 02544: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2545/5000\n",
      "\n",
      "Epoch 02545: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2546/5000\n",
      "\n",
      "Epoch 02546: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2547/5000\n",
      "\n",
      "Epoch 02547: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2548/5000\n",
      "\n",
      "Epoch 02548: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2549/5000\n",
      "\n",
      "Epoch 02549: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2550/5000\n",
      "\n",
      "Epoch 02550: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2551/5000\n",
      "\n",
      "Epoch 02551: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2552/5000\n",
      "\n",
      "Epoch 02552: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0109\n",
      "Epoch 2553/5000\n",
      "\n",
      "Epoch 02553: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2554/5000\n",
      "\n",
      "Epoch 02554: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2555/5000\n",
      "\n",
      "Epoch 02555: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2556/5000\n",
      "\n",
      "Epoch 02556: loss did not improve from 0.00949\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2557/5000\n",
      "\n",
      "Epoch 02557: loss improved from 0.00949 to 0.00942, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 7ms/sample - loss: 0.0094\n",
      "Epoch 2558/5000\n",
      "\n",
      "Epoch 02558: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2559/5000\n",
      "\n",
      "Epoch 02559: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2560/5000\n",
      "\n",
      "Epoch 02560: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2561/5000\n",
      "\n",
      "Epoch 02561: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0101\n",
      "Epoch 2562/5000\n",
      "\n",
      "Epoch 02562: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0100\n",
      "Epoch 2563/5000\n",
      "\n",
      "Epoch 02563: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0104\n",
      "Epoch 2564/5000\n",
      "\n",
      "Epoch 02564: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2565/5000\n",
      "\n",
      "Epoch 02565: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2566/5000\n",
      "\n",
      "Epoch 02566: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2567/5000\n",
      "\n",
      "Epoch 02567: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2568/5000\n",
      "\n",
      "Epoch 02568: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2569/5000\n",
      "\n",
      "Epoch 02569: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2570/5000\n",
      "\n",
      "Epoch 02570: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0108\n",
      "Epoch 2571/5000\n",
      "\n",
      "Epoch 02571: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2572/5000\n",
      "\n",
      "Epoch 02572: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2573/5000\n",
      "\n",
      "Epoch 02573: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2574/5000\n",
      "\n",
      "Epoch 02574: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2575/5000\n",
      "\n",
      "Epoch 02575: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2576/5000\n",
      "\n",
      "Epoch 02576: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2577/5000\n",
      "\n",
      "Epoch 02577: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2578/5000\n",
      "\n",
      "Epoch 02578: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2579/5000\n",
      "\n",
      "Epoch 02579: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2580/5000\n",
      "\n",
      "Epoch 02580: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2581/5000\n",
      "\n",
      "Epoch 02581: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2582/5000\n",
      "\n",
      "Epoch 02582: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2583/5000\n",
      "\n",
      "Epoch 02583: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2584/5000\n",
      "\n",
      "Epoch 02584: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2585/5000\n",
      "\n",
      "Epoch 02585: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2586/5000\n",
      "\n",
      "Epoch 02586: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2587/5000\n",
      "\n",
      "Epoch 02587: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2588/5000\n",
      "\n",
      "Epoch 02588: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2589/5000\n",
      "\n",
      "Epoch 02589: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2590/5000\n",
      "\n",
      "Epoch 02590: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2591/5000\n",
      "\n",
      "Epoch 02591: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2592/5000\n",
      "\n",
      "Epoch 02592: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2593/5000\n",
      "\n",
      "Epoch 02593: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2594/5000\n",
      "\n",
      "Epoch 02594: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2595/5000\n",
      "\n",
      "Epoch 02595: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2596/5000\n",
      "\n",
      "Epoch 02596: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2597/5000\n",
      "\n",
      "Epoch 02597: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2598/5000\n",
      "\n",
      "Epoch 02598: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2599/5000\n",
      "\n",
      "Epoch 02599: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2600/5000\n",
      "\n",
      "Epoch 02600: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2601/5000\n",
      "\n",
      "Epoch 02601: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2602/5000\n",
      "\n",
      "Epoch 02602: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2603/5000\n",
      "\n",
      "Epoch 02603: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2604/5000\n",
      "\n",
      "Epoch 02604: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2605/5000\n",
      "\n",
      "Epoch 02605: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2606/5000\n",
      "\n",
      "Epoch 02606: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2607/5000\n",
      "\n",
      "Epoch 02607: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2608/5000\n",
      "\n",
      "Epoch 02608: loss did not improve from 0.00942\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2609/5000\n",
      "\n",
      "Epoch 02609: loss improved from 0.00942 to 0.00924, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0092\n",
      "Epoch 2610/5000\n",
      "\n",
      "Epoch 02610: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2611/5000\n",
      "\n",
      "Epoch 02611: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2612/5000\n",
      "\n",
      "Epoch 02612: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2613/5000\n",
      "\n",
      "Epoch 02613: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2614/5000\n",
      "\n",
      "Epoch 02614: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2615/5000\n",
      "\n",
      "Epoch 02615: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2616/5000\n",
      "\n",
      "Epoch 02616: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2617/5000\n",
      "\n",
      "Epoch 02617: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2618/5000\n",
      "\n",
      "Epoch 02618: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2619/5000\n",
      "\n",
      "Epoch 02619: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2620/5000\n",
      "\n",
      "Epoch 02620: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2621/5000\n",
      "\n",
      "Epoch 02621: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2622/5000\n",
      "\n",
      "Epoch 02622: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2623/5000\n",
      "\n",
      "Epoch 02623: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2624/5000\n",
      "\n",
      "Epoch 02624: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2625/5000\n",
      "\n",
      "Epoch 02625: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2626/5000\n",
      "\n",
      "Epoch 02626: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2627/5000\n",
      "\n",
      "Epoch 02627: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2628/5000\n",
      "\n",
      "Epoch 02628: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2629/5000\n",
      "\n",
      "Epoch 02629: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2630/5000\n",
      "\n",
      "Epoch 02630: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2631/5000\n",
      "\n",
      "Epoch 02631: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2632/5000\n",
      "\n",
      "Epoch 02632: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2633/5000\n",
      "\n",
      "Epoch 02633: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2634/5000\n",
      "\n",
      "Epoch 02634: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2635/5000\n",
      "\n",
      "Epoch 02635: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2636/5000\n",
      "\n",
      "Epoch 02636: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2637/5000\n",
      "\n",
      "Epoch 02637: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2638/5000\n",
      "\n",
      "Epoch 02638: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2639/5000\n",
      "\n",
      "Epoch 02639: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2640/5000\n",
      "\n",
      "Epoch 02640: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2641/5000\n",
      "\n",
      "Epoch 02641: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2642/5000\n",
      "\n",
      "Epoch 02642: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2643/5000\n",
      "\n",
      "Epoch 02643: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2644/5000\n",
      "\n",
      "Epoch 02644: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2645/5000\n",
      "\n",
      "Epoch 02645: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2646/5000\n",
      "\n",
      "Epoch 02646: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2647/5000\n",
      "\n",
      "Epoch 02647: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2648/5000\n",
      "\n",
      "Epoch 02648: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2649/5000\n",
      "\n",
      "Epoch 02649: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2650/5000\n",
      "\n",
      "Epoch 02650: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2651/5000\n",
      "\n",
      "Epoch 02651: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2652/5000\n",
      "\n",
      "Epoch 02652: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2653/5000\n",
      "\n",
      "Epoch 02653: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2654/5000\n",
      "\n",
      "Epoch 02654: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2655/5000\n",
      "\n",
      "Epoch 02655: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2656/5000\n",
      "\n",
      "Epoch 02656: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2657/5000\n",
      "\n",
      "Epoch 02657: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2658/5000\n",
      "\n",
      "Epoch 02658: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2659/5000\n",
      "\n",
      "Epoch 02659: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2660/5000\n",
      "\n",
      "Epoch 02660: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2661/5000\n",
      "\n",
      "Epoch 02661: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2662/5000\n",
      "\n",
      "Epoch 02662: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2663/5000\n",
      "\n",
      "Epoch 02663: loss did not improve from 0.00924\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2664/5000\n",
      "\n",
      "Epoch 02664: loss improved from 0.00924 to 0.00917, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0092\n",
      "Epoch 2665/5000\n",
      "\n",
      "Epoch 02665: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2666/5000\n",
      "\n",
      "Epoch 02666: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2667/5000\n",
      "\n",
      "Epoch 02667: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2668/5000\n",
      "\n",
      "Epoch 02668: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2669/5000\n",
      "\n",
      "Epoch 02669: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2670/5000\n",
      "\n",
      "Epoch 02670: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2671/5000\n",
      "\n",
      "Epoch 02671: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2672/5000\n",
      "\n",
      "Epoch 02672: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2673/5000\n",
      "\n",
      "Epoch 02673: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2674/5000\n",
      "\n",
      "Epoch 02674: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2675/5000\n",
      "\n",
      "Epoch 02675: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2676/5000\n",
      "\n",
      "Epoch 02676: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2677/5000\n",
      "\n",
      "Epoch 02677: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2678/5000\n",
      "\n",
      "Epoch 02678: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2679/5000\n",
      "\n",
      "Epoch 02679: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2680/5000\n",
      "\n",
      "Epoch 02680: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2681/5000\n",
      "\n",
      "Epoch 02681: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0107\n",
      "Epoch 2682/5000\n",
      "\n",
      "Epoch 02682: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2683/5000\n",
      "\n",
      "Epoch 02683: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2684/5000\n",
      "\n",
      "Epoch 02684: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2685/5000\n",
      "\n",
      "Epoch 02685: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2686/5000\n",
      "\n",
      "Epoch 02686: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2687/5000\n",
      "\n",
      "Epoch 02687: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2688/5000\n",
      "\n",
      "Epoch 02688: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2689/5000\n",
      "\n",
      "Epoch 02689: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2690/5000\n",
      "\n",
      "Epoch 02690: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2691/5000\n",
      "\n",
      "Epoch 02691: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2692/5000\n",
      "\n",
      "Epoch 02692: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2693/5000\n",
      "\n",
      "Epoch 02693: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2694/5000\n",
      "\n",
      "Epoch 02694: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2695/5000\n",
      "\n",
      "Epoch 02695: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0106\n",
      "Epoch 2696/5000\n",
      "\n",
      "Epoch 02696: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2697/5000\n",
      "\n",
      "Epoch 02697: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2698/5000\n",
      "\n",
      "Epoch 02698: loss did not improve from 0.00917\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2699/5000\n",
      "\n",
      "Epoch 02699: loss improved from 0.00917 to 0.00915, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0092\n",
      "Epoch 2700/5000\n",
      "\n",
      "Epoch 02700: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2701/5000\n",
      "\n",
      "Epoch 02701: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2702/5000\n",
      "\n",
      "Epoch 02702: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2703/5000\n",
      "\n",
      "Epoch 02703: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2704/5000\n",
      "\n",
      "Epoch 02704: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2705/5000\n",
      "\n",
      "Epoch 02705: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2706/5000\n",
      "\n",
      "Epoch 02706: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2707/5000\n",
      "\n",
      "Epoch 02707: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2708/5000\n",
      "\n",
      "Epoch 02708: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2709/5000\n",
      "\n",
      "Epoch 02709: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2710/5000\n",
      "\n",
      "Epoch 02710: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2711/5000\n",
      "\n",
      "Epoch 02711: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2712/5000\n",
      "\n",
      "Epoch 02712: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2713/5000\n",
      "\n",
      "Epoch 02713: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2714/5000\n",
      "\n",
      "Epoch 02714: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2715/5000\n",
      "\n",
      "Epoch 02715: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2716/5000\n",
      "\n",
      "Epoch 02716: loss did not improve from 0.00915\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2717/5000\n",
      "\n",
      "Epoch 02717: loss improved from 0.00915 to 0.00911, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0091\n",
      "Epoch 2718/5000\n",
      "\n",
      "Epoch 02718: loss did not improve from 0.00911\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2719/5000\n",
      "\n",
      "Epoch 02719: loss did not improve from 0.00911\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2720/5000\n",
      "\n",
      "Epoch 02720: loss did not improve from 0.00911\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2721/5000\n",
      "\n",
      "Epoch 02721: loss improved from 0.00911 to 0.00876, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0088\n",
      "Epoch 2722/5000\n",
      "\n",
      "Epoch 02722: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2723/5000\n",
      "\n",
      "Epoch 02723: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2724/5000\n",
      "\n",
      "Epoch 02724: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2725/5000\n",
      "\n",
      "Epoch 02725: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2726/5000\n",
      "\n",
      "Epoch 02726: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2727/5000\n",
      "\n",
      "Epoch 02727: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2728/5000\n",
      "\n",
      "Epoch 02728: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2729/5000\n",
      "\n",
      "Epoch 02729: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2730/5000\n",
      "\n",
      "Epoch 02730: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2731/5000\n",
      "\n",
      "Epoch 02731: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2732/5000\n",
      "\n",
      "Epoch 02732: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2733/5000\n",
      "\n",
      "Epoch 02733: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2734/5000\n",
      "\n",
      "Epoch 02734: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2735/5000\n",
      "\n",
      "Epoch 02735: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2736/5000\n",
      "\n",
      "Epoch 02736: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2737/5000\n",
      "\n",
      "Epoch 02737: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2738/5000\n",
      "\n",
      "Epoch 02738: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2739/5000\n",
      "\n",
      "Epoch 02739: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2740/5000\n",
      "\n",
      "Epoch 02740: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2741/5000\n",
      "\n",
      "Epoch 02741: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2742/5000\n",
      "\n",
      "Epoch 02742: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2743/5000\n",
      "\n",
      "Epoch 02743: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2744/5000\n",
      "\n",
      "Epoch 02744: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2745/5000\n",
      "\n",
      "Epoch 02745: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2746/5000\n",
      "\n",
      "Epoch 02746: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2747/5000\n",
      "\n",
      "Epoch 02747: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2748/5000\n",
      "\n",
      "Epoch 02748: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2749/5000\n",
      "\n",
      "Epoch 02749: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2750/5000\n",
      "\n",
      "Epoch 02750: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2751/5000\n",
      "\n",
      "Epoch 02751: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2752/5000\n",
      "\n",
      "Epoch 02752: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2753/5000\n",
      "\n",
      "Epoch 02753: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2754/5000\n",
      "\n",
      "Epoch 02754: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2755/5000\n",
      "\n",
      "Epoch 02755: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2756/5000\n",
      "\n",
      "Epoch 02756: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2757/5000\n",
      "\n",
      "Epoch 02757: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2758/5000\n",
      "\n",
      "Epoch 02758: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2759/5000\n",
      "\n",
      "Epoch 02759: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2760/5000\n",
      "\n",
      "Epoch 02760: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2761/5000\n",
      "\n",
      "Epoch 02761: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2762/5000\n",
      "\n",
      "Epoch 02762: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2763/5000\n",
      "\n",
      "Epoch 02763: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2764/5000\n",
      "\n",
      "Epoch 02764: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2765/5000\n",
      "\n",
      "Epoch 02765: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2766/5000\n",
      "\n",
      "Epoch 02766: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2767/5000\n",
      "\n",
      "Epoch 02767: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2768/5000\n",
      "\n",
      "Epoch 02768: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2769/5000\n",
      "\n",
      "Epoch 02769: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2770/5000\n",
      "\n",
      "Epoch 02770: loss did not improve from 0.00876\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0105\n",
      "Epoch 2771/5000\n",
      "\n",
      "Epoch 02771: loss improved from 0.00876 to 0.00868, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0087\n",
      "Epoch 2772/5000\n",
      "\n",
      "Epoch 02772: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2773/5000\n",
      "\n",
      "Epoch 02773: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2774/5000\n",
      "\n",
      "Epoch 02774: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2775/5000\n",
      "\n",
      "Epoch 02775: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2776/5000\n",
      "\n",
      "Epoch 02776: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2777/5000\n",
      "\n",
      "Epoch 02777: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2778/5000\n",
      "\n",
      "Epoch 02778: loss improved from 0.00868 to 0.00868, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0087\n",
      "Epoch 2779/5000\n",
      "\n",
      "Epoch 02779: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2780/5000\n",
      "\n",
      "Epoch 02780: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2781/5000\n",
      "\n",
      "Epoch 02781: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2782/5000\n",
      "\n",
      "Epoch 02782: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2783/5000\n",
      "\n",
      "Epoch 02783: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2784/5000\n",
      "\n",
      "Epoch 02784: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2785/5000\n",
      "\n",
      "Epoch 02785: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2786/5000\n",
      "\n",
      "Epoch 02786: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2787/5000\n",
      "\n",
      "Epoch 02787: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2788/5000\n",
      "\n",
      "Epoch 02788: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2789/5000\n",
      "\n",
      "Epoch 02789: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2790/5000\n",
      "\n",
      "Epoch 02790: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2791/5000\n",
      "\n",
      "Epoch 02791: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2792/5000\n",
      "\n",
      "Epoch 02792: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2793/5000\n",
      "\n",
      "Epoch 02793: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2794/5000\n",
      "\n",
      "Epoch 02794: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2795/5000\n",
      "\n",
      "Epoch 02795: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2796/5000\n",
      "\n",
      "Epoch 02796: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2797/5000\n",
      "\n",
      "Epoch 02797: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2798/5000\n",
      "\n",
      "Epoch 02798: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2799/5000\n",
      "\n",
      "Epoch 02799: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2800/5000\n",
      "\n",
      "Epoch 02800: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2801/5000\n",
      "\n",
      "Epoch 02801: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2802/5000\n",
      "\n",
      "Epoch 02802: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2803/5000\n",
      "\n",
      "Epoch 02803: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0093\n",
      "Epoch 2804/5000\n",
      "\n",
      "Epoch 02804: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2805/5000\n",
      "\n",
      "Epoch 02805: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2806/5000\n",
      "\n",
      "Epoch 02806: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2807/5000\n",
      "\n",
      "Epoch 02807: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2808/5000\n",
      "\n",
      "Epoch 02808: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2809/5000\n",
      "\n",
      "Epoch 02809: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2810/5000\n",
      "\n",
      "Epoch 02810: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2811/5000\n",
      "\n",
      "Epoch 02811: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2812/5000\n",
      "\n",
      "Epoch 02812: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2813/5000\n",
      "\n",
      "Epoch 02813: loss did not improve from 0.00868\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2814/5000\n",
      "\n",
      "Epoch 02814: loss improved from 0.00868 to 0.00856, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0086\n",
      "Epoch 2815/5000\n",
      "\n",
      "Epoch 02815: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2816/5000\n",
      "\n",
      "Epoch 02816: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2817/5000\n",
      "\n",
      "Epoch 02817: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2818/5000\n",
      "\n",
      "Epoch 02818: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2819/5000\n",
      "\n",
      "Epoch 02819: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2820/5000\n",
      "\n",
      "Epoch 02820: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2821/5000\n",
      "\n",
      "Epoch 02821: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2822/5000\n",
      "\n",
      "Epoch 02822: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2823/5000\n",
      "\n",
      "Epoch 02823: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2824/5000\n",
      "\n",
      "Epoch 02824: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2825/5000\n",
      "\n",
      "Epoch 02825: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2826/5000\n",
      "\n",
      "Epoch 02826: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2827/5000\n",
      "\n",
      "Epoch 02827: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2828/5000\n",
      "\n",
      "Epoch 02828: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2829/5000\n",
      "\n",
      "Epoch 02829: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0094\n",
      "Epoch 2830/5000\n",
      "\n",
      "Epoch 02830: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2831/5000\n",
      "\n",
      "Epoch 02831: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2832/5000\n",
      "\n",
      "Epoch 02832: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2833/5000\n",
      "\n",
      "Epoch 02833: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2834/5000\n",
      "\n",
      "Epoch 02834: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 2835/5000\n",
      "\n",
      "Epoch 02835: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2836/5000\n",
      "\n",
      "Epoch 02836: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2837/5000\n",
      "\n",
      "Epoch 02837: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2838/5000\n",
      "\n",
      "Epoch 02838: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2839/5000\n",
      "\n",
      "Epoch 02839: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2840/5000\n",
      "\n",
      "Epoch 02840: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 2841/5000\n",
      "\n",
      "Epoch 02841: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2842/5000\n",
      "\n",
      "Epoch 02842: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2843/5000\n",
      "\n",
      "Epoch 02843: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2844/5000\n",
      "\n",
      "Epoch 02844: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2845/5000\n",
      "\n",
      "Epoch 02845: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2846/5000\n",
      "\n",
      "Epoch 02846: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2847/5000\n",
      "\n",
      "Epoch 02847: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2848/5000\n",
      "\n",
      "Epoch 02848: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2849/5000\n",
      "\n",
      "Epoch 02849: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2850/5000\n",
      "\n",
      "Epoch 02850: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2851/5000\n",
      "\n",
      "Epoch 02851: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2852/5000\n",
      "\n",
      "Epoch 02852: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0104\n",
      "Epoch 2853/5000\n",
      "\n",
      "Epoch 02853: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0103\n",
      "Epoch 2854/5000\n",
      "\n",
      "Epoch 02854: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2855/5000\n",
      "\n",
      "Epoch 02855: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2856/5000\n",
      "\n",
      "Epoch 02856: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2857/5000\n",
      "\n",
      "Epoch 02857: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2858/5000\n",
      "\n",
      "Epoch 02858: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2859/5000\n",
      "\n",
      "Epoch 02859: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2860/5000\n",
      "\n",
      "Epoch 02860: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2861/5000\n",
      "\n",
      "Epoch 02861: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0102\n",
      "Epoch 2862/5000\n",
      "\n",
      "Epoch 02862: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2863/5000\n",
      "\n",
      "Epoch 02863: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2864/5000\n",
      "\n",
      "Epoch 02864: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2865/5000\n",
      "\n",
      "Epoch 02865: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2866/5000\n",
      "\n",
      "Epoch 02866: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0089\n",
      "Epoch 2867/5000\n",
      "\n",
      "Epoch 02867: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2868/5000\n",
      "\n",
      "Epoch 02868: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2869/5000\n",
      "\n",
      "Epoch 02869: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2870/5000\n",
      "\n",
      "Epoch 02870: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2871/5000\n",
      "\n",
      "Epoch 02871: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2872/5000\n",
      "\n",
      "Epoch 02872: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2873/5000\n",
      "\n",
      "Epoch 02873: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2874/5000\n",
      "\n",
      "Epoch 02874: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2875/5000\n",
      "\n",
      "Epoch 02875: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2876/5000\n",
      "\n",
      "Epoch 02876: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2877/5000\n",
      "\n",
      "Epoch 02877: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2878/5000\n",
      "\n",
      "Epoch 02878: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2879/5000\n",
      "\n",
      "Epoch 02879: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2880/5000\n",
      "\n",
      "Epoch 02880: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2881/5000\n",
      "\n",
      "Epoch 02881: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2882/5000\n",
      "\n",
      "Epoch 02882: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2883/5000\n",
      "\n",
      "Epoch 02883: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 2884/5000\n",
      "\n",
      "Epoch 02884: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2885/5000\n",
      "\n",
      "Epoch 02885: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2886/5000\n",
      "\n",
      "Epoch 02886: loss did not improve from 0.00856\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2887/5000\n",
      "\n",
      "Epoch 02887: loss improved from 0.00856 to 0.00846, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0085\n",
      "Epoch 2888/5000\n",
      "\n",
      "Epoch 02888: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2889/5000\n",
      "\n",
      "Epoch 02889: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2890/5000\n",
      "\n",
      "Epoch 02890: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2891/5000\n",
      "\n",
      "Epoch 02891: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 1ms/sample - loss: 0.0090\n",
      "Epoch 2892/5000\n",
      "\n",
      "Epoch 02892: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2893/5000\n",
      "\n",
      "Epoch 02893: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0100\n",
      "Epoch 2894/5000\n",
      "\n",
      "Epoch 02894: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2895/5000\n",
      "\n",
      "Epoch 02895: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2896/5000\n",
      "\n",
      "Epoch 02896: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2897/5000\n",
      "\n",
      "Epoch 02897: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2898/5000\n",
      "\n",
      "Epoch 02898: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2899/5000\n",
      "\n",
      "Epoch 02899: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2900/5000\n",
      "\n",
      "Epoch 02900: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2901/5000\n",
      "\n",
      "Epoch 02901: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2902/5000\n",
      "\n",
      "Epoch 02902: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2903/5000\n",
      "\n",
      "Epoch 02903: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2904/5000\n",
      "\n",
      "Epoch 02904: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2905/5000\n",
      "\n",
      "Epoch 02905: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2906/5000\n",
      "\n",
      "Epoch 02906: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2907/5000\n",
      "\n",
      "Epoch 02907: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2908/5000\n",
      "\n",
      "Epoch 02908: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2909/5000\n",
      "\n",
      "Epoch 02909: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 2910/5000\n",
      "\n",
      "Epoch 02910: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2911/5000\n",
      "\n",
      "Epoch 02911: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2912/5000\n",
      "\n",
      "Epoch 02912: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2913/5000\n",
      "\n",
      "Epoch 02913: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2914/5000\n",
      "\n",
      "Epoch 02914: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2915/5000\n",
      "\n",
      "Epoch 02915: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2916/5000\n",
      "\n",
      "Epoch 02916: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 2917/5000\n",
      "\n",
      "Epoch 02917: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2918/5000\n",
      "\n",
      "Epoch 02918: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2919/5000\n",
      "\n",
      "Epoch 02919: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2920/5000\n",
      "\n",
      "Epoch 02920: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2921/5000\n",
      "\n",
      "Epoch 02921: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2922/5000\n",
      "\n",
      "Epoch 02922: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2923/5000\n",
      "\n",
      "Epoch 02923: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2924/5000\n",
      "\n",
      "Epoch 02924: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 2925/5000\n",
      "\n",
      "Epoch 02925: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2926/5000\n",
      "\n",
      "Epoch 02926: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2927/5000\n",
      "\n",
      "Epoch 02927: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2928/5000\n",
      "\n",
      "Epoch 02928: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 2929/5000\n",
      "\n",
      "Epoch 02929: loss did not improve from 0.00846\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 2930/5000\n",
      "\n",
      "Epoch 02930: loss improved from 0.00846 to 0.00839, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0084\n",
      "Epoch 2931/5000\n",
      "\n",
      "Epoch 02931: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2932/5000\n",
      "\n",
      "Epoch 02932: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2933/5000\n",
      "\n",
      "Epoch 02933: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 2934/5000\n",
      "\n",
      "Epoch 02934: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2935/5000\n",
      "\n",
      "Epoch 02935: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2936/5000\n",
      "\n",
      "Epoch 02936: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2937/5000\n",
      "\n",
      "Epoch 02937: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2938/5000\n",
      "\n",
      "Epoch 02938: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2939/5000\n",
      "\n",
      "Epoch 02939: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2940/5000\n",
      "\n",
      "Epoch 02940: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 2941/5000\n",
      "\n",
      "Epoch 02941: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 2942/5000\n",
      "\n",
      "Epoch 02942: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2943/5000\n",
      "\n",
      "Epoch 02943: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2944/5000\n",
      "\n",
      "Epoch 02944: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2945/5000\n",
      "\n",
      "Epoch 02945: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2946/5000\n",
      "\n",
      "Epoch 02946: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 2947/5000\n",
      "\n",
      "Epoch 02947: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2948/5000\n",
      "\n",
      "Epoch 02948: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2949/5000\n",
      "\n",
      "Epoch 02949: loss did not improve from 0.00839\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2950/5000\n",
      "\n",
      "Epoch 02950: loss improved from 0.00839 to 0.00827, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0083\n",
      "Epoch 2951/5000\n",
      "\n",
      "Epoch 02951: loss did not improve from 0.00827\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 2952/5000\n",
      "\n",
      "Epoch 02952: loss did not improve from 0.00827\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2953/5000\n",
      "\n",
      "Epoch 02953: loss improved from 0.00827 to 0.00822, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0082\n",
      "Epoch 2954/5000\n",
      "\n",
      "Epoch 02954: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2955/5000\n",
      "\n",
      "Epoch 02955: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2956/5000\n",
      "\n",
      "Epoch 02956: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2957/5000\n",
      "\n",
      "Epoch 02957: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 2958/5000\n",
      "\n",
      "Epoch 02958: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2959/5000\n",
      "\n",
      "Epoch 02959: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2960/5000\n",
      "\n",
      "Epoch 02960: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2961/5000\n",
      "\n",
      "Epoch 02961: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 2962/5000\n",
      "\n",
      "Epoch 02962: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2963/5000\n",
      "\n",
      "Epoch 02963: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 2964/5000\n",
      "\n",
      "Epoch 02964: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2965/5000\n",
      "\n",
      "Epoch 02965: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0097\n",
      "Epoch 2966/5000\n",
      "\n",
      "Epoch 02966: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 2967/5000\n",
      "\n",
      "Epoch 02967: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2968/5000\n",
      "\n",
      "Epoch 02968: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2969/5000\n",
      "\n",
      "Epoch 02969: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2970/5000\n",
      "\n",
      "Epoch 02970: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2971/5000\n",
      "\n",
      "Epoch 02971: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2972/5000\n",
      "\n",
      "Epoch 02972: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2973/5000\n",
      "\n",
      "Epoch 02973: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2974/5000\n",
      "\n",
      "Epoch 02974: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 2975/5000\n",
      "\n",
      "Epoch 02975: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 2976/5000\n",
      "\n",
      "Epoch 02976: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2977/5000\n",
      "\n",
      "Epoch 02977: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2978/5000\n",
      "\n",
      "Epoch 02978: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 2979/5000\n",
      "\n",
      "Epoch 02979: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2980/5000\n",
      "\n",
      "Epoch 02980: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2981/5000\n",
      "\n",
      "Epoch 02981: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2982/5000\n",
      "\n",
      "Epoch 02982: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2983/5000\n",
      "\n",
      "Epoch 02983: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 2984/5000\n",
      "\n",
      "Epoch 02984: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2985/5000\n",
      "\n",
      "Epoch 02985: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 2986/5000\n",
      "\n",
      "Epoch 02986: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2987/5000\n",
      "\n",
      "Epoch 02987: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 2988/5000\n",
      "\n",
      "Epoch 02988: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2989/5000\n",
      "\n",
      "Epoch 02989: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 2990/5000\n",
      "\n",
      "Epoch 02990: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 2991/5000\n",
      "\n",
      "Epoch 02991: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 2992/5000\n",
      "\n",
      "Epoch 02992: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 2993/5000\n",
      "\n",
      "Epoch 02993: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 2994/5000\n",
      "\n",
      "Epoch 02994: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2995/5000\n",
      "\n",
      "Epoch 02995: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 2996/5000\n",
      "\n",
      "Epoch 02996: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2997/5000\n",
      "\n",
      "Epoch 02997: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 2998/5000\n",
      "\n",
      "Epoch 02998: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 2999/5000\n",
      "\n",
      "Epoch 02999: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3000/5000\n",
      "\n",
      "Epoch 03000: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3001/5000\n",
      "\n",
      "Epoch 03001: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3002/5000\n",
      "\n",
      "Epoch 03002: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3003/5000\n",
      "\n",
      "Epoch 03003: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 3004/5000\n",
      "\n",
      "Epoch 03004: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3005/5000\n",
      "\n",
      "Epoch 03005: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3006/5000\n",
      "\n",
      "Epoch 03006: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3007/5000\n",
      "\n",
      "Epoch 03007: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 3008/5000\n",
      "\n",
      "Epoch 03008: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3009/5000\n",
      "\n",
      "Epoch 03009: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3010/5000\n",
      "\n",
      "Epoch 03010: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3011/5000\n",
      "\n",
      "Epoch 03011: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3012/5000\n",
      "\n",
      "Epoch 03012: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 3013/5000\n",
      "\n",
      "Epoch 03013: loss did not improve from 0.00822\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3014/5000\n",
      "\n",
      "Epoch 03014: loss improved from 0.00822 to 0.00800, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0080\n",
      "Epoch 3015/5000\n",
      "\n",
      "Epoch 03015: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 3016/5000\n",
      "\n",
      "Epoch 03016: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3017/5000\n",
      "\n",
      "Epoch 03017: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3018/5000\n",
      "\n",
      "Epoch 03018: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 3019/5000\n",
      "\n",
      "Epoch 03019: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3020/5000\n",
      "\n",
      "Epoch 03020: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3021/5000\n",
      "\n",
      "Epoch 03021: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3022/5000\n",
      "\n",
      "Epoch 03022: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3023/5000\n",
      "\n",
      "Epoch 03023: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3024/5000\n",
      "\n",
      "Epoch 03024: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3025/5000\n",
      "\n",
      "Epoch 03025: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3026/5000\n",
      "\n",
      "Epoch 03026: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 3027/5000\n",
      "\n",
      "Epoch 03027: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3028/5000\n",
      "\n",
      "Epoch 03028: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3029/5000\n",
      "\n",
      "Epoch 03029: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 3030/5000\n",
      "\n",
      "Epoch 03030: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3031/5000\n",
      "\n",
      "Epoch 03031: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 3032/5000\n",
      "\n",
      "Epoch 03032: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3033/5000\n",
      "\n",
      "Epoch 03033: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3034/5000\n",
      "\n",
      "Epoch 03034: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3035/5000\n",
      "\n",
      "Epoch 03035: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3036/5000\n",
      "\n",
      "Epoch 03036: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3037/5000\n",
      "\n",
      "Epoch 03037: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 3038/5000\n",
      "\n",
      "Epoch 03038: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3039/5000\n",
      "\n",
      "Epoch 03039: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3040/5000\n",
      "\n",
      "Epoch 03040: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3041/5000\n",
      "\n",
      "Epoch 03041: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 3042/5000\n",
      "\n",
      "Epoch 03042: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3043/5000\n",
      "\n",
      "Epoch 03043: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3044/5000\n",
      "\n",
      "Epoch 03044: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3045/5000\n",
      "\n",
      "Epoch 03045: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3046/5000\n",
      "\n",
      "Epoch 03046: loss did not improve from 0.00800\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3047/5000\n",
      "\n",
      "Epoch 03047: loss improved from 0.00800 to 0.00781, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0078\n",
      "Epoch 3048/5000\n",
      "\n",
      "Epoch 03048: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3049/5000\n",
      "\n",
      "Epoch 03049: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 3050/5000\n",
      "\n",
      "Epoch 03050: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3051/5000\n",
      "\n",
      "Epoch 03051: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0096\n",
      "Epoch 3052/5000\n",
      "\n",
      "Epoch 03052: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3053/5000\n",
      "\n",
      "Epoch 03053: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3054/5000\n",
      "\n",
      "Epoch 03054: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3055/5000\n",
      "\n",
      "Epoch 03055: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3056/5000\n",
      "\n",
      "Epoch 03056: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3057/5000\n",
      "\n",
      "Epoch 03057: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3058/5000\n",
      "\n",
      "Epoch 03058: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3059/5000\n",
      "\n",
      "Epoch 03059: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3060/5000\n",
      "\n",
      "Epoch 03060: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3061/5000\n",
      "\n",
      "Epoch 03061: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3062/5000\n",
      "\n",
      "Epoch 03062: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3063/5000\n",
      "\n",
      "Epoch 03063: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3064/5000\n",
      "\n",
      "Epoch 03064: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3065/5000\n",
      "\n",
      "Epoch 03065: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3066/5000\n",
      "\n",
      "Epoch 03066: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3067/5000\n",
      "\n",
      "Epoch 03067: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3068/5000\n",
      "\n",
      "Epoch 03068: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 3069/5000\n",
      "\n",
      "Epoch 03069: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3070/5000\n",
      "\n",
      "Epoch 03070: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3071/5000\n",
      "\n",
      "Epoch 03071: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3072/5000\n",
      "\n",
      "Epoch 03072: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3073/5000\n",
      "\n",
      "Epoch 03073: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3074/5000\n",
      "\n",
      "Epoch 03074: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3075/5000\n",
      "\n",
      "Epoch 03075: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 3076/5000\n",
      "\n",
      "Epoch 03076: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3077/5000\n",
      "\n",
      "Epoch 03077: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3078/5000\n",
      "\n",
      "Epoch 03078: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3079/5000\n",
      "\n",
      "Epoch 03079: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3080/5000\n",
      "\n",
      "Epoch 03080: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3081/5000\n",
      "\n",
      "Epoch 03081: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3082/5000\n",
      "\n",
      "Epoch 03082: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3083/5000\n",
      "\n",
      "Epoch 03083: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 3084/5000\n",
      "\n",
      "Epoch 03084: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3085/5000\n",
      "\n",
      "Epoch 03085: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3086/5000\n",
      "\n",
      "Epoch 03086: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3087/5000\n",
      "\n",
      "Epoch 03087: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3088/5000\n",
      "\n",
      "Epoch 03088: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3089/5000\n",
      "\n",
      "Epoch 03089: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3090/5000\n",
      "\n",
      "Epoch 03090: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3091/5000\n",
      "\n",
      "Epoch 03091: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3092/5000\n",
      "\n",
      "Epoch 03092: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3093/5000\n",
      "\n",
      "Epoch 03093: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3094/5000\n",
      "\n",
      "Epoch 03094: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3095/5000\n",
      "\n",
      "Epoch 03095: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3096/5000\n",
      "\n",
      "Epoch 03096: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3097/5000\n",
      "\n",
      "Epoch 03097: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3098/5000\n",
      "\n",
      "Epoch 03098: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3099/5000\n",
      "\n",
      "Epoch 03099: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3100/5000\n",
      "\n",
      "Epoch 03100: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3101/5000\n",
      "\n",
      "Epoch 03101: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3102/5000\n",
      "\n",
      "Epoch 03102: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 3103/5000\n",
      "\n",
      "Epoch 03103: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3104/5000\n",
      "\n",
      "Epoch 03104: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3105/5000\n",
      "\n",
      "Epoch 03105: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3106/5000\n",
      "\n",
      "Epoch 03106: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3107/5000\n",
      "\n",
      "Epoch 03107: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3108/5000\n",
      "\n",
      "Epoch 03108: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3109/5000\n",
      "\n",
      "Epoch 03109: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3110/5000\n",
      "\n",
      "Epoch 03110: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3111/5000\n",
      "\n",
      "Epoch 03111: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 3112/5000\n",
      "\n",
      "Epoch 03112: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3113/5000\n",
      "\n",
      "Epoch 03113: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3114/5000\n",
      "\n",
      "Epoch 03114: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3115/5000\n",
      "\n",
      "Epoch 03115: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3116/5000\n",
      "\n",
      "Epoch 03116: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3117/5000\n",
      "\n",
      "Epoch 03117: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3118/5000\n",
      "\n",
      "Epoch 03118: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3119/5000\n",
      "\n",
      "Epoch 03119: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3120/5000\n",
      "\n",
      "Epoch 03120: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3121/5000\n",
      "\n",
      "Epoch 03121: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3122/5000\n",
      "\n",
      "Epoch 03122: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3123/5000\n",
      "\n",
      "Epoch 03123: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3124/5000\n",
      "\n",
      "Epoch 03124: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3125/5000\n",
      "\n",
      "Epoch 03125: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3126/5000\n",
      "\n",
      "Epoch 03126: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3127/5000\n",
      "\n",
      "Epoch 03127: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3128/5000\n",
      "\n",
      "Epoch 03128: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3129/5000\n",
      "\n",
      "Epoch 03129: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3130/5000\n",
      "\n",
      "Epoch 03130: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3131/5000\n",
      "\n",
      "Epoch 03131: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3132/5000\n",
      "\n",
      "Epoch 03132: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3133/5000\n",
      "\n",
      "Epoch 03133: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3134/5000\n",
      "\n",
      "Epoch 03134: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3135/5000\n",
      "\n",
      "Epoch 03135: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3136/5000\n",
      "\n",
      "Epoch 03136: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 3137/5000\n",
      "\n",
      "Epoch 03137: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3138/5000\n",
      "\n",
      "Epoch 03138: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3139/5000\n",
      "\n",
      "Epoch 03139: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3140/5000\n",
      "\n",
      "Epoch 03140: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3141/5000\n",
      "\n",
      "Epoch 03141: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3142/5000\n",
      "\n",
      "Epoch 03142: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0101\n",
      "Epoch 3143/5000\n",
      "\n",
      "Epoch 03143: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3144/5000\n",
      "\n",
      "Epoch 03144: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 3145/5000\n",
      "\n",
      "Epoch 03145: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3146/5000\n",
      "\n",
      "Epoch 03146: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3147/5000\n",
      "\n",
      "Epoch 03147: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3148/5000\n",
      "\n",
      "Epoch 03148: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3149/5000\n",
      "\n",
      "Epoch 03149: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3150/5000\n",
      "\n",
      "Epoch 03150: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3151/5000\n",
      "\n",
      "Epoch 03151: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3152/5000\n",
      "\n",
      "Epoch 03152: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3153/5000\n",
      "\n",
      "Epoch 03153: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3154/5000\n",
      "\n",
      "Epoch 03154: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3155/5000\n",
      "\n",
      "Epoch 03155: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3156/5000\n",
      "\n",
      "Epoch 03156: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3157/5000\n",
      "\n",
      "Epoch 03157: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3158/5000\n",
      "\n",
      "Epoch 03158: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3159/5000\n",
      "\n",
      "Epoch 03159: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3160/5000\n",
      "\n",
      "Epoch 03160: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3161/5000\n",
      "\n",
      "Epoch 03161: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3162/5000\n",
      "\n",
      "Epoch 03162: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3163/5000\n",
      "\n",
      "Epoch 03163: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3164/5000\n",
      "\n",
      "Epoch 03164: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3165/5000\n",
      "\n",
      "Epoch 03165: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3166/5000\n",
      "\n",
      "Epoch 03166: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3167/5000\n",
      "\n",
      "Epoch 03167: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3168/5000\n",
      "\n",
      "Epoch 03168: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3169/5000\n",
      "\n",
      "Epoch 03169: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3170/5000\n",
      "\n",
      "Epoch 03170: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3171/5000\n",
      "\n",
      "Epoch 03171: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 3172/5000\n",
      "\n",
      "Epoch 03172: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3173/5000\n",
      "\n",
      "Epoch 03173: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3174/5000\n",
      "\n",
      "Epoch 03174: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3175/5000\n",
      "\n",
      "Epoch 03175: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3176/5000\n",
      "\n",
      "Epoch 03176: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0098\n",
      "Epoch 3177/5000\n",
      "\n",
      "Epoch 03177: loss did not improve from 0.00781\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3178/5000\n",
      "\n",
      "Epoch 03178: loss improved from 0.00781 to 0.00771, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0077\n",
      "Epoch 3179/5000\n",
      "\n",
      "Epoch 03179: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3180/5000\n",
      "\n",
      "Epoch 03180: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3181/5000\n",
      "\n",
      "Epoch 03181: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3182/5000\n",
      "\n",
      "Epoch 03182: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3183/5000\n",
      "\n",
      "Epoch 03183: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3184/5000\n",
      "\n",
      "Epoch 03184: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3185/5000\n",
      "\n",
      "Epoch 03185: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3186/5000\n",
      "\n",
      "Epoch 03186: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3187/5000\n",
      "\n",
      "Epoch 03187: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3188/5000\n",
      "\n",
      "Epoch 03188: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3189/5000\n",
      "\n",
      "Epoch 03189: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3190/5000\n",
      "\n",
      "Epoch 03190: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3191/5000\n",
      "\n",
      "Epoch 03191: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3192/5000\n",
      "\n",
      "Epoch 03192: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3193/5000\n",
      "\n",
      "Epoch 03193: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3194/5000\n",
      "\n",
      "Epoch 03194: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3195/5000\n",
      "\n",
      "Epoch 03195: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3196/5000\n",
      "\n",
      "Epoch 03196: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3197/5000\n",
      "\n",
      "Epoch 03197: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3198/5000\n",
      "\n",
      "Epoch 03198: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0081\n",
      "Epoch 3199/5000\n",
      "\n",
      "Epoch 03199: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3200/5000\n",
      "\n",
      "Epoch 03200: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0090\n",
      "Epoch 3201/5000\n",
      "\n",
      "Epoch 03201: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3202/5000\n",
      "\n",
      "Epoch 03202: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3203/5000\n",
      "\n",
      "Epoch 03203: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0077\n",
      "Epoch 3204/5000\n",
      "\n",
      "Epoch 03204: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3205/5000\n",
      "\n",
      "Epoch 03205: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3206/5000\n",
      "\n",
      "Epoch 03206: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3207/5000\n",
      "\n",
      "Epoch 03207: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3208/5000\n",
      "\n",
      "Epoch 03208: loss did not improve from 0.00771\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3209/5000\n",
      "\n",
      "Epoch 03209: loss improved from 0.00771 to 0.00760, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0076\n",
      "Epoch 3210/5000\n",
      "\n",
      "Epoch 03210: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3211/5000\n",
      "\n",
      "Epoch 03211: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3212/5000\n",
      "\n",
      "Epoch 03212: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3213/5000\n",
      "\n",
      "Epoch 03213: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3214/5000\n",
      "\n",
      "Epoch 03214: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3215/5000\n",
      "\n",
      "Epoch 03215: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3216/5000\n",
      "\n",
      "Epoch 03216: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3217/5000\n",
      "\n",
      "Epoch 03217: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3218/5000\n",
      "\n",
      "Epoch 03218: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3219/5000\n",
      "\n",
      "Epoch 03219: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3220/5000\n",
      "\n",
      "Epoch 03220: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3221/5000\n",
      "\n",
      "Epoch 03221: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3222/5000\n",
      "\n",
      "Epoch 03222: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3223/5000\n",
      "\n",
      "Epoch 03223: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3224/5000\n",
      "\n",
      "Epoch 03224: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3225/5000\n",
      "\n",
      "Epoch 03225: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0079\n",
      "Epoch 3226/5000\n",
      "\n",
      "Epoch 03226: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3227/5000\n",
      "\n",
      "Epoch 03227: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3228/5000\n",
      "\n",
      "Epoch 03228: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0083\n",
      "Epoch 3229/5000\n",
      "\n",
      "Epoch 03229: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3230/5000\n",
      "\n",
      "Epoch 03230: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3231/5000\n",
      "\n",
      "Epoch 03231: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3232/5000\n",
      "\n",
      "Epoch 03232: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3233/5000\n",
      "\n",
      "Epoch 03233: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3234/5000\n",
      "\n",
      "Epoch 03234: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3235/5000\n",
      "\n",
      "Epoch 03235: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3236/5000\n",
      "\n",
      "Epoch 03236: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3237/5000\n",
      "\n",
      "Epoch 03237: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3238/5000\n",
      "\n",
      "Epoch 03238: loss did not improve from 0.00760\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3239/5000\n",
      "\n",
      "Epoch 03239: loss improved from 0.00760 to 0.00748, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0075\n",
      "Epoch 3240/5000\n",
      "\n",
      "Epoch 03240: loss did not improve from 0.00748\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3241/5000\n",
      "\n",
      "Epoch 03241: loss did not improve from 0.00748\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3242/5000\n",
      "\n",
      "Epoch 03242: loss did not improve from 0.00748\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3243/5000\n",
      "\n",
      "Epoch 03243: loss did not improve from 0.00748\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3244/5000\n",
      "\n",
      "Epoch 03244: loss improved from 0.00748 to 0.00743, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0074\n",
      "Epoch 3245/5000\n",
      "\n",
      "Epoch 03245: loss did not improve from 0.00743\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3246/5000\n",
      "\n",
      "Epoch 03246: loss did not improve from 0.00743\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3247/5000\n",
      "\n",
      "Epoch 03247: loss did not improve from 0.00743\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3248/5000\n",
      "\n",
      "Epoch 03248: loss did not improve from 0.00743\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3249/5000\n",
      "\n",
      "Epoch 03249: loss improved from 0.00743 to 0.00741, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0074\n",
      "Epoch 3250/5000\n",
      "\n",
      "Epoch 03250: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3251/5000\n",
      "\n",
      "Epoch 03251: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3252/5000\n",
      "\n",
      "Epoch 03252: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3253/5000\n",
      "\n",
      "Epoch 03253: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3254/5000\n",
      "\n",
      "Epoch 03254: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3255/5000\n",
      "\n",
      "Epoch 03255: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3256/5000\n",
      "\n",
      "Epoch 03256: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3257/5000\n",
      "\n",
      "Epoch 03257: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3258/5000\n",
      "\n",
      "Epoch 03258: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3259/5000\n",
      "\n",
      "Epoch 03259: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3260/5000\n",
      "\n",
      "Epoch 03260: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3261/5000\n",
      "\n",
      "Epoch 03261: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3262/5000\n",
      "\n",
      "Epoch 03262: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3263/5000\n",
      "\n",
      "Epoch 03263: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3264/5000\n",
      "\n",
      "Epoch 03264: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3265/5000\n",
      "\n",
      "Epoch 03265: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3266/5000\n",
      "\n",
      "Epoch 03266: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3267/5000\n",
      "\n",
      "Epoch 03267: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3268/5000\n",
      "\n",
      "Epoch 03268: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3269/5000\n",
      "\n",
      "Epoch 03269: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3270/5000\n",
      "\n",
      "Epoch 03270: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3271/5000\n",
      "\n",
      "Epoch 03271: loss did not improve from 0.00741\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3272/5000\n",
      "\n",
      "Epoch 03272: loss improved from 0.00741 to 0.00729, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0073\n",
      "Epoch 3273/5000\n",
      "\n",
      "Epoch 03273: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3274/5000\n",
      "\n",
      "Epoch 03274: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3275/5000\n",
      "\n",
      "Epoch 03275: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 3276/5000\n",
      "\n",
      "Epoch 03276: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3277/5000\n",
      "\n",
      "Epoch 03277: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3278/5000\n",
      "\n",
      "Epoch 03278: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3279/5000\n",
      "\n",
      "Epoch 03279: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3280/5000\n",
      "\n",
      "Epoch 03280: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3281/5000\n",
      "\n",
      "Epoch 03281: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3282/5000\n",
      "\n",
      "Epoch 03282: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3283/5000\n",
      "\n",
      "Epoch 03283: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3284/5000\n",
      "\n",
      "Epoch 03284: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3285/5000\n",
      "\n",
      "Epoch 03285: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3286/5000\n",
      "\n",
      "Epoch 03286: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3287/5000\n",
      "\n",
      "Epoch 03287: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3288/5000\n",
      "\n",
      "Epoch 03288: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3289/5000\n",
      "\n",
      "Epoch 03289: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3290/5000\n",
      "\n",
      "Epoch 03290: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3291/5000\n",
      "\n",
      "Epoch 03291: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3292/5000\n",
      "\n",
      "Epoch 03292: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 3293/5000\n",
      "\n",
      "Epoch 03293: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3294/5000\n",
      "\n",
      "Epoch 03294: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3295/5000\n",
      "\n",
      "Epoch 03295: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3296/5000\n",
      "\n",
      "Epoch 03296: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3297/5000\n",
      "\n",
      "Epoch 03297: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3298/5000\n",
      "\n",
      "Epoch 03298: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3299/5000\n",
      "\n",
      "Epoch 03299: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3300/5000\n",
      "\n",
      "Epoch 03300: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3301/5000\n",
      "\n",
      "Epoch 03301: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3302/5000\n",
      "\n",
      "Epoch 03302: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3303/5000\n",
      "\n",
      "Epoch 03303: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3304/5000\n",
      "\n",
      "Epoch 03304: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3305/5000\n",
      "\n",
      "Epoch 03305: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3306/5000\n",
      "\n",
      "Epoch 03306: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3307/5000\n",
      "\n",
      "Epoch 03307: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3308/5000\n",
      "\n",
      "Epoch 03308: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3309/5000\n",
      "\n",
      "Epoch 03309: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3310/5000\n",
      "\n",
      "Epoch 03310: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 3311/5000\n",
      "\n",
      "Epoch 03311: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3312/5000\n",
      "\n",
      "Epoch 03312: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3313/5000\n",
      "\n",
      "Epoch 03313: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3314/5000\n",
      "\n",
      "Epoch 03314: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3315/5000\n",
      "\n",
      "Epoch 03315: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3316/5000\n",
      "\n",
      "Epoch 03316: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3317/5000\n",
      "\n",
      "Epoch 03317: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3318/5000\n",
      "\n",
      "Epoch 03318: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3319/5000\n",
      "\n",
      "Epoch 03319: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3320/5000\n",
      "\n",
      "Epoch 03320: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3321/5000\n",
      "\n",
      "Epoch 03321: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3322/5000\n",
      "\n",
      "Epoch 03322: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3323/5000\n",
      "\n",
      "Epoch 03323: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3324/5000\n",
      "\n",
      "Epoch 03324: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3325/5000\n",
      "\n",
      "Epoch 03325: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3326/5000\n",
      "\n",
      "Epoch 03326: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3327/5000\n",
      "\n",
      "Epoch 03327: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3328/5000\n",
      "\n",
      "Epoch 03328: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3329/5000\n",
      "\n",
      "Epoch 03329: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3330/5000\n",
      "\n",
      "Epoch 03330: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3331/5000\n",
      "\n",
      "Epoch 03331: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3332/5000\n",
      "\n",
      "Epoch 03332: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3333/5000\n",
      "\n",
      "Epoch 03333: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3334/5000\n",
      "\n",
      "Epoch 03334: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3335/5000\n",
      "\n",
      "Epoch 03335: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3336/5000\n",
      "\n",
      "Epoch 03336: loss did not improve from 0.00729\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3337/5000\n",
      "\n",
      "Epoch 03337: loss improved from 0.00729 to 0.00728, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0073\n",
      "Epoch 3338/5000\n",
      "\n",
      "Epoch 03338: loss did not improve from 0.00728\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3339/5000\n",
      "\n",
      "Epoch 03339: loss did not improve from 0.00728\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3340/5000\n",
      "\n",
      "Epoch 03340: loss did not improve from 0.00728\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3341/5000\n",
      "\n",
      "Epoch 03341: loss did not improve from 0.00728\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3342/5000\n",
      "\n",
      "Epoch 03342: loss did not improve from 0.00728\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3343/5000\n",
      "\n",
      "Epoch 03343: loss did not improve from 0.00728\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3344/5000\n",
      "\n",
      "Epoch 03344: loss did not improve from 0.00728\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3345/5000\n",
      "\n",
      "Epoch 03345: loss did not improve from 0.00728\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3346/5000\n",
      "\n",
      "Epoch 03346: loss did not improve from 0.00728\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3347/5000\n",
      "\n",
      "Epoch 03347: loss did not improve from 0.00728\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3348/5000\n",
      "\n",
      "Epoch 03348: loss did not improve from 0.00728\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3349/5000\n",
      "\n",
      "Epoch 03349: loss improved from 0.00728 to 0.00715, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0072\n",
      "Epoch 3350/5000\n",
      "\n",
      "Epoch 03350: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3351/5000\n",
      "\n",
      "Epoch 03351: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3352/5000\n",
      "\n",
      "Epoch 03352: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3353/5000\n",
      "\n",
      "Epoch 03353: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3354/5000\n",
      "\n",
      "Epoch 03354: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3355/5000\n",
      "\n",
      "Epoch 03355: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3356/5000\n",
      "\n",
      "Epoch 03356: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3357/5000\n",
      "\n",
      "Epoch 03357: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0093\n",
      "Epoch 3358/5000\n",
      "\n",
      "Epoch 03358: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3359/5000\n",
      "\n",
      "Epoch 03359: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3360/5000\n",
      "\n",
      "Epoch 03360: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3361/5000\n",
      "\n",
      "Epoch 03361: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3362/5000\n",
      "\n",
      "Epoch 03362: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3363/5000\n",
      "\n",
      "Epoch 03363: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3364/5000\n",
      "\n",
      "Epoch 03364: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3365/5000\n",
      "\n",
      "Epoch 03365: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3366/5000\n",
      "\n",
      "Epoch 03366: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3367/5000\n",
      "\n",
      "Epoch 03367: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3368/5000\n",
      "\n",
      "Epoch 03368: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3369/5000\n",
      "\n",
      "Epoch 03369: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3370/5000\n",
      "\n",
      "Epoch 03370: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3371/5000\n",
      "\n",
      "Epoch 03371: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3372/5000\n",
      "\n",
      "Epoch 03372: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3373/5000\n",
      "\n",
      "Epoch 03373: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3374/5000\n",
      "\n",
      "Epoch 03374: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3375/5000\n",
      "\n",
      "Epoch 03375: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3376/5000\n",
      "\n",
      "Epoch 03376: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3377/5000\n",
      "\n",
      "Epoch 03377: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3378/5000\n",
      "\n",
      "Epoch 03378: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3379/5000\n",
      "\n",
      "Epoch 03379: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3380/5000\n",
      "\n",
      "Epoch 03380: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3381/5000\n",
      "\n",
      "Epoch 03381: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0094\n",
      "Epoch 3382/5000\n",
      "\n",
      "Epoch 03382: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3383/5000\n",
      "\n",
      "Epoch 03383: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3384/5000\n",
      "\n",
      "Epoch 03384: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3385/5000\n",
      "\n",
      "Epoch 03385: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3386/5000\n",
      "\n",
      "Epoch 03386: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3387/5000\n",
      "\n",
      "Epoch 03387: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3388/5000\n",
      "\n",
      "Epoch 03388: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3389/5000\n",
      "\n",
      "Epoch 03389: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3390/5000\n",
      "\n",
      "Epoch 03390: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3391/5000\n",
      "\n",
      "Epoch 03391: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3392/5000\n",
      "\n",
      "Epoch 03392: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3393/5000\n",
      "\n",
      "Epoch 03393: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3394/5000\n",
      "\n",
      "Epoch 03394: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3395/5000\n",
      "\n",
      "Epoch 03395: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3396/5000\n",
      "\n",
      "Epoch 03396: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3397/5000\n",
      "\n",
      "Epoch 03397: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3398/5000\n",
      "\n",
      "Epoch 03398: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3399/5000\n",
      "\n",
      "Epoch 03399: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3400/5000\n",
      "\n",
      "Epoch 03400: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3401/5000\n",
      "\n",
      "Epoch 03401: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3402/5000\n",
      "\n",
      "Epoch 03402: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3403/5000\n",
      "\n",
      "Epoch 03403: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3404/5000\n",
      "\n",
      "Epoch 03404: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3405/5000\n",
      "\n",
      "Epoch 03405: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3406/5000\n",
      "\n",
      "Epoch 03406: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3407/5000\n",
      "\n",
      "Epoch 03407: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3408/5000\n",
      "\n",
      "Epoch 03408: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3409/5000\n",
      "\n",
      "Epoch 03409: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3410/5000\n",
      "\n",
      "Epoch 03410: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3411/5000\n",
      "\n",
      "Epoch 03411: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3412/5000\n",
      "\n",
      "Epoch 03412: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3413/5000\n",
      "\n",
      "Epoch 03413: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3414/5000\n",
      "\n",
      "Epoch 03414: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3415/5000\n",
      "\n",
      "Epoch 03415: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3416/5000\n",
      "\n",
      "Epoch 03416: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3417/5000\n",
      "\n",
      "Epoch 03417: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3418/5000\n",
      "\n",
      "Epoch 03418: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3419/5000\n",
      "\n",
      "Epoch 03419: loss did not improve from 0.00715\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3420/5000\n",
      "\n",
      "Epoch 03420: loss improved from 0.00715 to 0.00706, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0071\n",
      "Epoch 3421/5000\n",
      "\n",
      "Epoch 03421: loss improved from 0.00706 to 0.00699, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0070\n",
      "Epoch 3422/5000\n",
      "\n",
      "Epoch 03422: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3423/5000\n",
      "\n",
      "Epoch 03423: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3424/5000\n",
      "\n",
      "Epoch 03424: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3425/5000\n",
      "\n",
      "Epoch 03425: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3426/5000\n",
      "\n",
      "Epoch 03426: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3427/5000\n",
      "\n",
      "Epoch 03427: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3428/5000\n",
      "\n",
      "Epoch 03428: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3429/5000\n",
      "\n",
      "Epoch 03429: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3430/5000\n",
      "\n",
      "Epoch 03430: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3431/5000\n",
      "\n",
      "Epoch 03431: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3432/5000\n",
      "\n",
      "Epoch 03432: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3433/5000\n",
      "\n",
      "Epoch 03433: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3434/5000\n",
      "\n",
      "Epoch 03434: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3435/5000\n",
      "\n",
      "Epoch 03435: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3436/5000\n",
      "\n",
      "Epoch 03436: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3437/5000\n",
      "\n",
      "Epoch 03437: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3438/5000\n",
      "\n",
      "Epoch 03438: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3439/5000\n",
      "\n",
      "Epoch 03439: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3440/5000\n",
      "\n",
      "Epoch 03440: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3441/5000\n",
      "\n",
      "Epoch 03441: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3442/5000\n",
      "\n",
      "Epoch 03442: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3443/5000\n",
      "\n",
      "Epoch 03443: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3444/5000\n",
      "\n",
      "Epoch 03444: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3445/5000\n",
      "\n",
      "Epoch 03445: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3446/5000\n",
      "\n",
      "Epoch 03446: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3447/5000\n",
      "\n",
      "Epoch 03447: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3448/5000\n",
      "\n",
      "Epoch 03448: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3449/5000\n",
      "\n",
      "Epoch 03449: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3450/5000\n",
      "\n",
      "Epoch 03450: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3451/5000\n",
      "\n",
      "Epoch 03451: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3452/5000\n",
      "\n",
      "Epoch 03452: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3453/5000\n",
      "\n",
      "Epoch 03453: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3454/5000\n",
      "\n",
      "Epoch 03454: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3455/5000\n",
      "\n",
      "Epoch 03455: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3456/5000\n",
      "\n",
      "Epoch 03456: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3457/5000\n",
      "\n",
      "Epoch 03457: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3458/5000\n",
      "\n",
      "Epoch 03458: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3459/5000\n",
      "\n",
      "Epoch 03459: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3460/5000\n",
      "\n",
      "Epoch 03460: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3461/5000\n",
      "\n",
      "Epoch 03461: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3462/5000\n",
      "\n",
      "Epoch 03462: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3463/5000\n",
      "\n",
      "Epoch 03463: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3464/5000\n",
      "\n",
      "Epoch 03464: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3465/5000\n",
      "\n",
      "Epoch 03465: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3466/5000\n",
      "\n",
      "Epoch 03466: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3467/5000\n",
      "\n",
      "Epoch 03467: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3468/5000\n",
      "\n",
      "Epoch 03468: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3469/5000\n",
      "\n",
      "Epoch 03469: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3470/5000\n",
      "\n",
      "Epoch 03470: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3471/5000\n",
      "\n",
      "Epoch 03471: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3472/5000\n",
      "\n",
      "Epoch 03472: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3473/5000\n",
      "\n",
      "Epoch 03473: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3474/5000\n",
      "\n",
      "Epoch 03474: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3475/5000\n",
      "\n",
      "Epoch 03475: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3476/5000\n",
      "\n",
      "Epoch 03476: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3477/5000\n",
      "\n",
      "Epoch 03477: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3478/5000\n",
      "\n",
      "Epoch 03478: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3479/5000\n",
      "\n",
      "Epoch 03479: loss did not improve from 0.00699\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3480/5000\n",
      "\n",
      "Epoch 03480: loss improved from 0.00699 to 0.00689, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0069\n",
      "Epoch 3481/5000\n",
      "\n",
      "Epoch 03481: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3482/5000\n",
      "\n",
      "Epoch 03482: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3483/5000\n",
      "\n",
      "Epoch 03483: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3484/5000\n",
      "\n",
      "Epoch 03484: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3485/5000\n",
      "\n",
      "Epoch 03485: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3486/5000\n",
      "\n",
      "Epoch 03486: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3487/5000\n",
      "\n",
      "Epoch 03487: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3488/5000\n",
      "\n",
      "Epoch 03488: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3489/5000\n",
      "\n",
      "Epoch 03489: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3490/5000\n",
      "\n",
      "Epoch 03490: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3491/5000\n",
      "\n",
      "Epoch 03491: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3492/5000\n",
      "\n",
      "Epoch 03492: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3493/5000\n",
      "\n",
      "Epoch 03493: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3494/5000\n",
      "\n",
      "Epoch 03494: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3495/5000\n",
      "\n",
      "Epoch 03495: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3496/5000\n",
      "\n",
      "Epoch 03496: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3497/5000\n",
      "\n",
      "Epoch 03497: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3498/5000\n",
      "\n",
      "Epoch 03498: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3499/5000\n",
      "\n",
      "Epoch 03499: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3500/5000\n",
      "\n",
      "Epoch 03500: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3501/5000\n",
      "\n",
      "Epoch 03501: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3502/5000\n",
      "\n",
      "Epoch 03502: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3503/5000\n",
      "\n",
      "Epoch 03503: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3504/5000\n",
      "\n",
      "Epoch 03504: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3505/5000\n",
      "\n",
      "Epoch 03505: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3506/5000\n",
      "\n",
      "Epoch 03506: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3507/5000\n",
      "\n",
      "Epoch 03507: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3508/5000\n",
      "\n",
      "Epoch 03508: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3509/5000\n",
      "\n",
      "Epoch 03509: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3510/5000\n",
      "\n",
      "Epoch 03510: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3511/5000\n",
      "\n",
      "Epoch 03511: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3512/5000\n",
      "\n",
      "Epoch 03512: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3513/5000\n",
      "\n",
      "Epoch 03513: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3514/5000\n",
      "\n",
      "Epoch 03514: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0092\n",
      "Epoch 3515/5000\n",
      "\n",
      "Epoch 03515: loss did not improve from 0.00689\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3516/5000\n",
      "\n",
      "Epoch 03516: loss improved from 0.00689 to 0.00683, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0068\n",
      "Epoch 3517/5000\n",
      "\n",
      "Epoch 03517: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3518/5000\n",
      "\n",
      "Epoch 03518: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3519/5000\n",
      "\n",
      "Epoch 03519: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3520/5000\n",
      "\n",
      "Epoch 03520: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3521/5000\n",
      "\n",
      "Epoch 03521: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3522/5000\n",
      "\n",
      "Epoch 03522: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3523/5000\n",
      "\n",
      "Epoch 03523: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3524/5000\n",
      "\n",
      "Epoch 03524: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0089\n",
      "Epoch 3525/5000\n",
      "\n",
      "Epoch 03525: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0095\n",
      "Epoch 3526/5000\n",
      "\n",
      "Epoch 03526: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3527/5000\n",
      "\n",
      "Epoch 03527: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3528/5000\n",
      "\n",
      "Epoch 03528: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3529/5000\n",
      "\n",
      "Epoch 03529: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3530/5000\n",
      "\n",
      "Epoch 03530: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3531/5000\n",
      "\n",
      "Epoch 03531: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3532/5000\n",
      "\n",
      "Epoch 03532: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3533/5000\n",
      "\n",
      "Epoch 03533: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3534/5000\n",
      "\n",
      "Epoch 03534: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3535/5000\n",
      "\n",
      "Epoch 03535: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3536/5000\n",
      "\n",
      "Epoch 03536: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3537/5000\n",
      "\n",
      "Epoch 03537: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3538/5000\n",
      "\n",
      "Epoch 03538: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3539/5000\n",
      "\n",
      "Epoch 03539: loss did not improve from 0.00683\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3540/5000\n",
      "\n",
      "Epoch 03540: loss improved from 0.00683 to 0.00680, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0068\n",
      "Epoch 3541/5000\n",
      "\n",
      "Epoch 03541: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3542/5000\n",
      "\n",
      "Epoch 03542: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3543/5000\n",
      "\n",
      "Epoch 03543: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3544/5000\n",
      "\n",
      "Epoch 03544: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3545/5000\n",
      "\n",
      "Epoch 03545: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3546/5000\n",
      "\n",
      "Epoch 03546: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3547/5000\n",
      "\n",
      "Epoch 03547: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3548/5000\n",
      "\n",
      "Epoch 03548: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3549/5000\n",
      "\n",
      "Epoch 03549: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3550/5000\n",
      "\n",
      "Epoch 03550: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3551/5000\n",
      "\n",
      "Epoch 03551: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3552/5000\n",
      "\n",
      "Epoch 03552: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3553/5000\n",
      "\n",
      "Epoch 03553: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3554/5000\n",
      "\n",
      "Epoch 03554: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3555/5000\n",
      "\n",
      "Epoch 03555: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3556/5000\n",
      "\n",
      "Epoch 03556: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3557/5000\n",
      "\n",
      "Epoch 03557: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3558/5000\n",
      "\n",
      "Epoch 03558: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3559/5000\n",
      "\n",
      "Epoch 03559: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3560/5000\n",
      "\n",
      "Epoch 03560: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3561/5000\n",
      "\n",
      "Epoch 03561: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3562/5000\n",
      "\n",
      "Epoch 03562: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3563/5000\n",
      "\n",
      "Epoch 03563: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3564/5000\n",
      "\n",
      "Epoch 03564: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3565/5000\n",
      "\n",
      "Epoch 03565: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3566/5000\n",
      "\n",
      "Epoch 03566: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3567/5000\n",
      "\n",
      "Epoch 03567: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3568/5000\n",
      "\n",
      "Epoch 03568: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3569/5000\n",
      "\n",
      "Epoch 03569: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3570/5000\n",
      "\n",
      "Epoch 03570: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3571/5000\n",
      "\n",
      "Epoch 03571: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3572/5000\n",
      "\n",
      "Epoch 03572: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3573/5000\n",
      "\n",
      "Epoch 03573: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3574/5000\n",
      "\n",
      "Epoch 03574: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3575/5000\n",
      "\n",
      "Epoch 03575: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3576/5000\n",
      "\n",
      "Epoch 03576: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3577/5000\n",
      "\n",
      "Epoch 03577: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3578/5000\n",
      "\n",
      "Epoch 03578: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3579/5000\n",
      "\n",
      "Epoch 03579: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3580/5000\n",
      "\n",
      "Epoch 03580: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3581/5000\n",
      "\n",
      "Epoch 03581: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3582/5000\n",
      "\n",
      "Epoch 03582: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3583/5000\n",
      "\n",
      "Epoch 03583: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3584/5000\n",
      "\n",
      "Epoch 03584: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3585/5000\n",
      "\n",
      "Epoch 03585: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3586/5000\n",
      "\n",
      "Epoch 03586: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3587/5000\n",
      "\n",
      "Epoch 03587: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3588/5000\n",
      "\n",
      "Epoch 03588: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3589/5000\n",
      "\n",
      "Epoch 03589: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3590/5000\n",
      "\n",
      "Epoch 03590: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3591/5000\n",
      "\n",
      "Epoch 03591: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3592/5000\n",
      "\n",
      "Epoch 03592: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3593/5000\n",
      "\n",
      "Epoch 03593: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3594/5000\n",
      "\n",
      "Epoch 03594: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3595/5000\n",
      "\n",
      "Epoch 03595: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0081\n",
      "Epoch 3596/5000\n",
      "\n",
      "Epoch 03596: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3597/5000\n",
      "\n",
      "Epoch 03597: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3598/5000\n",
      "\n",
      "Epoch 03598: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3599/5000\n",
      "\n",
      "Epoch 03599: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3600/5000\n",
      "\n",
      "Epoch 03600: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3601/5000\n",
      "\n",
      "Epoch 03601: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3602/5000\n",
      "\n",
      "Epoch 03602: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3603/5000\n",
      "\n",
      "Epoch 03603: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3604/5000\n",
      "\n",
      "Epoch 03604: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3605/5000\n",
      "\n",
      "Epoch 03605: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3606/5000\n",
      "\n",
      "Epoch 03606: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3607/5000\n",
      "\n",
      "Epoch 03607: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3608/5000\n",
      "\n",
      "Epoch 03608: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3609/5000\n",
      "\n",
      "Epoch 03609: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3610/5000\n",
      "\n",
      "Epoch 03610: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3611/5000\n",
      "\n",
      "Epoch 03611: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3612/5000\n",
      "\n",
      "Epoch 03612: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3613/5000\n",
      "\n",
      "Epoch 03613: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3614/5000\n",
      "\n",
      "Epoch 03614: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3615/5000\n",
      "\n",
      "Epoch 03615: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3616/5000\n",
      "\n",
      "Epoch 03616: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3617/5000\n",
      "\n",
      "Epoch 03617: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3618/5000\n",
      "\n",
      "Epoch 03618: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3619/5000\n",
      "\n",
      "Epoch 03619: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3620/5000\n",
      "\n",
      "Epoch 03620: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3621/5000\n",
      "\n",
      "Epoch 03621: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3622/5000\n",
      "\n",
      "Epoch 03622: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3623/5000\n",
      "\n",
      "Epoch 03623: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3624/5000\n",
      "\n",
      "Epoch 03624: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3625/5000\n",
      "\n",
      "Epoch 03625: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3626/5000\n",
      "\n",
      "Epoch 03626: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3627/5000\n",
      "\n",
      "Epoch 03627: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3628/5000\n",
      "\n",
      "Epoch 03628: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3629/5000\n",
      "\n",
      "Epoch 03629: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3630/5000\n",
      "\n",
      "Epoch 03630: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3631/5000\n",
      "\n",
      "Epoch 03631: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3632/5000\n",
      "\n",
      "Epoch 03632: loss did not improve from 0.00680\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3633/5000\n",
      "\n",
      "Epoch 03633: loss improved from 0.00680 to 0.00677, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0068\n",
      "Epoch 3634/5000\n",
      "\n",
      "Epoch 03634: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3635/5000\n",
      "\n",
      "Epoch 03635: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3636/5000\n",
      "\n",
      "Epoch 03636: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3637/5000\n",
      "\n",
      "Epoch 03637: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3638/5000\n",
      "\n",
      "Epoch 03638: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3639/5000\n",
      "\n",
      "Epoch 03639: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3640/5000\n",
      "\n",
      "Epoch 03640: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3641/5000\n",
      "\n",
      "Epoch 03641: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3642/5000\n",
      "\n",
      "Epoch 03642: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3643/5000\n",
      "\n",
      "Epoch 03643: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3644/5000\n",
      "\n",
      "Epoch 03644: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3645/5000\n",
      "\n",
      "Epoch 03645: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3646/5000\n",
      "\n",
      "Epoch 03646: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3647/5000\n",
      "\n",
      "Epoch 03647: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3648/5000\n",
      "\n",
      "Epoch 03648: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3649/5000\n",
      "\n",
      "Epoch 03649: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3650/5000\n",
      "\n",
      "Epoch 03650: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3651/5000\n",
      "\n",
      "Epoch 03651: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3652/5000\n",
      "\n",
      "Epoch 03652: loss did not improve from 0.00677\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3653/5000\n",
      "\n",
      "Epoch 03653: loss improved from 0.00677 to 0.00675, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0067\n",
      "Epoch 3654/5000\n",
      "\n",
      "Epoch 03654: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3655/5000\n",
      "\n",
      "Epoch 03655: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3656/5000\n",
      "\n",
      "Epoch 03656: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3657/5000\n",
      "\n",
      "Epoch 03657: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3658/5000\n",
      "\n",
      "Epoch 03658: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3659/5000\n",
      "\n",
      "Epoch 03659: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3660/5000\n",
      "\n",
      "Epoch 03660: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3661/5000\n",
      "\n",
      "Epoch 03661: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3662/5000\n",
      "\n",
      "Epoch 03662: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3663/5000\n",
      "\n",
      "Epoch 03663: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3664/5000\n",
      "\n",
      "Epoch 03664: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3665/5000\n",
      "\n",
      "Epoch 03665: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3666/5000\n",
      "\n",
      "Epoch 03666: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3667/5000\n",
      "\n",
      "Epoch 03667: loss did not improve from 0.00675\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0091\n",
      "Epoch 3668/5000\n",
      "\n",
      "Epoch 03668: loss improved from 0.00675 to 0.00670, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0067\n",
      "Epoch 3669/5000\n",
      "\n",
      "Epoch 03669: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3670/5000\n",
      "\n",
      "Epoch 03670: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3671/5000\n",
      "\n",
      "Epoch 03671: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3672/5000\n",
      "\n",
      "Epoch 03672: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3673/5000\n",
      "\n",
      "Epoch 03673: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3674/5000\n",
      "\n",
      "Epoch 03674: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3675/5000\n",
      "\n",
      "Epoch 03675: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3676/5000\n",
      "\n",
      "Epoch 03676: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3677/5000\n",
      "\n",
      "Epoch 03677: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3678/5000\n",
      "\n",
      "Epoch 03678: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3679/5000\n",
      "\n",
      "Epoch 03679: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3680/5000\n",
      "\n",
      "Epoch 03680: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3681/5000\n",
      "\n",
      "Epoch 03681: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3682/5000\n",
      "\n",
      "Epoch 03682: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3683/5000\n",
      "\n",
      "Epoch 03683: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3684/5000\n",
      "\n",
      "Epoch 03684: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3685/5000\n",
      "\n",
      "Epoch 03685: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3686/5000\n",
      "\n",
      "Epoch 03686: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3687/5000\n",
      "\n",
      "Epoch 03687: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3688/5000\n",
      "\n",
      "Epoch 03688: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3689/5000\n",
      "\n",
      "Epoch 03689: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3690/5000\n",
      "\n",
      "Epoch 03690: loss did not improve from 0.00670\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3691/5000\n",
      "\n",
      "Epoch 03691: loss improved from 0.00670 to 0.00662, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0066\n",
      "Epoch 3692/5000\n",
      "\n",
      "Epoch 03692: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3693/5000\n",
      "\n",
      "Epoch 03693: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3694/5000\n",
      "\n",
      "Epoch 03694: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3695/5000\n",
      "\n",
      "Epoch 03695: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3696/5000\n",
      "\n",
      "Epoch 03696: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3697/5000\n",
      "\n",
      "Epoch 03697: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3698/5000\n",
      "\n",
      "Epoch 03698: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3699/5000\n",
      "\n",
      "Epoch 03699: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3700/5000\n",
      "\n",
      "Epoch 03700: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3701/5000\n",
      "\n",
      "Epoch 03701: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3702/5000\n",
      "\n",
      "Epoch 03702: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3703/5000\n",
      "\n",
      "Epoch 03703: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3704/5000\n",
      "\n",
      "Epoch 03704: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3705/5000\n",
      "\n",
      "Epoch 03705: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3706/5000\n",
      "\n",
      "Epoch 03706: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3707/5000\n",
      "\n",
      "Epoch 03707: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3708/5000\n",
      "\n",
      "Epoch 03708: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3709/5000\n",
      "\n",
      "Epoch 03709: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3710/5000\n",
      "\n",
      "Epoch 03710: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3711/5000\n",
      "\n",
      "Epoch 03711: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3712/5000\n",
      "\n",
      "Epoch 03712: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3713/5000\n",
      "\n",
      "Epoch 03713: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3714/5000\n",
      "\n",
      "Epoch 03714: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3715/5000\n",
      "\n",
      "Epoch 03715: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3716/5000\n",
      "\n",
      "Epoch 03716: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3717/5000\n",
      "\n",
      "Epoch 03717: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3718/5000\n",
      "\n",
      "Epoch 03718: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3719/5000\n",
      "\n",
      "Epoch 03719: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3720/5000\n",
      "\n",
      "Epoch 03720: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3721/5000\n",
      "\n",
      "Epoch 03721: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3722/5000\n",
      "\n",
      "Epoch 03722: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3723/5000\n",
      "\n",
      "Epoch 03723: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3724/5000\n",
      "\n",
      "Epoch 03724: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3725/5000\n",
      "\n",
      "Epoch 03725: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3726/5000\n",
      "\n",
      "Epoch 03726: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3727/5000\n",
      "\n",
      "Epoch 03727: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3728/5000\n",
      "\n",
      "Epoch 03728: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3729/5000\n",
      "\n",
      "Epoch 03729: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3730/5000\n",
      "\n",
      "Epoch 03730: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3731/5000\n",
      "\n",
      "Epoch 03731: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3732/5000\n",
      "\n",
      "Epoch 03732: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3733/5000\n",
      "\n",
      "Epoch 03733: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3734/5000\n",
      "\n",
      "Epoch 03734: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3735/5000\n",
      "\n",
      "Epoch 03735: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3736/5000\n",
      "\n",
      "Epoch 03736: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3737/5000\n",
      "\n",
      "Epoch 03737: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3738/5000\n",
      "\n",
      "Epoch 03738: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3739/5000\n",
      "\n",
      "Epoch 03739: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3740/5000\n",
      "\n",
      "Epoch 03740: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3741/5000\n",
      "\n",
      "Epoch 03741: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3742/5000\n",
      "\n",
      "Epoch 03742: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3743/5000\n",
      "\n",
      "Epoch 03743: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 3744/5000\n",
      "\n",
      "Epoch 03744: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3745/5000\n",
      "\n",
      "Epoch 03745: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3746/5000\n",
      "\n",
      "Epoch 03746: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3747/5000\n",
      "\n",
      "Epoch 03747: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3748/5000\n",
      "\n",
      "Epoch 03748: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3749/5000\n",
      "\n",
      "Epoch 03749: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3750/5000\n",
      "\n",
      "Epoch 03750: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3751/5000\n",
      "\n",
      "Epoch 03751: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3752/5000\n",
      "\n",
      "Epoch 03752: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3753/5000\n",
      "\n",
      "Epoch 03753: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3754/5000\n",
      "\n",
      "Epoch 03754: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3755/5000\n",
      "\n",
      "Epoch 03755: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3756/5000\n",
      "\n",
      "Epoch 03756: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 3757/5000\n",
      "\n",
      "Epoch 03757: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3758/5000\n",
      "\n",
      "Epoch 03758: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3759/5000\n",
      "\n",
      "Epoch 03759: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3760/5000\n",
      "\n",
      "Epoch 03760: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3761/5000\n",
      "\n",
      "Epoch 03761: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3762/5000\n",
      "\n",
      "Epoch 03762: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3763/5000\n",
      "\n",
      "Epoch 03763: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3764/5000\n",
      "\n",
      "Epoch 03764: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3765/5000\n",
      "\n",
      "Epoch 03765: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3766/5000\n",
      "\n",
      "Epoch 03766: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 3767/5000\n",
      "\n",
      "Epoch 03767: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3768/5000\n",
      "\n",
      "Epoch 03768: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3769/5000\n",
      "\n",
      "Epoch 03769: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3770/5000\n",
      "\n",
      "Epoch 03770: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3771/5000\n",
      "\n",
      "Epoch 03771: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3772/5000\n",
      "\n",
      "Epoch 03772: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3773/5000\n",
      "\n",
      "Epoch 03773: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0087\n",
      "Epoch 3774/5000\n",
      "\n",
      "Epoch 03774: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3775/5000\n",
      "\n",
      "Epoch 03775: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3776/5000\n",
      "\n",
      "Epoch 03776: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3777/5000\n",
      "\n",
      "Epoch 03777: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3778/5000\n",
      "\n",
      "Epoch 03778: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3779/5000\n",
      "\n",
      "Epoch 03779: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3780/5000\n",
      "\n",
      "Epoch 03780: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3781/5000\n",
      "\n",
      "Epoch 03781: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3782/5000\n",
      "\n",
      "Epoch 03782: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3783/5000\n",
      "\n",
      "Epoch 03783: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3784/5000\n",
      "\n",
      "Epoch 03784: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3785/5000\n",
      "\n",
      "Epoch 03785: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3786/5000\n",
      "\n",
      "Epoch 03786: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3787/5000\n",
      "\n",
      "Epoch 03787: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3788/5000\n",
      "\n",
      "Epoch 03788: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3789/5000\n",
      "\n",
      "Epoch 03789: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3790/5000\n",
      "\n",
      "Epoch 03790: loss did not improve from 0.00662\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3791/5000\n",
      "\n",
      "Epoch 03791: loss improved from 0.00662 to 0.00641, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0064\n",
      "Epoch 3792/5000\n",
      "\n",
      "Epoch 03792: loss improved from 0.00641 to 0.00635, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0063\n",
      "Epoch 3793/5000\n",
      "\n",
      "Epoch 03793: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3794/5000\n",
      "\n",
      "Epoch 03794: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3795/5000\n",
      "\n",
      "Epoch 03795: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3796/5000\n",
      "\n",
      "Epoch 03796: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3797/5000\n",
      "\n",
      "Epoch 03797: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3798/5000\n",
      "\n",
      "Epoch 03798: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3799/5000\n",
      "\n",
      "Epoch 03799: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3800/5000\n",
      "\n",
      "Epoch 03800: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3801/5000\n",
      "\n",
      "Epoch 03801: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3802/5000\n",
      "\n",
      "Epoch 03802: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3803/5000\n",
      "\n",
      "Epoch 03803: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3804/5000\n",
      "\n",
      "Epoch 03804: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3805/5000\n",
      "\n",
      "Epoch 03805: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3806/5000\n",
      "\n",
      "Epoch 03806: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3807/5000\n",
      "\n",
      "Epoch 03807: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3808/5000\n",
      "\n",
      "Epoch 03808: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3809/5000\n",
      "\n",
      "Epoch 03809: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3810/5000\n",
      "\n",
      "Epoch 03810: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3811/5000\n",
      "\n",
      "Epoch 03811: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3812/5000\n",
      "\n",
      "Epoch 03812: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3813/5000\n",
      "\n",
      "Epoch 03813: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3814/5000\n",
      "\n",
      "Epoch 03814: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3815/5000\n",
      "\n",
      "Epoch 03815: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3816/5000\n",
      "\n",
      "Epoch 03816: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3817/5000\n",
      "\n",
      "Epoch 03817: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3818/5000\n",
      "\n",
      "Epoch 03818: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3819/5000\n",
      "\n",
      "Epoch 03819: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3820/5000\n",
      "\n",
      "Epoch 03820: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3821/5000\n",
      "\n",
      "Epoch 03821: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3822/5000\n",
      "\n",
      "Epoch 03822: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3823/5000\n",
      "\n",
      "Epoch 03823: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3824/5000\n",
      "\n",
      "Epoch 03824: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3825/5000\n",
      "\n",
      "Epoch 03825: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3826/5000\n",
      "\n",
      "Epoch 03826: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3827/5000\n",
      "\n",
      "Epoch 03827: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3828/5000\n",
      "\n",
      "Epoch 03828: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3829/5000\n",
      "\n",
      "Epoch 03829: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3830/5000\n",
      "\n",
      "Epoch 03830: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3831/5000\n",
      "\n",
      "Epoch 03831: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3832/5000\n",
      "\n",
      "Epoch 03832: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3833/5000\n",
      "\n",
      "Epoch 03833: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3834/5000\n",
      "\n",
      "Epoch 03834: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3835/5000\n",
      "\n",
      "Epoch 03835: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3836/5000\n",
      "\n",
      "Epoch 03836: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3837/5000\n",
      "\n",
      "Epoch 03837: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3838/5000\n",
      "\n",
      "Epoch 03838: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3839/5000\n",
      "\n",
      "Epoch 03839: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 3840/5000\n",
      "\n",
      "Epoch 03840: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3841/5000\n",
      "\n",
      "Epoch 03841: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3842/5000\n",
      "\n",
      "Epoch 03842: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 3843/5000\n",
      "\n",
      "Epoch 03843: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3844/5000\n",
      "\n",
      "Epoch 03844: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3845/5000\n",
      "\n",
      "Epoch 03845: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0077\n",
      "Epoch 3846/5000\n",
      "\n",
      "Epoch 03846: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3847/5000\n",
      "\n",
      "Epoch 03847: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3848/5000\n",
      "\n",
      "Epoch 03848: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3849/5000\n",
      "\n",
      "Epoch 03849: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3850/5000\n",
      "\n",
      "Epoch 03850: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3851/5000\n",
      "\n",
      "Epoch 03851: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3852/5000\n",
      "\n",
      "Epoch 03852: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3853/5000\n",
      "\n",
      "Epoch 03853: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 3854/5000\n",
      "\n",
      "Epoch 03854: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3855/5000\n",
      "\n",
      "Epoch 03855: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3856/5000\n",
      "\n",
      "Epoch 03856: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3857/5000\n",
      "\n",
      "Epoch 03857: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 3858/5000\n",
      "\n",
      "Epoch 03858: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3859/5000\n",
      "\n",
      "Epoch 03859: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3860/5000\n",
      "\n",
      "Epoch 03860: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3861/5000\n",
      "\n",
      "Epoch 03861: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3862/5000\n",
      "\n",
      "Epoch 03862: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3863/5000\n",
      "\n",
      "Epoch 03863: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3864/5000\n",
      "\n",
      "Epoch 03864: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3865/5000\n",
      "\n",
      "Epoch 03865: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3866/5000\n",
      "\n",
      "Epoch 03866: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 3867/5000\n",
      "\n",
      "Epoch 03867: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3868/5000\n",
      "\n",
      "Epoch 03868: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3869/5000\n",
      "\n",
      "Epoch 03869: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3870/5000\n",
      "\n",
      "Epoch 03870: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3871/5000\n",
      "\n",
      "Epoch 03871: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3872/5000\n",
      "\n",
      "Epoch 03872: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3873/5000\n",
      "\n",
      "Epoch 03873: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3874/5000\n",
      "\n",
      "Epoch 03874: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3875/5000\n",
      "\n",
      "Epoch 03875: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0084\n",
      "Epoch 3876/5000\n",
      "\n",
      "Epoch 03876: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3877/5000\n",
      "\n",
      "Epoch 03877: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 3878/5000\n",
      "\n",
      "Epoch 03878: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3879/5000\n",
      "\n",
      "Epoch 03879: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3880/5000\n",
      "\n",
      "Epoch 03880: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3881/5000\n",
      "\n",
      "Epoch 03881: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3882/5000\n",
      "\n",
      "Epoch 03882: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3883/5000\n",
      "\n",
      "Epoch 03883: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3884/5000\n",
      "\n",
      "Epoch 03884: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3885/5000\n",
      "\n",
      "Epoch 03885: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3886/5000\n",
      "\n",
      "Epoch 03886: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3887/5000\n",
      "\n",
      "Epoch 03887: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3888/5000\n",
      "\n",
      "Epoch 03888: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3889/5000\n",
      "\n",
      "Epoch 03889: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3890/5000\n",
      "\n",
      "Epoch 03890: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3891/5000\n",
      "\n",
      "Epoch 03891: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3892/5000\n",
      "\n",
      "Epoch 03892: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3893/5000\n",
      "\n",
      "Epoch 03893: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3894/5000\n",
      "\n",
      "Epoch 03894: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3895/5000\n",
      "\n",
      "Epoch 03895: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3896/5000\n",
      "\n",
      "Epoch 03896: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3897/5000\n",
      "\n",
      "Epoch 03897: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3898/5000\n",
      "\n",
      "Epoch 03898: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3899/5000\n",
      "\n",
      "Epoch 03899: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3900/5000\n",
      "\n",
      "Epoch 03900: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3901/5000\n",
      "\n",
      "Epoch 03901: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3902/5000\n",
      "\n",
      "Epoch 03902: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3903/5000\n",
      "\n",
      "Epoch 03903: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3904/5000\n",
      "\n",
      "Epoch 03904: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3905/5000\n",
      "\n",
      "Epoch 03905: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3906/5000\n",
      "\n",
      "Epoch 03906: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 3907/5000\n",
      "\n",
      "Epoch 03907: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3908/5000\n",
      "\n",
      "Epoch 03908: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3909/5000\n",
      "\n",
      "Epoch 03909: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3910/5000\n",
      "\n",
      "Epoch 03910: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 3911/5000\n",
      "\n",
      "Epoch 03911: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3912/5000\n",
      "\n",
      "Epoch 03912: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3913/5000\n",
      "\n",
      "Epoch 03913: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3914/5000\n",
      "\n",
      "Epoch 03914: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3915/5000\n",
      "\n",
      "Epoch 03915: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 3916/5000\n",
      "\n",
      "Epoch 03916: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3917/5000\n",
      "\n",
      "Epoch 03917: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3918/5000\n",
      "\n",
      "Epoch 03918: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3919/5000\n",
      "\n",
      "Epoch 03919: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0090\n",
      "Epoch 3920/5000\n",
      "\n",
      "Epoch 03920: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 3921/5000\n",
      "\n",
      "Epoch 03921: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3922/5000\n",
      "\n",
      "Epoch 03922: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3923/5000\n",
      "\n",
      "Epoch 03923: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3924/5000\n",
      "\n",
      "Epoch 03924: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3925/5000\n",
      "\n",
      "Epoch 03925: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3926/5000\n",
      "\n",
      "Epoch 03926: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3927/5000\n",
      "\n",
      "Epoch 03927: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3928/5000\n",
      "\n",
      "Epoch 03928: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 3929/5000\n",
      "\n",
      "Epoch 03929: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3930/5000\n",
      "\n",
      "Epoch 03930: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 3931/5000\n",
      "\n",
      "Epoch 03931: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3932/5000\n",
      "\n",
      "Epoch 03932: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3933/5000\n",
      "\n",
      "Epoch 03933: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3934/5000\n",
      "\n",
      "Epoch 03934: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3935/5000\n",
      "\n",
      "Epoch 03935: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3936/5000\n",
      "\n",
      "Epoch 03936: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3937/5000\n",
      "\n",
      "Epoch 03937: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 3938/5000\n",
      "\n",
      "Epoch 03938: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3939/5000\n",
      "\n",
      "Epoch 03939: loss did not improve from 0.00635\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3940/5000\n",
      "\n",
      "Epoch 03940: loss improved from 0.00635 to 0.00625, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0063\n",
      "Epoch 3941/5000\n",
      "\n",
      "Epoch 03941: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 3942/5000\n",
      "\n",
      "Epoch 03942: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 3943/5000\n",
      "\n",
      "Epoch 03943: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3944/5000\n",
      "\n",
      "Epoch 03944: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3945/5000\n",
      "\n",
      "Epoch 03945: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3946/5000\n",
      "\n",
      "Epoch 03946: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3947/5000\n",
      "\n",
      "Epoch 03947: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3948/5000\n",
      "\n",
      "Epoch 03948: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3949/5000\n",
      "\n",
      "Epoch 03949: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3950/5000\n",
      "\n",
      "Epoch 03950: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 3951/5000\n",
      "\n",
      "Epoch 03951: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3952/5000\n",
      "\n",
      "Epoch 03952: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 3953/5000\n",
      "\n",
      "Epoch 03953: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3954/5000\n",
      "\n",
      "Epoch 03954: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3955/5000\n",
      "\n",
      "Epoch 03955: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3956/5000\n",
      "\n",
      "Epoch 03956: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3957/5000\n",
      "\n",
      "Epoch 03957: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3958/5000\n",
      "\n",
      "Epoch 03958: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0088\n",
      "Epoch 3959/5000\n",
      "\n",
      "Epoch 03959: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3960/5000\n",
      "\n",
      "Epoch 03960: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3961/5000\n",
      "\n",
      "Epoch 03961: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 3962/5000\n",
      "\n",
      "Epoch 03962: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 3963/5000\n",
      "\n",
      "Epoch 03963: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3964/5000\n",
      "\n",
      "Epoch 03964: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3965/5000\n",
      "\n",
      "Epoch 03965: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3966/5000\n",
      "\n",
      "Epoch 03966: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 3967/5000\n",
      "\n",
      "Epoch 03967: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3968/5000\n",
      "\n",
      "Epoch 03968: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3969/5000\n",
      "\n",
      "Epoch 03969: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 3970/5000\n",
      "\n",
      "Epoch 03970: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 3971/5000\n",
      "\n",
      "Epoch 03971: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3972/5000\n",
      "\n",
      "Epoch 03972: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 3973/5000\n",
      "\n",
      "Epoch 03973: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3974/5000\n",
      "\n",
      "Epoch 03974: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3975/5000\n",
      "\n",
      "Epoch 03975: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3976/5000\n",
      "\n",
      "Epoch 03976: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3977/5000\n",
      "\n",
      "Epoch 03977: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3978/5000\n",
      "\n",
      "Epoch 03978: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3979/5000\n",
      "\n",
      "Epoch 03979: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 3980/5000\n",
      "\n",
      "Epoch 03980: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 3981/5000\n",
      "\n",
      "Epoch 03981: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 3982/5000\n",
      "\n",
      "Epoch 03982: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 3983/5000\n",
      "\n",
      "Epoch 03983: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3984/5000\n",
      "\n",
      "Epoch 03984: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 3985/5000\n",
      "\n",
      "Epoch 03985: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 3986/5000\n",
      "\n",
      "Epoch 03986: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 3987/5000\n",
      "\n",
      "Epoch 03987: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 3988/5000\n",
      "\n",
      "Epoch 03988: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3989/5000\n",
      "\n",
      "Epoch 03989: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 3990/5000\n",
      "\n",
      "Epoch 03990: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3991/5000\n",
      "\n",
      "Epoch 03991: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 3992/5000\n",
      "\n",
      "Epoch 03992: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 3993/5000\n",
      "\n",
      "Epoch 03993: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 3994/5000\n",
      "\n",
      "Epoch 03994: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 3995/5000\n",
      "\n",
      "Epoch 03995: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 3996/5000\n",
      "\n",
      "Epoch 03996: loss did not improve from 0.00625\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 3997/5000\n",
      "\n",
      "Epoch 03997: loss improved from 0.00625 to 0.00604, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0060\n",
      "Epoch 3998/5000\n",
      "\n",
      "Epoch 03998: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 3999/5000\n",
      "\n",
      "Epoch 03999: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4000/5000\n",
      "\n",
      "Epoch 04000: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4001/5000\n",
      "\n",
      "Epoch 04001: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4002/5000\n",
      "\n",
      "Epoch 04002: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4003/5000\n",
      "\n",
      "Epoch 04003: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4004/5000\n",
      "\n",
      "Epoch 04004: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4005/5000\n",
      "\n",
      "Epoch 04005: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4006/5000\n",
      "\n",
      "Epoch 04006: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4007/5000\n",
      "\n",
      "Epoch 04007: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4008/5000\n",
      "\n",
      "Epoch 04008: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4009/5000\n",
      "\n",
      "Epoch 04009: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 4010/5000\n",
      "\n",
      "Epoch 04010: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4011/5000\n",
      "\n",
      "Epoch 04011: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4012/5000\n",
      "\n",
      "Epoch 04012: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4013/5000\n",
      "\n",
      "Epoch 04013: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 4014/5000\n",
      "\n",
      "Epoch 04014: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 4015/5000\n",
      "\n",
      "Epoch 04015: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4016/5000\n",
      "\n",
      "Epoch 04016: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4017/5000\n",
      "\n",
      "Epoch 04017: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4018/5000\n",
      "\n",
      "Epoch 04018: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4019/5000\n",
      "\n",
      "Epoch 04019: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4020/5000\n",
      "\n",
      "Epoch 04020: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4021/5000\n",
      "\n",
      "Epoch 04021: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 4022/5000\n",
      "\n",
      "Epoch 04022: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4023/5000\n",
      "\n",
      "Epoch 04023: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 4024/5000\n",
      "\n",
      "Epoch 04024: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 4025/5000\n",
      "\n",
      "Epoch 04025: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 4026/5000\n",
      "\n",
      "Epoch 04026: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4027/5000\n",
      "\n",
      "Epoch 04027: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4028/5000\n",
      "\n",
      "Epoch 04028: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4029/5000\n",
      "\n",
      "Epoch 04029: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4030/5000\n",
      "\n",
      "Epoch 04030: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4031/5000\n",
      "\n",
      "Epoch 04031: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4032/5000\n",
      "\n",
      "Epoch 04032: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4033/5000\n",
      "\n",
      "Epoch 04033: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4034/5000\n",
      "\n",
      "Epoch 04034: loss did not improve from 0.00604\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 4035/5000\n",
      "\n",
      "Epoch 04035: loss improved from 0.00604 to 0.00601, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0060\n",
      "Epoch 4036/5000\n",
      "\n",
      "Epoch 04036: loss did not improve from 0.00601\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4037/5000\n",
      "\n",
      "Epoch 04037: loss did not improve from 0.00601\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4038/5000\n",
      "\n",
      "Epoch 04038: loss did not improve from 0.00601\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4039/5000\n",
      "\n",
      "Epoch 04039: loss did not improve from 0.00601\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4040/5000\n",
      "\n",
      "Epoch 04040: loss did not improve from 0.00601\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4041/5000\n",
      "\n",
      "Epoch 04041: loss did not improve from 0.00601\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4042/5000\n",
      "\n",
      "Epoch 04042: loss did not improve from 0.00601\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4043/5000\n",
      "\n",
      "Epoch 04043: loss did not improve from 0.00601\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4044/5000\n",
      "\n",
      "Epoch 04044: loss improved from 0.00601 to 0.00598, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0060\n",
      "Epoch 4045/5000\n",
      "\n",
      "Epoch 04045: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 4046/5000\n",
      "\n",
      "Epoch 04046: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4047/5000\n",
      "\n",
      "Epoch 04047: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0064\n",
      "Epoch 4048/5000\n",
      "\n",
      "Epoch 04048: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4049/5000\n",
      "\n",
      "Epoch 04049: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4050/5000\n",
      "\n",
      "Epoch 04050: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 4051/5000\n",
      "\n",
      "Epoch 04051: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4052/5000\n",
      "\n",
      "Epoch 04052: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 4053/5000\n",
      "\n",
      "Epoch 04053: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4054/5000\n",
      "\n",
      "Epoch 04054: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4055/5000\n",
      "\n",
      "Epoch 04055: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4056/5000\n",
      "\n",
      "Epoch 04056: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 4057/5000\n",
      "\n",
      "Epoch 04057: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4058/5000\n",
      "\n",
      "Epoch 04058: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4059/5000\n",
      "\n",
      "Epoch 04059: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4060/5000\n",
      "\n",
      "Epoch 04060: loss did not improve from 0.00598\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4061/5000\n",
      "\n",
      "Epoch 04061: loss improved from 0.00598 to 0.00592, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0059\n",
      "Epoch 4062/5000\n",
      "\n",
      "Epoch 04062: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4063/5000\n",
      "\n",
      "Epoch 04063: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4064/5000\n",
      "\n",
      "Epoch 04064: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4065/5000\n",
      "\n",
      "Epoch 04065: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4066/5000\n",
      "\n",
      "Epoch 04066: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4067/5000\n",
      "\n",
      "Epoch 04067: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4068/5000\n",
      "\n",
      "Epoch 04068: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4069/5000\n",
      "\n",
      "Epoch 04069: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4070/5000\n",
      "\n",
      "Epoch 04070: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4071/5000\n",
      "\n",
      "Epoch 04071: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4072/5000\n",
      "\n",
      "Epoch 04072: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 4073/5000\n",
      "\n",
      "Epoch 04073: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4074/5000\n",
      "\n",
      "Epoch 04074: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 4075/5000\n",
      "\n",
      "Epoch 04075: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4076/5000\n",
      "\n",
      "Epoch 04076: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4077/5000\n",
      "\n",
      "Epoch 04077: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4078/5000\n",
      "\n",
      "Epoch 04078: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4079/5000\n",
      "\n",
      "Epoch 04079: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4080/5000\n",
      "\n",
      "Epoch 04080: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4081/5000\n",
      "\n",
      "Epoch 04081: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 4082/5000\n",
      "\n",
      "Epoch 04082: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4083/5000\n",
      "\n",
      "Epoch 04083: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4084/5000\n",
      "\n",
      "Epoch 04084: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 4085/5000\n",
      "\n",
      "Epoch 04085: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4086/5000\n",
      "\n",
      "Epoch 04086: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4087/5000\n",
      "\n",
      "Epoch 04087: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4088/5000\n",
      "\n",
      "Epoch 04088: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4089/5000\n",
      "\n",
      "Epoch 04089: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4090/5000\n",
      "\n",
      "Epoch 04090: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4091/5000\n",
      "\n",
      "Epoch 04091: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4092/5000\n",
      "\n",
      "Epoch 04092: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4093/5000\n",
      "\n",
      "Epoch 04093: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0060\n",
      "Epoch 4094/5000\n",
      "\n",
      "Epoch 04094: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 4095/5000\n",
      "\n",
      "Epoch 04095: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4096/5000\n",
      "\n",
      "Epoch 04096: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4097/5000\n",
      "\n",
      "Epoch 04097: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0072\n",
      "Epoch 4098/5000\n",
      "\n",
      "Epoch 04098: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4099/5000\n",
      "\n",
      "Epoch 04099: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4100/5000\n",
      "\n",
      "Epoch 04100: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4101/5000\n",
      "\n",
      "Epoch 04101: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4102/5000\n",
      "\n",
      "Epoch 04102: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4103/5000\n",
      "\n",
      "Epoch 04103: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4104/5000\n",
      "\n",
      "Epoch 04104: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0074\n",
      "Epoch 4105/5000\n",
      "\n",
      "Epoch 04105: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4106/5000\n",
      "\n",
      "Epoch 04106: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4107/5000\n",
      "\n",
      "Epoch 04107: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4108/5000\n",
      "\n",
      "Epoch 04108: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4109/5000\n",
      "\n",
      "Epoch 04109: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4110/5000\n",
      "\n",
      "Epoch 04110: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4111/5000\n",
      "\n",
      "Epoch 04111: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4112/5000\n",
      "\n",
      "Epoch 04112: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4113/5000\n",
      "\n",
      "Epoch 04113: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4114/5000\n",
      "\n",
      "Epoch 04114: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4115/5000\n",
      "\n",
      "Epoch 04115: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4116/5000\n",
      "\n",
      "Epoch 04116: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4117/5000\n",
      "\n",
      "Epoch 04117: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4118/5000\n",
      "\n",
      "Epoch 04118: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4119/5000\n",
      "\n",
      "Epoch 04119: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 4120/5000\n",
      "\n",
      "Epoch 04120: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4121/5000\n",
      "\n",
      "Epoch 04121: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4122/5000\n",
      "\n",
      "Epoch 04122: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4123/5000\n",
      "\n",
      "Epoch 04123: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4124/5000\n",
      "\n",
      "Epoch 04124: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 4125/5000\n",
      "\n",
      "Epoch 04125: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4126/5000\n",
      "\n",
      "Epoch 04126: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4127/5000\n",
      "\n",
      "Epoch 04127: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4128/5000\n",
      "\n",
      "Epoch 04128: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4129/5000\n",
      "\n",
      "Epoch 04129: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4130/5000\n",
      "\n",
      "Epoch 04130: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 4131/5000\n",
      "\n",
      "Epoch 04131: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0071\n",
      "Epoch 4132/5000\n",
      "\n",
      "Epoch 04132: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4133/5000\n",
      "\n",
      "Epoch 04133: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4134/5000\n",
      "\n",
      "Epoch 04134: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4135/5000\n",
      "\n",
      "Epoch 04135: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4136/5000\n",
      "\n",
      "Epoch 04136: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4137/5000\n",
      "\n",
      "Epoch 04137: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 4138/5000\n",
      "\n",
      "Epoch 04138: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4139/5000\n",
      "\n",
      "Epoch 04139: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4140/5000\n",
      "\n",
      "Epoch 04140: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4141/5000\n",
      "\n",
      "Epoch 04141: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4142/5000\n",
      "\n",
      "Epoch 04142: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0071\n",
      "Epoch 4143/5000\n",
      "\n",
      "Epoch 04143: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 4144/5000\n",
      "\n",
      "Epoch 04144: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0064\n",
      "Epoch 4145/5000\n",
      "\n",
      "Epoch 04145: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0071\n",
      "Epoch 4146/5000\n",
      "\n",
      "Epoch 04146: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4147/5000\n",
      "\n",
      "Epoch 04147: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4148/5000\n",
      "\n",
      "Epoch 04148: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4149/5000\n",
      "\n",
      "Epoch 04149: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4150/5000\n",
      "\n",
      "Epoch 04150: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4151/5000\n",
      "\n",
      "Epoch 04151: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4152/5000\n",
      "\n",
      "Epoch 04152: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4153/5000\n",
      "\n",
      "Epoch 04153: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0086\n",
      "Epoch 4154/5000\n",
      "\n",
      "Epoch 04154: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4155/5000\n",
      "\n",
      "Epoch 04155: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4156/5000\n",
      "\n",
      "Epoch 04156: loss improved from 0.00592 to 0.00592, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0059\n",
      "Epoch 4157/5000\n",
      "\n",
      "Epoch 04157: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4158/5000\n",
      "\n",
      "Epoch 04158: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4159/5000\n",
      "\n",
      "Epoch 04159: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4160/5000\n",
      "\n",
      "Epoch 04160: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4161/5000\n",
      "\n",
      "Epoch 04161: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4162/5000\n",
      "\n",
      "Epoch 04162: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4163/5000\n",
      "\n",
      "Epoch 04163: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4164/5000\n",
      "\n",
      "Epoch 04164: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4165/5000\n",
      "\n",
      "Epoch 04165: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 4166/5000\n",
      "\n",
      "Epoch 04166: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4167/5000\n",
      "\n",
      "Epoch 04167: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 4168/5000\n",
      "\n",
      "Epoch 04168: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4169/5000\n",
      "\n",
      "Epoch 04169: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4170/5000\n",
      "\n",
      "Epoch 04170: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4171/5000\n",
      "\n",
      "Epoch 04171: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4172/5000\n",
      "\n",
      "Epoch 04172: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 4173/5000\n",
      "\n",
      "Epoch 04173: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4174/5000\n",
      "\n",
      "Epoch 04174: loss did not improve from 0.00592\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4175/5000\n",
      "\n",
      "Epoch 04175: loss improved from 0.00592 to 0.00569, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0057\n",
      "Epoch 4176/5000\n",
      "\n",
      "Epoch 04176: loss did not improve from 0.00569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4177/5000\n",
      "\n",
      "Epoch 04177: loss did not improve from 0.00569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4178/5000\n",
      "\n",
      "Epoch 04178: loss did not improve from 0.00569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0080\n",
      "Epoch 4179/5000\n",
      "\n",
      "Epoch 04179: loss did not improve from 0.00569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4180/5000\n",
      "\n",
      "Epoch 04180: loss did not improve from 0.00569\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4181/5000\n",
      "\n",
      "Epoch 04181: loss improved from 0.00569 to 0.00558, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0056\n",
      "Epoch 4182/5000\n",
      "\n",
      "Epoch 04182: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4183/5000\n",
      "\n",
      "Epoch 04183: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4184/5000\n",
      "\n",
      "Epoch 04184: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4185/5000\n",
      "\n",
      "Epoch 04185: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4186/5000\n",
      "\n",
      "Epoch 04186: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4187/5000\n",
      "\n",
      "Epoch 04187: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4188/5000\n",
      "\n",
      "Epoch 04188: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4189/5000\n",
      "\n",
      "Epoch 04189: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4190/5000\n",
      "\n",
      "Epoch 04190: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4191/5000\n",
      "\n",
      "Epoch 04191: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4192/5000\n",
      "\n",
      "Epoch 04192: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4193/5000\n",
      "\n",
      "Epoch 04193: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4194/5000\n",
      "\n",
      "Epoch 04194: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4195/5000\n",
      "\n",
      "Epoch 04195: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4196/5000\n",
      "\n",
      "Epoch 04196: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4197/5000\n",
      "\n",
      "Epoch 04197: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4198/5000\n",
      "\n",
      "Epoch 04198: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4199/5000\n",
      "\n",
      "Epoch 04199: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4200/5000\n",
      "\n",
      "Epoch 04200: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4201/5000\n",
      "\n",
      "Epoch 04201: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4202/5000\n",
      "\n",
      "Epoch 04202: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4203/5000\n",
      "\n",
      "Epoch 04203: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4204/5000\n",
      "\n",
      "Epoch 04204: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4205/5000\n",
      "\n",
      "Epoch 04205: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4206/5000\n",
      "\n",
      "Epoch 04206: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4207/5000\n",
      "\n",
      "Epoch 04207: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4208/5000\n",
      "\n",
      "Epoch 04208: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4209/5000\n",
      "\n",
      "Epoch 04209: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4210/5000\n",
      "\n",
      "Epoch 04210: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 4211/5000\n",
      "\n",
      "Epoch 04211: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4212/5000\n",
      "\n",
      "Epoch 04212: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4213/5000\n",
      "\n",
      "Epoch 04213: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 4214/5000\n",
      "\n",
      "Epoch 04214: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4215/5000\n",
      "\n",
      "Epoch 04215: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4216/5000\n",
      "\n",
      "Epoch 04216: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4217/5000\n",
      "\n",
      "Epoch 04217: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4218/5000\n",
      "\n",
      "Epoch 04218: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 4219/5000\n",
      "\n",
      "Epoch 04219: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 4220/5000\n",
      "\n",
      "Epoch 04220: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4221/5000\n",
      "\n",
      "Epoch 04221: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 4222/5000\n",
      "\n",
      "Epoch 04222: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4223/5000\n",
      "\n",
      "Epoch 04223: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4224/5000\n",
      "\n",
      "Epoch 04224: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4225/5000\n",
      "\n",
      "Epoch 04225: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 4226/5000\n",
      "\n",
      "Epoch 04226: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4227/5000\n",
      "\n",
      "Epoch 04227: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4228/5000\n",
      "\n",
      "Epoch 04228: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4229/5000\n",
      "\n",
      "Epoch 04229: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4230/5000\n",
      "\n",
      "Epoch 04230: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 4231/5000\n",
      "\n",
      "Epoch 04231: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4232/5000\n",
      "\n",
      "Epoch 04232: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4233/5000\n",
      "\n",
      "Epoch 04233: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4234/5000\n",
      "\n",
      "Epoch 04234: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4235/5000\n",
      "\n",
      "Epoch 04235: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4236/5000\n",
      "\n",
      "Epoch 04236: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 4237/5000\n",
      "\n",
      "Epoch 04237: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4238/5000\n",
      "\n",
      "Epoch 04238: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4239/5000\n",
      "\n",
      "Epoch 04239: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4240/5000\n",
      "\n",
      "Epoch 04240: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4241/5000\n",
      "\n",
      "Epoch 04241: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4242/5000\n",
      "\n",
      "Epoch 04242: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4243/5000\n",
      "\n",
      "Epoch 04243: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4244/5000\n",
      "\n",
      "Epoch 04244: loss did not improve from 0.00558\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4245/5000\n",
      "\n",
      "Epoch 04245: loss improved from 0.00558 to 0.00546, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0055\n",
      "Epoch 4246/5000\n",
      "\n",
      "Epoch 04246: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4247/5000\n",
      "\n",
      "Epoch 04247: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4248/5000\n",
      "\n",
      "Epoch 04248: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4249/5000\n",
      "\n",
      "Epoch 04249: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4250/5000\n",
      "\n",
      "Epoch 04250: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4251/5000\n",
      "\n",
      "Epoch 04251: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4252/5000\n",
      "\n",
      "Epoch 04252: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4253/5000\n",
      "\n",
      "Epoch 04253: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4254/5000\n",
      "\n",
      "Epoch 04254: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4255/5000\n",
      "\n",
      "Epoch 04255: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 4256/5000\n",
      "\n",
      "Epoch 04256: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 4257/5000\n",
      "\n",
      "Epoch 04257: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4258/5000\n",
      "\n",
      "Epoch 04258: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4259/5000\n",
      "\n",
      "Epoch 04259: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4260/5000\n",
      "\n",
      "Epoch 04260: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4261/5000\n",
      "\n",
      "Epoch 04261: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4262/5000\n",
      "\n",
      "Epoch 04262: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4263/5000\n",
      "\n",
      "Epoch 04263: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4264/5000\n",
      "\n",
      "Epoch 04264: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4265/5000\n",
      "\n",
      "Epoch 04265: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4266/5000\n",
      "\n",
      "Epoch 04266: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4267/5000\n",
      "\n",
      "Epoch 04267: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4268/5000\n",
      "\n",
      "Epoch 04268: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4269/5000\n",
      "\n",
      "Epoch 04269: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4270/5000\n",
      "\n",
      "Epoch 04270: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4271/5000\n",
      "\n",
      "Epoch 04271: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4272/5000\n",
      "\n",
      "Epoch 04272: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4273/5000\n",
      "\n",
      "Epoch 04273: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4274/5000\n",
      "\n",
      "Epoch 04274: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4275/5000\n",
      "\n",
      "Epoch 04275: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 4276/5000\n",
      "\n",
      "Epoch 04276: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4277/5000\n",
      "\n",
      "Epoch 04277: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4278/5000\n",
      "\n",
      "Epoch 04278: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4279/5000\n",
      "\n",
      "Epoch 04279: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4280/5000\n",
      "\n",
      "Epoch 04280: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4281/5000\n",
      "\n",
      "Epoch 04281: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4282/5000\n",
      "\n",
      "Epoch 04282: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4283/5000\n",
      "\n",
      "Epoch 04283: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4284/5000\n",
      "\n",
      "Epoch 04284: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4285/5000\n",
      "\n",
      "Epoch 04285: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4286/5000\n",
      "\n",
      "Epoch 04286: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4287/5000\n",
      "\n",
      "Epoch 04287: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4288/5000\n",
      "\n",
      "Epoch 04288: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4289/5000\n",
      "\n",
      "Epoch 04289: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4290/5000\n",
      "\n",
      "Epoch 04290: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4291/5000\n",
      "\n",
      "Epoch 04291: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4292/5000\n",
      "\n",
      "Epoch 04292: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4293/5000\n",
      "\n",
      "Epoch 04293: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4294/5000\n",
      "\n",
      "Epoch 04294: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4295/5000\n",
      "\n",
      "Epoch 04295: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4296/5000\n",
      "\n",
      "Epoch 04296: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 4297/5000\n",
      "\n",
      "Epoch 04297: loss did not improve from 0.00546\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4298/5000\n",
      "\n",
      "Epoch 04298: loss improved from 0.00546 to 0.00541, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0054\n",
      "Epoch 4299/5000\n",
      "\n",
      "Epoch 04299: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4300/5000\n",
      "\n",
      "Epoch 04300: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4301/5000\n",
      "\n",
      "Epoch 04301: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4302/5000\n",
      "\n",
      "Epoch 04302: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4303/5000\n",
      "\n",
      "Epoch 04303: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4304/5000\n",
      "\n",
      "Epoch 04304: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4305/5000\n",
      "\n",
      "Epoch 04305: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4306/5000\n",
      "\n",
      "Epoch 04306: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0082\n",
      "Epoch 4307/5000\n",
      "\n",
      "Epoch 04307: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4308/5000\n",
      "\n",
      "Epoch 04308: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4309/5000\n",
      "\n",
      "Epoch 04309: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4310/5000\n",
      "\n",
      "Epoch 04310: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4311/5000\n",
      "\n",
      "Epoch 04311: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4312/5000\n",
      "\n",
      "Epoch 04312: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4313/5000\n",
      "\n",
      "Epoch 04313: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4314/5000\n",
      "\n",
      "Epoch 04314: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4315/5000\n",
      "\n",
      "Epoch 04315: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4316/5000\n",
      "\n",
      "Epoch 04316: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4317/5000\n",
      "\n",
      "Epoch 04317: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4318/5000\n",
      "\n",
      "Epoch 04318: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4319/5000\n",
      "\n",
      "Epoch 04319: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4320/5000\n",
      "\n",
      "Epoch 04320: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4321/5000\n",
      "\n",
      "Epoch 04321: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4322/5000\n",
      "\n",
      "Epoch 04322: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4323/5000\n",
      "\n",
      "Epoch 04323: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4324/5000\n",
      "\n",
      "Epoch 04324: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4325/5000\n",
      "\n",
      "Epoch 04325: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4326/5000\n",
      "\n",
      "Epoch 04326: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4327/5000\n",
      "\n",
      "Epoch 04327: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4328/5000\n",
      "\n",
      "Epoch 04328: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4329/5000\n",
      "\n",
      "Epoch 04329: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4330/5000\n",
      "\n",
      "Epoch 04330: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4331/5000\n",
      "\n",
      "Epoch 04331: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4332/5000\n",
      "\n",
      "Epoch 04332: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4333/5000\n",
      "\n",
      "Epoch 04333: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4334/5000\n",
      "\n",
      "Epoch 04334: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0083\n",
      "Epoch 4335/5000\n",
      "\n",
      "Epoch 04335: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 4336/5000\n",
      "\n",
      "Epoch 04336: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4337/5000\n",
      "\n",
      "Epoch 04337: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4338/5000\n",
      "\n",
      "Epoch 04338: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4339/5000\n",
      "\n",
      "Epoch 04339: loss did not improve from 0.00541\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4340/5000\n",
      "\n",
      "Epoch 04340: loss improved from 0.00541 to 0.00536, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0054\n",
      "Epoch 4341/5000\n",
      "\n",
      "Epoch 04341: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 4342/5000\n",
      "\n",
      "Epoch 04342: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4343/5000\n",
      "\n",
      "Epoch 04343: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4344/5000\n",
      "\n",
      "Epoch 04344: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4345/5000\n",
      "\n",
      "Epoch 04345: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4346/5000\n",
      "\n",
      "Epoch 04346: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4347/5000\n",
      "\n",
      "Epoch 04347: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4348/5000\n",
      "\n",
      "Epoch 04348: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4349/5000\n",
      "\n",
      "Epoch 04349: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4350/5000\n",
      "\n",
      "Epoch 04350: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4351/5000\n",
      "\n",
      "Epoch 04351: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4352/5000\n",
      "\n",
      "Epoch 04352: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4353/5000\n",
      "\n",
      "Epoch 04353: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4354/5000\n",
      "\n",
      "Epoch 04354: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4355/5000\n",
      "\n",
      "Epoch 04355: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4356/5000\n",
      "\n",
      "Epoch 04356: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4357/5000\n",
      "\n",
      "Epoch 04357: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4358/5000\n",
      "\n",
      "Epoch 04358: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4359/5000\n",
      "\n",
      "Epoch 04359: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4360/5000\n",
      "\n",
      "Epoch 04360: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4361/5000\n",
      "\n",
      "Epoch 04361: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4362/5000\n",
      "\n",
      "Epoch 04362: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4363/5000\n",
      "\n",
      "Epoch 04363: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4364/5000\n",
      "\n",
      "Epoch 04364: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4365/5000\n",
      "\n",
      "Epoch 04365: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4366/5000\n",
      "\n",
      "Epoch 04366: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4367/5000\n",
      "\n",
      "Epoch 04367: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4368/5000\n",
      "\n",
      "Epoch 04368: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4369/5000\n",
      "\n",
      "Epoch 04369: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4370/5000\n",
      "\n",
      "Epoch 04370: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4371/5000\n",
      "\n",
      "Epoch 04371: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4372/5000\n",
      "\n",
      "Epoch 04372: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4373/5000\n",
      "\n",
      "Epoch 04373: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4374/5000\n",
      "\n",
      "Epoch 04374: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4375/5000\n",
      "\n",
      "Epoch 04375: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4376/5000\n",
      "\n",
      "Epoch 04376: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4377/5000\n",
      "\n",
      "Epoch 04377: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4378/5000\n",
      "\n",
      "Epoch 04378: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4379/5000\n",
      "\n",
      "Epoch 04379: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4380/5000\n",
      "\n",
      "Epoch 04380: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4381/5000\n",
      "\n",
      "Epoch 04381: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4382/5000\n",
      "\n",
      "Epoch 04382: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4383/5000\n",
      "\n",
      "Epoch 04383: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4384/5000\n",
      "\n",
      "Epoch 04384: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4385/5000\n",
      "\n",
      "Epoch 04385: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4386/5000\n",
      "\n",
      "Epoch 04386: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4387/5000\n",
      "\n",
      "Epoch 04387: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4388/5000\n",
      "\n",
      "Epoch 04388: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4389/5000\n",
      "\n",
      "Epoch 04389: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4390/5000\n",
      "\n",
      "Epoch 04390: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4391/5000\n",
      "\n",
      "Epoch 04391: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4392/5000\n",
      "\n",
      "Epoch 04392: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4393/5000\n",
      "\n",
      "Epoch 04393: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4394/5000\n",
      "\n",
      "Epoch 04394: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4395/5000\n",
      "\n",
      "Epoch 04395: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4396/5000\n",
      "\n",
      "Epoch 04396: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4397/5000\n",
      "\n",
      "Epoch 04397: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4398/5000\n",
      "\n",
      "Epoch 04398: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4399/5000\n",
      "\n",
      "Epoch 04399: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4400/5000\n",
      "\n",
      "Epoch 04400: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4401/5000\n",
      "\n",
      "Epoch 04401: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4402/5000\n",
      "\n",
      "Epoch 04402: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4403/5000\n",
      "\n",
      "Epoch 04403: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4404/5000\n",
      "\n",
      "Epoch 04404: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4405/5000\n",
      "\n",
      "Epoch 04405: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4406/5000\n",
      "\n",
      "Epoch 04406: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4407/5000\n",
      "\n",
      "Epoch 04407: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4408/5000\n",
      "\n",
      "Epoch 04408: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0078\n",
      "Epoch 4409/5000\n",
      "\n",
      "Epoch 04409: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4410/5000\n",
      "\n",
      "Epoch 04410: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4411/5000\n",
      "\n",
      "Epoch 04411: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4412/5000\n",
      "\n",
      "Epoch 04412: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4413/5000\n",
      "\n",
      "Epoch 04413: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4414/5000\n",
      "\n",
      "Epoch 04414: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4415/5000\n",
      "\n",
      "Epoch 04415: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4416/5000\n",
      "\n",
      "Epoch 04416: loss did not improve from 0.00536\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4417/5000\n",
      "\n",
      "Epoch 04417: loss improved from 0.00536 to 0.00521, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4418/5000\n",
      "\n",
      "Epoch 04418: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 4419/5000\n",
      "\n",
      "Epoch 04419: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4420/5000\n",
      "\n",
      "Epoch 04420: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4421/5000\n",
      "\n",
      "Epoch 04421: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4422/5000\n",
      "\n",
      "Epoch 04422: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4423/5000\n",
      "\n",
      "Epoch 04423: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4424/5000\n",
      "\n",
      "Epoch 04424: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4425/5000\n",
      "\n",
      "Epoch 04425: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4426/5000\n",
      "\n",
      "Epoch 04426: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4427/5000\n",
      "\n",
      "Epoch 04427: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4428/5000\n",
      "\n",
      "Epoch 04428: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4429/5000\n",
      "\n",
      "Epoch 04429: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4430/5000\n",
      "\n",
      "Epoch 04430: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4431/5000\n",
      "\n",
      "Epoch 04431: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4432/5000\n",
      "\n",
      "Epoch 04432: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4433/5000\n",
      "\n",
      "Epoch 04433: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4434/5000\n",
      "\n",
      "Epoch 04434: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4435/5000\n",
      "\n",
      "Epoch 04435: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4436/5000\n",
      "\n",
      "Epoch 04436: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4437/5000\n",
      "\n",
      "Epoch 04437: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4438/5000\n",
      "\n",
      "Epoch 04438: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4439/5000\n",
      "\n",
      "Epoch 04439: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4440/5000\n",
      "\n",
      "Epoch 04440: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4441/5000\n",
      "\n",
      "Epoch 04441: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4442/5000\n",
      "\n",
      "Epoch 04442: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4443/5000\n",
      "\n",
      "Epoch 04443: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4444/5000\n",
      "\n",
      "Epoch 04444: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4445/5000\n",
      "\n",
      "Epoch 04445: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4446/5000\n",
      "\n",
      "Epoch 04446: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4447/5000\n",
      "\n",
      "Epoch 04447: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4448/5000\n",
      "\n",
      "Epoch 04448: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4449/5000\n",
      "\n",
      "Epoch 04449: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4450/5000\n",
      "\n",
      "Epoch 04450: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4451/5000\n",
      "\n",
      "Epoch 04451: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4452/5000\n",
      "\n",
      "Epoch 04452: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4453/5000\n",
      "\n",
      "Epoch 04453: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4454/5000\n",
      "\n",
      "Epoch 04454: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4455/5000\n",
      "\n",
      "Epoch 04455: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4456/5000\n",
      "\n",
      "Epoch 04456: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4457/5000\n",
      "\n",
      "Epoch 04457: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4458/5000\n",
      "\n",
      "Epoch 04458: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4459/5000\n",
      "\n",
      "Epoch 04459: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4460/5000\n",
      "\n",
      "Epoch 04460: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4461/5000\n",
      "\n",
      "Epoch 04461: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4462/5000\n",
      "\n",
      "Epoch 04462: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4463/5000\n",
      "\n",
      "Epoch 04463: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4464/5000\n",
      "\n",
      "Epoch 04464: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4465/5000\n",
      "\n",
      "Epoch 04465: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 4466/5000\n",
      "\n",
      "Epoch 04466: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4467/5000\n",
      "\n",
      "Epoch 04467: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4468/5000\n",
      "\n",
      "Epoch 04468: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4469/5000\n",
      "\n",
      "Epoch 04469: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4470/5000\n",
      "\n",
      "Epoch 04470: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4471/5000\n",
      "\n",
      "Epoch 04471: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4472/5000\n",
      "\n",
      "Epoch 04472: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4473/5000\n",
      "\n",
      "Epoch 04473: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4474/5000\n",
      "\n",
      "Epoch 04474: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4475/5000\n",
      "\n",
      "Epoch 04475: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4476/5000\n",
      "\n",
      "Epoch 04476: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4477/5000\n",
      "\n",
      "Epoch 04477: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4478/5000\n",
      "\n",
      "Epoch 04478: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4479/5000\n",
      "\n",
      "Epoch 04479: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4480/5000\n",
      "\n",
      "Epoch 04480: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4481/5000\n",
      "\n",
      "Epoch 04481: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4482/5000\n",
      "\n",
      "Epoch 04482: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 4483/5000\n",
      "\n",
      "Epoch 04483: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4484/5000\n",
      "\n",
      "Epoch 04484: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4485/5000\n",
      "\n",
      "Epoch 04485: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4486/5000\n",
      "\n",
      "Epoch 04486: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4487/5000\n",
      "\n",
      "Epoch 04487: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4488/5000\n",
      "\n",
      "Epoch 04488: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4489/5000\n",
      "\n",
      "Epoch 04489: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4490/5000\n",
      "\n",
      "Epoch 04490: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4491/5000\n",
      "\n",
      "Epoch 04491: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4492/5000\n",
      "\n",
      "Epoch 04492: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4493/5000\n",
      "\n",
      "Epoch 04493: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4494/5000\n",
      "\n",
      "Epoch 04494: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4495/5000\n",
      "\n",
      "Epoch 04495: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4496/5000\n",
      "\n",
      "Epoch 04496: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4497/5000\n",
      "\n",
      "Epoch 04497: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4498/5000\n",
      "\n",
      "Epoch 04498: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4499/5000\n",
      "\n",
      "Epoch 04499: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4500/5000\n",
      "\n",
      "Epoch 04500: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4501/5000\n",
      "\n",
      "Epoch 04501: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0075\n",
      "Epoch 4502/5000\n",
      "\n",
      "Epoch 04502: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4503/5000\n",
      "\n",
      "Epoch 04503: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4504/5000\n",
      "\n",
      "Epoch 04504: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4505/5000\n",
      "\n",
      "Epoch 04505: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4506/5000\n",
      "\n",
      "Epoch 04506: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4507/5000\n",
      "\n",
      "Epoch 04507: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4508/5000\n",
      "\n",
      "Epoch 04508: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4509/5000\n",
      "\n",
      "Epoch 04509: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4510/5000\n",
      "\n",
      "Epoch 04510: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4511/5000\n",
      "\n",
      "Epoch 04511: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4512/5000\n",
      "\n",
      "Epoch 04512: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0061\n",
      "Epoch 4513/5000\n",
      "\n",
      "Epoch 04513: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4514/5000\n",
      "\n",
      "Epoch 04514: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0060\n",
      "Epoch 4515/5000\n",
      "\n",
      "Epoch 04515: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4516/5000\n",
      "\n",
      "Epoch 04516: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4517/5000\n",
      "\n",
      "Epoch 04517: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4518/5000\n",
      "\n",
      "Epoch 04518: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4519/5000\n",
      "\n",
      "Epoch 04519: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4520/5000\n",
      "\n",
      "Epoch 04520: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4521/5000\n",
      "\n",
      "Epoch 04521: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0064\n",
      "Epoch 4522/5000\n",
      "\n",
      "Epoch 04522: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4523/5000\n",
      "\n",
      "Epoch 04523: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4524/5000\n",
      "\n",
      "Epoch 04524: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4525/5000\n",
      "\n",
      "Epoch 04525: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 4526/5000\n",
      "\n",
      "Epoch 04526: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4527/5000\n",
      "\n",
      "Epoch 04527: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4528/5000\n",
      "\n",
      "Epoch 04528: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4529/5000\n",
      "\n",
      "Epoch 04529: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4530/5000\n",
      "\n",
      "Epoch 04530: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4531/5000\n",
      "\n",
      "Epoch 04531: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4532/5000\n",
      "\n",
      "Epoch 04532: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4533/5000\n",
      "\n",
      "Epoch 04533: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4534/5000\n",
      "\n",
      "Epoch 04534: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4535/5000\n",
      "\n",
      "Epoch 04535: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0069\n",
      "Epoch 4536/5000\n",
      "\n",
      "Epoch 04536: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4537/5000\n",
      "\n",
      "Epoch 04537: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4538/5000\n",
      "\n",
      "Epoch 04538: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4539/5000\n",
      "\n",
      "Epoch 04539: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 4540/5000\n",
      "\n",
      "Epoch 04540: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4541/5000\n",
      "\n",
      "Epoch 04541: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4542/5000\n",
      "\n",
      "Epoch 04542: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4543/5000\n",
      "\n",
      "Epoch 04543: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4544/5000\n",
      "\n",
      "Epoch 04544: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4545/5000\n",
      "\n",
      "Epoch 04545: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4546/5000\n",
      "\n",
      "Epoch 04546: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4547/5000\n",
      "\n",
      "Epoch 04547: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4548/5000\n",
      "\n",
      "Epoch 04548: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4549/5000\n",
      "\n",
      "Epoch 04549: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4550/5000\n",
      "\n",
      "Epoch 04550: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4551/5000\n",
      "\n",
      "Epoch 04551: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4552/5000\n",
      "\n",
      "Epoch 04552: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4553/5000\n",
      "\n",
      "Epoch 04553: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4554/5000\n",
      "\n",
      "Epoch 04554: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4555/5000\n",
      "\n",
      "Epoch 04555: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 4556/5000\n",
      "\n",
      "Epoch 04556: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4557/5000\n",
      "\n",
      "Epoch 04557: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4558/5000\n",
      "\n",
      "Epoch 04558: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4559/5000\n",
      "\n",
      "Epoch 04559: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4560/5000\n",
      "\n",
      "Epoch 04560: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4561/5000\n",
      "\n",
      "Epoch 04561: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4562/5000\n",
      "\n",
      "Epoch 04562: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4563/5000\n",
      "\n",
      "Epoch 04563: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4564/5000\n",
      "\n",
      "Epoch 04564: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4565/5000\n",
      "\n",
      "Epoch 04565: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4566/5000\n",
      "\n",
      "Epoch 04566: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4567/5000\n",
      "\n",
      "Epoch 04567: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4568/5000\n",
      "\n",
      "Epoch 04568: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4569/5000\n",
      "\n",
      "Epoch 04569: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4570/5000\n",
      "\n",
      "Epoch 04570: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4571/5000\n",
      "\n",
      "Epoch 04571: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4572/5000\n",
      "\n",
      "Epoch 04572: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4573/5000\n",
      "\n",
      "Epoch 04573: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4574/5000\n",
      "\n",
      "Epoch 04574: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4575/5000\n",
      "\n",
      "Epoch 04575: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4576/5000\n",
      "\n",
      "Epoch 04576: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4577/5000\n",
      "\n",
      "Epoch 04577: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4578/5000\n",
      "\n",
      "Epoch 04578: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0076\n",
      "Epoch 4579/5000\n",
      "\n",
      "Epoch 04579: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4580/5000\n",
      "\n",
      "Epoch 04580: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4581/5000\n",
      "\n",
      "Epoch 04581: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4582/5000\n",
      "\n",
      "Epoch 04582: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4583/5000\n",
      "\n",
      "Epoch 04583: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4584/5000\n",
      "\n",
      "Epoch 04584: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4585/5000\n",
      "\n",
      "Epoch 04585: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4586/5000\n",
      "\n",
      "Epoch 04586: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4587/5000\n",
      "\n",
      "Epoch 04587: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4588/5000\n",
      "\n",
      "Epoch 04588: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4589/5000\n",
      "\n",
      "Epoch 04589: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4590/5000\n",
      "\n",
      "Epoch 04590: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4591/5000\n",
      "\n",
      "Epoch 04591: loss did not improve from 0.00521\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4592/5000\n",
      "\n",
      "Epoch 04592: loss improved from 0.00521 to 0.00516, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0052\n",
      "Epoch 4593/5000\n",
      "\n",
      "Epoch 04593: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4594/5000\n",
      "\n",
      "Epoch 04594: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4595/5000\n",
      "\n",
      "Epoch 04595: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4596/5000\n",
      "\n",
      "Epoch 04596: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4597/5000\n",
      "\n",
      "Epoch 04597: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4598/5000\n",
      "\n",
      "Epoch 04598: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4599/5000\n",
      "\n",
      "Epoch 04599: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4600/5000\n",
      "\n",
      "Epoch 04600: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4601/5000\n",
      "\n",
      "Epoch 04601: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4602/5000\n",
      "\n",
      "Epoch 04602: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4603/5000\n",
      "\n",
      "Epoch 04603: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4604/5000\n",
      "\n",
      "Epoch 04604: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4605/5000\n",
      "\n",
      "Epoch 04605: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4606/5000\n",
      "\n",
      "Epoch 04606: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4607/5000\n",
      "\n",
      "Epoch 04607: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4608/5000\n",
      "\n",
      "Epoch 04608: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4609/5000\n",
      "\n",
      "Epoch 04609: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4610/5000\n",
      "\n",
      "Epoch 04610: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4611/5000\n",
      "\n",
      "Epoch 04611: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4612/5000\n",
      "\n",
      "Epoch 04612: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4613/5000\n",
      "\n",
      "Epoch 04613: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4614/5000\n",
      "\n",
      "Epoch 04614: loss did not improve from 0.00516\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4615/5000\n",
      "\n",
      "Epoch 04615: loss improved from 0.00516 to 0.00507, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0051\n",
      "Epoch 4616/5000\n",
      "\n",
      "Epoch 04616: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4617/5000\n",
      "\n",
      "Epoch 04617: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4618/5000\n",
      "\n",
      "Epoch 04618: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4619/5000\n",
      "\n",
      "Epoch 04619: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4620/5000\n",
      "\n",
      "Epoch 04620: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4621/5000\n",
      "\n",
      "Epoch 04621: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4622/5000\n",
      "\n",
      "Epoch 04622: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4623/5000\n",
      "\n",
      "Epoch 04623: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4624/5000\n",
      "\n",
      "Epoch 04624: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4625/5000\n",
      "\n",
      "Epoch 04625: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4626/5000\n",
      "\n",
      "Epoch 04626: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4627/5000\n",
      "\n",
      "Epoch 04627: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4628/5000\n",
      "\n",
      "Epoch 04628: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4629/5000\n",
      "\n",
      "Epoch 04629: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4630/5000\n",
      "\n",
      "Epoch 04630: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4631/5000\n",
      "\n",
      "Epoch 04631: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4632/5000\n",
      "\n",
      "Epoch 04632: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4633/5000\n",
      "\n",
      "Epoch 04633: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4634/5000\n",
      "\n",
      "Epoch 04634: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4635/5000\n",
      "\n",
      "Epoch 04635: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4636/5000\n",
      "\n",
      "Epoch 04636: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4637/5000\n",
      "\n",
      "Epoch 04637: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4638/5000\n",
      "\n",
      "Epoch 04638: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4639/5000\n",
      "\n",
      "Epoch 04639: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4640/5000\n",
      "\n",
      "Epoch 04640: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4641/5000\n",
      "\n",
      "Epoch 04641: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4642/5000\n",
      "\n",
      "Epoch 04642: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4643/5000\n",
      "\n",
      "Epoch 04643: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4644/5000\n",
      "\n",
      "Epoch 04644: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4645/5000\n",
      "\n",
      "Epoch 04645: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4646/5000\n",
      "\n",
      "Epoch 04646: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4647/5000\n",
      "\n",
      "Epoch 04647: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4648/5000\n",
      "\n",
      "Epoch 04648: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 4649/5000\n",
      "\n",
      "Epoch 04649: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4650/5000\n",
      "\n",
      "Epoch 04650: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4651/5000\n",
      "\n",
      "Epoch 04651: loss did not improve from 0.00507\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4652/5000\n",
      "\n",
      "Epoch 04652: loss improved from 0.00507 to 0.00501, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0050\n",
      "Epoch 4653/5000\n",
      "\n",
      "Epoch 04653: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4654/5000\n",
      "\n",
      "Epoch 04654: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4655/5000\n",
      "\n",
      "Epoch 04655: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4656/5000\n",
      "\n",
      "Epoch 04656: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4657/5000\n",
      "\n",
      "Epoch 04657: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4658/5000\n",
      "\n",
      "Epoch 04658: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4659/5000\n",
      "\n",
      "Epoch 04659: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4660/5000\n",
      "\n",
      "Epoch 04660: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4661/5000\n",
      "\n",
      "Epoch 04661: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4662/5000\n",
      "\n",
      "Epoch 04662: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4663/5000\n",
      "\n",
      "Epoch 04663: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4664/5000\n",
      "\n",
      "Epoch 04664: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4665/5000\n",
      "\n",
      "Epoch 04665: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4666/5000\n",
      "\n",
      "Epoch 04666: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4667/5000\n",
      "\n",
      "Epoch 04667: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4668/5000\n",
      "\n",
      "Epoch 04668: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4669/5000\n",
      "\n",
      "Epoch 04669: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4670/5000\n",
      "\n",
      "Epoch 04670: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4671/5000\n",
      "\n",
      "Epoch 04671: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4672/5000\n",
      "\n",
      "Epoch 04672: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4673/5000\n",
      "\n",
      "Epoch 04673: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 4674/5000\n",
      "\n",
      "Epoch 04674: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4675/5000\n",
      "\n",
      "Epoch 04675: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4676/5000\n",
      "\n",
      "Epoch 04676: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4677/5000\n",
      "\n",
      "Epoch 04677: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4678/5000\n",
      "\n",
      "Epoch 04678: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4679/5000\n",
      "\n",
      "Epoch 04679: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 4680/5000\n",
      "\n",
      "Epoch 04680: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4681/5000\n",
      "\n",
      "Epoch 04681: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4682/5000\n",
      "\n",
      "Epoch 04682: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4683/5000\n",
      "\n",
      "Epoch 04683: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4684/5000\n",
      "\n",
      "Epoch 04684: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4685/5000\n",
      "\n",
      "Epoch 04685: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4686/5000\n",
      "\n",
      "Epoch 04686: loss did not improve from 0.00501\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4687/5000\n",
      "\n",
      "Epoch 04687: loss improved from 0.00501 to 0.00471, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 4ms/sample - loss: 0.0047\n",
      "Epoch 4688/5000\n",
      "\n",
      "Epoch 04688: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4689/5000\n",
      "\n",
      "Epoch 04689: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4690/5000\n",
      "\n",
      "Epoch 04690: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4691/5000\n",
      "\n",
      "Epoch 04691: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4692/5000\n",
      "\n",
      "Epoch 04692: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4693/5000\n",
      "\n",
      "Epoch 04693: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4694/5000\n",
      "\n",
      "Epoch 04694: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0049\n",
      "Epoch 4695/5000\n",
      "\n",
      "Epoch 04695: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4696/5000\n",
      "\n",
      "Epoch 04696: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4697/5000\n",
      "\n",
      "Epoch 04697: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4698/5000\n",
      "\n",
      "Epoch 04698: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4699/5000\n",
      "\n",
      "Epoch 04699: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4700/5000\n",
      "\n",
      "Epoch 04700: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4701/5000\n",
      "\n",
      "Epoch 04701: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4702/5000\n",
      "\n",
      "Epoch 04702: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4703/5000\n",
      "\n",
      "Epoch 04703: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4704/5000\n",
      "\n",
      "Epoch 04704: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4705/5000\n",
      "\n",
      "Epoch 04705: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0064\n",
      "Epoch 4706/5000\n",
      "\n",
      "Epoch 04706: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4707/5000\n",
      "\n",
      "Epoch 04707: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4708/5000\n",
      "\n",
      "Epoch 04708: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4709/5000\n",
      "\n",
      "Epoch 04709: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4710/5000\n",
      "\n",
      "Epoch 04710: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4711/5000\n",
      "\n",
      "Epoch 04711: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0050\n",
      "Epoch 4712/5000\n",
      "\n",
      "Epoch 04712: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4713/5000\n",
      "\n",
      "Epoch 04713: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4714/5000\n",
      "\n",
      "Epoch 04714: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4715/5000\n",
      "\n",
      "Epoch 04715: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4716/5000\n",
      "\n",
      "Epoch 04716: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4717/5000\n",
      "\n",
      "Epoch 04717: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4718/5000\n",
      "\n",
      "Epoch 04718: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4719/5000\n",
      "\n",
      "Epoch 04719: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4720/5000\n",
      "\n",
      "Epoch 04720: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4721/5000\n",
      "\n",
      "Epoch 04721: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4722/5000\n",
      "\n",
      "Epoch 04722: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4723/5000\n",
      "\n",
      "Epoch 04723: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4724/5000\n",
      "\n",
      "Epoch 04724: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4725/5000\n",
      "\n",
      "Epoch 04725: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4726/5000\n",
      "\n",
      "Epoch 04726: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4727/5000\n",
      "\n",
      "Epoch 04727: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4728/5000\n",
      "\n",
      "Epoch 04728: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4729/5000\n",
      "\n",
      "Epoch 04729: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4730/5000\n",
      "\n",
      "Epoch 04730: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4731/5000\n",
      "\n",
      "Epoch 04731: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4732/5000\n",
      "\n",
      "Epoch 04732: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4733/5000\n",
      "\n",
      "Epoch 04733: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4734/5000\n",
      "\n",
      "Epoch 04734: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0057\n",
      "Epoch 4735/5000\n",
      "\n",
      "Epoch 04735: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0048\n",
      "Epoch 4736/5000\n",
      "\n",
      "Epoch 04736: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4737/5000\n",
      "\n",
      "Epoch 04737: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4738/5000\n",
      "\n",
      "Epoch 04738: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4739/5000\n",
      "\n",
      "Epoch 04739: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4740/5000\n",
      "\n",
      "Epoch 04740: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4741/5000\n",
      "\n",
      "Epoch 04741: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4742/5000\n",
      "\n",
      "Epoch 04742: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4743/5000\n",
      "\n",
      "Epoch 04743: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4744/5000\n",
      "\n",
      "Epoch 04744: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4745/5000\n",
      "\n",
      "Epoch 04745: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4746/5000\n",
      "\n",
      "Epoch 04746: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4747/5000\n",
      "\n",
      "Epoch 04747: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 4748/5000\n",
      "\n",
      "Epoch 04748: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4749/5000\n",
      "\n",
      "Epoch 04749: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4750/5000\n",
      "\n",
      "Epoch 04750: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4751/5000\n",
      "\n",
      "Epoch 04751: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4752/5000\n",
      "\n",
      "Epoch 04752: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4753/5000\n",
      "\n",
      "Epoch 04753: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4754/5000\n",
      "\n",
      "Epoch 04754: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4755/5000\n",
      "\n",
      "Epoch 04755: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4756/5000\n",
      "\n",
      "Epoch 04756: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4757/5000\n",
      "\n",
      "Epoch 04757: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4758/5000\n",
      "\n",
      "Epoch 04758: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4759/5000\n",
      "\n",
      "Epoch 04759: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4760/5000\n",
      "\n",
      "Epoch 04760: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4761/5000\n",
      "\n",
      "Epoch 04761: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4762/5000\n",
      "\n",
      "Epoch 04762: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4763/5000\n",
      "\n",
      "Epoch 04763: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4764/5000\n",
      "\n",
      "Epoch 04764: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 4765/5000\n",
      "\n",
      "Epoch 04765: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4766/5000\n",
      "\n",
      "Epoch 04766: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0079\n",
      "Epoch 4767/5000\n",
      "\n",
      "Epoch 04767: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4768/5000\n",
      "\n",
      "Epoch 04768: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4769/5000\n",
      "\n",
      "Epoch 04769: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4770/5000\n",
      "\n",
      "Epoch 04770: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4771/5000\n",
      "\n",
      "Epoch 04771: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4772/5000\n",
      "\n",
      "Epoch 04772: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4773/5000\n",
      "\n",
      "Epoch 04773: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4774/5000\n",
      "\n",
      "Epoch 04774: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4775/5000\n",
      "\n",
      "Epoch 04775: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4776/5000\n",
      "\n",
      "Epoch 04776: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4777/5000\n",
      "\n",
      "Epoch 04777: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4778/5000\n",
      "\n",
      "Epoch 04778: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4779/5000\n",
      "\n",
      "Epoch 04779: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4780/5000\n",
      "\n",
      "Epoch 04780: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4781/5000\n",
      "\n",
      "Epoch 04781: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4782/5000\n",
      "\n",
      "Epoch 04782: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4783/5000\n",
      "\n",
      "Epoch 04783: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4784/5000\n",
      "\n",
      "Epoch 04784: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4785/5000\n",
      "\n",
      "Epoch 04785: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4786/5000\n",
      "\n",
      "Epoch 04786: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4787/5000\n",
      "\n",
      "Epoch 04787: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4788/5000\n",
      "\n",
      "Epoch 04788: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4789/5000\n",
      "\n",
      "Epoch 04789: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0050\n",
      "Epoch 4790/5000\n",
      "\n",
      "Epoch 04790: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4791/5000\n",
      "\n",
      "Epoch 04791: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4792/5000\n",
      "\n",
      "Epoch 04792: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4793/5000\n",
      "\n",
      "Epoch 04793: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4794/5000\n",
      "\n",
      "Epoch 04794: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4795/5000\n",
      "\n",
      "Epoch 04795: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4796/5000\n",
      "\n",
      "Epoch 04796: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4797/5000\n",
      "\n",
      "Epoch 04797: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4798/5000\n",
      "\n",
      "Epoch 04798: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4799/5000\n",
      "\n",
      "Epoch 04799: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4800/5000\n",
      "\n",
      "Epoch 04800: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 4801/5000\n",
      "\n",
      "Epoch 04801: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 4802/5000\n",
      "\n",
      "Epoch 04802: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4803/5000\n",
      "\n",
      "Epoch 04803: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4804/5000\n",
      "\n",
      "Epoch 04804: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4805/5000\n",
      "\n",
      "Epoch 04805: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4806/5000\n",
      "\n",
      "Epoch 04806: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4807/5000\n",
      "\n",
      "Epoch 04807: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4808/5000\n",
      "\n",
      "Epoch 04808: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4809/5000\n",
      "\n",
      "Epoch 04809: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4810/5000\n",
      "\n",
      "Epoch 04810: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4811/5000\n",
      "\n",
      "Epoch 04811: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4812/5000\n",
      "\n",
      "Epoch 04812: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4813/5000\n",
      "\n",
      "Epoch 04813: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4814/5000\n",
      "\n",
      "Epoch 04814: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4815/5000\n",
      "\n",
      "Epoch 04815: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4816/5000\n",
      "\n",
      "Epoch 04816: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4817/5000\n",
      "\n",
      "Epoch 04817: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4818/5000\n",
      "\n",
      "Epoch 04818: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4819/5000\n",
      "\n",
      "Epoch 04819: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4820/5000\n",
      "\n",
      "Epoch 04820: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4821/5000\n",
      "\n",
      "Epoch 04821: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4822/5000\n",
      "\n",
      "Epoch 04822: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4823/5000\n",
      "\n",
      "Epoch 04823: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4824/5000\n",
      "\n",
      "Epoch 04824: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4825/5000\n",
      "\n",
      "Epoch 04825: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0050\n",
      "Epoch 4826/5000\n",
      "\n",
      "Epoch 04826: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4827/5000\n",
      "\n",
      "Epoch 04827: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4828/5000\n",
      "\n",
      "Epoch 04828: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4829/5000\n",
      "\n",
      "Epoch 04829: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4830/5000\n",
      "\n",
      "Epoch 04830: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4831/5000\n",
      "\n",
      "Epoch 04831: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4832/5000\n",
      "\n",
      "Epoch 04832: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4833/5000\n",
      "\n",
      "Epoch 04833: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4834/5000\n",
      "\n",
      "Epoch 04834: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4835/5000\n",
      "\n",
      "Epoch 04835: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4836/5000\n",
      "\n",
      "Epoch 04836: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4837/5000\n",
      "\n",
      "Epoch 04837: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4838/5000\n",
      "\n",
      "Epoch 04838: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4839/5000\n",
      "\n",
      "Epoch 04839: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4840/5000\n",
      "\n",
      "Epoch 04840: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4841/5000\n",
      "\n",
      "Epoch 04841: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4842/5000\n",
      "\n",
      "Epoch 04842: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4843/5000\n",
      "\n",
      "Epoch 04843: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4844/5000\n",
      "\n",
      "Epoch 04844: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4845/5000\n",
      "\n",
      "Epoch 04845: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4846/5000\n",
      "\n",
      "Epoch 04846: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4847/5000\n",
      "\n",
      "Epoch 04847: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4848/5000\n",
      "\n",
      "Epoch 04848: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4849/5000\n",
      "\n",
      "Epoch 04849: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4850/5000\n",
      "\n",
      "Epoch 04850: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4851/5000\n",
      "\n",
      "Epoch 04851: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4852/5000\n",
      "\n",
      "Epoch 04852: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4853/5000\n",
      "\n",
      "Epoch 04853: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4854/5000\n",
      "\n",
      "Epoch 04854: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4855/5000\n",
      "\n",
      "Epoch 04855: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4856/5000\n",
      "\n",
      "Epoch 04856: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4857/5000\n",
      "\n",
      "Epoch 04857: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4858/5000\n",
      "\n",
      "Epoch 04858: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4859/5000\n",
      "\n",
      "Epoch 04859: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4860/5000\n",
      "\n",
      "Epoch 04860: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4861/5000\n",
      "\n",
      "Epoch 04861: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4862/5000\n",
      "\n",
      "Epoch 04862: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4863/5000\n",
      "\n",
      "Epoch 04863: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4864/5000\n",
      "\n",
      "Epoch 04864: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4865/5000\n",
      "\n",
      "Epoch 04865: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4866/5000\n",
      "\n",
      "Epoch 04866: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4867/5000\n",
      "\n",
      "Epoch 04867: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4868/5000\n",
      "\n",
      "Epoch 04868: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4869/5000\n",
      "\n",
      "Epoch 04869: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4870/5000\n",
      "\n",
      "Epoch 04870: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4871/5000\n",
      "\n",
      "Epoch 04871: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4872/5000\n",
      "\n",
      "Epoch 04872: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4873/5000\n",
      "\n",
      "Epoch 04873: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4874/5000\n",
      "\n",
      "Epoch 04874: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4875/5000\n",
      "\n",
      "Epoch 04875: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4876/5000\n",
      "\n",
      "Epoch 04876: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4877/5000\n",
      "\n",
      "Epoch 04877: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4878/5000\n",
      "\n",
      "Epoch 04878: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4879/5000\n",
      "\n",
      "Epoch 04879: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4880/5000\n",
      "\n",
      "Epoch 04880: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4881/5000\n",
      "\n",
      "Epoch 04881: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0069\n",
      "Epoch 4882/5000\n",
      "\n",
      "Epoch 04882: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0074\n",
      "Epoch 4883/5000\n",
      "\n",
      "Epoch 04883: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4884/5000\n",
      "\n",
      "Epoch 04884: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4885/5000\n",
      "\n",
      "Epoch 04885: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4886/5000\n",
      "\n",
      "Epoch 04886: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4887/5000\n",
      "\n",
      "Epoch 04887: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4888/5000\n",
      "\n",
      "Epoch 04888: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4889/5000\n",
      "\n",
      "Epoch 04889: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4890/5000\n",
      "\n",
      "Epoch 04890: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4891/5000\n",
      "\n",
      "Epoch 04891: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4892/5000\n",
      "\n",
      "Epoch 04892: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4893/5000\n",
      "\n",
      "Epoch 04893: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0049\n",
      "Epoch 4894/5000\n",
      "\n",
      "Epoch 04894: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4895/5000\n",
      "\n",
      "Epoch 04895: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0049\n",
      "Epoch 4896/5000\n",
      "\n",
      "Epoch 04896: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4897/5000\n",
      "\n",
      "Epoch 04897: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4898/5000\n",
      "\n",
      "Epoch 04898: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4899/5000\n",
      "\n",
      "Epoch 04899: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4900/5000\n",
      "\n",
      "Epoch 04900: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0048\n",
      "Epoch 4901/5000\n",
      "\n",
      "Epoch 04901: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4902/5000\n",
      "\n",
      "Epoch 04902: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4903/5000\n",
      "\n",
      "Epoch 04903: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4904/5000\n",
      "\n",
      "Epoch 04904: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4905/5000\n",
      "\n",
      "Epoch 04905: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4906/5000\n",
      "\n",
      "Epoch 04906: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0072\n",
      "Epoch 4907/5000\n",
      "\n",
      "Epoch 04907: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4908/5000\n",
      "\n",
      "Epoch 04908: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4909/5000\n",
      "\n",
      "Epoch 04909: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4910/5000\n",
      "\n",
      "Epoch 04910: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4911/5000\n",
      "\n",
      "Epoch 04911: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0048\n",
      "Epoch 4912/5000\n",
      "\n",
      "Epoch 04912: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4913/5000\n",
      "\n",
      "Epoch 04913: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0049\n",
      "Epoch 4914/5000\n",
      "\n",
      "Epoch 04914: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4915/5000\n",
      "\n",
      "Epoch 04915: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4916/5000\n",
      "\n",
      "Epoch 04916: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4917/5000\n",
      "\n",
      "Epoch 04917: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4918/5000\n",
      "\n",
      "Epoch 04918: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4919/5000\n",
      "\n",
      "Epoch 04919: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4920/5000\n",
      "\n",
      "Epoch 04920: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4921/5000\n",
      "\n",
      "Epoch 04921: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4922/5000\n",
      "\n",
      "Epoch 04922: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4923/5000\n",
      "\n",
      "Epoch 04923: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4924/5000\n",
      "\n",
      "Epoch 04924: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4925/5000\n",
      "\n",
      "Epoch 04925: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4926/5000\n",
      "\n",
      "Epoch 04926: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4927/5000\n",
      "\n",
      "Epoch 04927: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4928/5000\n",
      "\n",
      "Epoch 04928: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4929/5000\n",
      "\n",
      "Epoch 04929: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4930/5000\n",
      "\n",
      "Epoch 04930: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4931/5000\n",
      "\n",
      "Epoch 04931: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0048\n",
      "Epoch 4932/5000\n",
      "\n",
      "Epoch 04932: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4933/5000\n",
      "\n",
      "Epoch 04933: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4934/5000\n",
      "\n",
      "Epoch 04934: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4935/5000\n",
      "\n",
      "Epoch 04935: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4936/5000\n",
      "\n",
      "Epoch 04936: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4937/5000\n",
      "\n",
      "Epoch 04937: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4938/5000\n",
      "\n",
      "Epoch 04938: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4939/5000\n",
      "\n",
      "Epoch 04939: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4940/5000\n",
      "\n",
      "Epoch 04940: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0062\n",
      "Epoch 4941/5000\n",
      "\n",
      "Epoch 04941: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0064\n",
      "Epoch 4942/5000\n",
      "\n",
      "Epoch 04942: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0068\n",
      "Epoch 4943/5000\n",
      "\n",
      "Epoch 04943: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0062\n",
      "Epoch 4944/5000\n",
      "\n",
      "Epoch 04944: loss did not improve from 0.00471\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4945/5000\n",
      "\n",
      "Epoch 04945: loss improved from 0.00471 to 0.00459, saving model to CNN_NAT.h5\n",
      "20/20 [==============================] - 0s 5ms/sample - loss: 0.0046\n",
      "Epoch 4946/5000\n",
      "\n",
      "Epoch 04946: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4947/5000\n",
      "\n",
      "Epoch 04947: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4948/5000\n",
      "\n",
      "Epoch 04948: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4949/5000\n",
      "\n",
      "Epoch 04949: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0073\n",
      "Epoch 4950/5000\n",
      "\n",
      "Epoch 04950: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4951/5000\n",
      "\n",
      "Epoch 04951: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4952/5000\n",
      "\n",
      "Epoch 04952: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4953/5000\n",
      "\n",
      "Epoch 04953: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4954/5000\n",
      "\n",
      "Epoch 04954: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4955/5000\n",
      "\n",
      "Epoch 04955: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0067\n",
      "Epoch 4956/5000\n",
      "\n",
      "Epoch 04956: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4957/5000\n",
      "\n",
      "Epoch 04957: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4958/5000\n",
      "\n",
      "Epoch 04958: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4959/5000\n",
      "\n",
      "Epoch 04959: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0048\n",
      "Epoch 4960/5000\n",
      "\n",
      "Epoch 04960: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4961/5000\n",
      "\n",
      "Epoch 04961: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0053\n",
      "Epoch 4962/5000\n",
      "\n",
      "Epoch 04962: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 4963/5000\n",
      "\n",
      "Epoch 04963: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4964/5000\n",
      "\n",
      "Epoch 04964: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0065\n",
      "Epoch 4965/5000\n",
      "\n",
      "Epoch 04965: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4966/5000\n",
      "\n",
      "Epoch 04966: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0052\n",
      "Epoch 4967/5000\n",
      "\n",
      "Epoch 04967: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 4968/5000\n",
      "\n",
      "Epoch 04968: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0059\n",
      "Epoch 4969/5000\n",
      "\n",
      "Epoch 04969: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4970/5000\n",
      "\n",
      "Epoch 04970: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0063\n",
      "Epoch 4971/5000\n",
      "\n",
      "Epoch 04971: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4972/5000\n",
      "\n",
      "Epoch 04972: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4973/5000\n",
      "\n",
      "Epoch 04973: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4974/5000\n",
      "\n",
      "Epoch 04974: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0047\n",
      "Epoch 4975/5000\n",
      "\n",
      "Epoch 04975: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0047\n",
      "Epoch 4976/5000\n",
      "\n",
      "Epoch 04976: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0049\n",
      "Epoch 4977/5000\n",
      "\n",
      "Epoch 04977: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4978/5000\n",
      "\n",
      "Epoch 04978: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4979/5000\n",
      "\n",
      "Epoch 04979: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 4980/5000\n",
      "\n",
      "Epoch 04980: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0057\n",
      "Epoch 4981/5000\n",
      "\n",
      "Epoch 04981: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4982/5000\n",
      "\n",
      "Epoch 04982: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0054\n",
      "Epoch 4983/5000\n",
      "\n",
      "Epoch 04983: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0058\n",
      "Epoch 4984/5000\n",
      "\n",
      "Epoch 04984: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0071\n",
      "Epoch 4985/5000\n",
      "\n",
      "Epoch 04985: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0049\n",
      "Epoch 4986/5000\n",
      "\n",
      "Epoch 04986: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0051\n",
      "Epoch 4987/5000\n",
      "\n",
      "Epoch 04987: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0059\n",
      "Epoch 4988/5000\n",
      "\n",
      "Epoch 04988: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4989/5000\n",
      "\n",
      "Epoch 04989: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 4990/5000\n",
      "\n",
      "Epoch 04990: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 4991/5000\n",
      "\n",
      "Epoch 04991: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4992/5000\n",
      "\n",
      "Epoch 04992: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0061\n",
      "Epoch 4993/5000\n",
      "\n",
      "Epoch 04993: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0060\n",
      "Epoch 4994/5000\n",
      "\n",
      "Epoch 04994: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0056\n",
      "Epoch 4995/5000\n",
      "\n",
      "Epoch 04995: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 4996/5000\n",
      "\n",
      "Epoch 04996: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0057\n",
      "Epoch 4997/5000\n",
      "\n",
      "Epoch 04997: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 4998/5000\n",
      "\n",
      "Epoch 04998: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.0064\n",
      "Epoch 4999/5000\n",
      "\n",
      "Epoch 04999: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0070\n",
      "Epoch 5000/5000\n",
      "\n",
      "Epoch 05000: loss did not improve from 0.00459\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 0.0066\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "history = m.fit(training_data_ip, training_data_op, epochs=5000, callbacks=callbacks_list)\n",
    "np.save('NA_TCN.npy',history.history['loss'])\n",
    "end_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 253.83426713943481\n"
     ]
    }
   ],
   "source": [
    "print('Time elapsed:',end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "from time import time\n",
    "m.load_weights(filepath)\n",
    "filename = '../../SWE_Data/Data/snapshot_matrix_pod_test.npy'\n",
    "test_data = np.load(filename)[0:64*64,:]\n",
    "pca_vectors = np.load('../../SWE_Data/PCA_Vectors_q1.npy')[:64*64,:num_modes]\n",
    "\n",
    "true_pca_evol = coeff_scaler.transform(np.matmul(np.transpose(test_data),pca_vectors))\n",
    "test_data = np.zeros(shape=(1,num_coeffs+num_ivs,500))\n",
    "test_data[0,0:num_coeffs,:] = np.transpose(true_pca_evol[:,:])\n",
    "\n",
    "test_data[0,-2,:] = -1.0/2.7\n",
    "test_data[0,-1,:] = -1.0/4.0\n",
    "viz = False\n",
    "\n",
    "mse_val = 0.0\n",
    "\n",
    "num_inference = 1000\n",
    "start_time = time()\n",
    "pred_mean = np.zeros_like(test_data)\n",
    "pred_pca_array = np.zeros(shape=(num_inference,np.shape(test_data)[1],np.shape(test_data)[2]))\n",
    "\n",
    "for inference in range(num_inference):\n",
    "\n",
    "    pred_pca = m.predict(test_data[:,:,:burn_in])\n",
    "    pred_pca = np.concatenate((test_data[:,:,:burn_in],pred_pca),axis=-1)\n",
    "    pred_pca_array[inference,:,:] = pred_pca[0,:,:]\n",
    "    \n",
    "    mse_val = mse_val + np.sum((pred_pca-test_data)**2)\n",
    "    pred_mean = pred_mean + pred_pca\n",
    "    \n",
    "    if viz:\n",
    "        \n",
    "        fig,ax = plt.subplots(nrows=2,ncols=2,figsize=(12,10))\n",
    "        ax[0,0].plot(test_data[0,0,:],label='True')\n",
    "        ax[0,0].plot(pred_pca[0,0,:],label='Predicted')\n",
    "        ax[0,0].set_title('Mode 1')\n",
    "\n",
    "\n",
    "        ax[1,0].plot(test_data[0,1,:],label='True')\n",
    "        ax[1,0].plot(pred_pca[0,1,:],label='Predicted')\n",
    "        ax[1,0].set_title('Mode 2')\n",
    "\n",
    "        ax[0,1].plot(test_data[0,2,:],label='True')\n",
    "        ax[0,1].plot(pred_pca[0,2,:],label='Predicted')\n",
    "        ax[0,1].set_title('Mode 3')\n",
    "\n",
    "        ax[1,1].plot(test_data[0,3,:],label='True')\n",
    "        ax[1,1].plot(pred_pca[0,3,:],label='Predicted')\n",
    "        ax[1,1].set_title('Mode 4')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Plotting some contours\n",
    "        true_rb = np.transpose(coeff_scaler.inverse_transform(true_pca_evol))\n",
    "        true_recon = np.matmul(pca_vectors,true_rb)[:,-2].reshape(64,64)\n",
    "\n",
    "        pred_rb = np.transpose(pred_pca[0,:num_modes,:])\n",
    "        pred_rb = np.transpose(coeff_scaler.inverse_transform(pred_rb))\n",
    "        pred_recon = np.matmul(pca_vectors,pred_rb)[:,-2].reshape(64,64)\n",
    "\n",
    "        fig,ax = plt.subplots(nrows=1,ncols=2,figsize=(12,5))\n",
    "        cx = ax[0].contourf(true_recon)\n",
    "        ax[1].contourf(pred_recon)\n",
    "\n",
    "        fig.colorbar(cx,ax=ax[0],fraction=0.046, pad=0.04)\n",
    "        fig.colorbar(cx,ax=ax[1],fraction=0.046, pad=0.04)\n",
    "        plt.tight_layout()\n",
    "        plt.show()      \n",
    "    \n",
    "end_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAALICAYAAABijlFfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdeXxcZ3Xw8d8zo8W75UXyEsd27KwkIYmTEJawNE0oewsk0NICgYIDLYVCeUnpWwqFFkra0pSSvsQUaAiFhpgESIiT2EmcON5tOZYl29r3bTT7plnv8/4xi0ajkTQjzSqf7+fjj62Ze+9cS6O59zzPec5RWmuEEEIIIYQQQsyfqdQnIIQQQgghhBALhQRYQgghhBBCCJEnEmAJIYQQQgghRJ5IgCWEEEIIIYQQeSIBlhAVRilVV+pzEEIIIVLJtUmICRJgCTFPSqltSqlvK6UcSqm9M2x3p1JKK6UeVUrdPofXqVNKPQo45nXCk8/n2/k4lhBCiPJSadem+HG+pJTaGT9vuT6JilVV6hMQotJprbuAe5VSNuDbSqk6rbUzw6ar439/cprnZ3sdJ3CXUmpevRXiF9AdwB1A13yOJYQQojxV2rUJ+LLW+t7EF0qpk0qpnVrrXfM8rhBFJzNYQuRPF7Ab2Jn+hFJqB3ACkhejktFa79Na3wc0lvI8hBBCFEVFXJuAO5VSqefYRWwgUIiKIwGWEPn1IHBPhsdXI7NFQgghSqMSrk13pM1WbQOOl+pkhJgPSREUIo+01vuUUquVUju01rPOEMUXBe9k4gK3LT67lLrNl1KenzLCGD/Gl4ldiLYBjVrrffP4bwghhFhAKuHaFE9pTOy7I/7YfdNtL0Q5kwBLiPzbRWyk8B6IrXmKX9wyVVh6DvjdRGqGUup2pdSDWuvEvnuBexMXRKXUtgzHOEls5K8rvk2nUurGMkj3EEIIUT7K/toUP5cPAHcBn5zrf1SIUpMUQSHy70Ey5LqnS1RrSr3YxEf3dsarKe0gNmrYmPJ8V9ox7szweCOQcyUoIYQQC1rZX5u01k6t9S6t9R3AD9LWZAlRMWQGS4g801p3KaUa4xeYfYB9mk13TPOcE7iJWErFbLNQ2wBnWmnd41nsJ4QQ4gJS7temDFUOH4z/kSqCouJIgCVEYSQWFDtnyDnvYqI8bqo6YlWd7MBsfUAagQ+mvYasvxJCCJFJWV6b4oHYXqXUKklvFwuBpAgKkT/JHPR4JaTbiV2QJknku2utd8e/3pby3J3A7niaRCPQlVjsG39+R+qxEhevtGPUpW8nhBDiglUJ16YTwH1pwdUdxMrLC1FxZAZLiHmKX0DuJZafvialUeJ9xEfs4qNziRK5344vFm4Efhf4slLqOLERwzqt9V0ph088n0jJqIsf71EmmkKmHgOYuEBOc747iF1g7wRWK6U6gX3ZVJYSQghRGSrp2qS1diqlHolXJnQC24Gu1MbDQlQSpfV8G28LIYQQQgghhABJERRCCCGEEEKIvJEASwghhBBCCCHyRAIsIYQQQgghhMgTCbCEEEIIIYQQIk8kwBJCCCGEEEKIPKmYMu1r167VW7duLfVpCCGEKIGTJ09atdb1pT6PdHJtEkKIC9d016aKCbC2bt3KiRMnSn0aQgghSkAp1Vvqc8hErk1CCHHhmu7aJCmCQgghhBBCCJEnEmAJIYQQQgghRJ5IgCWEEEIIIYQQeSIBlhBCCCGEEELkiQRYQgghhBBCCJEnEmAJIYQQQgghRJ5IgCWEEEIIIYQQeSIBlhBCCCGEEELkiQRYQgghhBBCCJEnEmAJIYQQQgghRJ5IgCWEEEIIIYQQeSIBlhBCCCGEEELkiQRY4oLn8odLfQpCCFEyvTYf/7TnPIPO8VKfihBCLAgSYIkL3rNnR0p9CkIIUTJff+Is33+xk3f8+wHODbtLfTpCCFHxJMASF7ynzgzTMuQCYDwULfHZCCFE8UQNzbFuOwCu8TBf/XVLic9ICCEqnwRYWZIb74UpamgOdtj4m8eb0Vqzp3kYAE9A0gaFEAvf2SE3nmAk+fWxHrukTQshxDxJgJWlf36mtdSnIArA4gkQihqc7nfSZ/fz1JlhHj7cw54zE2mDWuvSnaAQQhSINxjhUz89OeXxM4OuEpyNEEIsHBJgZSESNXiiaajUpyEKYNAxsaj7SJeNA+1WvvqbFsa8weTjLUOyJkGISqSUulMp9e0st/1SfPudSqmdhT63cnCww5qxsEXToLMEZyOEEAuHBFhZsPtCOHwhmclYQKzeYDwlcGKm6kiXnWDEwNAw5okFWMFIlBfbxkp1mkKIOVBK3a6U+hJwD1CXxfbfBrq01ru11ruA7UqpOwt9nqW2vzXzZ9uBNmuRz0QIIRaWqlKfQCWweIJEDI0/FGVprXzLKpUnEGb5omoA/vnpVg532Rhw+JPPH+60Jf+dCLAcvjCn+hzFPVEhxLxorfcB+5RSa8giwAJ2aq3vTfl6L3AvsLsQ51cuGnszf7Yd7rLROeZle/2yIp+REEIsDFlFC/GRwC5gNUB8hG+6beuAnYAT2B7f/t60bbI+XjmwxtPF3IGwBFgV7ESPgzddXo83GOFIt40+u3/S8yPuQPLfiRRBmy9I26i3qOcphCgepdSODA/bgduLfS7FFAhH6Rib/rPtZI9DAiwhhJijWVME55A68WWt9X1a613xwOr21Hz2SkzFSMxmuMalslIlG3D46bB4ef//O0SvzT/jttb4z9zuCzHqDkh6qBAL12piAVUqJyQHDBek8yMeosb0n2sD0nRYCCHmLJs1WDu11qlpEnuJ5bVP5860BcJdwB3zOF7JJWYzpHRtZRvzBHn0RD8dltlnpMY8QRr7HNi8IYIRQ4JrIRauTEFUIuBanWmHeCGME0qpE2NjlblG88zAzIUsUgsACSGEyM2MAdYcUyfuSEv52wYcn8fxSi5xcy032ZVtzBtid+NAVtt6ghE++qNjWDyxtMHU9EEhxILiZGoglfg6fWYLiKW1a61v0lrfVF9fX9CTK5RDKWtOMxl0zjzLL4QQYnqzzWDlnDqhte5K/DsRUGmt75vr8cqBEU+jcAcis2wpytmYJ4gzh1lITyDCyx2xm5ARlwRYQixQdqbOYtUBaK0XZL3yqKGzCLBkBksIIeZqtgAr59QJiAVL8TTBbwOfnOvxyiUNIxIPsGQGq7Kl9rbK1uHOWLniUZnBEmJB0lo3Eh/oS7Ea2FeC0ymK1hHPrNezYWeAcNQo0hkJIcTCMluAlXPqBMRG/eIpFHcAP0hZk5XT8colDcOQAGtBSBSuyEU4GvvZDzkDBCPRfJ+SEKIElFLb0oor7Ur7+g7gwSKfVtE0zbL+CmIDi8+2jBbhbIQQYuGZLcDKOXUiQ6rfg0xcqCoyFSMaryDnlgCrYmmtk+X25+JQp5Xnz1nyeEZCiEJRSu2ItwO5E/iAUupLaWuAbyeluFK84u02pdSd8f0604oxLSinB1xZbfdYlmtWhRBCTDZjUyetdaNSKuvUCaXU7cBepdSqTAFTrscrF4ksCYc/VNoTEXPmDUYIRuae7nKi14HZpPidKxtYVG3O45kJIfItnvbXCNw3zfO7gF1pj2XcdiFqHswuwOq2+gp8JkIIsTBlU6Z9xtSJtFSLE8B9acHVHUDqSGDFpWJEjdiNud0nAValsnrn97PTGo502fFIoRMhRAXTWtOTZeDU7/AnU+SFEEJkb8YZLIilTsTTK+4kVnI9PXXiduAuYLfW2qmUeiSeYuEEthNrKnxvDscrO4kZLAmwKo87ECYcMbDNIz0wlScQpn55bV6OJYQQxeYaD+MJZjdQFI7GUqsbViwq8FkJIcTCMmuABTOnTqSnWqSkZszpeOXIiK/BckiAVXEs7gCtI17M2czVZsETiOALRlham9WvjhBClJU+e279rfod4xJgCSFEjvJ027mwReMpEnZZg1VxRt1BDnZaGZtnimCCOxCmbdSTl2MJIUSxZQqw3mo6zsfNe4Cp6YADDmk4LIQQuZJh+CwkAqxA2GA8FGVxjRQ5qBQWT4B9Z0dZu7QmL8fzBCIMOMa5YfOqvBxPCCGKKT3Aeo06x66afwOgQTn5p8gfAir5vBS6EEKI3MkMVhaiKYt8bb78rOURxTHqDmLxBHm6ZSQvx3P6w7SOyAyWEKIyjbomN01/n/kAHr2Y3dE38amqJ3i4+luYmKi42iafd0IIkTMJsLKQ6IMF4PBJL6xKMuqO3Uy0jXrzcrwem29e/bSEEKKUUiuqrsDH7eZGXjCu5/+Ed/Kt8B/xRnMz7zMfSG5zfsRditMUQoiKJgFWFlLL1FplBqsi2H0hzg27sXjy+/PqsHilmqQQomKlDhDdV72LFfh4OHIHGhMPRt9Fh7GR95gOJbfptfsJR+feQ1AIIS5EsgYrC5GUAGvAMV7CMxHZGnD4ec/3DmI2qdk3zkGHxcsSWYMnhKhQiQBrOX5uMzXy39G3cVxfGX9Wccq4lDebm5LbRw3otfm5tGFZCc5WCCEqk8xgZcFISRHsz7HErSgNhz+WyhnNc5PMfodfZrCEEBUrkSL4JlMTNSrKs9EbJz1/Xm+mQTlZgyv5WL9UEhRCiJxIgJWF1Jt0CbAqg7NAJfW1Boc/xO6TA0QkbUYIUUFCEQPXeGzw6fWmFtx6MY368knbnNObAXiVqTf5mFz3hBAiNxJgZSE1wMq1SaMojUI2hQ5HNV989DS/PTNcsNcQQoh8S62Ce6OpjVPGZRhptwFNxjbcegk7zU8mH5MASwghciMBVhYkwKo8zvHCV3vstOSnMqEQQhTDkDNWVXUFPi5XA5w0Lp+yjZclPBh5F280N1OPE4Bem/TCEkKIXEiAlYXUMu2eQIRAOFrCsxHZcPoLH2CNeStvLdbz50cltVGIC9TPjvYB8FrTWUxKcyxZ3GKyVn0xAOuVHYBuqwwsCiFELiTAyoKRVihBihyUP0eB1mClqsR+WA+80EnzkPS1EeJCo7VmT3MsrfmNpjN49aKMM1gAw3o1ABuVDQCLJ5BxOyGEEJlJgJWFiARYFcdRhBksWwUGWA5/iCNdtlKfhhCiyLzBCP5QLPviDaZmjhhXEZ6mU8tIPMBKzGC5xiPSC0sIIXIgAVYW0kt92yTAKnuFqiKYylpBKYKJmyOnP8zhTgmwhLjQjLpjs1CrcLPNNMJxI3N6IICNFQR1FRviARZU5oy9EEKUigRYWUjtgwVg9wXROr/9lUT+uPxhWkc8BX+dSrrh+OKjpzEMjdMf4li3nWAkKmsJRdKYJ5ickXX4QvL5tgCNumM/3+tNnQC8Ylw6w9aKEb2aDWpiMMbirpzPOyGEKDUJsLIwZQbLG6LXJot+y9XuxgGCkcKns/hDUfyhSMFfZ75s3iC/OT2EzRfC0DAejvKdvW009jroGpNKiBei9HSvlzvGeKF1DIDHTw3ycoe1FKclCmjEFZvBut7UQVQrmvQlM24/oOu5QbVTS2ym3uKRAEsIIbIlAVYW0gMsu0/WsZSrDouXb+85X7TX++dnWov2WnPVbvGiNTQPuZKPPfhiF62jHp6SXl4XpPbRyYH1S21Wnjs3CkDTgJODHfL5ttCMxgtVXKEG6NHrGWfRjNv/Z/Q9bDaN8YfmF2L7u6XQhRBCZEsCrCxE09JlmgZcDDjGS3Q2YiZ9dh+hIi7G/snhXkJFmC2bj/bRWLpkU79r0uPnht3saR4pxSmJEksNtn3BCMe67bzcYSUQjtI04JKb6QVoND6DdakapENfNOv2B41rceklbFdDAAy75D0hhBDZkgArC0ba/fOxbjveYPmnhuWiElLdsuEJFPf/ETU0PWXehDPRHLtpwDnp8efPW2gd8Uh1sAtMKGLQafEyHq8oN+YJMugcxxOIcGbQRZfVJwHWAtRn91NFhC1qlA69Mat9BnU9F6lYumivtbw/54QQopxIgJWF9BTBUNTAt4ACrHDU4MX4+otK5y5ygAXQaSnvdUyJtROnBybPYFm9ISKGZsgZm40NR42iVF8sF+m/1xeKM4NORt2BZG+jsZRiLY+e6AdgxB2oqCIuYnZdVh9b1CjVKkqnkW2AtSYZYPU7ZN2xEEJkSwKsLKT3wQIW1AxW04CTXvvCuHh6AoXvf5Wuo9wDrHj1r+lumP/2V82cHXJzftjDfx3oLuapldTIBTpLc6TLjsUTTFaVG0spXvBkU2xNnsUd5IXzFiwX6PdooQlFDPrtfi5WsYG0Hr0+q/0G9Vo2xgMsmdUUQojsSYCVhfQy7bCwAqxj3Y7kTVY4alT0TVWxUwRhIgWvXCVmKqZzoN3KzodPcLLXzrEe+6TnLJ4ALUOuBTnb01/mP7dCOdJlmzSDlXrjnGhE6w1GONRpm7RWS1SuPrsPQ0O9iqUJj7FyyjZmk5ry2KBeywo1zgp8OHzFH7wSQohKJQFWFjLdXC6kFMHmIRdWbxCrN8ipPueUm+xKUooZrEFn+RY88QTCWfWvGXCM88OD3XjjAarWmn/f187rv/U87/zuy3zwwcMLalABLtwA65U+J0POQLJs94leR8btnjs3StOABFgLQedYbP3UWtwAWPXkAOuLb72cj7xuy5T9+nUDAFvVCMGoUZLPVyGEqEQSYGXBWOApgs2DLsY8QR461MMPX+7idL9z9p3KVClmsIbKNMCyuAM8cXoYT5bv1X77OJ5g7AbqW3vO82/72njnqzfwt++8isY+B//w5NlCnm7R9V+AlUCDkSieYITxcJSnzgwTiRocaMu8/tIdiPCL4/0LpgDOhawrEWApFz5dO6lE+8rF1Xz81kv4i9suY+2y2kn7tehY0HWNqQeY6KUlhBBiZhJgZSHTGixfMFqCM8k/qzdIr83PmCfImUEXz7SMcqwn84h2JShNgBXIGISX2plBF786NZjTPt5AhL1nR9n1Uhd/8trN3P/B6/nEG7fxsTdcwi9O9NO9gCqJDTj8GIZGZ0gBXqic/okZiMY+Jx/50bEZC8MMuQJ87n9fuaC+RwtRoqH4WuWaMnv15bdfyZKaKlYvreFXf/563nR5ffK5ft2AUy/lWtUFSKl2IYTIlgRYWUjvgwULZwbrff95CIhVEmsejKUDne53crizMhuN5prC8npTMz2LPsQ65p4WGYoaZVlxrWnAlXO6pycQ5q9/2cRVG1bwd++6GqVi6zLuefM2qkwmHjrUU4AzLQ2XP4wnGOHJpmF+eqQXYEEHElpr7L7JVSIPZfF7vvfsaLIghqhMXdZEiqALa8r6q8vXLeMPX7M5+fWmVUv4wh2Xp+ypaDK2ca0pVvzmQi0MI4QQuZIAKwuZZid8wUhF34wZhiaaUqLb6Q9j9U7cfD3dPFyqU5uz5kFXzjNYHzbvBeBWU/O8XrscqzA29uU+ExkxwDUe5jsfeDU1VRMfDw3LF3HblQ082TREZIH0zfIEIzj9IbqtPs4Nx9amLKQZulSBcJT9bWM45liGv93iWTA/9wtR4n29RrknzWC9/ZoNU7Z99UUrWVQ98bvfrjexTQ0DumzToYUQotxIgJWFTDNYEUMTjFTmDYfWsea4Y55gxvRHgPYyLz2eye6TAzkHWD4WA3CJaX4B5YF267z2z7dQxOD4HIuV3HXTJpYvqp7y+O9fvxGrN8TxCk4hTeUNRHD4w3RbfclCJS8skH5wqc4MuPjab1o40GbF5p1bgNU26mXfudE8n5koBk8gHJ+51NQr56QA645XrZuyvcmkuLRhWfLrXt3AEhWkHie9tvIbSBJCiHIkAdYsDENTo0OsYWo1LZuvMpuyeoMRuq0+hlzTj0ZWYoB1qNOac6+WBmLBwgfML7IWF2aiQO4zk3vPltfN58leB4Hw3AYAfv/6i2gedBEIT15neOtla6kyKV5qXxhBiCcYTs5gJUbm97daSnxW+dcx5uF/j/dzZtDJMy0jczrGr18Z5Gh35VYXvZAlPhNvM51ijfLwit4OQMPyWq7euCLjPpc1LE/+u0/HgrAtavSCrbwphBC5kgBrFlGt+UbVjzm56NMsZ/LFpVKr7Tn9Yfrtfoad0wcjY55gxd1s2n3haWfkprMp3nizQTk5sejTdC76MK21d/MZ8+M5Hef8iHtKQFIqUUPz1d/MPeVx1B2gz+7nVN/k9/fyRdXs2LKKFyt4lie1vYI3EOF/j8UKdww6xnH4QlP+zwtBjzX2udU04GJP89wCrKYBlzSarVAjrtj6uTvNLzGsV/N49FYA3nJFfXKNZbrJM1iJAMsi7wFRsZ46M8wHHjyMW1oNiCKRAGsWUUNzi+kcAB8yPzfpucZp+seUO9d4mH7HOMMzzGABfPInJyqimIfLH8YXjMy6vuRmdZ61uFAYvMt0mNW42aTG+H7k3TQalya3a9Zb+WL1o9ThYYdq4z2mg7Oeg9blsX5nzBOk3+6nbXTuM5AdFi99dj+HO6emPb5u2xrOjbgr4n2Ryd/9ugWXP4w7EMYbjPB0ywiu8TC+UJT/3N+BNxhZcBfgRCPsYMSYV8NoKdFdmRKFKS5SVlqNi4lQBcCbL2+Ydp8/vmUzl8WDrAFdT1QrtphGKjZrQ1zYQhGDbzx5lmPddh54vqPUpyMuEFWlPoFyZ2jNkF7LFixca+qClEmK6Rp0ljunP0yf3Z9c2D+dcFTTb/dz1YbMaSTlwuYLMuYJznjzaMLg0dqv022s41uRD/G9mv9IPnfEuJJl+Nlh6uDRyJt4ztjBjTX3s1HZeKz2awD8NvBaophnPI+uMV/Jv1cvtY2xfNH8fq3bR73Y/SFqzFPHX27YXIfW0NTv5PWXrp3X6xTb91/s5JeNA1y+bhlNgy7C0cnvlx8ciFVKG3KO02/4uXrjykyHqTg9tvwE/lJJsDKNxAfSNiorLUasr5VJwa0z/P7WLanhpq2rabd4CVOFhVVswI4/FCUcNajO8NkgRDnSWnPvL5uSLQYefKmLazetRGtYs7Sm4q5jonJIgDWLiKFZo2Lrr1YxeVbg9IATmzfImrTmjOXOOR7iuXOjZDOY3VcBAZbDH6JxltSutfE1dJeYRvkj8/MAtBkX8YxxM/uNG9hhagfAxkpG9SoA1qmJAPpq1UNTfO3CdDrHSrduzTA0JpPiSJeNdSsWzb7DDNotHnps/uQIdqrrL64D4FSFBVhHu2z8057zAPzrs22EZqiI96EfHOXqjSt4+E9vwTUeZuXiqQU/KkUoYtA64snLsUbdgeT7TFSOEXeAGsLUKzfDeg0AV29cycolM7+v162YuK5ZdB0NKvYZa/eF5v0ZI0Sx7D45wONp/SC//fR5ltdWc/HqxRV1HROVRYahZmEYmtUqdoOySk2+gda6sqqOBcJRtNY4/OGsgiugIhY1O3zhWUuSb1QT/X5+x3ya74Tv5K2hf+ZfIx8AYH/0egD2RncwrFcDsF7Z8enYTcZrTOdnPY+eEqYIJqrgjXqCPNk0NK9j9dj8RA09qSltQt2SGrbVL62YtUoWT2zUMrX62UzBFcRuIF3jsf97pa1DTHVu2M3hLhv+UH7WBkYMzV6pJFhxRlxB1qtYgZIhHbuZvGnrqln3W58SRKUGWGMemckUlWP3yYEpj/Xbxzk77OZIl31eadNCzEQCrFlEIxFWEQuwVqqpMxSzpdmVk2daRnD4w7hy6IXTUQHVBO3+2YsTbEgJsLx6ET+Ovm3S8436ci4L/IST+grGqCOqFTea2jETuxm/VE0eAcuklOsTzsbfh2OeID3zLKWcuOBMt6bthotX8Uq/oyL6wL3UFltHNpZjI+hEcPncOUvGPniV4HiPna/8an793dL9zWNNeT2eKDyLJ8BFKvZ7MERsBuvmratn3S91lmpM17E2EWCVYVN1ITLxhyIzDr66xsM8cXp+A5JCTEcCrFkYfjtmpQlp85QUQYBBR+U0XnyyaZg+uz/jzMR09jSPlE11vOk4fCGss1z0U2ewThhX4GHJlG3C8YzZKGbMSnOn+SUWqdj3KjF6OxPnHJu45sP54dggQD5Hl4MRI+PP/obNdVi9IQYq4L1/steONxiZ9f2RLvGzPNXvwOqL7VtpTVYHHOPJAhf5YvOF6XeUvpiLyN6oO8BGYp9/Q/EUweviqb4zaUhNEaSONXgwE63YGaxKHSgRc7fnzMiUtbbpPv+LV/jMzxqLdEbiQiIB1mz8sZG/Tr2RJSpILZNvomfqJVVu+u1++uz+nGZaXONh3vHdA7QMuYjMklpVKo4sAsbUGazvRt6b82ukrseaz3kUSuuom6ihsfvye/Pj8IcmlTaHiXVYTQNTe8OVmxFXgNYRN9YcG+y6AxH8oQj99nFGXAEiUWNKHn+5G3AUJr33e893TnlM0mzKU9TQjHmCbDWNENEmBvVaVi+tYePK2ddQTU4RXIVJadbiwlKBpdpP9Tl46/0vcf++Nh4+0lvq0xFFEAhH+doTLbNupzU8e3a0YivjivIlAdYstC8RYF0EQF3aLFYlzWDZfCF6rT4Od9pm3zhF15iPf/ztOb799OzrkErBkUXAuF7Z6TQ2sDXwPzTqy2fd/hOhv0r+ezRl/cF8z6NQzg97GPMEs15bly2nf2oKxaUNyzApaB3NT/GEQrJ4gjQNuLDOYdQ9kf57esDFh/7rKAc7rBU1Cl6oz6anzgzTYfEmU0S11hwo0+bTSqkvKaXuVErtVErtzGL7nSl/vlSMcywkmzf2mXCJGqZPNxChimsuWjlt/6tUq5bUcNuVsVLuYzpWUbNBOZPV2CqF1pqv/qaFDouX+/e189ChnopIbxbzc7jLhieQXdAUihgV3d9RlCcJsGahfLFgpFNvBKYWurD5QmWfQgex9Ai7L8Rvzwwn+6Lk4lCnjafOjJTlhcmeRWpevXJhZSWQXQW0fcaNHIheA8Qaba7BTRUzf1h7ghHCJZjlC0cNum0+DndN7Vs1X22jHn5zemjS6N6iajNb1yylLU/V6QppzBOksc+Zc4ogwJn4DN1/HejiWLcduy/EoHO8In7fgYKlcHoCEf7iZ420x9dntlu8NA+W32ymUurbQJfWerfWehewXSl15wzbf0lrvSvxB9hX6UFWorT+JWqEHr0egKs2LM9qX5NJ8fnbY4NRicI/G5WtIlKDU+1vHZs0295h8fJyR/4/K0V5yTVgeu68FHet8nIAACAASURBVPAR+SUB1iyUP/ZL2mkkAqypN5UtQ+Vf6MI1HiZqaM7P46Z40DnO/jIc5ZkpZeVu89P8sXkfa3ElR2GzdW94J7ujb2JP9DWYlKZj0Ue4r+rBGffJZX1bvgw5x9Eafv1K/hfrPnF6iDODrik30JevW172M1hRQ2P1BmnsdcwtwBqM/V4nKhDafCGGnOPYK6DZaq/NV9CiK+dGPBzpig0+PdY4iDdYlkHnTq317pSv9wL3zLD9B1O/0Fo3AjcX4sSKZdQdADRb1QjdegMAF9Utznr/DXWxNME+HZvJ2qxG48esHN97YWpj2a/8qpmX2srvWibyIxI1eLJpOKd99reOleUAsqhcEmDNQo0nZrBiF6dERcFUn3joeFHPaS5seVqb8/dZ5DQXk9aarhnKo3+t+if8Y/WPWKtc2HRu/byGWMsXw5+iP35zAfCBqhdn3Ge6ynuFMh6K8qXdscpuB9rzPyr73HkLnkCE589b6Erp83XF+uX02HxlPZsz6BjH0LGBgbmsj0sPKh2+EEOu8TkFa8X2wvnCl5c/Gi9xvPtk/5R1eqWmlNqR4WE7cPsMu9mVUo+mHGMn8Ei+z62YRj0BGnCyVAXpjs9grc2hb+OapTXUVJlwswy7XsYlaqSk1VJz1WP1cbJ36vrZHpufnx3tK8EZiWI42GnL+XPa7gtVXPqrKG8XVIDlcdk58Z33c+yX92e9j8lvw6mXMhpPkVirpqbCuMbDZb82I9dF/tPpsfnLagTf6g3NkGc98TNZqfxYc5zBSjhrbEn+26tnXhxe7HVYPTYfR7tjPW4KUWggMaD3WOMg9+9rTz5+xfrlaF3eZfz3t80vyGi3TB5MicRngG3eWNXKcizsYPMG0Von3xOF1DLkYsQdwOqdWgilDKwmFlClcgIopaYroXcPsEMp5YinBtrTZsAqjs0bYpspNpI/lwBLKZWc8erV69miRnNq81Fqe5pHpn3uaLet7K/bYm7mmrLcXsbXM1F5sgqw5rBQ+EvxP4+m57DHj/MlpdQ2pVRd4t9z/Q/kouV//pqb3Pt4zZmvcv7Y3qz2MY3bsOkV2FlOVKuMAZahY+tvypktTwEWwOn+8mky2z3D7NUaJqduxtZg5W6ItXwh9CkARvXMDTotRS5hXKzmxlZvcNJI8OXrYus4Wst4HdZ801kz3XudHXIz5g3yZz9tpMdWfuXKX2wbwxOMFKWk/LArQF88fbIMK3BlCqISAVfGJlBa6y7gQaAL+DYzpAfGr4UnlFInxsbKN9XM5g2yVcWCjB4jEWDV5HSMjfE0wR69ji2mUUJRXY4BdUYHZ1hr5fCHOdKdW8GnhSgSNfj6E2f56QKqrtg1NrfP5vYyT3sXlWXWAGsOC4Uf1FrfF/9zF/DBtCBrNbGLVyfQHT921/z+G9lZ7jxLv9rIgNrApt9+mO6zs6f2mcdt2FiBgQkbK6kn88iIq4QlurORz7SmclrQnpq2lm6Tmnzjk2uKYKrHjDfxs8htLFcz37j+4kT/nF9jLrqLeJPvGp94j29ds4Qas4m2Mr4gFSIAah50YfUGOTfiLlpwm4vDnTZGXIGipLoEIwZNA7HBFl+o7G64nUwNpBJfZ5zeU0o9CDRqrW8E7gJ2pqYMpooXwrhJa31TfX19vs4572y+EJeoYYK6OtlkeO3y7GewADaujM1g9ekGNmKjikhF9MKKRA1OzdBkFuDf9rYV6WzKk9aaP33oBD862M3hThuj7kBF/Gxn022d20xUOQ8YisqTzQxW1guF46kX6dMbD2bYfhWwXWu9qpgpGPWhQUZWXkf1n/6WgKplxS/ezyt7f0Y0Mv3NgXncij1+Yz6mV1I/Tblu53h5p02cH8lfIY5iz9LM5ESG/HqIFbe4v/qBSY/NNUUwwc1SGpSTa9T04wEH2q1FuUA5fCEMQ3O8CKlgCd5gJNkLrcpsYlv90rIOsAqRyurwhzkz4MITiMw4e1oqx3rsDDj8jBVpndhTZ2LpZ6lFLspkjZqdqbNYdQBa6ykf4ok1W1rrffG/dwM3AtMOJlYCmzcUryC4Do2JmioTy2urcjpGoinxqF6NSWnqcZXVNWA6raMefKGZ14ge73EwWGENxPPpeI+DF+PFPtpGPTx3zsIfPHCwLD/bcjHd+S8hVvRlOk83jySbzAsxXzMGWHNYKLwayJTyN+lrrbWzWLNWCT6PkwbsROu2sW7Tdnx/9Gu8puVcf/DTOP5hO6/c9zaO/sdHOfL/7uHwrs9y+Id/xeEf38tiZ3ty5mNM11GfIUUQSlM9Lhen+vKX1pevghnzpbXm5WkKO3yl6mEuMcXKrv46+noA+vX8RprdegkAT9b+LWummcmEwsycpDveY2f3yQFeKHJVx9RUsEvWLk1W2Cs3kagxacYtnxJpR+WWIjjmCdJr89M04KJYxbASvcJSU8bODLrwBEr7eRivAJj+obca2DfNLquJZVWkHqMLqOg1WHZfiE3KmqwCWL+sNqseWKletz028zUST49er+xYPOVfDOCJ09lVkdtd5KyDcvJ0yhq1bquPgx1WBp3j/M1jZ0p4VvNzfsQ9pahRNRH+o/q7nF30cR6o/nemC7I8wQj/daC7CGcpLgSzDWXNuFA4fSRQa92llLoxLXi6g7SLWnwdlz1+/Dqt9X1zOflcjHSfZTtQs+4yALZccT2he09y8rmfo889wRpfB3X+Zmp0mBrCVKuJka82vQmIzWBdbsr8Yews0M1cPjxyvC+vMw35XM81H312f8aeXgoDjeKJ6C08Ev0dXjau4R/Cf8JYxmUZ2XOzJPnvNcqNbZoZsW6rj5u3ZlzmkTdH432Zis09HqFuSWwNx5Y1S9l3bpSooTGbcrtpKzTneLhgQYY7XlSlx1pewWVjPB3qlSKukQxFY99kXzBCj9XHxrrF9Nn8XFS3mKihk++VEtmllLozJUviDmIZFQDEBwJ3xNPf9ymlJmVaxDMyijoQmG82X5ANysYJI9bP6tKGZTkfY9vapaxdVsuoL/aZtk45yqrQUSaBcJT/OZrdmqL/PtTL526fvfn8QqO15nDXxBq0iKF59mws4DrcZWPA4WfTqiXT7V62vvKr5imPfdi8l3ebj3DO2Mw7zccwcz/7jevo0es5Yrxq0rY/OdzDn/3OdpbU5DbTK0S62d5Bsy0UnnIlj48cAskL1O3EUi0S9hGrzpQI1B5USu2Mr++aJB6I7QTYvHnzLKc6M+fAOQDqLp74ZaqpXcSN7/gYvONjU7bXhkE0GuFwaz8P/fQ8AGPUUY8rfgM/efKvXCsrBcJR7v1lfkejyqVMb5898w3ucvxUKYNTxmW8bFwLMO/gCsCtlyb/Xa+ctOmLM27XbfURihjUVBWuSOfRbhsOX/GD+tRZoS1rlhCOaoac41y8urwuxMWo5pheSKLUgebZeD++YgZYCd5ghIOdVgxD02vzs3n1ErrGfLztmvVFP5cErfW9iQJNxLIoOtNS0m8nttYq8di98TXHnanHKNoJ55lhaPw+D6tqvYzEq+B+/o7cAwmlFNvrl9LhnZjBKvd1Oid6HDNUl53M4Q+xv9XCW65omH3jBaLD4uGvfnF6ytKBcHRiVOpQh40P3Fxen+uz0VpzbnjyYPK7TIe5t+p/eSl6LXeH7+UrVQ/zsapneJs5tgb/vcG/55S+LLm9OxDhxdYx3n7thqKeu1h4ZrsDzHmhcJpHgd9NndHSWnelzXztBTJexPK5kPj6t36UobuPcfHl12e1vTKZqKquYdWqtcnHhvVqqlU0Y6GLck0RnC4ImQ+bN1gW/Y+mq5S2Ot4M2qFzH62diZuJBp1rZ0gRbOx18HABKzIZhubskLskawfc8dQvrTVb4kFVId5j81WMQYARd2BSY8oem49wfI1aKSTStkrxWeQLRmgf9fKjgz302Hyc6nPQNceF5vkUL7a0O/73rrTndmmt70j5uktrfW/88V2ZBv0qiXM8TEP8Mj2sV1Nlgmsvmts61EvWLsXOcoK6ivXKUfbNhg+055Y6/Z0LqNiFPxThMz87xelZUokTs1mVZMwTnJTGXoeHf6j+ES16C38Z/nMMTPx95KM8Gb2FHmMdhla8x3xoynGeaam8/7soP7MFWDktFE4VHwm8N31GSyml0/qQOElbo1UI5qoqNm69guqa3CooVZknRqR79ToAtqjRKduVa8pEISqdOfxhDrRbkzfbpTLozHyRX0Xsxs7B8ry+nkdPjOZNtxYPYul7HZbCFX/whiIZS4jPTlPD/H5m7vgM1oBjnC1rYzN65bgOqxgzWP5QNNmeQWtNy5CbzhmqWhbaqLt0swqGjq296rb6ONA+xnPnLUXvCScmG/ME2aBiAdYIq7mobvGcZ1i3rl2KxoRFr2KdsjNS5g1Zpyt+NJ2mAdcFU+zimZYRzmdRLW/fOQsvtZVvC4JMOtPKs3/AvJ865ePL4U9gZ6KK8GfCn+W20L/ytHEz7ze/xOtMLZP2S02dFGKuZgyw5rBQGIj1ugL2JoKrtGIZ96YFZ9uARspUlWniW5QMsExTA6xSpOXMJhQxCrYQf3+rhfbR0o5QDzoyXxBXxWew7Dq/AVaqTP3QUhUyhWauLQHeYzpM26KP8vmqjJWns5IIqs+PeFi/YhE1ZhO9ZVjsoVgj7IkbTac/zJBznJbB/FXrzFWpCw8k2jeEo7Fg016CFFYxYcQdYH3KDNbmNUtn2WN6W+P7jrCK9TjKOkVQaz2nfka/fmWwAGdTfvady74B+8sz9BErR+mz5u81H6TRuJRWnb7ERGFg4puRDzGm6/h5zT/yBtPEUopRd7DsBxFE+ctmkciutL5XUxYKpz6vlLqdWBB2Ij5jtQ34IEw763UX8K25nHwxVKfMYA3qtUS0KeMM1plBF/12X7KMdal5gxF+e2aIf3mmMKkPL5y30DbqKemH0KwpguQ3RfAVfSk/jvweAJ+qepL3m16adttCljGe68zhpaYBAD5mfgYTc3uf/sfzHbSNejg37MZsUly8enHZzWAd67bzvRc6ivJaAw4/r/Q7GXSO4xoP02bxEIyUJn22lDNYEOuLlcpRputSLxSjrsDEDJZePa+CBVvWxPYd1atZp0pTYCdbY55gshBNthSw58zCTwubqfJuJuXU8zIbTf0T53ul6uMqUx+PR2+ddvsB3cA7Q99kTK/ko+ZnJz33Sn9us6BCpJs1wIov8t2mlLoz3jA400LheyBZ1GIvsQDMEf/TyeQUwF3xhcc742mEDxazF1auqswT36IIVQzqtRkDrIih2fVSN/4yWJsE8OiJfs4NewgVKOAbcgX46ZHeko5wZaogCFCXSBHM8wxWFDN/H/lo8ut/rfk+G8icSlDIEV73eG43D2aiLGWcNcQCzxXKz9WqZ06vPeAYp2XIlSzPvWXN0rIrV95t9WItUqXLxxoHeehQDwMOP67xMA5fqOiDDq/0O3nhvGXO/aeqiMy4pnCuyvkm/EIw4g7QoBy49RIC1HLx6sWz7zSNhnhz4hG9ivXKgauM+z62W3LPrNDEgomFntbabfXl1L6iedDF3rNT73fKVWpq3x+YXyaszTwZfe2M+wSo5ZfRN3Gb6RT1TARVR7qK12NSLExZlTnLdqFwvL+VyvDnrpTtnYnjxBcUl21wBVCVlrM+oOvZqDLfVP/6lUG8OY6cFYLNG+RXpwaTN8GF0jLkTq7JKYXpGgKuUW5C2oyXud9QzOQr4bs5HI1Vo9xqyjzqafUGMea2UGpWufZ3+jPzr2lZ9Kf8cdVz2OOFP+4wn2A5c5t5ahv1pgRYS+iz+ycVeyi17iKWT9/TPMKTTUPcv689FmD5w7zUNkZ/vPBHod4Dqf5tbxv/fahnzmXp/67qYU4s+jRfr/oxW9QInzP/khtU+7zPy+kP5bXBucjNqDtAg3Ji0bElz5vnUelz1ZIaqkyKEb2aJSpITcRLKFIe2RrpprvuLcPPW0yn+FrVf1PF1Ou0Bg5UWEpcrnJdyuAORNj58An6yixLIZMh53iy4JIJg983H2K/cR2OlLVX03kk+haqlMH7zQeSjz11ZphoET6/xcJVuDrSC0R6gDXGymlHe92BCMe6S784smnARcuQuyjT+6UqdGEYOmOgsRYX7zcf4KzeSizxI/8ejr6Vr0TuTr5eJuGoLlhvtFy/57eaJ/qCtOtNnDQu47NVv+LMok9wrPbPuERl15Az4USPnSFXIFlJ0B+KFm3GKBvFnFGLGppwVHN+xIN7PIzLH+Y7e9vot/sxDM1LOVYzy5VrPMyhTisv5rQYXdOz6EPcY34CgLebjwHwkaq9/LD6X/h89S95vParVGe4Cc2F3Rfie893lFXwfSFJD7C2zmMNlsmkYr2w4s2G1ykHzjKdxTraPXXm4TPmx2le9An+u+afubvqWd5rfnnKNmaleLHIjduL7egcZmW0royKgqf6JoLH15rOskHZ+dUM6YGpuvUGXjG287vmiXIAFk+QMxWWIinKiwRYs0hNEQQY03XUq+lHgfY0l/6DqHXUQ8TQU7qZF0Ku6Wr54glkrqT3o5r7WI6fL4c/UdDXH4vftMxUTbAQRQcC4WhOqVcKg6vURMl4m17BM9Gbkl83KCfvN0+/liyTxj4noYjBeDjKxrrYLOF06+FKobsAlTOzEZvBCuHwhxlwjtNl9bG/wDdsjX2OSb1rsrEqnir65eqfAxPvZYBLTUPJf893FssdiLCneYSxOaYuivkZcQdowIElXgh469q5B1gA9ctrk/201iv7nIvtFJJhaI6lBViblIXPVj3G/uh13Bv+JF3Gev6p6gc8UH0/S5n43DK05sU2y4IdEHD4Qvz69NwKeTxxemj2jUqsaWDivuy9ppdx68XsM3bMsMdkzcZWLlcDxOYyYyTAEvMhAdYsUotcAFj1SpaqID2LPkQdUysVHe60lXxauauIpaJLNYOVafS0mgivNnWzK/ouzuktBX19F0sJafOM1QQtBSg60DqSW2GRzcrCCjWOLb4ezaWX8uPo2/l55HeS2+gcZ/oS72+HP5wMsIZd5RFgufzhkq39SaQIQqzCZfOgi5M5lovO1VzWjKxLGyAKTdNvfr2a/xqEqKHpKHG10QuVzROMz2CtYsXiKpbVZv45Z6t+eS0jTDQbLsYAXq7aLd4pmQ1/Yn4OE5p7w5/kkejv8PHw/8HPIt5pPsbvp/RA0oDVG5pS6nuheKJpiEB4bmmdpwdcBWn5kk+n4wFWLSHeZj7OnugtBKnJev82vYmVys+6lHVYzQMSYIm5kwBrFul9Q8b0RKPGTWrq6LQ7EOFUX+mqz2it6crxAqEwMgaL2SjVGqxMzVQTa4oKWZ59gsLKSuqndDGYkO9S4YahOTvszimYSaT/7TdiDbarVZQwVfww+vbkNpnex9lw+EIpM1jlUdK2O4f0wGX4SR2tnC/XeDi5+H/QOc7LHdbkbFq+F8974gMbuTYVfqvpOE/X/vWkx9Jn5PdHrwNi/f7MzL9oT28ZNqJe6LTWhPxOFqkwFl3Hprr5r0etX1aLJZ4iWI9z2jWwpXR6YPJ7uZYQ7ze/yPPGDYwSm33r0Ru4NvhftBqbuMv84pRjlGPLlXx4tiVzsYotaoS/r/ox36j6EbVM/zMt5/VphqFpjrfIuEZ1s1yN5zR7BdCmLwbg8ni1XZAZLDE/EmDNotqUliKY0ne5JsMaBZOCF1qz7zORb083j9CV40jTN6t+yCuL7plTE9pSzWBlKgG9XMVu5Dy6MMUt0ln1Sn7PfJwGMgfUFk8wr98fTyBCn93PSA4zYw3xm+cO4yIAlhALhHr0+uQ2mapiZqN50MWqJdXUVpnKZgar25rdbMk67DQv+gQfNz+dt9d2+sPJdL3GPkes6E0wgj8UyfuFuideyCPXdX53m59Je0RTj5P/jLyH/xd5NwD7jB149GL+qno3D1R/d97naizQlKty5gtFqYvGZiAtuo5t9fNvWVG/vJYgNbj1EuqVq2BrTOfjdFpw9D7zAeqVmx9H35a2peLR6Ju5wdTBdjWRNmdSU4+xEIQiBkcyNM+9SZ3nqZov89GqvXy4ah+fNP922sq4hzvLN8Dqtvnwxpu+X2vqBuC0sT2nY5wzNhPU1fxN1f8kr5Nto27CZdJ6R1QeCbBmYTIpUiexUtcrrFBTR2YvXrWEQ52lK3Tx9SfP5pwi9UdVLwDTF2yYid0bKknOeqYCF4kZLDfzW2uQrQblZIUa55+qf5DxeYs7wLE8lnq1+0MMO8cZySGYaYjPsL1kXAvAUeMqINZy4J7Q5zliXMWlaogrVB93m5/OqQnxz4/3o5RiY91ihsqgKePL7VYae7O7ObpIxW4W3pOSIpRPXWO+ZLA16s7/YulEQ81cZxGsrJz09Rrc1KgoFl1Hh3ERhla8bFxDNH5peJv5eH5OWBSV3RtKDq6MUccV6+c/q39pQyxIs+g6GpQDh6/81talF3a60/wS54zNHDZeNWXbX0ffQESb+KB5f/IxrWODIwtNn91HJG3pgpko36r+ITa9gtuC/wLAF6sf5fCiv2CLmrqW/FAZLH+YTur6q2tN3Vh0HZZ4Omu2XCzjU+G/5CpTP58wPwVAxCjdml5R+STAykJqoYvUFMFlTL3R3bJmCU0DrmQKTzF5AmGGc7zRTQ2qGmYo3jEdiydIy1DxSzFnTBFUsZ+HR8+9HHEuHonG1jFtm6YK36g7yME8jvrZfSH6HeNZNzGuJcQlphGceikt+hJeF/gPHoq+Nfn8M8bN/HvkfSxlnGdq/5qvVf+Ez1U9zm2mxhmOOuF0v5N+u58NKxcx5BwvyXs+1c+P9/Hwkd7ZN4Rko+V8pMDNpsPipTfPlQ0TacC5pgiGqJ709atMse+XRdfxa+P1vDP0TXr0BupU6vmW502VmJ7NF0ymL1t0HZfMs8AFwDUXrUwer0E5GfOUV4qg1npSD6y1uLhBdbAn+hoyVZQdo45njZv4gHk/i4h9pmrg/IiHQJn0s8yXTOvKdqh2LjMN8q+Ru+jSGyc990D1d6c0o3f6w2WbPnlmIHYPYibKa01nOW1sm2WPzF4wbmBv9Eburno6Wcr//Mjclk8IIQFWFqpTprBsrOSzoc8AsExNDbDWrVhE1NCc7i9+7u7gHCq5XWvqSv67XjnZpMa4UvVlvb83GOGR4/05v+58ZbqxXEHsIuIpUP+rdP8WuZPvR97FRmXNWNK62+rLa7qJ3ReiZciVdb+jn9T8E+83H0iWaR5mDek3GoeNq/mD0DcmPXadqTPrc3ru3CiaWAPiUjak1FpzIIdS5YlgvKoIAdaZQRcWTzCvAWi/3U84auScppW+1jKxBuW0sZ0IVcniMON6YnH4RZRvapDIzO6bmMGy6FVsWT3/AGvb2qUsrTEzRh0NOBktQJXU+Rh2BfCHJn6f32hqwqQ0z82wFucn0bdSp3z8nmlipjZqaFqGFtbam/R12dvUED+o+VcgFlTAxNrLz4X+jGtMPbzLdGTKcV7KqR1E8bRbYp9rbzcd4yJlSw5+zsUj0bewWnm51XQGgLML7L0gikcCrCykF7p4Lv6BlKlR64rFsUpN6Ytti2HQkXuAdVVKMHWzqZWXaz83ZRH8TCKG5lenBoredDJTWfBEymaxUgQBWoyt1Kgol6mBKc+1jnryWtHO4QvlVAXqFtN5AEyzzECc0dt4IX5xBVieYWZ2Ovc908rhThtWT7CkF1+HP4w7hybfid/dKgxW4M3YeDRfzgw4sbiD/OxoX97Sad2BMDZvCFeOKYKrlYeQNvPF8D0YWvEe82HajYsYpH7Sdu8NfZ2HIncA8BdVj8+7J5YoLls8wBrXNXhYzOY185/VN5kUl69fnpzBsua5iM98daZVz73O1IlXL+Kc3jztPkeNKxnRq3hHvBdcQmpPpYUg9XuzAh8/rfkmdcpHs7E1eb38VPgv2RH4Pr8xXk+HsZGPVqWv14SOIlYozkVnfObyLebTjOkVyXu0VOtW1PLEZ27lI6/bwqZV0w/Cvmhch1sv5q2mE0As9VyIuZAAKwvVab2w/NRiaJVxBsvQsHXNkkk5wcWS6wzWIoLcbj7JcLy3yc6q3yafW0H2H6SeYLToRQ5ahqeOKiUCA3eRilwAtMYrD12qMvcJyWcpY3sON9PLUoL/bBoJfy78GXaGPs+gXpNx4GA6iRFjzdxmUPMl14qNiWB8sQpysPZzHKn9DIspzA3jmUE3Fk+Q35weSq5Vax50zSvYcgciWL3BHGewNKvwsMe4hd3RN7PHuBmA3dE3TdnyvN7MVyN388PI2/nDqv38XdVP5nyuovhiM1gOLLqOarOJlYurZ98pC5tWLcGi61isQvi95RWEdFjSA6wumvUlGDPc5mhMPB29mTebTicr6NWYTQsqLSwQjvL8+YnCW1+oepR1OPhG+I/5TPgvJrajFjsr0Jj4VfQN3GhqZx2T1xAPzGEQt9B8wUjyc/U61clpYzs67WeuFHz/T27k2k0r+frvX8OP776Ze968jfdct3HK8cJUcdy4MjlA2TLszrjmW4jZSICVhaq0XlgaE14WZRzp9wejvHpTHU0l6J+Q6wzWX1b9kh2mDlqNi6c89ypT9mmCc3nt+QhFDFrTLoCLCfAe80EAvBRnDRZAn24AYPM0lfjcgTCRPFQhOjfs5mwOa92uTmku/Ej0LbNu72Ypzxo349WLk+lzucp2bVi+RaJGzgFW4nd3k7KyXI2zVrnZYWrnbvPTM5YqngurN4jNF+TssDvZwuG7z7Vzeo6fERZPAE8ggsUTyHINluaz5sc4Vvvn1CtXso3B34Q/wTuC3+TB6Lun2U/xjciHeSZ6E2+Mp8uIymD1BGnAiYU6VizKT3AFsLFuUTLlOOouXUpwJoky3RBbf/oq1ZvVWpwXjetYpMLcaGoDQKNpHSn+uuJC+c0rQ8lMimX4+SPz8zwSfQs/jL6THr0h4z57jNcA8ImqpyY9Pugov5YLgXv5qgAAIABJREFUifTH5fjZroamVA+srTLx2Kdfzw2bJ4peXLZuOV9++1V87T1Xs6TGPOWYR40r2W4aph4nWsf6mwqRKwmwslBlmvpt8rAk40i/LxTh1ZtWMuwKYClyjnq2o0tfrXqIh6u/mUwP/JfIXcnnnDqWLnC16s7ptXtsxfvgPT/iTlZoS/h01W+4Pr6ebKYRy3wLUMuorpu21LnW8//eaK35wi9O80RT5lmyTG4ytQJwa/Df+Urk41nv52HJpNmvXJSqwe/JXsccZrCmLvr+XNVjfK36J/ypeU++Ti1J69ifREGYzjHvnAclGnudeAJhPvVwY1Yjq0/W/F++UL2bBuVkmQrgSDSdZhln9dZZ928xtrLVNMqZ2j/NaXZTlM6IOxArRKHrWLusNm/HvahucbI627KwtWRtOjI52Tsx2/I20zFqVTjZ/28mx4wrCWszbzA1AxCOatpGvWVbMS8XWmv+6+WJddZvNjVRqyI8Fn3jjPt16ov4WeQ2Pln11KSy7VZviPFQeRUASSzHuMbUjUlpTuvJAdZHXrdlUnCVavXSGh7Z+TqWL5rchPtgvOrubeZTAJzoyV81YHHhkAArC+kzWABevThjimDLkJtXbVgBQFORC10MZDm69LGqZ3ijuZkNysbT0Ztp1tv489Bn+VToL7k++AM6jQ281Xwyp9fe9VJn0SovPXx4aqW42jn08MqXXr2Ozabpe5/9z9Fe/KG5r2EJhA3ODbuzLm4B8EbzGZqNrQzoeqJMHaGbjlcv5nLTYM4BNsQKnhgluCnZd26UEVdus2eZAoXXxIPSRapwM3Hnh2N9VXpt/pzTasNRA601p/oceAIRQlnMjC5lnGtMPZMes7Eip9dNpMEuV+MZ1xqK8jPqDrBOORjVq1i/Mn8B1oaVi5MzWA04c25qXygWT2DSQNZ7zQfpM+o5Em9LMRMfizmtt/MGU0vysWDEoG8BNMjuHPPSNjqROvm75kZsejmN+vJZ9/159DYAbjC1T3p80Fle35ej3bHg53oVK86UPoP1oVu2zLj/tZtW8g9/cM2kx1r0FrqNdbzbFGvjcThDDzEhZiMBVhaqTBkCLBZnLNPebfXROebFpKCpyF3Ac82Pvtw0yIBeC8BvjdfydDwt4NHom7nFdD5jL4zp9Nj8fOzHhe+ZY/eFePzU4JTHZyvkUEh9et2MzXofPzWIzTv32Z1EA8VsNeBgh2rj5fgoXC48LKZBOflt7f/l3aZDOZUx1zr3xrf5cHbYzan+7HrXvFp1shbXlDRIS0p/u5UU7qbx/IiHXlusJ81ss279KTd4hqF5pd+JezxC26gn64qEifV3nw59LvnYs9EbczrnVr0p+e/6ObRyyFSQRhSW22VnuRpnWK/m4tX5S5neWLco2QuyXjnoKpOiBy2DqSl9mh2mdl42rp2yFmc6B42ruVZ1TRp4WQhpgs1p35fXm1o4ZFydVZbHeR1rvHt9WlXZv3msGV+O16RCOtYdC35ebeqkx1iHi4mm2jduWZVVi4J3vXojWycVglE8Y7yGW0znWUyAc8PueQ2SiguTBFhZSC9yAcTXqmQeyWkZcrNlzVLaR4u3UNYfimCbQ4rWgK6f8tgL8bSKV6uuKc/NpBgVhvY0D09pmFhLiA3KRkBXc2vw/oKfQ7pzxmbWK8e0AanTH57TzyYh+w92zUfMz/C16ocwMPGz+AhkLjwpBUL+o+Z7/KH5hZz2L+ZavIQBx3hWOfJb1Ai/qf0KP6z5Z240tWHTy4loE/uj12HTE41YE02IC2HYFeALvzgNwIh76kxZ6izw7pMD2LyxbQ512jjZ66Df4efssJtsJwoTPdo69Ua+E76Tr4c/zFiODTh79Hruj7wPgA0q91SZo3lsti1mp7XG5Il9Fo3oNWxbu2yWPbK3ceVi3CwhoKtpUM6c+y4WSlvKtXaLGmWF8k9JFZvJoeg1mJXmFtO55GOtI+URPM5Harn5bWqY9crBYePqrPYNU0WL3sLOqt9yV0oz5mM9do6VScqcwxdiNP45ep2pkyY9ec3dR1438+xVgtmk+Nt3Tm5GfcS4kmoV5XpTJ4aGEz0LrwH1hazX5sOZYxXeXEmAlYVMKYJWVsZvNqbe6ZwddrO9ftmUsrGFEoxE+cNdU3tWZCNTgNWj12NoxXZT9mt+IPZhl68y1NPJVDL1ZO2neJf5KK36YgbiRSeK6anoLQC823R42m0SN8pz4QtmN4t0s2rl69UP8Q7zMZ41bqJPr8v5tTxpBUJqcky9PFPkWVvD0Aw5xwnO0iaghjD3Ve8CYtXFNikrSwhyRfAh7gl/PllV0KWXcIka4fNVj7KxQP2fEgVwRtNuTp3+0KTqZQOOcV5oHUNrzc+O9dI95qNpwJW8ocjGdtMwhlb06nV8N/o+fhR9+xzOWHF/5P0EdTXr5xBgnR5w4spjNU0xM4c/zBoj9t4d0au4bF3+Aqy6JdUsqjYzFi/VXi7V1VLT4K6LDwyeMS7Jev9T+lLGdU1yHVaVSdE6WvkzWC0phZH+wPwyhla8lENmw7fCHwLgTvNLkx4vl9LlXdZYtsFaXGxU9klFTVYurubt12Qu4pHJ717VMGktVqNxOYZW3KRiqeOHpNDFghE1NJ9/5JVZ7xvmSwKsLGQqcnHa2MY65WQjU3/pzo942LZ2CT1Wf14qyM2msdeZddXC9H4/Z42pIzxBaujX9bzbdJj1Gf5/04kYGk+BUwf6M6wzW6ZiN6qOlFmIYhpmDU3GJbw+JYc/nc0bom+OxS58Wc5gLVUTN+znjel7v8wkwOT1GiZye/8Wuz2B1RucUvBkKs0D1d/lFtN5DkUnRimfM3YQxUyQGj4f+jO+Fv4Ij0dvZbtpmM9VPc57zS+zQ7Xl1LIgF312P0dTcvvPDrsnpdNZPAGaB10MOMY50Galc8yb0/f3BtXOa9R5enUDQWpm32FGimG9ek4zWJtXL8mpxYCYnxFXIBkID7OaTavylyKolIqtw4o3G3aUqLBNug7LxMDEtaYuArqatpTU1tmEqOa4cUXyMzxiaM4NV36p9vZ46fpqInzEvJdnjZtyGoQ8rq/ku5E/4CbVysqUz8FyKfqQSFG9xhRbM9yiJ4Lqt129npqq7G9xlVJcsW7iHsLNUtr1Rdxg6gDgaFd5BJVi/vY0D9NYhF53EmBlIdMarEbjMoBkaddUoYhBv2OcUDT2d6Ed7Mj+Fz91fUmjcSlDrM24nYFiu2mYf695IKdzKfQFd6Z1Zl4WzemYMzUdzFarcTGXzjDjN+YN8sALHXM69mz57mai3GXeT4OaSGFozeHmItWStF5QdRmq7c3kWLetqE2nrTOsbVtCgN01X+P1phbuMJ/k+5F388nwX/HjyO/xxuC/8YXwp5PbHtNX8d/Rt/Fk9LW8El8kvVL5eKz2azxQ/d2CnPuIO8AD+2PrGzosXpoHXQw5x/GHImgdW6PVMuTiUKcVTzDCK/3ZD6TUEuLx2q/yOvNZDhuvmn2HbM6X1WxVI6gcg+6P33pJVusgRH5YvUHWx/sXWfQq1q+Y2+fidNavWIRVr2S1cpescmgqrfWkHlivNnVxVm8hQtUMe011yLiaK0wDrCY269NnL84AaaF4AmHG4q0zblDt1Ckf/5+9945v477v/5+fwyI4AHBPSZRE7S1L8pbteCV2XDs7TdMkznDcpk2Tpknc9pukaUbdzCbNdOu4aRrbiTPtpPGI95RkTWsviuImuCfmfX5/3CBIYhxAAKT64/Px8MMicHcAwcPd571er19Hr0j7OE9Gt2ITkquVA+ZjRzqG8yZqlYxmvYK1TpwDNMVTgzdusl69MlhZMzVJe0Q2slbRRLVe6xjO671tgdzx7Al/Xl5nIcCyQLwWweNyMaOyIKE/zF7d7+ZMT+7bBK0O+F+iHGWncgiAu8Pv5B2hzybc9pe6+Wi68yizmTVKxWgwMsP3J1aEIZ4vmRVu3pj+hXg6p2U9VWIQTwKBhP3nB3nkUEdGF+jxFLK477E9zlcd9/BXtt+YjxnKb+ni0Ye8W1Qty1lKelncs73jfOXR4xm9diYkW+AtEx1sU07ybtsfATiqLmYMN5+PvJdWWU2Imf5Ar8rV3Bb6AsPSbWazp6vwZRPDV+bZk37+/anTdAwG+NQvDvGrfe10DQU40jHMD5/VWp4iquSExbnOBjF5A9ltQUnNCs9HN7BJOcvttseycrwFckP/WIga0U+/LCaquHDH8fmZDbXeAvplCWViZF4EWB1DAcb0a6SCynrRPENJzuDqVZV8+0+34LAJlldODfqNma11+vc9qsp5aaxrlViFx8ttR4hKkVGy5ZBchl96uc62z3wsokoO57kdPB5GYL1eaaZZrTZb3CuKXVy2PH7yOBlraj1TTLmPqEuoEQOUM0QkKjnWeeG3jf7/ndFgJG/tngsBlgXiiVxEsPP76CXcZNs1I+sP0K/P3ORa+EFVpSU5eDcBHnR+kW86vw/AUbmEcJIM33eit/GL6M605c9zWcGKJ6AQW5Hzisw+61s2znRzT5dTsh6AJjFT4RDghdN+xkPRjC7QqVQEK4T291+saIvqr4TfEXe2zgoPq5cC8J7wXZxRa/Fl8Jnma/YQoG8s8TxSla54ZyRBevFaPu4wRWZgpRnzSq5V9s5osZ0t7YMTSClpH5hgJBChY3CCV8728/NXWxkORBgPRc05A8CyN0+Dnhg5o9byhJqeamAivhu9lVNqPVcsmA7Pa/rGQlSIYfzSR5ErvSqOFWq8BQxQQikj9Cf5/uWL2CTmMtFBkQjGnb/61js3c9/7tvMnm+o4+s+v5/4PXYLbMRl8HtHb5dfr1RCYrJBciJztnfxctokTHJGNDJN+JVmi8FR0C1cph6Zc//adn1vRBykl+1u1a/wGpXlKe+Ab1tdgi9N5lIp3X7yYn37wYoxdDZ/ADXoL4v45/p0XmB39YyEu/tIfac+Tsu1CgGWBeC2CAI+ol1IsAmyd5hMBEFGhvMiZ0wqWlJJXWwYszT290TZVBGNQphp8FpxVa6gUQ7iwHjTlMqMZz3+jVExm9H8cuTHtY5YVOVlX56GsSJtRqfe5WV2T/izXGakFacuUzrjPB8Ja5SqTC/R4ir+vZPL8bFar+V70ViD9mwtoBouNgftpkTX6Iir98zdfFy9Ifr4ZAZYhyd4rrQdYsd8PJxHeZXuKe51f58225zN8p/EJhFX6xkLm7NUrzX30jgZNb5dMMSpYfxb6B8aYfQushuCgXK4vNi58E9b/q/SPBakUg/ild0o2PlvUegvokyU4RZTw+PypYsCkwMV0NblrVlVy6+Z6hNCuiw6bQrWngOvXTgoBDVPMebXSrGABU5IbFxqxKogrlTaOxZm3BvjotSto/peb+NwtiatbT6lb8IhxtutegaDNfs8lbQMT+EeC+BihQfROCapvXFeT0TGFEKyv93LtGu28OKAuJyAdXKVoyq+vtS9UsC5kHth93qx254OFAMsCdptCRfHMIfGzqtZatkjEN5mt87lzms1/rX2It/8wsXJdLNMrK4OkVpYyqiCx7UapGMjhMHtr/8yFu08PAP48dBe/VpO703tiFIKMoHlJeSFCCG7aoF2Qr19bzd1v2Zj2ezN8lCpIvuBId7CyZySQ8oJQyGQW2Y8vyZbpMSCLqRH9/MDxTVaJ85b3ax+YyLmapEGyimkVUz/r9AKsyUzvIsXPlx33AlDOCO44FevZ0DYwQYduOjy9BTZTGoSfkLTRk6YkeyoOqUupFENcqhw1Z1WWi3a+4/h2WomYBXJH/1iYSgbx46OyOHsmwwY1XrcpKOQIDuTtu56I2C6RDcpZRmUBZ+XUroR3bI8v+jO9PfyIbDRN1gXQ3HvhSrUbQhQ+RqgUQ2aXRSxXrqjg49etQAjBzpWVXNFUETfB+Ly6gaC08zplv/nYvvNz+7c3KmhGp8FhvdrkKbBz8bKyWR37T3doLfYTFPC8uoHrbXsBycHWuQ0qF5gdz53Mz+yVwUKAZQG7Ivjwzpk93V2UEZY2FiUIQMqKnJzJodP9Iwety6iXi6mzG1ZayIxtEv1+8ZiNoW4qWuKo8JXqLWwDKStymD3ZXreDh//qCjwFdv50h3bjfdMWTRTiqlWVbGrwpj2UP0EB49JFmUg+I/PSmV7LbV4AvzvYablFEMCfRhCRikFZzHKlk9fb9nC34z8t7zcWiuZNvjnZzF+s6EdUCgYsJBUMhhK00nza8SDPuT5u/Q1a4KnjPVk3420QfjpkhSVD0XQwPHQecH6J7zs1z7lfOD/PG22vmJ5bC8wt/aMBs0WwxpddgQvQZ7DQFuE+RnKuHJuK2C6RTcpZjsjGKee922HjqpXx73fXralm6+LJpNRhdSlLlW5KGEcCp7ovzAArEI6agjhGcvV0nADrLVsbzKresooivvSm9XzzHZsR0xogxingZXUd1yqTc1g9I8G4Sc98cVSXoF+vB8SH9QrWtWuq4451pMPlTRUU6rOLT6tbaBC9NIouzvhHmchjBWSB7DEeisxoa821efRCgGUBl13hlk0z53RUFDpkecIKj8uuMDQRztliM9YzJxVGthkgLG2WFl6nZAMhaeMq5aDl7LR/Fn5PqTjfn7hFcJDUbX0bF3kpdtnZutjH2joPBz57A2/fpmWqtizysbK6mMuXVyCEYOviycx/rDdGMvqkh3KRvILVOxpKS+J2z7n+KS0w8YitmsWqKM2WgZjPNN6cYTLaBiby4n2UqkWwWa0mIhX68SDTuNwZ84m71NUA3B76pGnCXJnib5wu33/mdFI1xPSRbFFOZyx0koxTsoEno1sAuFg5jouQmeRwM/fzOAvA+OgQhSJIr/SwKAsKqdOp9RaYFawyMcLg2Nx6YRlJTDsR1oqWGQIXN2+sTSj0YVMEn7hhlfnzEam10a0RLfqxL8wA60DrICFdAXGToimVnlInAyyXXeGNG2u5etVk4CmEYEl5EWtqPdy8Yabw05PqFpYpXSwTk4ndV87OnTfUMX39s145R6tayZCeQItt+8wUl93G5U1aQta4B2xXTiCBY10LbYIXIo8d6Zph6fKeH+3OqTLkQoBlgcoSF+VxWgQBWmUly0UH8WYSjPJ5WxzvpmxgSLBaoVwMc0A34bsnerOlfUYo5BV1LbfbH+MexzeoJnVg0DmU3fapWFrjBVi6yp2VCtbS8iLqfW7W12tVHiVmtk5RBF996ybTN8OQbhfCej93HyVUkPria1VWfzwU4Yx/dIpX0nRuVl7hMttR8+dXsiTJDVONOsvEMOnM3Xzmt4f5258fSL3hLElVwWqVVZyS9Wm1B8KkIuVPItezPfBdnla3MEz2/IRiSe3jZZ1G0cnlymEaRC/PqJuydtxY7gx/nK+H3wrAJ+wPmY/H+rAtMIeMaS3rfuljaUX2TIYNyoqcjCoe7d+M5DSploqhiTC9+uuvFG24RHiGwMUHrkhuOHzpsnIWl2nf7SP6vkbbWe9oaF7IkafLbn2G00GE99sf5VV1Je0xliz/7+Y1fOddW/EVxl/XvOfSxhmPvaRXr2Nnzl+ewwDrRNdkBes1XeDCYRNcuSJ99cB4GPf9M7KOPlnCxYqmjntkHqgnLpAeUkoe3N064/F0vdLSZSHAskBVSQEOm4KvcObA8HlZxTqlhU/ZfzbjuYAeGedK6jWdrHe5GOaMrGN74Ht8LfJ2y/v9MPpGAK6yHWJXwV/RmKINKNutTgZSyrgVrAbRy5AsZMyCB1ZjRRENpW7W1cVfbG9aNNkqYgRY5UUuyxfsPt0bJhVWlSW/8ugJzvWOMxxIXMb+uuP7U36ePtw9G55St5j/rhTDfMvxXVZbnMXaf36QPef6c9qjPxIIJ7zZlTDOWtHCcbmYr0TeyTcjb0nr2B7d/6sPD359jskeYwlwg7KHSuZfP/69jq/xU+e/ANrcRC4IY+dRdQcAd9h/bz5enKFNwgLZxTaudVT48dFUlX3/MSEELq9m41AmhtNK9GWbs/6p/lcw9RrYWF7ImlpP0mMoiuAGverhx4dfek3vI4BzfRee0MWuZi3wuVQ5Qr3o44eRN2IIH1UUu3j79uTV7e2NpTNmsc5LrRtgseg2H5srJcGBsRDdw0E8jNGodHNY79zY3lhGSUF2hF1uWFeN06YAgj3qarYLPcDqWKhgXWg8dqRrhnDUzcor/JV4KMEe2WEhwLJAlUcbFDaU5mK5Rw9AVoqZ0fGI3hqY7QBrLBghqsq0JHLLGKFfevDjS6tV6kV1A1cGv2n+fJXuo5WIXM1g+UeDTMTJJC4XHfpAc2rVvIZSNztXVnJ5U7mFbQtx2hSqSlxmxSsV/bKEcgsBltW+/qdP9JhtHokY1RXi3h/6O64I/lva5prJGMPNZ8Lv44vhPwPgVttLfMr+oOX9hwORnKpK/nRXYkWga5QDOEWUR6PbeVrdwuPq9rSO/T+R6wA4rk4uRJwxEsX3OL/JfzvvzuBd545KBlmuq1iGpY12mZ1MbjzOyyrz3y9Etcx2sVgIsOaaSFTFHdQW173SS0NpbqquXm8Zg7KIxaJnTitYsXO5a0ULw7KQFjnZInb1qqp4u83gmtWT2x1TF5stggDnLjAlwUhUZb8upnSdso9x6eI5dVK46Y0ba3HZk3ujCSG486qprZZh7LTLChpjAqyWvvGUM8K5wLA7MRQfDYn2y5anvrdbxVPgMNcKe9RVLFF6qGLA9Dhd4MLh4Wl6BbcoL/Fd57dxtz0PkdxdvxYCLAtUlWjVkYqimYpM52QtL0TX4RMzL8LdwwGKnLa4rW2z4cXTvfSNBbGqleAmQKEI0i+TZ/IS0SqruTn4JbpkaUoPnFE9+Ms2iT7D5UqHKZGeDJddodhl5z2XLrGU4WoodfO+yxup8rioLLGmxNWHl3JGSNVK19w7Rjiqpmw9STW7V8w4FWKYu8Pv5Cl1K23S2mIiHX4SvYH/jN5MVGoBbJdMT5UuVz4yp3tG+dpjJxI+v0k5w7h0sV82ZXT836pX0Bi4nwEmvzOOaR5YjaILQe76t9Nlq3LS/Hc3pWklUtIliJNhqS3eDa+YoiyrKy6QPv3jISp1ewK/9FIeJymYDWp8bk7LelYo7fiH5+7vHtt+v1wY94LJZNvFS62pyW1vLKNY9ww7KhtpEu3m9/1cHHGl+cyJ7hHTnH6ncogX1XUEmTwPXr/eWsv7rZvruGbVVHGQFlnNkpgACyZb9fKJMX+1TvcsMypYVpOhVnmdHnjv1uewdijHOdU9ynBgbucOZ8uRjiEe3H2e5076+eLvjl6QbbDpEGsp4CDCXY4HOKQuZeBtvwZ79pVWDRYCLAtUJ6lggSZ5bswCxdI9EqS+1J3VClY4qvLcKT+9I+m0B2rvrZfMAizQMkS/i17C1crBlG2CuZBqj9ceWMw4NWLAlMuPR0WxkxKXnYpiF0IIUzEpFbXeAv7iquU0lhdR4rLjstCn2ys9uESYNSna6CKq5GT3CH88NnmjGgmE6dSlusdDEVRVMpwgwCpniBuUPaZq21mZ+PfPFleHvgGAW6T3t81VgLW3pZ9IkkC+VIzQK9MTtkiFc5rptluEqGH+ZDO3xQRYfRkmUzLhmKopcRotgtco+02p6wXyS99oiEoxREQqjNo82GepppaIqhIXp9R6mkT7nFawYj334iXbrC64nXaFnSu1iu9RdTEuEdFnq+HwBTZzY1SvvIzSqHSzT11pPlde5GR7o7WgUwjB69ZMFYw4J2vYpJylMua6d3QOWuaMCtYGpZkOWUafbiKf7QDLqIAelUsYlQVs1+ew9p6bP9f9dGntH+fP793FXb96jff/1x7+84Vm3vuj3QQj/zeDrM6hCbpikkCvV3ZTL/r4RuRtYMu+T2AsCwGWBao8WgWrLIHQxaAsxidmtn2pEkIRNasiF11DAY52DKd1UzN8urrTrD5M54eRW4ii8F7b40m36xnO/g03nkT7StEGwOkkFayG0kJqfQVUWKxCGdhtCqVFTq5o0lQFjTbRZDyq7qBH+viC476U2z58sINf7m0zfz7QOkhL3zhSSl463cdIMJKwQvlNx/e4x/lNs13vlGyw9kvNglZZzSF1KV7SC5jiBcbZ4FhncgXNMkZMKels8dfhjzIqp876LU1gLD0XXBQTYGVbnj0+2gl6RtYRlA6KdZGL+5xf5feuf8zD6y8wnd7RIBUM0Y+HQlduqlegCT+dlvVUiGEmBrtT75AjjORlERMzkm2eArs5S2uFa2IW0zCpJHihtQgeatMCLGMm7WDMTNp1a6qxKdZN6Lc3Tl0zPKFeBMDXHD80H/vf17oyfq+ZcjxG4MKQZ6/1FlCRZd+3hlI35UVOotjYp65gh260vDsNJeD5RDAc5bbvvki/rvxpJCl3NffHFYH4v8DxmLXCYtHNp+w/o0Wt4lk1fb/TdFkIsCxgtA5UJKhgDVCCj9G47ULn+sZp7R/P2rB/++AExzpHuPcFaxliOxFzbmq6fG26+PGxT10xZSEXj5Pd2c9oxVuob9HVjParidvAllcWU+t1U5kgOE7FJXpPd2Wxa4Y3yHTaZCW/i17CGtGSsnXsv19q4bCe+fOPBNnT3E/bwATPneplf+tA0pt6hT7ndYXtCP8RuYnmPFSwAIZlIR6RXsB0vn+ckSy3U7x0ptfMYCaiTAybUtLZ4jF1O5cGvwPAtyJvBpg33k8uQqwXzRxTsy/NngijNfC8rGIEN++1PcYWMakwZgyFL5A/tArWIH7ppTSBQlw2qCxxmbNOypB1E/Js064HWMb38EzMtXB9vddyxwLAJcu0a32zrCUoHaxRtN+raw5bIDPhpD7ju0FoAdbhGOuOd+xI7/qwsqqEZTGekM+rG/mvyA1crBwzWyhfPttHSx6FQCJRlZPdoxQxwVLRZQZYW2L8zLKFEIINDVpVbLe6mlWiFQ+j7L8A57AGxkJs/cITCZV3v/b4Cfa2XJiBYzJiz83P2P+jfM3CAAAgAElEQVQHrxjlY+GP5LSF3mAhwEqD8gTZkUFZhE1IU9p5Otk0Xu0YnGAiHLXsSH2X/QHutD9CUNpNn4jZsFeuZK1owZ1k3uKl09mXbo03g7VNOcl5tdJUeYvFoWfp1tSWUOfLPLNlBNeVJS52WGitOC3rKRJBs7qWiIlwFP9IkEA4yjeeOMl3nj5Na/84337yFIfahjjRnbhC0ykn38cD0ddZ/E1mzzBFeNKsYLX0jfOHLGc4//XRExxoTa7gVyZG6J9FS2wiRiikMXA//xZ5MwHpYLFeHV4kunm37Ymsv55VVovzOEWU5/WsXCQPl/Y7Qx/j9tAnGaSECDbcIsSvXZ8zn3/I9c+UcGHNr1zo9I4GqRRD+KXP8uxoJlSVFNCvJzCio3OzKFNVSZveImgk/Q7HSLRftyY9P6RFZYXU+9xEsXFcLmKtPt8zMB7OqRpqNpFSmr6Jq5VWWtVKhvX7/rYlpVP8Ha2gKIJvvXPLlMdeVtdRIMJmAAdwuD1/bYLn+sYIRVTWihYUIU2J9nR/N6tsbNACtz3qahQh2aac5GDrIJEUAlTzjZ+8ci6hKBTASCDCB3/8Kj0XWEIhFcYM5TLRwfW2vfxn5Gb2yxV5ee2FACsNar3xpcAH9RuNN06boEG25rDSzaYZzuuPqJdl5fX3q03YhXZxS8SrLdnP7nQMzvy9NyjNCb8oXrcDmyJ4+7YG6rzuWbcOVJa4uHFdjS7bmhjDzPEx110sEqlbZ9oHJ3jiaDeqhJPdI+w7P8ALp3s5mcREOhyjFJiP+SuDIVmEN46YSzJa+8d5/GhX1qpYUkrO9owSTGEOWMqIuQDMBRKFTllGjdAWlz93foEvOu7jY/ZfUEP+vWFq9ffx++jF/Dp6OXeFP5Tz1xykhKd1Kf8aEf87b8W2YIHs0TcWokIM0YuXel/2TYYNqjwuBvWFuy04MCcByNneMdMk9FLlKOfVStqZFGW4KY5ZbiouWqIt0o+pi1mlaC1TUVXO6ZxZOnQOBUxVvxWijZMx7eOXNWWmKrq+3sOisslzaY+qGTPvUCYr1Kd6krdsZxOjPXy9onXxGBW6LTkKsAyhiwNyOSFpY4dygomwmjQJOh+578VzKbcZGA/z0Qf350SobK4wup/+xPYSqhQ8GL0mb6+9EGClQV2CG9YgWgm9lMQBVraUBIcn0pNEVZC8FF3L/wvfnpXXb5PaDSzRggq0G9/u5uxlNaOqpHtaYGknQi19nJPxFZHsNoXSQicet5OGMvess7m3ba7nti31eNzJZdBPyXrz38tFR5ItNd77o92mUeZzJ/1ICVKS9OJtzEE9HL0UK/L02WKYQjxpViT6xkLsOtsfd4YuXVRV0j44wUgKWWAXIYpEMOstgtPpkuVmgGUEOB+z/4ofOL+ZbLecUKV/H9tkJR8Pf4QzMefhXFIWR/xngdzRNxKgEq1FcHF5biTaQRO5MMzdvXI47ftSNphs05LsUI5PMVlfXllETYKEaDJW12rXjNOynkoxjFe/p7f2XxgWBEb1ykaUZaJzynyuETymixCC69dM3mf78XBSrZ8SYBmvmw+M11qvNNMtffgpxWVXWF+fG2GfTQ1ellYUEcTJIbncFLowxEQuBH69r42BcWtJzlfO9nPfi/93RIo0HzvJLcrL7Jar6YnT8ZQrFgKsNEgUYBkLuXhCFwbZ6uMeDVqvBNiJUC962StXEiA77SK9UutHrhDJlZX+9ucHsuaB1DcanKEYV80ANiFplwl8LwSUFWkKMW/a0sB7L2uc1XvY1lhGWZETjzu56swgJXwr8iYAqkTqC3BsZTO2fH8iSQXLI8Z4IrqVj4b/OuXxs8mwLMItQrgJcKftYQqwltUdCUayEmD1j4f4wu+Optzue45vadtnWeRiOp2UUUs/02X5G0RvTl83HtVigLC05fx3TsVHQx+hW07OQpSKuQ2whBCfEkK8VQhxhxDiDgvb+6btszUf7zNbjA314hRR/NLHiqrcnQvFLjsT9hJUKfCJ0Tmp8BhtwjX0UypGpxgMb1tiTSlvOquqjQBLE05qEu0AWRWqyiWGamuj6MIlIpxUJxMtmxdlPqM0Xdp9t7qabcoJFH3W2Kq3YzYw1HbXi3NmS+imRb6U3l6ZIoQwBVBeVVeyXjTjJHxBBVhfezz53Px0vvrYiZwpAOeT0z2jNPeOcYlyjOVKJw9Frsrr6y8EWGlQWuiIK9dtLGoqSRx0dA1lJ8AaCVjJFEo8jHGTshu7UKcYL86WAYqJSMX0WklE28AEz57sycprdsT57OqE1obVkcBMVUqZkyFvb4oAC+C7kdsALQjMlJ6RxAsWrxhjmNxlpxMxpFdqb7c9yl2OB/kL+yOW981GhrN7OMBjR5K3XboIca1tPwCjMnctUgBdsoxFip+XXVMD3Xz7Qa0W53m77Rn8ePMyuBuPx6MXEZAOHlYv55rgNzijq7mVzWGAJYT4V+CslPIXUsp7gOVCiLcm2d4HPCml/IqU8hf6w3+fj/eaLcLD2jXXL71msJALhBD4Ct0MUUQpo/iTXK9yhZGEWqVo864n1clqzdYlmQUTK/XPzJB7b1K0LoRTeazQzIZz+kD/Bt0mwRCiWVTmtnTvSsRFS0qpiBGK2q2uxiMmTEuS0/5RJpLM92STzqEABQRpEu0c1n+/bRlW56xiGA4fUJtwiQhrRMsFI3RxpH1oip2BFYIRlZ+/emGrCkaiKl997Dh2GeEu+/30y2J+p16S1/ewEGClgRAibl97h6wgKgVfd/6AXzo/F2fP+DLjmTBqIcC63fYohwo+xLedmuJZMp+odJEo9OHhTtsjXKYcTrqtIQU6WzrjXBzq9CpBR4IKVjgqE/qWzQaPBZPiEA76ZAnVSdooZ/UeGGdYFqXeMA6GaEcmGMayd9h/D2C5ggWwNws3o2RBp0GsCaYxK5Ar/Ho112gPNHCLEKtSeKFli1KGedR1F5VimKEMz4lscEf4E6wO/hcA4xTwJ6Ev6u9vTitYd8QESgBPAB9Osv2/Aqb+tB6U5X6YLYuIUe3878VLXWn6LXLpUOXR2gRLxYjZ5pxPjOr/SqEtBGPnjdbVZeaHVO9zU+yy0y4rCUiH2eZ9PIVq6XzBUJ/drJxmTLrMz2RV9eza52yKMD2hQBN8ANihHAO0Nv7X8uQX1jkUYK1owSYkR/T5q22NuQ2wdiwtw6YIU7F4i3Kas71jDFlsu5tLvvP06Yz2e/xI/uX3s8nPXm3lsSPdXKPsZ7Nyls+F3zfFcDsfLARYaRKvTTCEg060hf5FyqkZz4PmnJ2NwUErFax32/5o/vuhyE72ZVkxpV+WYBcq9zu/nHS7gSy1CHbGqWDVmxWs+AFWMBzNSYDldTtwWjAd7pGlOQmwFFQ8YpxhMltM3/PnFyUUa0mF0YLj04UuAmlcrPa1DMx6DtFvwV+tUWg3hVuCX6SbzNqErJIsoHnMdRcC1ZQyzhW32l4y/71Cb2eaOybnAccoICjt3GTbjT2c/+x/gta+fuC6JLvdAfwx9gEp5QXTBxSKqLgCWuLJj49CZ+bJFCtUFmtCF745qGCFIirdI9p9YZXSRrf0MRjTHrusMrPro6II1tZ5UFFolrVmi2Cu/PyyjaGYtkU5zUF1uemHt6Z29tXMa2ICrE7KOa9WTpnDOtCa+4qOlJLOwQnWKecAeE3V7kmbGrIv0R5LSYGDzYt8dFNGhyxji6IFLQfa5vflQUppWXF6Omf8YxecyXYsz5/UroVbldOEpI3H1W15fw8LAVaaLEkwOBySyW9mrQMTWSkpD1tQYysQk4HNd6K3kW0hhNKYWbNP2h9k+gyKQSK/hXSJV96uEf0MyOKEs2XjOQywLl6aeuHelaMAq1gXmci0WlHlcXHliszUpM7JWj4Xfq/5syuN4GE0GOG27744K7f46UIn8TACrETiJ9nkt+rlfDD0CS4OfIfvR26Z8fyX7D/iVMF7SPT9yAZXKq/RprfJPq9uyNnrpI/AJSJsUU6z7di/zsUbKEMLqGIZBLMVcApCCGOAZ1nM/NWncvwes4p/NGjOxg4ruR/kLi92MiBLKJ2DGazOoQkM4cKVopUTMf5vDaXuWQWXG+q16tdpWWcGWFaq53NNJKrS2j+OixBrRQv75aQ/ZDY8oq5YUTHFpHi3XKMHWNof4mBb7hfjI8EIY6Eo68U5+mQJnZSxpLwwoYVONrlcV2E8oDaxWegB1jyfw9p3fiCpNPu7bE9yp+3hhL6dD12gbYJRVfLSGS3A2qKc4ohcOqN69eP376Ayx+fNQoCVJksr4i9si0Xqxd8TR2fveD+aQkGtmHF98F7jvKxKsnVmxCoIfsT+MOXEb5/IVgUr3oBxqUguwy0lOZnBqvZY88PqlqVJlRYzYYno4k22FwHSnsH63C2awlZ5kcuUnc0EY/gbMBW2rNI3FjJbZcNpeIj0j4X4w2udlhY5jaKLXulhJA8zalFs/FG9iG7K+NfIO2c8/y77U4A1NclMUFC5RDnKU9EtXBr4dz4S/puMj7WubrKFaDazGvHwjCW2dMgh8VaUxoUx3hfYVEiImdky5rhmoAdgrwohXvX7M8sQZ5vu4QCVYpCgtBN1ZtYilw4VxS4GKKFMDNNjobqcTYz2QAWVFaJ9SntgU9Xs/B7NAEutp0H04iLE8MT898JqH5wgokrWiXM4RJQDejvb5kW+KdWnTPG6HVwUI4W+S11NuRgxr2/HOnLfRhmrIKgJXAjW1+f+XAe4fLnWLbNfbWKJ0kMZwxyc5xWs7z19ZsZjApUv2u/lXMG7+LLjXu5yPMgvnf9EbRx7kQf2tJptpxcSJ7pGGA5EsBNhozjLPnVqF9frVldx1cpKFCW3KswLAVaaNJbHD7B+GLkZgHGZOCJ+4fTs1cVStQiuEO0oQjIhnRxQl+dk6P0L4XdP+dkj4rdPZEtFMF4Fy8tYwja569ZoN5NcVLC2LilNqCYZSzelVDCEjewN/j7qvIvPO34MYEokW6GsyMl7L23E63bgdTu4dk01mxf58BU6Uvp6TeeMOhlglSZRzUy4v36DPOO3vu/zp/z89QP72XMutfT/UtGdVVEX60xeqD8U+tspz8S20WQTD2MUiSBnZB2dlDOO9dbP6bOk16+t5upVmgXDey5dwrWzCMIN/hjVPLJc4TkZBh9kZiBl/BzvRDIeezXmsT8CcatYUsp7pJTbpJTbKisr422Sd3qGNZPhXrx4CrMbJMejvNiFX3qpYIie4fzKmBtJt0WiB7cIcUJOVrBW18xu3mhNrbb/GVmHIiTLRCeqhMF5Pm8z2R6ojSkYAdbNG2oRIjsLyZ0rJ7sfdutzWJfoc1jNfWOMpUgAz5Yv//4YLkKsFG2mwMXa2tzIs09ny+JS3A7bZOCqnOZQ29C8DbyllLx8dmbQ9Df2X/Fu+5Pmzz+I3EKTaOd/nF/GydRzPBRR+Y/nz04/xLxnb4t2OV8tzuMWIXN2DjTBl2//6ZZEu2aVhQArTRoTVLDujd7MDyM3m7Kl8TjRNTyrFikpZcoK1nJd9egNoX/httAXMn6tZNwbvYnGwE95IKIZthm+TNPpH89WBStOgCXG4rbJbWzw8uGdWjK6NAcB1pZFpZZmmLplGYqQVJK9DJc7pvWzK5E8fRx2NJahKIKNDV4UReCwKTx056VsqPdy8bL05pS6YtasmUhwn9WzYUfarWc7XznbT0SVHE8iXW/QqHTlpT0wGdOVLd+g7Obttqez+AqStyjPUa8LvWTSLrqxYTLrawywv0+3MrhqZSWXLLN+fiXig+FP8q3ImykZOw+hvM+w9DOziuWDhHNVZ+M8l7ClcD7ij/HAKi/KfctURbETv/ThFFHGh/JbxTN8qVYbAhcxCoKbGmZX0VhWWYTDJsygbY3QKrDx7kPzCaPSsEU5TataiV8//bMpALE2ptLdIqvplR42Ca1KImVuvaH6RoO82jLAStGGQ0RNifZcqmXG4rQr7FhaxmtyKRGpsEU5Te9oMGsWPNnmWOcw4zHtgQUE+Qvbw3zM/it+Ed3JpsA9vD34Ge6O/Cl/Ff4oy5VOvur4IS6mrtseOdhBIJwfhchs8WqLltTbqicbYitY/3jTmlmJfaXDQoCVJovLCkmUDBqTbgpEOGHVIqJOupCni5SS/rFQUqGMq5UDfM2hiWC15qA1cCqCh6Kap4BHxA+wBvT3m+mg5G8PtNMzEoibOfQyZsqGx1JZ7DIN9cpy0CLodtqo9hawscHL4rLEbWiGF9ArBX/NdpH9CkaXtH7TNAwYYxfVDpvC8sriDCoVgrcGP8shdWnCwDoZfzjcSVSVHOkYtpT5U1XJ86esLd4KCFIr+mlW5zbAivVmO6PWstP2Gl9x/Ae+LCnqbRDNfN35A77r+DYwaXSeDiurS3DYtAtZVYmLdXUedq6opNZbwOZFvoxMWuNxVF2MFAoM5Ne4Ukq5D2ZkN8qYJmIRs/0gMBgziwXJA7J5h39Em8HqlV6qZmmsboVqT4GppKmOzL79PR0M0QlDQTDWUHfjLPyeYPLaeEbWMSZdbFS0DP58H/hvNhUEz3BALgfAZVcyVlSMx1RvNcFRdQlrlckW4L/4n72zSiInY58evK1XtGvJa1ILsFZnQcDDKhcvKyOAi2NyMVuEtng/nEayMJ/85JWprdl3O/6DTzse5PHoRfxj+P0MUcxuuQaA59RNfDP8Fm61vcTH7b+Yst9wIGKpe2Q+sVcPsHYox+mSpXToInSrqku4YW3+1geWAqwMzBo/pf/3ULxB4XSPN59w2hUqEgzGjemCC4VJ5KszlTJ95qSf+148l3Sbv7T/1vx3lNyY7sViBDiJFtoD4yE++dBBHj6Y2QzKE0e7uelbL8R9zivGGIyTufe4HQzolbOy4txIctZ4Cvjkjau4bXNdwm265GSl5zLlSNbfQzqGslUebbG8cZrS0srqEq7JoBXsVbmao+qSjCpYh9uHefZkD+f7xxmx0E7yytk+S5ljgcq/Ob4HWBe4yHb79fbAd7ko8H0GKaZfFnNf5EZOy0mjz8oU5txWMZQJGxVtUZuuZP+yiiKqPQVUlWjnRZWnAIdNQVEE775kCXabQp0vOwHW0+oWfnb9K1C9LivHS5N7pvleXU+MDLsQYtm05/+FqSqD7wA+ndu3mD38o1qLoF/6WJxAjCmbrKgqpkdP9BSGevOa5TYCrFVKG+fVSrM9tqLYSV0WkgMrq0tQUTgsl7JJD7COdM7/AKuKARpEL/v1jP2mBp8l1Vur1PvcFDgmj3dENrJStJrXpJFghPNZsqSZjrFoXi3OMyzdtMlKfIWOuNY5ucIwsD6gNrFJOYuCmla7ez555sRkYrKAIDcqr/Kb6GXcEf7buHLl34q+hfsjr+MO2+/ZKqYaE2eqRDgX9IwEaBuYwMMY1yn7eDy6DaOF/46dy3I+dxVLym9eBmaNP9SNGr8ipXwb8I7YICvd481Har0FZvY3FuMiX5jEaPRc71hGctX37zrPg3uSe+sYPkU/iLwx7eNnchE2Xi/RDJYq4Vf72zMyWZZSMjAeiuuvIlATVrBKCuym/1YuKlgARS47VzRVUJkkS9wTU2EaJfs3gHRm64z3uXFa68zOlRUsLivE7Ug/GB+kBB+j2DOQIT/SPkzvaJCemNaK4UD8IfJf7G2zdMzN4gyvt+0BmBLUJMPKLF06+CmlDy8guCj4Az4feQ/dMedBVZZET2JVQgEGSW+o/+Jl5VSVuKj2aOdFjWfyPH7ndq0tqsbrZmsWlMdCOFBtua+mxENK+WkmVQE/BZyZ5ot1HTG+WFLKrwA+I0EI9OmPXRD0Do9TzhB+vCyrnJ3QgxXKi12MObXMcCVDeRW6aI2pYMXOX62r82Zl3siYwzqkLmOtaEFBnffD/qe6R9ikaO16B1StgpUN9cBYFEVMERE5qi7BKaKsE+fMx874c/M5HenQAtwm0cEZWQ8INjX4sjZfZoWNDV6cNoX9ahMlYoLlooOz8zDACoQjU+xtrlIO4RYhveso8ef1pcif0UE5X3P8AHfMOvbRI115M5KeLftatErnW2zPUSDC/CK6E9AS47dsSpwUzwVWVmmWzRr1XvXp7RQ/nLZ9uuaP844aTwFr45Tdx6QWYBUlURRs6RtnV3N65daoKnnlbB+9o8lnmupEP09Et3J35F1pHd/rdnD9mvSFAQyRiaWiM6mYQ7oBViSq0jUcYCCBUXEJEyhCxp098RRoFSyXXcHtzF0VTwiRNMDqY7JX3ZeBGMRMMh+kNaRIazxTM7sNpYUIIRLOFSZjj7oSl4hwnbIv7X2Pd43oAdbkgmxvy8CMG3MgHOVxi8qbr7ftBuDO0Mc4Lhdb2ieRYE020AJgQY+cXOBUZWker4SpCY10Z7AuWVZGlcdltgHWeicDTUPuuKrExc6VlRl7ps0X9ETfL/T/3zPtuXuklNfH2d78L7/vdnYEh3uxCUmv9LK6Jj9tU65SbcFSKQbzNosyGozQNxbCQYSlomuKgqDRDj1bjFmjFlmNS4SpYCijRGG+GA6E6RgKmIp+xmeyeZbtkvH4p1smq9HPqRsZly7eZZsUTWjOQSAqpeSorlK4XOngjK5mO9t5u3QpcNjY0OBlv+4tukU5xdkcBZSz4bEjU++bb7U9S4/0sUtdk3S/Mdx8MvxhGkU3Dzi/ZK7rWvsn+LcnTybddz4gpeQnr5zDQYS/sD/Cy9G1HNLbZd9z2ZKsVnOtkPTVMjBrLAM+Na2PHXQJ3AzNH+cdNd6CuNldo4LlTtIi2NI3xsHWQcZD1jP/TxzttmQwXC/8CY13k3HjumoaStPP5htl5g/a/8Df2X+ecLt4N95QJLEYyMB4mI7BAIMJRDKMma94KoIlBXYGx0M5kWifTrIAS0Vhn65cU5aF2ZtiMhuwdtoUcx4jUabv79+wmts21+F22LjEoujF0+oW2mQFb7c9k/Z7OtY1jH8kOCXDdqZnlBenqWx+848nU4q6GFyknGKXuppH1R2W30ciT7ts0s1kBeubzu9zg7Jn1secXjGOV8lNxsVLy6n2FFDj0b7z8YbgHTaF16+vydiwdYH8I/U5KL/0saQsP3+36vJyJqSTKjFIz0h+ApCWPu36v0j04BDRKcqm2Zo3MpTpOvVW7zrRlzVfx1xwqlu7xzSKLvzSw6huU7EhBwHItsYys4o1RDGPRC/lJtsujCRgLio63cNB+sZClDBOjRgw/+b5kmiPZXtjGc2yhkFZxGZxel62CMaOZSwW3bxO2c/Po1cRIbW4w8vqOj4TuZ3NyhkuimkV/OXediJp2KvMBSe7R3nxdB/blBNUiUHui94IaBXp91zamPf3kyqcS8usUUp5FrhI/7/B9UwOFqdr/jjvvEZAywrF6/sd0wOsoiQtguf7xznVM0LviLWLdSAc5c7/2Ztyu2LG8YrxGQpmVlhf700aLFjh9cruhM91DQdmtH+d70+c9ekfC9E9HDDFKqbj0/2XBuNIlXvcDkYCEUoKcq8SY8ywJOLNoX/mpFqf0azSdIwq2K+iV3Bt8KuW9vG6HVy1qjKlCePOlZV8/tb1XL2qko9dt9LSsVUUHotu53LlCG4C2IhyrbIXK5W2s/4xghGVvTHG26e6R9mn/yyl1ORhn7MuD1vNQNrJhUSedtlkXE49R/7Bfv+sj1kSE2yPygJLN00Dp02h2uOiqsTF1asqEQIuXx7/mrGquiQvn9ECs0dKiX1Cu0f2Si8ed35UsmpLC+mRPirFYN5aBA0vvcVCCyhjZy5XZalyV1niorLERad+TakVfZaTPXPByW7t/rBU6aJZ1gLa9T9X80nbY7wgD8llFIuA6b95rCv7og9Ge+AyvUJn+DFm6++dDjuWlgKCA2oTW5TTDIyH41rJzCWxBsgfsf2WMHZ+HLnB8v6/iV5OUNq5zjbZodI7GuQ5i4JTc8VJPdFwpfIaYWnjJVWrtn5457K8KQfGkirAStes0VBvAsygKbbPPa3jzUevEYArmirwFMz0GTE8sAqTtAgGIyr7zw/ijzNbFI9ui20XtUL7GDOpYK2oKjGFEDJlIInoQiiizgiWTvckD7DO9Y0xkWBo2qtXsOK1RpUU2BkOhPFk2Sw1HhXFrpRVkAFK2KacpI7MPdAuFsd4n+0xAH4XvUTvP0/N+noPN6ytxmZhqNPrdvCJG1amdRF6St2MS4R52PkZzhT8Ofc6v256oljhhVO9/PZAO994/ASHO4bMTOChtiHaBydIIpg5Dall0GV67TB1PjcOm2B7Y6k5c5Ftpqs9BnBSySD3OL7OIpG+8loBQVbpymmQfvWqrMiJEAIhBJctL+ezb1yb0M5ACMFbtjbwsetWxH1+gfnD0EQYn6otqobsZXmbS6n1FuDHRxWDdOepgnVOr2A16t+f87rvnV0RSZVd06Wpsti8n9aJPsJRiWr9opRXjPmwpaKLc7qK6tpaT87Og9hOB6Ndr0lpB+B450jWBU8OtWkBltECeUbW4bIrNJTmvgthOoZY1H61iVWijSIm2BXHb2quGBwPmdVWJ2Fusu3iN9HL8WNdeXgMNy+oG7jV9qIpYALwsz2tSfaae07pPptXKofYJ1eYldxsWhWkQ6oAK12zxuk8BFwbU9Ga7fHmBVWegrgVkskKVvLgKRhR8Y9MbpNMet1q37fhidOeQQVrRXXxFFlfTwbVn1QtbMZNETTp7bO9icvq/WMhTiTxPDJurPF+V09B/ipYbqeNv3/DmqTVvwFZQpUY5DFX5mJkP3J+hQ/a/wBgZlStsL7Oy/Vrrc/WNVWVxE0cJGKXuoYno1tYod9YIb1WxvP943zqF4f49lOnOdIxzJmeMVRV8psD7ZbbTEoY50XXR3GJcNoBltftoLTQyeZFPt64sTatfa2yV67ircHPckzV5sKWik6us+3lBttefuZM36fu3x3f4R32Z8yfw9L6eV7jcU0x37bbFG6/fGnSfbYsLuVj17gb/nkAACAASURBVK2kIkeKnAtkB/9IkEqhBVgB5+w9zKxS7XHpFaz8iVwYwcQS0c2oLKBXn3ddXFaII03j9GQsqyxikGImpJNaoS2gW5J0Xswlzb1jFDFBlRg0K3rr6nJnwHt50+S997SqJfyM4CeiSo52ZreKdahNO7eblA5C0sZ5WUVTVbGl5GG2qSh2Uest4IBsQhGSjcpZdp2dP8vX+3dNiqFdrByjREzwuLot7eP8d/QGqsUgt9kmlZyfPNYzRZxqvnG6Z4QyhtmgnOP56AZAmz3Pp9JkLKmuRumaNZroaoGfjq1ozeZ48414FZIJCxUsA/9o0OxnNYY349E9Yu2mVaffANINsO5+8wYqirWWoTpvASuqitmUxmDs7aFP0qJW0SB6SdYeFhsw9Y4F43pbgdYS2T8e4liSC/Qa0cKwLKSdqb+rwya0CtZEOK1AYTbcsLaabUsSZ0fqhVZSLxGZtxC0Sa16+1BkJ8fkEsv7bVnsw5fmLFo6gWkEOx8I/x23BL9oPpZuO2QwZhZvIhylazjA3pYBnj9lreK3RTlFvX7u+9PwBgMtGC8rctJYUWRegHMRmL8qV3NT6Mv8TegvcYkIb9DbaetEf1JxmHhcb5tsF340up2fRK9PsrVGkdNGWZGT27Y0UJ5hoLS6xpPQ/2+BuUcLsIYYly4c7vy1TZUXufBLL1ViwHK3xWw5p7cILhHdevVKOzGzPS+otccKOmS5eX892Do/lyktfeMsE50AnNFbBLcmuS/NlopiF2vrtPOsFw+DsogVYjLRdiCLhsNSStPeZrnooEXWEMGeN4PheKyr8/KabnS8VrTMK5+op473mP9+m+1ZRqSbF9X1aR/nWXUjB9TlfNL+c1MZO6JKHpzHVazjXSNcoRwGNAEWgLdva8ir0mQsSQOsdM0aDXTZ9SeM4MoQt8j0ePOReAsxQ47bilrY4bYhfvRiM0PjYV5JUl7utlzB8hOWNtO9PeX2PjeFThvv0GWZqz0F3Hf7Dq5eVTnNTDA5T6tb+K/ojRSKIOUkDopOdI1wQL859QwHE/azv3Sml/7RUFKp19VKK8fkYqbLjd64rgaP28FwnipYoMnWJlNqMiTDR2XmLZgTONmlruaTEetim3ZFcFlT+tXM4rQ/N8FrchmfDn8IIOk5YIWf7WnlRNcIjx3psrR9rIBId7oBlttOaaGTxvIiU7I9V5UsicJBXc1op+018/EKrHvr/I3tl1N+vjP8ce6N3pRyP5dDYVV1CZsX+TKeqVpb5+EN6+fWwHmBxPhHNZNhv/RSnmI2NJuUFjnpkaV4xTj9Q/kxXD3rH0Ogslk5zdGYhFO25wWX61L352UVS/SuiaOd2TELzyaqKmnuHTXnk87qLXvJEn/Z4MomY2xDcExdwjpl0kx83/nsWFKA5h1qKCg3iXazJfGS5fmr1E5nY4OXfjz4pYcVoo2zvWNxLWXmghP6HFIdvdysvMJPo9fF9b0SQqtyfuaNaymMq7gs+FL4z6gSg7zR9rL56B8OW7s355uekQBn/WNsV44zIt0clkuxK4L3pejSyCVW6ulpmTUKIa5DC5peFUL4dEXBd1g93oVCSZwKyRBF7FZX8QH7/1KUolXqZ6+2cvcfjvP40a4p7XPTsSp9Wyf66JJlqBb+pIVOG40VhSwuKzQj+yKXnVU1JXzkmiZWVqfnoWKYGn7ZcS+VCYLLfecH+MnLmrN411CAsQQB1t6WAU52jyRsm/QwxhrRwnF10Yzn3npRA6VuByN5msEyWJHk8/p/4ffzdHQTNlQylVovIkiv9JDMv2I62xvLMqriOWxKRr5YP4tew7h0US5mt8j61pOnCEbUKQqDyVgkJrN1PRaTCwaeAgfbG0tprCiizleAEHDrZmvzbZnQIquZkNqNbkTqyRgR//tSQJD/cHydJtGGmwDvtj3Bxx2/jLttKsJRSa2vgK1LfNx51fKMjvGnOxazo9GawuQC+adnOEglg/TiNf3N8kFZkRM/mpKbOpL+TGG6DOreiGvEecrEKC9GJyXDt2f5/DQCtnOyhkbRBUjO9Mw/xbiu4QChqGSZ0klUClqkpgo827nqVGxZPBnAHZTLWCPOm/M6+7NYwXpEV8TzMMZS0WW2W1+eQQIxWxgzPafUBlYpmlfjq+eyF1RmyngwYipOX207iE1Ifh69asZ2K6uL+fVfXs5tm+v5wBVLefrvro677tsjV3FSrefttmfNx451Ds9Ly4JX9DbNzcppDqnLUFG4ZFn5lLb4fJNyNZ6OWaMuavEEWsA0oP93Bl2m3eLxLgjizykJvhe5lTIxyoaYbE4iVAm/PdBBz0hwxlColJKvPHqc3RY9s+pE34yWuUT43A7qvO64Ag2+QqfpAWKVA7KJb4Tfyo22V7nT/kjcbQ61DZnmkN0jAUYTyM73j4V45kRP3OcAPmH/OS7CumHeVJaUF+F22glHZd4qWABNlYkrfmO4eVldi1uEKEwxm5cItwjOUKNLxYevmu6UYJ3iAntGve39lFA2ywArXRrEZCuhlQrWDeuqMX61kgI7H79+JXXeAqo9BVy6rDxnYhegVbGMOc3/1lv7qmPMh9eJZq5R9gOwRpznette/sv5FT5u/yVfdNyX8euOBiPU+9xUlRRkbK68tKKI2jnqY18gNf5RrUXQL300+PI3+O8rdJizj0WhvoSJs2xxWg9wdijHAXhZXQtkXrFPRkOpG7siaJY1FAktgJ1vanGA6cO0XHTSKqsI4cjpdcxg65LJhNZr6jJcIsIqoc3/tA9OmPf72fLMCa3NfptyAkVIdsk11Hnnbq4GYMuiUhw2wQm5iBWiDYHK08cTr1vyxR+PTSY5rlBeo12Wc1ZO7cooctq4973b2bzIx/uv0Ko71Z4CvvdnW+O0XQr+oF7MFnFqiv+i1Q6TfPLymT5chFgtWjmgd4vcsC59f9dsYmki1KpZo5RyUEop4vz3NqvHu1CIV8ECzdkcNId5K7x4ppeekSDPnZwqf7nv/CDfe+aM2XucjMWim9XivOX5K2+hkzqfmyUJjFbX13mpSCHtPZ1vR9/MebWSCpH4/Ro+Kd1JWgT7RkOMJXAMF6jcZNvF/6oXc1jODCDKCp2MBLTZrnzNYAHUl7pxJTGw65NahvfXzs9SkEGQVUTAXJinoqLYSXmRk6tWZq666XU7uGhxado3sD7poTwLnl/psEj0sE9tYm3gR6YPXSIEcPebNnDJsnI+d8ta7DbFVNRz2BT++dZ1eN0OPAX2nM0bfTT8V/xD+AP8OKL5c8QGWL93/SP3OTUJfkOWv0H0mgP2sTwa3W75NaWcaiacKXVZOMYCucE/MtkiuKQifwGWy25jQGiJDc0LK7dtUkaAtVx0MCQL6UJrE9vY4M26DLPdprCorJAWXTRiqeiaIk41XzAEo5aJTnMxvaIqvS6UTKgqKTDFsQ7q9+NNyqS1RjYW4X2jQVMZ7hLlGEHpYL/alHYSONu4nTbW1nk5KpdQLAIsE508frRrzn2intaDUQ9j7FQO8Wx0I7GdLzuWlvG9d1/EIl1tMzaR2lRVwo9u307RtHbBl9W12IRkR4xC8AO7z8+w3plrdp3t4/XKbhwiym7dUPn16+a2rT2/tsb/h3DalbiL6h58DMoiVlsMsKQE/3CAR6ddjJ46br3d4h/tPwXgR5E3WNrep/tjXJagh1lRBNetqbL8+gZ9eClNssA2bk7+kQBjMUbLE6Go2RKYzMxxrWihUgzzdHTzlMeLnDYKnTZToh3ii5DkCpsikrYJ9ukqV6uUNq5WDqZ9/EICTGAt4N25spI1s5Tn1YROvFy5Ir2McJ/05L2CVSv6aJcVKYMruyJYVVNCWbGLf33LxrjqeU367GFTVTHvzZEp4Uvqeu6PXksfHqJSTGlxNFBQp7QOrhUtU57/evit3Bn+eMrXKnLaKNNFTup8s28XysYxFsgNfcOjlIsReqWXpsrcL65jGXFo95FKMZjz1iHDymGJ6J7if5Utg+HpNJYX0qy/TqPSNS+9sIyZtKUxAdbKPAlAXLxUa8tsk5X0y2I2iMkA639f65z18WPFIzYpZzgilxDEmZcKXSo21nt5VV0FwDblJAPjYY4kESzLB4ba4jttT1EsAvwkOul95St08MCHLkmafK33ublj59Q28v1qE+PSxQdsf8Cut4Ae7xoxZ73mAz3DAc72jvFh++85pi7iOXUDOxrLct4mm4qFAGsWxM/wa2XjbcoJU3klFf7RIM+d7J1y8X7htDVfBTcBrlIO8qvolRyRjZb28RU6uKixlCtXJP6iZeKQ3i9LkqrIjYWijAUjmshFTIvgP//uKLf/1x6iqqQ/SYC1VTkFTLaFGJQVa1LbiiIY1o+bzxZBgJs2JBZH0OanNGKN+6zgIIJLRBiz2CK4o7Fs1upRa2o9rK3zpN1y04+HyiQVzFxQKkbpk4lvtk49CaIogk26f8miFF45v/yLy0xBB2+OAvUoNlQU7rT/jsuUw3zS/qD5XAVDU2YZlyuZLVRuXFdjtvFk2hoYS1mRM6P5vAVyT3BQS8j58eXdGyhaUI4qhWY2nGMvrHOmyXAP5+VkEjBXC+7GiiLaZQVhaWOp6CIUUedd5v6Mf5Q6+nCLkClw0ZSHChZoCT0NwWvqsikVrP2tg0nv51Yw1GQFKmtFC4d15b7VNXMfYG1o8NIsa+iVHrYrJ4DsintkQmu/1sJ6mXKUY+riKarDO1dUWmr9/+CVS6dUQIM4+XzkPVxmO8ptthfNxx87nPuZS6vsbRmgnCHWKi38JnoFEmXO2wNhIcCaFZsXxx+q/1nkappEBx9OMI80nXBU0jsapGtI+3JIKTltMTtwqXKUAhHmCfUia28aLcBaXpncQ2JZBopMA5RQKpIPAftHgvSMBBkNRmkbGEdKycMH2nnupJ+HD7bTl0SJp1b0E5I2uqcZ5pUWOtmmDzgPT+S/RRDgLVsbEj7nj/FnukQ5mtZx3XqQnqpCY1DtKeBNW2Yn1LC21sPrVmuD0ulwQm2gVvSnpYw3GxRUPIwzROLFxKXLtOx6KKImrTLGIoTAW6idP9dmUMm1ymcj7wPgGuUAH7E/bD7+kPPzvN62h2E5uVBuUSffh0vEtziYzuLyQjOorPXOPpMnhOCrb9s46+MskF2klER1gQm/9GYsxZ8pniI3fXioZDDnUu3nesewE6FB+GmRkwuo1bW5qdisqi4his1UEpRoQhvzibaBCZbpSZizshanXclbBSs2mXdANrFStLJWnAO07pzpow/pYgRYS0Q3JWKCw3oSeVVNfqu08djY4AUEr6qr2Ca0AGtvy9wFWM29o4SimpjWeqXZlJE3sHovK3LZ+c1HLue2zXXmYz+LXs0ZtZZ32Z40H/vtgfZ5Y7x9qH3IDHJ3q6sB0vIAzRULAdYsuChBpeBX6k6aZQ3LRXqZ547BAFFV0jMSTDiHNJ0NohlVCvarTSm3NbrGvO7UN+ClGXiKDMjiKbLZ8TjbO0rPiKYi+JNXWugenvxd79913qxAxaNG9NMty5DTTluv22FK0hoKOpmYJc+Gak9BQsPhbsq4OfhlvhZ+Gw2iFw/WzSoNYYxUM1iG4lVliWvWcsVr6zymCW867FVXArBVOTmr17eKhzEUIRmQiW+2VzRVYNPP+3Syuj79O3Lt6mrsOTKzfCB6LYOyiO36wL7BEqWH9co5RnDzZHQLAO8Lf5qLA9/hqLqE+yPXWjr+otJCekeDlBTYE86Mpst1a3L3eSyQGSPBCMURrZVqQPiyarZrhaoSJ37po0oM0p1Ds2FVlbT0j1Mn+rALdUqAlStPJEMp75ysYanQ2vhPzSMlQSklbQMxHlhqLZsavGblPtcsLS8yrwf/HbmePrx8OqYaP5uAY2/LAOd1oYx1epv0EXUpNkHC+fF8sqKqhCKnjT3qShqVbioZ4GDb3Pmk/Xq/5kNWzQAVYtgMRkFbI92YxjxSkcs+rStH8NPodWxVTrNG/1uc7R3jmZNzL+wBWmvkDuU4E9LJYbmUJeWJNQbyyUKANQuSlVy7ZFnc4fRk3PtCMw8fbDf7zK2wTjnHWVnLhIUKx9suaqDEZcdXmHqxVV1SkPag7IAsoVAEkwo5/PZAB/6RIBPhKI8c6GBX8+RntCeFzGmd6KOTmVK8pYVOtujVxLmYwTJIdpM/Iht5TR8EXiPOJ9xuOmV6y+W4TD6DtU4f+k0U5KWDUe0otXCexHJENhKUdq5WDsz6PVjBqJYOJgmwGkrdVOifyYo0FmFGa+DGBi+1+uxReQ7kXttkJZv1tpr3hj495bl60cdfh/+a1YH7aJa1dFPGTaF/ocOiWmhDqZv2wUBW1bYKHDZW1cydwecCM+keCpituSOO/Evp13gK6JE+KsVQTmewOocDhCIqy3W/pzOqlmFfXFZIUZYFLgyaqoopcto4J2t0LyzJ8a75M3vSNxYiHJUsFx0MSzd+fDk1GJ6OoggW6Z0OfXh5Xt3ASl22HJjVnM7df5gUVVivNBOSNk7KBhaVFeY9iRAPmyLYtMhnzmFtV07Q2j9hrkHyzS5dpvxiXYzicEwF6x3bF1GQZnv35U0VU4Rjfhm9koB0TKliPToPPLGCkSiHWofYoRxnn7qCMHZuTjKykU/m/iy9gFlUVpiwHauT8rQDrGdP+nlgVyuHLSgHAtiJsEFptjx79eat2sXJZyH4UBTBTz5wcVrZ6n60hVcpiQPE3x/qxKgqdwwFePyo9T7eGvrpkvECLIeZoR+emJsZLEjuhwVwVPfvWG9Bwh/Ayyj/6/oHIHUFy5iZy4bngyGQ4SlwkE6xIoiTh6JX8S7701OGnXOFTz/PBpO0CFZ5XBS7HLjsCnVptMkVOBQ8BXYaSt3U+9xcsqwsYw+pZLTJyTnIw2qj+e9e6eEnkesYp4CARYGT6TSUFdI5NJGV9sBYNiUx1l4g/3QOBcyZvaAr/+ar9WWF+KWXKjFIx1DuZMzP9WqV/xVCW8Cf1ueNchnw2xTBujpt1qZQBKlikOZe6x0IuaZzUAtol4sOzsh6QLA6zwmQjTHXgzNqLbWi35w/P9E1ktHMWiAcneKltU6c46RcRBh7XhQSrbJ1cSlHZCNj0mUGNsfnyIz6lB7MvsP2DOfVSvZLravJYRN88Ir0zXaLXHY+eOXkfkMU8zv1Ut5ke8H0eX3+VO+czyQ+c8IPwWHWihazPfCqlblr7U+HhQBrlmxJMIfVIcuoZgAb1lr9DHaf6+fL/3s89YbAP9l/TK3on6Gql4iKYhdLygstZ/JrvAXUpLE4G5B6gJVE6CIyrWf32RNWe7QltaKfzjgBli+mlW0kEMauiDkZxl9Rlfxz9ePjtFrHDbZXrR1PTGYCU6kIrq/zUlbkzGpmT1EEXrfDUsXT4HuRWwGtspprfBYqWFUlBUgki0rdaSkrCiFYX+9FCMHbty3iwTsuZUV1cVI5/kxo060VAtJBHx4+EbqTG4N3sy34fT4TeX/Gx/W6HdR4CugYnMiKwEUs79qxeMaMZiYzmwtkhy69gjUsCykqyn91cVFpIT34qGCI7sHseB/F46ze2dEkOuiRPob1xEqu2gMN6nwFZiKkQfhp7cvd75guhi/XcqWDM3KyopdP7rhy0jKlWVcxNNophybCGbWNHukYjlkrSNYp58wE1Kp5IHBhsLq2hAh29qiruUyfrz7akV+hJ4BIVGVgPEwZw1xuO8IvozvNUYprVlVlrKb3oSuXmVL8APdHXkexCHCDoq1hOocCHJujgNLgkYMdXKR7pO2WWoC1oSE3qqLpshBgzZLGBH2eXbIcm5BT1MCyzU7lEI9Gt/Mb9QpL25cXOVlRVcz6eusXqHQWZ/16gFWehlS3VdnbMkZwiXDCCpbBcCBMSYF9VjLlmVKbUsZa8KvolVysHKeO3hTbTlWPS6UiuK7Ow9ocKGmVFjqTKiROp5tSIlKhTqT+/WaLUcEa+P/YO/P4xs7y3n/fo32zJVvyvo3H49n3LclkJiQzWQgEwhaWUgoUQluWFrgNXWh7b4HSQOFye29vIeX2lkKgrJclhCUJCYEsM8lMkpnMvs94G++7bEs67/3jHB3LtiRLtpbj1N/PJ5+MpSPJluVz3ud9fs/vl6aDFfI5GBqPGBbs2bBR7wrevUXrUpd57NQGXDmd7zup5+Y5RQQQfF/dx2nZQGJ2yUK4sSXIVFS76Oa6wNpQW8pDH7mRKv2i3VTuzqsZyDLp6dQLrB5ZOmMxVCiqSp30SD82EWNypDdvWUDn9UDdVUo759TpAfx8W3ZXlbq4mlBgdeTZij4bOgbD+BinSgwYksn5XFJzzfraUmPjKW4T36zLOAH+/AdHszZDePHq9LqpTvRQLkZ4WWrdlFSb2sUgPu/8tLqOVUo7IQaLIiE9eLEPybSJ1pPqtBnRG7ct3PTK47DOUG68IFsYlB6jWwfwo5faF/z8iyWmSn57rpddymki0sILagu1fhdue+EVTMlYLrAWSardog69EKjJUiaYKSWM0aD0cFSdG7ibDEVou9p3bqrGYc28u5PN/EYP2oI0Hy5ymv6dGda8cQKexA5WtCjzVwChDMKZn1bXA7BWuZz2uA3iAvfb/sX4epLUP5PPYSXgsedlkVtR4mD/mgrc9sw+MzEsdFFGbZ4+94nEZ7BSmVyUe+xEYip9Y1MLCqaMyy4VXScZcNup8DmMma5c8EN1D4PSY5hZLJZ4SOSelqAh18pHfpXbbjVMfv7o5paCu3YuM03XcJiQGKSX0qxksLki6HXQrTulBslf2LA2myxZKdo5K6cXjZvyvFtdXeqkXe8014keetM43Raas90jRjFzXlbjtCkZXYdyTVB/zUuyioi0sFaZnjN+/HQPPznakeqhSfllQi7oNqHFsxxRVwHTxiNmIL7BHv/eNioXilJg/fglbTP2euUEo9LJMb0YXV9Twm3rFhe2+6btdThtWqkgUXhebTUc+wB+9EKHkWNaaF5uH2JwPMIu5RRHZTMTONi1wjyfj+UCa5HU+F3YLHN3mzulpoWvFv1z7ssFcaOETOevAm47iiKyzo/IZnEWtyNPDEnNFU265CAxXDJOotvdcDhSlPkrIKPd40u681X850nFuyyPzPi6W6betbtdz2x69YbcD3a+anUFrZW+rHaJO2UZNeS/wPKLEWJSMELyTY79ays4pzt+LWQuYeOsLLgyj11zi/Q6MsoTyYQYFnZO/jP3Rj6Wk+fbuyqE06awIugx5jOqS3PbwYqztcGP227hTdvq8Bbpb24ZrYMVZIge6aeuwN0LgKDXbpz7Q2KIzjzNYV3oGaOSAUpEmLNSi8UoddmyjpPIlqpSbQ6yR5ZQJ3qMKBAzcPjygGH6cU7WUh9wF0W9Ee/kTGLnpGxgkzg/4/6/+fFxLvdlNrvWMRjmUELA8DblLGPSwWlZT8hrz8mcca7wOKxU+ByclI2oUmizYtdGCm5ffvCCdr29XjnBc+pqomjn47dsrzM2CBeK5tI8rRx6Vl3HSqXTKOy7hif4zdnF2fEvlEMX+3EwxSZx3pi/etf1TUX5XpKxXGAtEosiuHff3C5SfFYoW6OLTFmlO/WcUuszOn6hJ6VsrC7HcDEmHYTyUWApXcSk4Iqcm22QKNMcmYgWbTe9zGNnvmvbID4GpYcmkd7cI4z2+/pE5P00TTzIAMkLHK/Dwv1v0uQA2czLZcprNlZT43exsylzd7IOGSyIRHCXcpoLsmaObX+cV2+sNgqshQRvzu5Ou+0W6gNugj4HX/29HTmTY0WwEiM3M4O7m8uoKtFmJzv0+YxcuggmsrLCS0OZG4siZrhNLVNYuhIkgs0LiNdYLF6HlV70zTUG6BjMvYRuKByhfTBMi6LJkeLzRhv1Ocl8EjeJaZdB6kQvE1GVqWh+ZJDZMBSOcObaKCuVDiJSy+oq9PxVnMTNqJfUlWxSLiCYfo8GxyN873BbsofO4f8+dZFE34TtyhleUlcSw7IgqXe+aQ55GMPFJVnJeuUy41Mxrg4Ubk4vpkquDoQJMUCL0sEz6jrjvutW5sb0JvH6//9iNzIpbbzX8jPjth++UByZ4JErA2xVzmEXMQ6pa/A4LKbqcC4XWDngw7esmnPbMB7GpCNvHaygGEKVgl4yk0cEFlhg3diSmSV0nHgeSq5ZIbpol0EizFzIOawKtQk7mMMTkaIVWFaLQrknsy7WGuUKf2n9BqUpHBd9IsxltYJvx24m3TxOXcCds25KMur1BfTNq0MZB/e1ySC1opc/tPw4q8yvbKimj13iFA/Frkt5TEOZm3M9o9gtyoIWHrN3/oQQrK7yEfI62FRbuqCiLd/sbCqjosSpGVwMhRFCy2jLByvKPTSWa+9rsbrGy0Df4DAlYpweWUpNaeEX2EIIRm3aQi5fVu0nO7W53lVCW8idVbUOVqbh4YshvnHVJkPUCW2nPl9dumw4o7vGtYgOLstKolgXnYG4UG5omV6AH5XNlIiwYXQR54kMDK16RiZ58OC0vNDFBGvFFY5IbY21fgFS73zzen1G94RsYr0espw4Q5ZvzlwbIaZKrtfnop7RxxCCXgetOSpIb1w1Xaj1UcrP1J3caTmIohfRj57sZjKanaHbYpFScuTKALvEKVQpOKy2FixgO1OWC6wc4LRZkrjWCTpl9lbtmVLGCIN4Mt75XmiGT43fxcdubTUG2uejm/wUWI3iWlJ54IqgZ0aBMTIRLepiL5Mcqkuyip3KGd5vfZjftz4MwB7lGHcohwA4oBxml3KK4RTSt0TWFsiSd1tjIGOb8gejBzgna/mE7T94i+WJvHw/n7R9nQhWvq/uTXlMmdvOuWujrAh6sObIXXFNlY91NSWUex1F6Rakw25RaK30sabKh8tuoWMwTMjryFvoaF3AxcqQtsD1OpZnsIrB+FQU+4TWLe7Bn5McvIUgHF7GpCNvVu0nOrQCa7W4yoD00qt39AuxyRHyOvDYLbTJELWi975LugAAIABJREFUF4FK20DxC6zOoUSLdq2j11SkAmt30/QC/EVVswffPEsmeKx9KK3F/UQkxn/98XHGp6YX6pvERaxCNWacClFQZ8sbttbislk4rjZRr/RQwijPXsjPxnoynjyjFa7XKScYli5jbOTv37hx0fLAONsby/j4ra3G14/FtlEmRtkizgGaWdnjpworE2wbCHNteJJdyklOygaG8WTdEMg3ywVWjkgWytot/dxpOcTHrd/J+euViyH6Zea7OYvRLX9k/yr2r63IyL2nW/rz4pxYI3oNS+tEZl9gh8ORoplcADRm0CmJBxMCqPqf4IP2z/Jl+5cAyVftX6BO9DIiUz9XfO5vX2so5TG5xGZRjEDJ+eggyB1Tf8+A9LJaZCYLyQYHU9yhPMe/x26lLYnpCWimLiUuG+d6RnO6CFsR9LBHP4k3B811sV9d5cNuVdhcp/2ddg5NUJ0neSBoHdv4BS1xBisfgczLJKczIWS4V5YS9BbnvS912fSw4cG8dLBOdWkF1hblvG7spJ3/WkL5/xsUQrCywkubDOEQUUIMGZlDxaRrKIyVKI3impEJVqy4BLvNgsehbfaelzWMSieblfNzjvvqb1LnI37n+av89FjnjNu2KZrBxQt60dZcgN93tjhtFrY2+HlZL2zWK5c5eDH/M8hxnjw7XWAdUtegomBRBHtbc1tsvOv6JsPs4tfqJiallTdbnjTu/97hqzl9vfl4+nwvVqJsU84Z81ev21wzz6MKy3KBlSMSs5jixPOgPmz9Yc5fr1yM0JdiLicZiw1j/OitrXzwVS3zHjctEczdkKeDKUJimI4kBVaieUE0pjI2FStqB+vLv7t9XpnGrxIc48oZnuG6uFpMn6SGSf08PoeNUpeNN2yrW8R3mx3ZFa6CE2ojrUruC6xGcQ2LkBxL46Dpd2sOglf7x3NaYFktijHTZLYOVjx+IR4E3DEYpjYPDoKJbG/S9O5ex3QnfXO933AzXCa/tA+EjZnXISWQs05ttpR7HfTo6oV82Jhf6hvHzQSt4iovyunrUKFkui0hr7HBVyd6jEyuYtI5NEGD6MYmYoZF+4oinpPq9POiisIxtZktyrk5x3zz0BWePp98Pvdgkq7PDuU059QaYwZ5pQkLLNCk2cf1nK714hIXesaMYOx8c6pzhAoGaFa6eFafv2oOerJyi86EUreN29drKqJhvHw7djNvsfyaEAOA5hbZV0CHzafP97FBXMItJjmkrsGqCNPJ9pcLrBwR8MxdfH46+k4ABmUuT3oSK1HKGaYviw7WtkUO/gW9DnauKJvXxOGUbMAnwoazUS6Iyyw75NyBzQ0Jw7XxTK1iW0avrU5fzHYQ5FvRmwHN1vV55x8a9/3C8WfGv4fTdLCiqkpTeWHnLRxWBXsWC7izspYW0U4ui20bUX7H8iig2RKnIuC2caFnDFXmbxFWF5j5/udzFi4TGsq080xz0IOUko7Bibw5CMaJX8S9Dhu7msqoLnXSHPRQG3AVJez7Pxsdg2GjgzVuz81A+0Ko8NkN9UJXHiSCbf3jrBeXsAjJS/rGSlO5m/ICWZLHO1gAdaKXy/3Flwh2DU3o51eta+R1WKn0Fd6mP87GummFy3OylQ3iEj5mmj1ICR/79kt0D08X4aoqOd8zysGLMwssgcp25QzPq5o0rcRpNZWDYCK7m8vop4QLahX7lKMA/OJ4eqfgXDA2GaVvbMrIpTqorgWgNU+jA69JyMT8VuwWbCLGPuUYoJltPDyrA5kvRiYiPHriGrv0n/s5dQ3Vpc6iOGimY7nAyhGBJB2sp9SNfCryO/jFGH5yIyn4oOVHnHO+ixrRawT7zsdH9q9akE31bEpdNm6Yx5XmoN6q3aWcWvTrxYlniXUwt4OVWGANh7UCq9gD92urSqgsSX/h//Po+3k0tpUtSmrJRLoZrOGJqNGpKBRCCEpcmb+352QtXjFBFbnTo7/V8ji/Z9Us7C+mLbDsnOtZuINgJlTPcm1sCXnn3YDIJ3FXQ0URDIUjhCOxnIcMp8LrtLK1wc+fHFjFipCHWr+L65ozd55cZmG0D4anJdmewsiFk1FT6qJHlwh2j0wSyWHY8FRUpXN4wnAQPK0758bjKQrBiqBnRhaWGUwuuoYnWCm0Be0FWcOaKl/OZm4Wwr5V09fnp9UNWIU6I5A2TtfwBK/7X0/x1Lle/unxc/z+155j/xd+PSdfrEV04BdjPC81Sb3ZuhOJ7Ggsw+uw8rC6mxuU45QxzK9Odef9dV+8qnWPdiqnGZVOTkgtuH5dnsK3X7W6wlDonJL19EkfN1heNu7/zvO5V6wk40cvdjA2FWOXcorzajW9lLKlwOuhTFgusHJEsgILtBMfQLPITWX/duuvAPCIyYwkgh67hY8eWJUz6cg7dzemvf+SrKJb+tmr72rkgpoUHazKEocRcAiagyBkK2XLPa/eWM179qyY97huqXUVz6vV3DT5xTn3R0lfzFzXXPgd62ze2/iOby7DtuMuXgDjpN6tDXjsnOseRRHkzVnL47BSklDMr6spKdoMBMx0C2zXLdoLFTzrtllYU+3jdZtr2VLvZ1tDwHSOTq9E2gfCVIoBemQJZSVFlIeVuemRfkpEGIecNDLYckHHYBgptWvohLTRgXbe27eqcAVlrd9FGCe9ehZW7+hUwV47FZ2DEzSIa/TKEkZwZ5VVmA9uSpgHPqKuIizt7FFeTnps1/AEv/PVg3z+F6d5PIW74A49zPY5fWa50BuK2WC3KuxpKeeR2HasQuU65QSHLw8wMpHfzLRf6cYSO5VTHFFXEcOCRRG8YWvtPI9cGHarwgdv1iS6EoVn1PXsU44ZboLH2ocK4qD4yIlrCFR2KqeN+avXbDLX/BUsF1g5I5nJBcBF3fmuWclNgXVFnR7qz0QiWF+W2+DBva2heaRQgh/HrudW5TCVOepcVOuhtV1y5o74bOvteIFV7A5WS4U3o+yh36obaJNB/ib6bmO+7Ki6gk9FNGmpg+QXcYfuCrfYubqFkI38Ml4Qf8j6Qxrmyf3KlAbRzYS0cefk36U8pqrESYXPwfnuURrK3DjzKFWLS/CCXi2EeHY4cSGpSOiaxhe4hepgKYpgW0MAl93C+ppSbt9QZVo5zyuJ9sEwFWKAbhko2O86GStDHnr0yJCQGMxpDlD8uZpFJxdllZF7t6qAHY34e9smg9SJHobCEaQsbJhsItGYyrXhCWoTzJ+KXWCVuu2GCcIUNp5TV6cssDJhh3KaHlnCZT37cmejefKNkrG6qoSTspGItLBeuURUlUnnynLJU+d6KWWUtcpVo9C4qTWU13PBtgSzs4di1xESQ9ygHDdu++7z+TW7CE/FeOZCH6tFG6Vi3Pi5b1lTvA5+KpYLrByRKmfqqqwgIi0562BVigEuqxX8Y/RufhbbPe/xuQ4e9DqsbJgni+LfYrcD8Fe2b+TkNSvEIP3SyxQzF/ez50tGJswxgwVz5WPJeFi9jhsn/5HfqhuJYOX1k3/LO6f+ggk9ZNhF8oFRmyKwWURGjoW5JpsOVqdeYN1ieZGv2z676Nd+lfICd1oO8Rt1Iyd0x6Zk7GgK8L69zZztHsm7rKSh3M0NK8upDbgpddlorfIZDo+FwmO3EPQ6ZsxfxK2yq/NscpFI4rlmVYV3wdl7y2RO7+gkVWKAazJQtJBZ0Dby4h35EENc7c9dgXVct2hfITq5oMuCfQ5rQS3pyz127FbFsGqPqZK+seJ1sbpHJpFAreg1pItmsDDfnDCH9ZS6gVal3TBByAYHU+xTjumLZ+18urameJtXmdBQ5mYKG2dkHRv0PKxj7UPpH7QIJqMxznaPJHT6tELj5tX5LTSayj3GJvbj6haGpZs3WH5r3P/Q0c68ZmL95mwPU1HVmL86pK4h6LVjz7GpRy5YLrByRKodgxhawvqKnBRYkmrRzyPqdr4YvYceUrfMrYpAERhBoLlkR1P62Yo2WcG/xF7Day3P5mT2LCSG6JFzf9bZi8fhsNbBKi2yRBCmwymz4SXZwjAentUHVX+u7kx6nBSaRXgxHMPikjhrBlr/kYQZskZl8Xr0f7N/HoAh0i8kmso91AdcXOwdoyVHQYup+N3rGvnka9bREvLid9sIehzU+F0ZvT+54r/cvpo3bqudMR/XMTiB3aIQzCD4OlckdsqFEJSlkE0vkzsmoyqVYoAuGcjLuT5TKnxOeqS2AK7IcQfruYv9OJiiQXQbeU/NIU9BB9oVRVBT6tTDhrUsrCs5LCKzpXMojEClTvTSrkuxm8qL72q6PaHLFDdciFutZ8PdlqcIiSG+EbsVAIsQRd1AyIT49/eyuoL1yiVAGpsD+eDw5QFiqjZ/NSmtvCi1nMp8R7coimCrbpo2iZ2fxXZxu/IcTn1DeCgc4dcZhEovlF+e0NQwu5RTtMkg7YTmXZMWi+UCK0c0lrtTWhNfkNVzUs0XQiljuMWk0RlIx/61FbxmUw0fu3X1vMdmSyYX8lP6IHK5WPwJJiQGjYt3IjWzOljDE+YwuQBtwbFQzstamiYe5Al1a9L7ozFZtN1Kvy6FzdYuNywXv9gekdrv+/ux1OHCoIVtXukfJxKTee9g7V0VZF1NCZ+6ez2lLhsBj503bq0raODn3lUh3rqzfsaCs2MwTFWps6hD78sdrPyjRqcoZ5huAjNm8AqN3arQi7boqhQDXMmRy56qSp6/PECraMMqVE7oVtjFyEOqDbj0LKwIwRx36bKlc2iCIMM4RIR2GcTrsBYtAy2RRNn6SdlAVCp6sZEde5SXaZflPKPbjleUOIru0jofRoElmwiKYaro52Rn/gqs3+r5V7uVUxyVzUxipznoobEAhfZ7bmgy/v1DdQ9eMcF+5QXjth8cac/L68ZUqZuHSHYpp435vNvWVubl9RbLcoGVIxrK3KyvLU1qTXxBVrNGuco2cWZRr5HK7GE2XoeVOzdWs6bKhysPeTSZFA+DepfBz+LzQkIMJu3Wze4axgdKvY7iF1h2qzLDgCN7Ul9MJqMqq/LcmUnFn716LQ1l7qznv1xiao5lb3ZIbET5SvQ1PKOuT3tkU7mbs935dRCMEy9q3HYrfpeNgNvG7+9dYUhE/SlmM3NFucfOypBnTsHbORTOSKaaT8o8dlNsdrySKYn2owjJNRkoqGQuGWM2P5PSSpXoz1nx0Ts6yVA4YizS4y5p80Vh5IM6v9uYd6oXPVzuK0zOUTI6BycMw592GaQpmNtZ64WSOAc2iZ3zsoZ14nLWz7NOXNZzpbSfaf08YwlmoMLnwG5VjDysDcol2gfDecvD+s3ZPlxMsEFcNOSBr1pdMc+jcsOrVocMA6WD6lq6pZ/XWp4x7v/58S6OteVeHnm0bZD+sSmaRBcVYtCYv4rnMZqN5QIrR7jtVvavqTDSzBN5LLYNgC/Z/onFZAL5hbZoHJxHIrWprpQ1VSU5sWZPxnwW5AADuoV8QCy2wJKpJYKlsyWCUTx2S9HCNmeTzwVusTpYXoeVNVU+1mS4wNk7+d+5P/I2AFrFwodfPUzgFJGMjF0ayt2cK1CBlUiJ3sHyOqzUlLoIuG15c3OKs66mJOnCqmNwIiOjlXxS5rbz0QOtRf0eXun4Y9MGQMUusNwOO9dkgCrRb7hYLpb486wTlxmWLq7qcrh11YWfx2kod8/IwjrfXbwCq2MobBSdp2S9KeSBoDm2JnaajssmNisXsJD5TI6LCZpFp1GoQP5lb7lAUQTNQQ8nZQMxKdigXATgO3kwfZiKqpzsHGaLch6biE0bXOR5/iqOEML4nago/DS2m1uUF/EmbKJ+5uETOTeCiVvfx2OADqlrsFsU08pHzbESfYVw58Zq3Pa5O7aH5Fo+GXkPDUrPoswuPGjOYHGpVCrWVZewIuhhfZ6GQitLnIaTXSoG9CIwIBY3g+UljEtMJZUIznYpG5mIFN2iPZGFzGHNh1vvSBbTAntFyJNx8X5VVvI9XdJ3o/IyNqILes2gHqbam+RzkIjHbiHk1RwEq0udBe1mlrpsRlxDtd/J9sayvFvpJ4uHiKmSruGJghpcJKPEZeV3r29MGWGxzOIpVzWXsh4C+IrcuS912uiknGrRT8/IJBORxQ+6d+humOuVS5yUjYaDYDE6WA1l7hlZWMWcwbraP84mcYF+qQUgZyvZzhc2izIjGuJnsV2ExBCvU57O+DnWi0soQhrdSoADawvTmVksq6t8hHFyTtaySWgZl4+dzH0e1rH2IaKqZLdyElUKDqutOKwKu1cUbhbp5jXTv5OfxK7HISLcqhw2bnv2Qn9OLdtjquT7h7WcrX3KUa5JP+dlDY3l5ujeJmO5wMoh9WVuYwE8m8djWwCMlO+F4EHbzRsjfYHVWunDblXyssAHCPkc7GsNUVXiJJUselDmRiIY0hfW3Uk6WLOLqeGJiKkkSfnoYJW6bFgUQVMRB9pbQt6sJIo9BBiSbj5q+z5/Z/3qgl6zHE3L3kv6AqspqA2/n+0eLXgwZZnHbhis1JS6uGl1KO/hh8kMXbpHJoipsqi23aDtctosypKQ9yxFpJSUS62DNWoPFn2RUea10yXLjGDxjhx0sTqHwiiorBFXOKFqC+6qEifli5JfL4zGcveMLKxihg1f6B1jk3KBl9SVgDBVCO+GhKiKR9TtnFLrea/1Zxk//oDlCFPSYphkWBVBjd+cHYrZxDc+X1Bb2KqcQ6Bypnsk53lYT57R86/EaU7KBkZws7u5PK+RJLO5dW2lkU12RK6iTQa5K0EmCKTMOFsIT57toWNoAitR9ilH9TW1mGGsYjaWC6wc40mxi9hOiGvSz0a9bbwQvELbzRuVqRfuAmjJs3zMZlG4Y30VN64KzggXTGQUFxFpMWSNC6VanzvrZuYfkUURc0xFRiaiprBoj1NV6sxp8KwQ2n9VJc6iyiB3rSijPMuB6ri0b/YJOFPihXbfPB2spnIPqio531P4AsvjsBrymPW1Jbx5Wx1BrwNFgC+JdHgxxDvIyQqs+K7/bBOYYmFW+cZSZyqmOQhGpAXVWfjQ8dmEvA46ZRnVoh+QOZEJtg+GaRJdeMSk0dHYXF8cu+745ziehdU7OlWULKxoTOVK7wjNooNTsgHI3nQon8zcVBJ8M3YLG5VLGc6gS16tHOJpdQPDaNfO8iVklhNXdhyRqwiIUZpFJ1LC0RzPIz1+6ho2omxTzhrywDs3VOX0NeZDUQRvNCTwgodi17NXOTbDOfrRE9dy9jfyoxc044ydymlKRJhf6SZgt6wxb3dzucDKMak6WAAn1UbWiisLfm5vBh2sV2+oKkgA44F1lXzs1lbqUy6eBIN4CCyyg1WvD/JelTP/iEqc1jk7tmbsYN2cwz/+UpeNkYkoKwroUJeMhjI3LpsFexZF3gcjf4wqBQNkL+25RTnCV+z/HSCpVDSRpqCbzuEJxqdiRd3VXV9TistuwaIIgl4HWxpyu8sW/wwkL7C080SxO1hxit1ZeaUyFVWpFIN046fMV/zfdY3fSZcswyEiBBihbSAHBdZA2DBJiM/kbM5zVzgVfrfWoY5nYUWLlIXVNhAmIIewixjtMogQmm29WZg9mvD/YnvpkgG+YPtnrPNIxHeK0zQq3fwkdr1xWyEdWRfL3lUh3rK9jsOqNnu6W58VOngxd4HD3SMTHG0fZoO4iEtMcUhdg0UR3FHgAgtgd/O0JPEnseuxiRivsRw0bjvROcxvzvYu+nUiMdWwZ79ZeZFJaeW36kYAwzLejCwXWDnGk2QGK84J2UiLaFvwHIpHhFGlYJzU8oi37KjDV4AuTqnLRo3flTZzahI777D+iofsf0HJAgutOtFDVCp0ypna4mSzViMTUVPNYDWUublxVTBnz1fq1AqsdUWWXAkhEEJQmoVD3knZyJeib6JaaJk2G8UFHMy/OLES5Qu2LwPwaGxrWongH+9fxfv3NnP2mraD1mKSXd3qUueMAM5cEC+wErOv4sQLrGLPYC2TXyIxSSX9dMsA1UW0aI9TF3Ab5+nqHDgJxlTJkSsDrFLaiUnBOantlm/J8d9SNjQFPXTIILWiF5C056CIzJaLfWOGo3CnLKOxzF1Qadh8bKideX0awc2nIr/LCuUa20X6TKy3Wp9gRLp4WN1l3Lax1twBw4nYrQp3bKjivKzhqhriFuUIAE+fW3yREedX+kzXTr14e05dw/qaEvxFmHVtrfAZHcbjspGTagP3WJ6YccwfPXiEw5ezD5tO5ETHMONT2kznLcoLHFTXMo6TUldhA8ezZbnAyjHuNFKgU2oDdhHjGceHeMusD2EmeJlgFCfpLLwL/WFLV2DFtfgblEu0irasnreEMf7C+iD3Wn5Khywnxsz3NdnrDofN1cHaXOfPqUzLbtP+XLc2FG+BkUi2gc6X9S7kduUMP3F8kk9b/3Xex+xRjhMQo7xv6uO8L/KnqGlOWW/cVovfbTccBFcV0QgkkXU1pdQGctthiO9YJ/sdtA+GKXFaTSWXXSb3TOkhw9dkgLqy4newmoJuuvQCq0r0c7lvcQXWkSsD9I5O0SLauCIrmMKG225hWxFnLlaUu+mQ5ThFhDJG6BqeKPj30DEY1mWY0CnLZ1ijmwG/2z4nk+sJdTOT0sotliMpH+dlnDuVg/wkdj1hpjcMloKDYCLaDJrgUXUbNyov42CKF64OMpyjOaxH9QJrt3KK82o1vZSyrUhdHEUR3LW5Rv9K8B+xm9msXGCduGQcMzoZ5ZcnFpcD+9wl7fNeL67RonTwuKp5GhSrm50pywVWjkknEbwotRZuUAzzedsDWT+3l/C8BhfJXAzzSbpF9vsjH+d/R18HTM/QZMoe5WXutf4Uh4jgFHNPTLMXj1JKhk02g2W1KHOcDheDokutNuTJHTJbqrLcNb+kf/4P6Lt6u5WT8z5mv3KEMengN7ocIBVeh9UIWDzfM0qZx57T934xbK33U5HjjY/6gBurIpJ2bNsGwtQGlueeAIQQ9wkh3iyEuFcIcW+Wj/1Kvr6vXBAvsLpkwBRy0FUVPjr1jMZq0c/l/sXZmP9Wlxa1iA6je/Wq1aGidmu0Dlb8Z+yjuwgFVtfQxIxMzDVV5iqwYO7CdwwXB9W1M8JoZ/N+609xi0n+I3bzjNt3FdAZLxdU+ByUe2z8Wt2MU0TYrpwhpkoePrpwB+k40ZjKwQt9WImyWzlpBDEXc9P1jdumo0h+GNvDpLTxVsvjM455+lzfgp9/IhLjIf29u0V5EcCYv3qVyYvv5QIrx6STCF6Wi5vH8YgwY2kMLsBcBdbj6lb+T/TVAIREdnadiflZR9RV875uOBIjpkpTSQQBAjkMmo3EVDx2S9HzjeK8eXtdVscfk80cVxt5r/XnAFiEOu9jtipneUFtYZL0xVJi5/Zc96hp5IGgXfwqfE5ac2g+U+KyEfQ6knewBsLU5bhjthQRQtwPXJBSfk9K+QCwUgjx5iwe25zXb3CRRCZGKRXjdMtAUVz1ZlNV4qSXUqJS0TpYveOLGnA/1TWMhRhNossosHavKK6Zx4qgx7BqrxW9XBueLPj30DE4QbXoIyztDOLNOJOwkCRzdntM3UaL0kGjmNvNKGWUP7L8mB/EbuSoXGnc7rFbTCV/zAQhBOtr/TynriYiLdygHAfgu4ezU/Ek42j7ECOTUTaKi3jFBE+r6wHY0VS8InRjbamxJhnCyy/UHbzO8syMUZhj7UMc71iY0ccXHzlj2L3vV45wXq3msr5Zu73R3MX3coGVY9IVOMMJAcFRmf1br0kE0y+cXGk6aPmg1GVLu+Dvx0dUKlRkUWA1ii526d2Nmye/wH+JfGDOMbNnT4bD2h+zmSSCoHWxcuUkODIRZUNtKUoqb/wCc+fG6qxyplQUvhnbb3xtnSd80skka8RVXpQt8z53SF9gSik1i/YiBTEnY2XIS0WJg/ftXZGz5/Q5rQR99jkFlpSae5tZivAic6+U8nsJXz8CzD2ZzEIIYerCKo46rO3qXpOBOZKsYqAoAiEsdOOnWvQzMhmlfxEmECc7R2gVbThElFNqPVC8gPU49WVuo0tXI/roKoJVe9dwmGrRp3fShKkcBONsqp3bUXlM7zq8fVZ3A7TgWJuI8a3oLTNuX6obRWurfIzh4qhsNpQaL1wZYHRyYfP3cX5zRuvqXq8Xbc+q62gocxf1fC/ETIONH8b2EBCj7FNemnHcP/zidNbP3TU0wb89fQkANxPsVk4a8kCbRRR9Hn0+lgusHOPJ0I45nMaoIhlvUp7kJsvRtBbtkF6imA/8bjv704QAShR6KSVE5rsXv3Z8jLstTxOWdi7KakaZK3ea3amK50yYSSIY5/duaMJpW9yf2p6WcvrHpkylObZbFfa0ZLejfCWhi2shfQdrp3Iam4jxoppBgaV3sPrGphgcj5iqg6XoToKv21Rj3LZY62Gf08aaqpI5BdZQOMLoZHTJLkxyhRBiW5Kb+4EDGTz8AFoxZm5GtE5AFwEqfMU3uQDtnKBlYWmSoLPdCzM3Gp2McqV/nG2KZopwWGqubMXOe6opddGPjwlpo0b00TFUeIlg56AmEYwbipjxb3220QVAm6zgu9F9vN/yEFsTzC7cTPBuyy+YkDZeSuhegbkd4tIR7yq+pK5kvbiMgooq4cgizR6eOKPNX92gHOekWk8/JQUNF05FYoH1G3UTXTLAh60/RCRc4x8/3cOvz2SXi/XV31xgKqo9x43KMRwiasgD11T5sBUxriYTzP3dLUHmk+idVTWpg0+Es3ATlHzBrjmpuUTqHUGLHuxZSEpdNvatCmFN01XpkaVZSwQBBkl9MZ29sIwPkJqtgwXwhm21lHsWJ+H5yC2riKmSTXXmmL+Kc2BtZVbHJxZYWuyAJiF6j+VnvErXV8d5v+Wn9MiSeeev1laXGAVW3OCi2Aux2VgUgdNuNTp+f33XugV3HZrK3XgdVv7hLZvnOIbGrbHNuOgqMGXAbG/kQQAhRMqZ/uRlAAAgAElEQVRdCiHEAeA7efy+coY6pOXCXJMB0zhpeRyWhCwsON4xvKDnudijzW9tU87QI0tpkyFKXTajU10sQj4HVkXhiqygUVzLSZhyNkgp6RyaoFr00ynLCfkcppTQ+d32pDO6fxt9F52U88/2L/EOy2P8tfXfedLxJ+yxHOcpdQNTzDyf3bY+u+uLWYjPxb2sNuEWkzSLDgCeWoSbYO/oJC9eHcTHODuUMzyjywNz6VS8ULY1BIxNwwhWPh95K1uU89ylPDvjuH/61bmMn7NzKMzXn71sfH275XkGpcfI/drTUvyfez6WC6wcM18H6/VTn+LzkXsACGbY1dkgpsOJtyupbU4di+ySLIRSl411NSVph6x7pH9GgVVDLx+2/ID44joVYZl6AbqifKbsbnhCK1bNNoMFWlct22DeRBxWhZfatPdvh8k0x6/bUsOBtRUE3OmlonE65PRJ0Ski+BlFoPI3tq/zb/bPGffVi2vssxzja9Hb552/eu2mamOBedakBVac6lJt0bGzqWzBw+nbG8soSbGREC+wav3/6U0ukhVR8YIr3R+RX0o5726QbprxvBDi+Z6e7HZlc8XUgLZo6xOpPw+Fxue00SXLqdLDhk8ssMC6olu8rxVXOao2A4LWSm/RM9UsiqCyxMkFWcNK0UHvaGFnsPrHppiKTFHBAB2UU2/ijZStDX5m/7pGcPO+qf+CQPJ3tv/De60/JyiGeffUffxh5E/mPMe+FnObGKRiZciLRWhzxwCbxAVAm8OaiKSXxqfi4WNaaPGbLE/iFBH+X+xGAG5YWfxCw6II3rB12uziB+qNvKw28cfW78847tClfv79mUvzPt/prhHe/sCzTOrdKytRDiiHeUzdRhTtXGe2tVAylgusHDNfCOw4Tk5JTU/+asshVop2qknvsLJH19sCfC16a8rjCi0PBHDaFKpLndSnsQnulOU0iG7iBdVX7V/g47bvUSfS7+bYReoO32wL7uFwXCJojoXGbBYjCXPbLfz2XB8tFV6qSs0hBYrjsFr46u/t5J4d9bwpwU0oFRFm/n7WKleoE3MXqHcpzwAYF5F0bKwtNZymzneP4rFbjELGbMRDwKtKHFl3HVz6TvXWBn/KrLt2fUc917bwS5BB5hZS8a+Tpn4KId48a2YrJVLKB6SUO6SUO0Kh4iwCY8MdhKUdi6u06IVHnHKPnU5ZhkdMUsI4JzoXV2DViR6j620WuVh1qZPzspoGcY2JyckFL5gXwtWBMJUMYBGSTllOfZl5N1I21pWSzOPklGzgA1Mf46Raz4tqM5+MvIcn1C1zulchnwOrdWkuUe1WhZUVXs7LGvqll72WY4BWID+m26xny49f1DZUXm05xMtqE8dkM62VXtN0r9+2q974t0The7F9rFQ6qWXm9f1vfnx8Xqnggwcvcykh5mG3cpJSMc4vYjuM24oZ15ApS/PTa2I21fm5fZ629km1EYC/tn2dxxx/yjPOD6cN4t2unOGCWsXKia/zN9F3pzyuEAHDs4mHzq5Lk8VxXDZRKsapF9qJJf7/ZEGziZrdVEG0dotCU/nMC4vRwTLhDBawKJcvp83CoYt93GjilvhH9q+ioTwzM4/vRG/iW9GbUaXggHKEr9nuN+4LMMxXbF/kD60/4bjaSDvzL17ry9xGDsi57lFaKoq/052K+EWhe2RqXut2e4Lc16oItjcGKHFaWVtdknKmr30gjNtuyal75RKln7ldLD9Asg6VbmyRvY65iIjxXnplKSEThAzHCfocM7KwLvSMoqrZOwle6R+nhDFKxLjh2rfNJPl/1X4XF9Qa7CJGvegpqEzwSv841UbIcDn1Jo5jSGZ0EedF2cKrp+7n7qlP841Y8k3jnU3mX0Cno7XSh4rCI7Ed7FeOGCMhj5/OvsDqHArz/OUBFFQ2iIs8p64GiuseOJuWCh+NCRvtz+oW8tfNimOREj727Re5/+enmIzO3Zz4v09d5HuzHBdvV55nXDp4Ut0EaBJ4s8SwpGO5wMoDySxKE+kgyHG9yIoT16zPZrM4x22Ww7wgV+lhu8kXjlZFZGywkQ8+fttqPnqgNel9R1XNPe3PrN9CQcUntAuSNoMzk4qENY6T5MF8LRVerLNmzUaMGSxzLizLvfYFd9diqmQiovL6LTXzH1wkPA4rZZ7M3vv7oh/gz6Pv55Rs4PetP6NZmbbtvdVymNstz+MTYcOaOR1CQK3fhUWfATzbPcJKk8oDYVqbf6F3dN6dxwPrpufVdjQFWF9TQm3AzbrqkpQFZNvAOLV+l2kLzEIhpTzC3IKpDHg0xUO2Ac0JeVkfSPjalK6CtskB+vGZIgMrTk2p0zBfqBb9TEbVBYXxXukfMzrbbVLbZDFLB6um1GlkWq4QnXQMFs7o4mr/OLW68qNdlpvaRW1LEolgNuxdtTTlgXHWVGkqm5+rOykRYfYoLwPw+KnupIVFOn6q50A1iw48YpJj+prKbEXoHRuqjX+flnV0Sz/3WJ9g9jhI39gU//zEeX55/JpxW+/oJP/wi9P87UMnGJ+a+f7sUV7mGXUdE7o53HXNxY1ryJTlAisPZGKb+u6p+3gyNj28n6rAus/6bQC+Ocu+dDY+pxW3rXjyOKfNwj07k+cinZYNALzGcoh9ylHjdq+YWWCVM8RB54eMr5PZeAsBX3rbljm3D4ej2Cxi0W59+aKm1MVfvmbtgh47OB5hdaWPLSZyEEyG353djtJDseuMfz+rau9NXBoI08Hc6Qh5Hdh1GcnwRIRrw5OsqjBfLkycpqC243ypd5yKWZ0Hu3Wmpf+2hgANugRo/5pK6su04ipdFIMWMmyeBXeReWBW7tWtgBEeLIRojt8fz8qK/4fmIjiof32hsN92ZjimBhmQvqwDv/NJQ5l7RgcL4FJvdoHDUkrOdY8mFFhBqkqcVJrk56zxu4yw4SoxQEcBrdqv9o/TqrQRkRYuyyrWm7jA8jqsRpGxEJZawPBsrl+pfUaeUjcwIl3crjwHaMXFd5/PLhPrB0c0Q5vN+ixXfLZre4O53qO7Nk9vAksUvhR9E7uVU3zG+q9Jj//Yd17kHf/yLJ99+CTv/OpB/tfj5+bISoMMsVLp5KBubgFww8rlAus/LZkM2PcQ4MHYtGNwpUhu31khBnk4tovDcnXa5yvz2AuegTWbQIoFdgQrfxl5LzB90YW5HazE96BdlvM7U38x57nWVJXQWjn3pD0yEaHEaTPtzv1rN1Xzus21OBagKZ+Kqfy316837c8WpyzLAuursTv5eWwnH5j6KG+b+isuqFXstbxs3H9BrU7zaA1/ghTuvMkNLkArtO1WhUt9Y3Mc0VorvVT7pxeRIZ/DsMG/eU2FVmClWVBJKbnSP05ThlLNVzpSyk+gdaHeLIS4Dzg/a8bqAElysfQO1lv0x96XznWwmHhig/TjM41FO0BzyMM1AqhSUKNL2S72ZVdgtQ2EuTY8Sb1eYLXLoKncU2v9LnrwE5OCStFfUIng1YFxVos2LsoqnA6nqSWCoAVDL+SqZbOInOVHFout9QGqSpxMYeMJdTM3W6ZdcrMJHX7x6qAxy3iD5Tj90ss5WUPQa087+14MNtSWsiI4/Zn8VuxmHozu53esj82ZxQKIxCRPn+/jK09e4FTXSNLnvMVyBIBD6vQG9fWvpAJLv8i8OUE+kclj3iyEuD/F7ffpu4f++L+z/cbNTF3AbQykp0NzR9KI66pnExKD9Mj0F5dVFV4UIYpicpGI02ZJ2UH6buwmAFaLq8ZtXmZKK0rF9IX4T6Y+yBE5V3K4K0VLfHgiakqL9jjlXgcuu2VBi/+djYEl0RIPZKmJnsLGH0Q+yi/UnQCG7WycbuaXPyTa9ZvdQRC0TKzGMjcXe8eoKnUSTCiy1laVzCi6yj0OtjeW4XNYWRnysKGmJO2sY+/oFKOTURrLzb3oKiRSys/p3anP6Z2pxPsekFLOGQCJ3y6lDOiPM+Vslk8dZkD6qCgxx5A7QGtlCVGsdBEwpGwXerIrsJ67pG3CbVQucE36GcBnqvy/Gr+LGBZ6KaWKAdoHCldgdQxO0CquckbW01LpNU3ofCp2NAXm8QpOTl3AbfoNxflQFMHrt2odncNqK1VigAq0TeSXrg7SM5KZA+UXfhkP6JXcqBzjaXUDEoUt9QFTvkfvvmGF8W+Jwr/G7gBgn+VoqoekJMAwf2X9Bi+qKzmqd+0aytxUl5qrsEzFvAWWXiRdiEsogJWzZBezjz+g7xZ+gORWuWXA/cB54KL+3KaUYCwUiyJ48P275z2uk3JWTnydHlnKH1h+QoiZXSw7EfxijN55Cqy7t9YyPhUregcLUnexprAxIL1sUKYt52dLBMuY3sEYIvnu1ZYUg84jExFTWrTPZtUCFv+VJnXEm02J02rMQi2EHyQ4Bv5z9C5jkDf9a87sYNmtiqmti0FzGr3YO8aKoIfPvGEDALevr+SenfUzZIPlXjs7GgPUBrSZqnKvI22BdVnvFDQt8Z3fZTIgOomHCfqlr+jZUIlU6sVeuwwaEr+TWToJvnBFq2d3Kqd5Tl0DCDbXmafAisdRXJMBKsUAbQPj8zwiN6iqpG9wkEalmzNqnem7V7BwK+1sA+zNytt2auMR8c30zcp5474fvtA+7+MfP9XNb85qGxVrxRUqxSBP6rmQ8836F4s3bKslcRlwXtbQJoPcqRzM+rneYvk1PhHmvsi9qCgoAvaaIPcrUzLpYN07S1bxCElkFXGklI9KKT8HHEnznAFgpb5DmJEt7lJjZTCzhXQMCyExhFNE+APrQ8btZQzTKLQBwJ6kdeo0m+pKCUdiRe9gQeoCC7TA4bXiivH1bIlgQEwXWIMy+ftXVZJ88Twcjpi6gxVntr18JnjmCa82C0KItL//+TgsV/Mv0Tv5XOQe7o++XTd1SU9iB+tc9yjNQc8cAxSzsSLo4UrfODFVGoHATUEPO5vKqPA5eNvOemwWQdDroLHczRfvmZ45LE3jDnhRn3VZlgi+8pkY1oqXAXymsWkG7RxgUQRtMmQUWMc7hpHJ/LpTcKJzmBp6qRV9HNI3WTaaSCJY4tICw6/JMipFP1f7C9PB6h2bJBTTHOguycolMWtZVeqkocxtzMlmyuu3zG9wtBRYEfRQ5rFxQjYSlQpblOmg3X/81dm0xXk0pvKZh6cd+G5VDqNKwa9i2wC4Y8P8M8rFoMRpm+X4Kfh69Fb2Wl5mmziT8fNYifIu6yMcVNdwRo82UqU5cr8yJe2nXgixLcnN/Wja9QUjpRx8pXWtZlPismYkEwT4ZOQ9AFQa80mSQ44/4hHHfQDzdrBWV/kYn4riNsFCPJDGSa5H+vGKaVlgqg7W3ZN/m1IeVplCDjMyETWtRXsiC5GvmaEzmSl1i7zofyb6Tv537O6Mj0/sWp7rGTW1g2CcpqCHqZhKx2CYOn0XulrvXIV8Dt574wp+Z3cjAbc2U5ipU9jlvnEsilj072AZ89PXrbmK9UtzFVigZSO2yRBV9GMhxlA4YuSzzYeqSk52DrNTOQXA8+pqmkOeGRspxUYIQY3fSZcMUCUG6BwKE1uAFX22dAxOGHNpbTKUUbC7Gdi7KpiVVb8iMFXHcrE0lnuYwMHzcjW3KoeN20cmovzBNw6n3Hx4+OUuznVPx/fcZnmew3IVvZSyrcE/b+ZqMXnf3plTP/8eu5VeWcJHrZn3U+62PEWd6OXL0btm3H5ds7mMPdIx37ZCGXNDGQcBFjP4q89yxWe67lvo85gZIUTGobDfiN3Kr2JbaBaaXfVacQWrmM6DSjeDVeaxU+a2MxFRMy7o8kk6J7kepn+OCWnDxzg+xvmw5Qf8hfVBPmb7HsPSzYuyJeVzzHZeizM8sTQ6WDe2BPE5Mv8+11T5TNGZzJTdBT75xQusiUiMK/3jtGTg4Fls4h2mS31jlLps+JxW41zRWumjJeTlgze3ZN2Ju9g3Rl3Ahc3kHbxlFs9grxY6Ooh3xhyfGfA5rLTJEFahUqUvH051Jh9gn82V/nHGp2LsUk4zLF2ckg1sMeFiu8bv4poMEBCjWOUU1xZgRZ8t7QNhoyvYLoNLZiPlptYQUVViy1A+vqrCl3XHy8w06k6wP43tplVpp0VMG1y83D7MEylCd7/z3PS8ei09bFAu8Us9aDdR1WBGbl9fNWPjJ4yTf47exV7Ly+wSJ9M8UkNB5Y8sP+K42sjjqvazCqE1ExaTKVpo5vsUJzuzxQuuha6kHgW+M2umK6lxhl6APS+EeL6nJ33ysxnJxj73gqxmhehEoLJfmamuTNfB2t4YYCKqFWNmWIinCzjtkdrHaVLaGMLDO62Pccz5Pj5u+x73Wn8KgJPUg58euwVviuJkOLw0Olgeh5XXbs48z+quzTV4sijIis31BTbjiO9sX+4bR0qWRAcrvvMYl/TVBdxU6UO7a6p8KIpYUFfict/YsjzwPwnjvdria8ReYbrFaMBjN8KB6+JGF72j6R5icLR9CIDtyhmOqK2oKCnnbotJjd/FNV1lUSEGaCuA0UX7oJaBNSUtdONfMgXWDS1BbBaR8bnZzHmPCyEetfFIbDsAr1JemnH/J753lB++0E73iFakD41H+OzDJ3nqfK9xzK0WrfP1iLqdCp/D9HO2Qgju3bdixm0Pxg7QLf38le3rOJhK+/g/tn6fZqWLf4y+kcTs1z1LSB4I8xdYg8wtpOJfJw9umgcp5YVZrkyPAJ9IcewDUsodUsododDSC52rzsKc4KKsxiWm2CLO06K0c1UNcfvk3/OP0btpJ/WH6r7bVzM+pSWEm6HASmfVfVLVBj4dIkKlmP4IvKC2cGDycwDYReoAvlTdq0hMJRyJmTZkeDatlZkXAdsaAqZ2xZvNDSuDBXWxixdYF/UF3FKw9q0sceCyWYwCa3uj39iMWagrlJSSS73jppaNLJM7ov2XUaUg5jXfYrTC56BNL7Bq9Y5Lpk6CL1wZQEGlWXRwUs9PNGP+X02pczrvi8IYXbTpHax2GUSiLBknNa/Dyo7GMkYmohkdf+fG+eM5lhL1eoHVRTln1NoZWaAA3SOT/Mm3X2TXZx5jx6cfYdunH+ErT16YkQd1m/I8p9U6LsnqJXOOf+fuphlmFxM4+GTkPawXl/kftn9CoCZ9XIto44OWH/G92D5+oe4wbpcSbl6ztOqA+QqsfuZ2sfygzVFl+2K6LbucJS8cBF5RNu1xsnF/ezS2jU5Zxj/YvkyD6OaKrOC0bOCL0XsgRZJEidPKqkofYT312mWCGax0O+8H1eRBuxdlFeekNtQalak/khUpnjt+4i5xFf/nz4S6DN2fVoY8rKr0stWEO7ipsFsVfve6xoK9XokuC73Qu3Qc9IQQNAU9RgDrx25dTdC7cHMQWLZo/8+GdfgqPSJAud98odq1fjcdsztYGRZYR64MUk0fdhHjsqzEomjZh2YjLhEELb+xc6hQEsFe2mQIn8OypJQNN68JZTSHF/Tal8Q5PBv2tYaM69QT6hZ2Kyfxk1wy2zs6NWeez88Iu5RTPKJqHbDmJSCDB212fMUss7dfqjv5dPSd3GF5jpOO93CHcmjG/UGG+N+2/8E4Dj4TeQeJa1+33bLkwqfTFlhSyiPoM1cJlKHJ/BbKJ2YVZ82kdxxcstRkUWBdo4yvR29lpdLJenGZy7Ji3sfEd0bG9QLLY4IOVqouE0A72u7DsHTz2cjbjduvyhAguG3yfm6e+kLKx6eaaRuZiAAsmQ5WpuGA979pE0Gvw1RBopkQ/1wWAqOD1TNGhc+RUkJqNlYE3Vzq03a9yzz2RTsfXlxCBeYyi8c93k6PpdKU54amcjdT2OiSAWNm6Gz3yLxGB+GpGCc6hmhQNKe8y7KSaj2Y22zU+F10GQVWf8YmHosh3sFqkyFq/EtrI+WuzTUIAaF5NpJes+mV1b0CqCxx8oev0ubKvx/bi0NEeZPlyYwff4vyAlahGvNXS0GlEee1SX6f/xq7g4di1+EUEf6r7WtY0TbIr1eO8037p6kXPdwb+TgDTG+sWBXBTa0hHNbir3GzIZMz1wOzcq9uBb4S/0IPDE6Zi5VIiq7XW4DPZvL4pUa2LfxTuhWlQ0S4KivnPT6egzFudLCK/+GrnGfu7KbJL3Jg8vN8JXYXP45dD0Cn1OZ2zsj6tD93qtb4cFjvYC0BkwvIvINVlmVwr1kopLtVXNcfz5VaKqwIerjSP85UNLlMIltOdWlZQ2uqzNfRWCb3BCJdjDhrTOcgCNCiS6DbZdAIGx4Yj/Dbc73pHsbzl/uJxKQRT3JVVtBk0o5sQ5mbYTyEpZ0qMUBHngssKSU9A4OExJDm0LhEshHjVJe6uLElSDiS/nx39yvEnn02b9xWiwBOywYOq6t4h+VXkGEE822Ww3TKMo5JbaYpU1dZM/DuPU1Y5sjeBR+JfIgPTX2YKjHAy47f52H7n/Og7e/wizE+HPkwz6rrZjwiqkr2r51/TWw25i2wpJSfAJp117/7gPOzsqsOkJCLJYTYph/3ZuAeIcR9s+zeH9Bvu1cPMf7KKzULq9qf3UnwtFpv/PtKBh2sBv3iE5cImsGmPZWML85lWWVYsE+hdR+mZGbf98oUrfF4B2spBA2DpkkPuG3z7swulY7cbLKZPVwMm+tKDQe1i71jNIeWToG1qsJHTJVc6stMOjUfJztH8LttWRnrLLM0iUamqFB7iZbUmypkOM5aXdLXJkPUi27j9m8/fzXVQwB45nwfAI3iGlPSQocsp9Gkpi3VpU78bjvXZIAq0U/nYH4lgoPjEQIRzWW4XQapyXJtYQbevL2O0cnUc1gVPocp5+1yQWWJk1X6ZuCD0f2sVDq5Xjkx7+PKGeJm5UV+EduBRMFls7CjyZwBw8kIuO3cs6Nuzu0qCg+p1/H+qY/xdd3C/ZuxW7hl8h94VJdCJqIIuHn10pq/AshoZasHB6e67wHggYSvj6BJ/pI+Ru9ipXy+VxLZ7uS3E2REunAzwW/UDfMeX6+7CJnJ5CKbHdXPR+7BSpSfq7syOj5VgTVsSASLX2BmytrqEtx2C4+e7E55zFL6eRIp89hxWBUmc9SdScVt67WgxaHxCH1jU0uqgxU3LjnXPUrrAsKnZ3Oyc5g1Vb4Fm2Qss3To6bhItVCxlzdlNedbKOLdlYuyitcqz+BgiknsHL40kPIxj5/q5oEntWjM9eIS52UtKorhwGY2hBCsqy6h80o5VaI/7x2s9sGw0Q1sk0H2liwNg4tEbl9fRcBtw2Wz0JFkZu1d1ze+os9fTUEPZ7pH+al6HX8tv847LI/xjLo+7WPebf0FNqL8e+w2QMuAWmoyuT+6uYVvPZdsc0XwiLqDRxKMLJLhsmmzV0vJnj2O+cTNryBKXbas5rBAsH/yH1g/+a8MM/8gY3zeKRwxj0TQZlEyHti/Rhl/EvkQ42T2Hs0vEVw6HZ/rm8u5ff10ErvLZjEkgU3lbmwWgcOEsweZIITIexfL77bxrus1M42Lehdo9kCtmVkZ8iIEnL2WmX11OlRVcrprxJRmAMvknv728wC4K5qzciQtFEIIbBbBObUWi5Cs0PMdu4Yn6EphBvHbc71EVYlAZYtynhdUbWalkPOc2bKuuoQOyqkRfYxMRhkKR/L2Wm0D44ZhSJsMZTzHayacNgsfuGklHUMTlCfI331OK2UeO++9cUWaRy994vOxk9j5fmwftyvPUc5QyuPdTPAuyy/5pbqDC1JzC72uwDEouaC+zM266oVfm8KR2JK17l+aK7glghCCL71ta1adpW4CTJBZpR4/SY0bEsHiF1iQ2oxiMYR8jpQFZLyDtZQKrFdvrJrhiHNdc5kxb7CjqQy/276kd/NuWZNfvfSWer8hoYxbtC+lDpbLbqEu4OJcz+ILrCv944QjsUVdxJZZOox3a52eQM1Kmk26qeC2WzmrO8OuSghWPXQpebrL8Q5todksOikR47ygh82beaawMeihXZZTRT9Wonm1ao8bXGgZWAE21aXOxjQz776hiZYKL6qUVJU4aA55GJmI8levXWuKEYd8ktiN/WbsFuwixlssv055/Nssj1Mqxvly9C7jth1NS8tFL85H9rcs6HF2q4LTphhqlaXGcoGVZ3atKMvbws/vnlVg2cxxgtrWkHuNcLrZkmHdpt27hCR1LRU+wxCksdzN3VtrDfOL1kovK0w6e5Apf/Xatdy6Ln9FVmPCxepizxiKwLRyolS0hLycvZbcrjcbTnbqBhfV5l2MLpM74hlYobpmUzrsgabeuCiriUlBi9Jh3P6VX5+f4yYopeREh/YZ3iS04vEldSVum8XUwdlBj512GcIiJJUMcLU//wVWhwzisFlNW1jPh9Nm4YHf3Y7DaqFreJILPWN8YF/zK9bcIpHEz/J5WcvTsXX8me0/+Lj1O4aTXhwv47zP+lMOqmt4Ud9scFgVNtQuzU2029ZVLdi067Z1VUvGHXg25jw7v8LIV4EV/8CG9RksM0gEAfa05D5tu7IkdVdvZCKC12HFoiytjo9TlwV+9EArr99SS32Zi10rymip8C6pbkwyhBD8fh4lH4nD7xd6x6gvc5t2sZmKVZU+LvSOzck9yZaTXSMogpzMci1jfqzDV+kVARxO824oBL12prBxRVbQktDBOt4xzNO6mUWcZy70GZtka5UrTEob52UNG+tKUUx8Tg/6HHToDrg1oo+r/fmbw2ofjFu0B1lfY+73ZT6aQ14e+/hNfPmd23nowzfy53euXdJqjUzZ1uifMaP+2eg7APiw9YfcpLxk3F5JP39v+yoVDPK5yFuN2/e0BJfc/FUcRRH8cZZdLIsimIqq/N4NTfn5pgrA0lqRLFHyEQwnxHQG0PhUDKsiTLPAvH5lOdYcXwDS5WsNh6NLxqJ9Nlvq/RzQOz31ATdfeusWrm8OsmIJOeKlYm2eJGteh3VGoO5Ss2iP01LhZSqqLnrn+2jbICtDXpy2pXnxXSY73OPt9JBM7z0AACAASURBVNnMLZmJz2Cek3W0iI4Z9/3b0xeNLpaqSr706FnjvrXiMmdkLTHM75ZW7rEbBVat6OVqHiWCV/u1Gax2GTIMcpYyHoeVOzZUsaF2aUodF4LbbuXdCcXCMdnM6yY/BcAbLE8BktXiCgedH+K1lmf5X7G7OSxXG8fvXzu/s7SZefuuRsrcmY9xuO0WNtf72dawdJ0lzbEif4WzIpj7ncZSl83o2IxPxUzTvQJtFuqGHHex0kkERyYiS9bS/Kvv2mG0v1+1uoIav0tPQF96BcNsSl22vAxjf+LVa4xNCynlki6wAM52L3wOK6ZKDl8aWLLa/GWyJxDpYsxl7qHvuDnFOVnDCtGJhZhx36Mnu/m7h08yNB7hE98/yqGL8bksyVrlCidVzbzmgMlzb8q9Dtqldp2rEb1cyZNEMBJTudrTT4UYpE0GTW38sUx6ts4qFo7KlTwc28VrLc/yXft/43/a/icAj8a2zpi9slkEdyzROaQ4dqvCn9+5NuPjRyaivHdP05Lubi4XWAUgH7MhAfe0njU8FTONwUWcu3Ps+pJOIjg8EaHEtTQ7WIlSj0RzkJWvgA4WTGfi5JL9ayqMgqp7ZJLxqdiSLLBaK30IMT1DtRBOd40wMhll1wpz7/YvkxviGVgRX/38BxeR1bo5xVm1FruIGeHBcb72zCXe+7Xn+O7haflgiEGCYpgTshGXTWFznbl3rkucVmIWJ33SR63oy9sM1qXeMSrUaQfBusDScxBcRiNZx+6vI+/h/sjbWC3aqBc9fDbydt4X+dMZZme3r69akjbls3nTtjrWVfuYr2TyOa1sqC3htZvMvZE0H8sFVgHIx45TIKHVOh6Jmc6B5/VbanPqAFXhm08iuDQ7WKl4pexS1uZ4MeC0KTO6mRd64hbtS6/A8jqsNJV7jAH/hfCc7sr2/9m78+i2rvNc+M8+GDmD4DyIokjNsiRLlhQ58ZRY8pDEbQa5boaVtL2JnA7J7ZDK9/b268267dfEzpebsU0lZ2jSpkljpU2TtE4iOYnj2ZIlW7NEkSIpziM4gcS4vz/OAQmCGEkQOAd4fmtpxQAOwA0EwMZ79rvfd89armDlg+G+GzCLIEzlTdkeSlw7tODoulZJcL3oXXS7LyDxWtfivlhblW4AwOXgWjQ4CnS/z0gIgYoidR9WgxhBz/jskgIe6XBlYAqNYhhAqER7bswN+ajUbkFLxMnTEZThq4HfwA7P17DF8484Gnhoyf3uN/jqVYiiCHzpfbthjtOGprmiEFNzfnzqoW2G21cfiQFWBlQV22C3pO+lriy2LqrI4vb4dbeCZVIEttanb/WiMs7Zm4lZ3/x+tFxh1M2skWripHYux61rHIt+eN0YMW6ABai9dC72x+6FksipzjHUldl5VjtPhHpgFVTru2fQOm2PZLvWvycywIpmi+gCAFyWa2I2ldebyhK1kmC9GIHHH8TwtCftf6NtMCLAKmeAZWSfvG9T4oPCCAHcsQqFw7JlfXUxPvUb2+DxB+GI2JO1o7EMnaNuvG9fU06kvTPAygAhRFrTBP/lo/vx/z28c/6yW4cpggDSGvQ44zQvnpz1oTTHAqxcUV2SvrSGsgILvv7hvYuu6xydgdWsoL7MmAHG1vpS3BybXVaTUiklTnWOYW+z09B56pS8UA8sR/3y+spkiqIosJgEZlCAXlmxqFR7LFuVLvTISkyiGNsajVGOurrEjj6pNhsG5KqkCd7USrT7pAmjihOVceZC0r8Hb6mNu+Uh0t5mJ8qXWeJcrz7wprX4Hw9uhsvtQ3WJDXubndjd5MC5ngm8ZX0F/vdDW7M9xLRggJUhj+xtQrpWO2vL7PM9sAA1RbBAZymCAOAoSN+XQkWML5hAUGLK42eApVM1pXbsXJOevRTOIiuKIvphdAzPoLmiUPfpRLGEVnmXsw/r2uA0Bic92N9Ske5hkU75R9oRkAI1azZkeygJhT6r7cH6Rc2GY9mttOGNYAsAYH2VMVoO1JXZ0SsrUCzmUIaZVakk2Ds+i0Yxgj5ZgYoSO0+mGJwQAvdsTL4i4Pv26Xu/5XJ97O5WfPUDu1FWYMGpzjFcH5rGH761Fd/4nb05UxFXf7/Kc9R/u2MdfnKuD2e7XSt6nCKrCSURPzJnvX7UpTkVKx3K0lR4otBqivmBm9TO/OdaimCuqC6x4b6tNegYnsbUnD/xHeIoj1LitXN0xtAFQbZpAdalvsmUA6WfXxwAABwwePleSp51ohODSjXqbfr7vo9UXmiFy+1Dm2zE+5RfQCAIGeOcbg3G0ChG8I3ggwCwqA2DntU7CnBeVgFQS7V3jaY/wOoZd6NBjKBXVqLOoCv1tNgfvW09bozOhFXQjK7EbsaDt9RlaFSZ9+D2Ojy4vQ6z3gDsFiXnTh5wBSuD7t5YteLHqC1begZLrymC4atsK1Ee53EmGGDpWnWpHVvrSrE1DT2xnEWL0yoCQYnuUTeaDbr/ClBTjCqLbbi4jEIXJy4PYleTI26POMotpbM3MWJrzPYwklI/3wurHoXCgwYxGvPY3zb9EgDwWnADTEJgQ7UxVrDqHfZFzYY7tT2h6eILBDEwOac1Ga5alYrElHlrnIV4aEfiwOmhnfU5s5oTT4HVlHPBFcAAK6PetG7lqTzhpbxDZnXWByskXUFPRbz9V3MMsPSs1G7GrWsc2Fa/8oaSzqLF/x/3uWbhDQTRYuAACwC2N5TijZ7UVrb7XLM41zOB+7bmRnUpSkwGg6jx92K2eG22h5KU0ImPtmD0SoIhNRjDn1h+gBOB23BOtmBtZSGsMSqM6U1dWQH6wnph3UjzCtbAxBzM0odaMY4eWYU6B1ewcsU+7fdgsS12ps8H32SMzzpFZ4xvsRyxsWbllZFqS5d+wep1Bassha7d8TjjbPDkCpa+CSFQXmSdT4VbiciNvh3zFQSNUXEslj3NTlwfmsb4jDfp+/z0gpoeeHCrvpuxUvpMjA2hFG7Icn1XEAwJ9cKKVao9ZLNyEwDwpP/tkFCwu8k4Pd0aHAUYQSk80oIGMZL2FaybY27Ui1APrMr5VUEyvg3VxWhwFOAD+5e2XLCaFfzvh7amtRIzZR4DrAyqKLbFLNaQrMqSxfcPBiVmdVrkIl1Bj5Mpgoa3raF0xa0KIj87N4anAQDNlcZOm9mrlaM9HdEXKBYpJb5/+iZ2NJZhfbWxg0tK3kDnRQCAvUb/BS4AtaUCALhQgmFZig0xAqz1WgGMNi0Q29tsnABLbUMh0Csr0CBGMTHrS+lESSI3x91oFAtNhmu5BytnKIrA375nOw5uWXyS7K6NVTi4tQa/+xZjnEih2BhgZdiGFa5iRRa4mPMHAECXK1iOAgtK7CsP/OKlCDLAMobWqmL8wT0rKy0duRevc9SNYpsZVQbvcL+jsQxWk4LTnfE3PIec65nAlYEpPLI3N6tLUXTTfdcAAOWNqfXRyZYtYY3mzwVb8RbTBQgElxy3UfRiWJZiHOrZ+nSkE2eK1aygqsSmlWpXA6ErA1Npe/ybY7OLemA1MEUwp9y9sQobaxfvN3z/viZ86qFtWRoRpRMDrAxbX128onLthRErVW6vfgOs0gILvvL+3Xj3roYVPU68jb0MsIzBYlLwsbtbl90Xq6LIilsaFv/w6hiZQXNloeE3x9otJmxvLMOpJAOs7526CbtFwUM761d5ZKQnvuF2BKVAbfPmbA8lKRazCRaT+tn8j8Cb0ShG8CblypLjNivduB5UC3coYuUnITOtvsyOXlmFBi3AOtOd3Ep0MnrG3WgUw/BLBYMoRwMbiuecUrsFHwxLE7xtbTmq0tg/krKHAVaGNVcUregMXZFtcSA1qwVYBTqsNGMxKbh7Y9WKixCsSRBgWU3KitPPaPVZzcqyfyB84bdvxZaISoSdIzOG338Vsqe5HOd7J+Y/z7GMzXjxw7O9eGhHPUrtPKmQTywTNzAoKmGzGyclNnTi60TwNnikGW9Vzi66vRyT2C5u4OXgFgDqniabWX9zWTxqoYsK1AgXrPDhbBoDrJvjs1gv+tAla2C1WHgiMUf9zbu24yvv34UnP7SHwVUO4a/SDGtyFmJvsxPLPeke2Wh1YQVLf3uwQiqWmcJVZDWhosgadwVrctaH0gKL4Vcx8kVjeeo/Dt/cWoE7NyxuceD1B9Ez7sY6g1cQDNnfUgFfQOLVBKtY//jCDcz6Ajh8V0uGRkZ6UeruxqhtZdkAmVanFWWYhR1n5Qa8Wbm46Pa7lHNQhMSvgjsBANsajJMeGFLnsKMPakW4GjGGC72pt1yI5eaYGxtED67JRlYQzHHv3FHPokU5hgFWhjVXFmF9dTEqlx10RAZYavPWQpt+z/rF20MVz58c3IhDexrj/iifmPWlraExrb7GZaxg/eFbl+7d6h5zIyiBdQYvcBFye0sF7BYFv7wyFPOYaY8f33qpC/dtrcGGGmP0CaL0kMEg6n03MVNirMC6Nayf1YuBbdgmutCAYe0aid8z/xQ9shLnpfq8NhnwfV1fVoAerdlwoxjB4NQcfIGle81SNePxY2JqCs1iANdkI9Y6c+NkElG+YICVYU3OQqyrLEJN6fICrMi9VqGUokIdpgiGVC4zwKootuJDtzfH7YmiBlhMmzCK21vUM72RxVri2dG49Kz29SG1gmBLjqQI2i0m3LG+EicuDSIYlFGP+fpzNzAx68MfRAk4KbcN93ehWMwCVcYocBGys3Ehrfd44C54YMFfWv4ZgNpceKfSgS/634Og9lOkpcp4QUS9o2Ch2TBGIaXav2qlbozMoFX0wSQkrgXXGL5aKlG+YYCVYXaLCbuaHKgpWV4/C0OmCBYtL5gsK7AkrJo0OetngGUgd22swm1ry5cUrIilqsSGkih7ja4NTkEYcEN8PO/cUY9e12zUcu0j0x4c+3U7HthWO1/+mvLHYPs5AEBRw9YsjyQ1t7dUzv93HyrxZf+78KDpFJ63fQKfsXwNzwVuwfHAXfPHtFYZ7/Nc57CjXwuwQoUu+lyzK37cGyMzaBLqinanrEWLAV8bonzGACsL7BYTqkvTE2DNGCBF0LnMFaxkAqcJbQ8WGce6yqKoq1Kxjo3m6uAUmpyFuj6xkKr7ttWg0GrC9051L7ntiyfbMOcP4s8fMNYKBqXHTK+6d6m2ZWeWR5Ka1og+bV8LvAPPBHahGLMYk8X4pO9jkNrPEAFjrmA1OArghQUDshxrtICobyI9AVa9GFUfTzrRmiP7TYnyRe78OjGY5exFAdTCD+H0XKY9pMRmhtWkwJtCXnp1iQ1lBYkDM6YIGk9tqR1NzkIUWEyY9cWvmherAuW1gSlsNOB+jXgKrWb81p41+M4rXfjkfZtQr63evtY1hn9+pQsfvr3ZkGf4aeXEyFVMohAVtcbqfWYxKSi0mubnKS8s+G++P4cNXtjhxQQW3s8bqosNecKkqtgGswLclFVYo6j7y/pcK08RvD40je1iFLPSinGUcAWLyGC4gpUle5udy+qHVWjAFEEhREqlR4ttZtQ7ChIGTsGgxOQcAyyjqSmzo7LEijpH4lXc+7fVLrnO4w/gxsiMITfEJ/KRO9dBEQKf+tFFSKm+v48cP4f6sgL8+f1cvcpXxVMd6DOvhVCMN2XXRsnW8MC6KLgCgJ0GTX1VFIGaUju6ZfV8U+CbY+4VP+753gnUixH0yQpYTMqy920TUXYY79s6R9y6xoHDd7XCakrt/4LIflduj5YiqOMVLADYuSb58rsldjNqSm0JA6cpjx9Sssmw0dSW2lFZbEu4v+6ujVV46+bqJdffGJmBPyixsTb3AqzG8kJ88r5N+PmlQXz4m6fw3r9/EV2jbnz20I4l6cGUP2q83ZgsXpftYSzL5rrkPqf71jlXeSSrp6G8ED2yGvUYhQV+dI7OrOjxJmZ9WorgGPqlE9UldrYiITIYBlhZYjUr+LP7NmJtRSHscarkhShCDcpMEcteM94ArGYFlhQDtUzb25z85Flqt6Clqjhu9UBA7YEFgHuwDKa21I6KYtuiBtLR3r67YpzRvjowBcCYJZ2T8ZE71+HIA5twsXcCQSnxtQ/vwZvXVya+I+WkidFBVMKFYOXGbA9lWfYmETjta3bi0G2NGRjN6mh0FKA7WA1FSNSLEXSOrGwF62LvBACgToyiX1Yse0sBEWUPT4lmkcWkYH11MYptZpy96Yp77PZGB965o27J9W6vX/erVwBwx/pKKAIIVaCuLLZiZNob9dgSuxkbk6gON6EFWFzBMpaaMhtK7RbsaCjDv2jXrSkvnO9tFRKrWt61wSmYFZEzTYYjCSHwB/esxx/cw3LsBPS2nUUZgIL6bdkeyrJsr0+cvbC/xWnoFZp1lUV4TuuF1SSG8NxkLWa9ARQsc25uG5qGGX5Uw4U+VBqy+AdRvtP3skceuH9bbVI/FG9vqYiaLuX2BpY0H9ajDTUl+NDtzfOX4zVaVgOsxKsT4241QHMWLa9KIWVHVbENdotp0Z4LRaj7GMLFKuV+qW8SrUmscBIJIY4IIQ4JIQ4LIQ4nefwRIcRTQogjmRhjIpM3zgAA6jfvy/JIlieZVN5mg58sWVdVhJtSnZ/XaPuwVpImeGNkBrViHIqQ6JMVOVfQhygf8BdKlt2/rXZRqlQsu5scUSuqGWUFCwC2hOXi22L8OFYEUGK3JFUtbWxGDbDKC7mCZSShM9UbqotRYDGhtaoIw9MeNGhFLzbWFMNRaInaoFpKiddvulLa00f5SQjxOIAOKeVxKeUxAK1CiENxjj8qpXxC+/cwgEf0EGQpg+cxijJU1jZleyjLUmq3JCzQYPTV6HWVRRhEOTzSPF+qPZTKvBydozOog1qivV86sbaCTYaJjIYBVpYVWE1Yl8Ty//bGsqgpFDOewJLKgnoVWrWymhT4w3PBwmysKUFpgRl2S+Kg0eVWUwTLC7mCZURmk4LtjWV4cHsdpub8KNcaUt+xvgrrq4qjvt+7x9wYd/sMW3GMMuqwlPJ42OUTAB6NdqAQwgEgMk/7aKzjM6li6gp67esNWUEw5JYEaYJGD7CaK4oQhIJeWTkfYL2eIO0/ns6RGdRpPbB6ZSWanMZ+fYjykXG/sXPIpur4y/+VxdaopW4BbQUriWBED0Kl2otsJnj90Xti7WpyoMSe3IpUaAWLe7CMa8/acty/tQaAWnYfUNNt7tlUFfX40I+WWPuziABACLE7ytVjAA7EuIsTwBEhREvE9ZGXM8rrmcMafxdmyo25/ypkfXXsjITKYiscBj9JVmQzo9hmwk1ZPZ8imGhfdSxefxA3x2fnmwwPoALNXMEiMhwGWDqQaPn/jw9sjLkB2O0NoMhmtADLDE+MAGt9dQnqyhL3RwLUPVhlBRaYdV5BkWJ7164GbKsvQ1mBBUEpoQi1yuADtywt6AKoAZbdouRsBUFKGyfUgCqcC5hfrVpEStkB4Dbtf0MOAjgZ7cG1PV2nhRCnh4eH0zTkpW5ePQOrCMDSuGPV/kYmtMYJsHY05sbJEmeRFZ2yBi2iHwqCuNQ3EfNEYjzXBqcQCErUiVFMyELYC0s5xxEZED+1OlBoM8Mco+uw3aLgg/vXxryv2xvQdZPhcBVaClhZgQVurz/qMeWFlpjFDSKNu30scGFwG2tKoCgCd26oxPneCfzmrfWoLbXHPOP9+k0XtjeU8QcHJRLtV3so4IpaN1xKeSb031oQdgAxUgSllMeklHuklHuqqqKvtqbDaPtpAED1hr2r9jcyYUPcACs39lNWl9jxenA9SsQsNomb8AUkOkamU36cS32TAIBGMYJeWYV6lmgnMiT+StGJ8hiBQigoiWXG4zfMCpbVrMBRaEF5oRUznkDUY8oLrdhaV5rU443PeOFggYuccN+2WoxMe7G+uhi1MVYwPf4ALvZNMj2QkuHC0kAqdDlyZSuapwDcG7GilXGy93W4pQ0NLbdkcxgrtr66eEkPx5Bc+Tw3OApwSm4GAOxRrgJYXqGLC31qD6xmMYBOWYNWg+9PI8pXDLB0orrEFnUVqyJKJbVwbm8ABRZjrGABaqGLymIrZn3RA6yyQktSBS4ANUXQafDcfVLds6kKFpPAyLQXFTFONpztdsHrD2JPCk2rKW+NYekqlgMApJRxN8do1QcfC1/RypaK8ddxw7YZJrNxvuOjKbFb8KYoDYcriqx4c2tuNNGucxSgR1ZiSDqwQ6hx+ZVlBFjneiZgQgBrxBA6Za3hS9gT5SsGWDrhLLIuKre+u8kBi0nETYGTUsLtNc4KFgCsKS+IukJRYjdj3zpnShUB1RUsBli5oNRuwf6WCjx7dRix+o2+cH0EigBub63I7ODIcLTgKDKQciLGnqoQrYz7iVBwFaNYRkZMukaxzt+ByRpj9r+K9MAttUuue/euhpzpZ1ddYgMg0CedqBHjAIALvRMpPYYvEMSl/knUixFYRQCdsiZugRAi0q/c+GbLAc4i66IUikO3rUFrVXHcAMvjDyIoYZg9WACwpa50vu/XGi23/AuP3Ipv/s5e3Lu5OqWeVuoeLKYI5ooHbqlFx8gMzsf4UfLstWHsXONAaZJVJinvHYvoe3UQaul1AIAQoiX8diHEAahB2GkhhEOrKPhIxkYb4cbZX8AkJEo23pmtIaTVfVuXBljve5Mxe3tFU631+hqW5agS6nfY690uBGK0JInm6sAUvP4gmsUgAKAzWIs15awgSGREDLB0orzQCm9goeLQ3uZybKotme8dFc2MRy0UYaQVrK31pVhXoaY83L2pClaTgt/YWY89zU7saS5PukT7rDeAWV+AK1g55KGd9bBbFHz31e4lt/WMu3GuZyLqjzSiaKSUjwFoEUIc0hoGt0f0xZovYqEVtTgBNQAb1/61I4tl2t1tz8EnTWjZdU+2hpBWtWV23La2fP7yO3fUJdVQ3iiqS9TMjCHpQJVQF0+nPP6U9mGF2lCsE/0AgE5ZO199l4iMhQGWTjiL1MIPoX4XDeUF2FRbEncFy+1V9zEVGKQPFgDsbirHGqe6crWppgT1DjsUbeVuZ6Mj5kboSONutQcWqwjmjlK7Be/e1YAfnOnF0NTcott+ck79wfFglDQjoliklE9IKY9r/3ss4rZjUsqD2n+7pJQiyr+HszNywDF8Gh2W9Sgszo0qewDwpwc3AgD2NTvx179p7MIdkeodaoA1jDJUikmYoZ4APdWZTE0V1TOX1ZWrVtGHSVmAITjinmQlIv1igKUToSqC1SV2lBdaUGg146Ed9Whyxk4PCAVYRTbjpAjWOwpQpZ3pm5zzL+qBkkrp7VCAlUpKIenfo3e1wh8I4kvPtM1fFwhK/PPLXdi3zskN35QXZqZcaPVexXjlnmwPJa3esr4ST33sdvzTR/bFrJxrVLWldggBDEl1la4Carn1F9tHkrr/1JwPL1xXmwu3ij50yHrYLaac2aNGlG+S+uQKIY5oaRaHhRCHk7zPIa0aU1oeL9eFKqeVFZjRoO1NWuMsxAPbYp+xn9F6SYUXxzACu8WEErsZw1Me7G5aXone8RkfAKRUFIP0r7myCB+6vRnfeaUbL3eoPza+d6obPeOz+L23rMvy6Igy4+qLP4ZV+FG8/cFsDyXt9jY7YTMba85KhtmkoLzAimGprjhWa2mCL7WPJrUP63TX+Pw2gValH+2ynvtNiQwsYYClBUkdWprFMQCtERuHI48/oOW7P4oozR5Tfbx8EUoDKLKZ0eBYaCyoxEmZc3uMt4IVUl1iw/CUB7uayhMfHMX8ClaOnQUl4JP3b8K6yiIc/vZp/O1/XcZf/+QS9rc4cf+2mmwPjSjtTv3wK3j5qx9bdF3g0o8xgSJs2ntflkZFy1HnsGNIqj97QpUEJ+f8ePVG4jTB1zrV44swizoxhvZgPWpi9AQkIv1LZgXrcMTG4BOI0d0eAKSUJ6WUTwCI1UMkpcfLF6GNrDazKemqQaEVLCPtwQqp0gKsLUk2FY60kCLIACvXFNvM+Nbv7sPaiiIc+3UHNteW4ivv3w0Rq347kYEFBi5h18BxeObcAIDpyXFsc/0KV8vvgcXK/TdG0lxRiE6pZp20iL756394tjfhfUN7tVq0Ahftsh5NrCBIZFhxA6wYPUDGoFZfSlm6Hy+XVGoNhYUA3r27Ian7zBpwD1ZIVYkdw9OeZeeXh1IEHdyDlZPWOAvxoz96C974q/vwwz98Czd6U86yrrsdNuHDjXMvAAAu/vRJFAoPSm//3SyPjFLVUlWMCRRjSDqwQSwEVScuDyIYJ01w1hvA2W41pbBVC8yuy3psqOGeUyKjSvTr1gk1AArnAubL2qYq3Y+XM4ptZtgtCgqtZmyrT65qVGgFq8hge7AAoKrYhqHJucQHxjDu9qLEboYlhcIYZCxCCJQxgKYc17TzHgDA+JVfY2piDOsufRVXzFuwac+92R0YpSzU47Et2IANykKANTbjjdnfDwBOd42F7b/qg18q6JY1WFPOAIvIqBL9Oo0W9IQCJOcy/l66Hy9nCCFQWWzD2Iwn6fuE9mAVGnIFy4YZb2C+l1eqRqY984VBiIiMqrJ2Da6aN2Fn+1FMfOHNKJcTwP1/A6Hw5JHRNGoFqq7JRqwXvQAWVq1OaiXYo/nlleH5/24VfeiSNfDBjPqw/dhEZCyJvsFdWBr4hC4n39xhmY+nVRk8LYQ4PTw8HHlzzqkqsWFk2pv08UbfgwWogdJyjE57mTZGRDmh4veeQlvhrfAJK87v/xw27837rHlDCu2fvi4bUCzmUBf2s+ap0z3wa6tU4bz+IP7j9YXVrhbRjw5ZD2ChtxYRGU+iAGsMS1edHIDamHEZfy+lx9MaQe6RUu6pqqpaxp8zlqpitfBDsma9AdgtStLNefUkFGCl8nzDjUx7GGARUU6orF+LnY/9HOv+6hx2P8i9V0ZVq1X9awuq+6g3KD3ztw1MzkVdxfrRG30YnVFPrCoIYp1QS7QDQF0ZV7CIjCpugCWlPANteO0+cAAAIABJREFUj1QYJ4CTy/lj6X68XFNZYktpRWfG60eR1XjpgYAaTALLD7BGZ7yoKGaKIBER6YPFpMBRYEGb1AIssbh64Dde6ISUC2mDN8fc+NzPr85fbhTDsAk/2mUdygstbDJMZGDJfHqPRfSpOgjgaOiCEKIlxT5WcR8vn1UV2zDm9kZNI4jG7Qmg0Ga89EAAqC7VAqxlpAj6A0GMu5kiSERE+rKxtgTjKMWILNX2YS149cYYvvWiGmQFghIf/sar6J9YKPYUqiDYHqxHQzlXr4iMLOHyh5TyMSHEES0oagHQHtHH6gCAhwEcB+ZLsR8AcAiAUwjRDuCktnqVzOPlrcoSG6RUKw5VlybOvZ7x+lFoMeYKlrPQCrMiMDCReiXBMbcXUi6UticiItKD/S0VePXGGK7LxZUEQz7140v4+aVB1Jba0TEys+i2+QBL1uPuyuKMjJeIVkdSv861xsGxbjsG4FjY5TNQmwzHu0/M2/JZKG1uaMqTXIBl4BUsRRGoKbUvOnuXrJEpNV+dK1hERKQnB7ZU40vPtKEt2IDfML0ItZLg4n3SL7aPRr1vq+jDsCzFBIqxua5k9QdLRKuGCb46UlWirsgkuw9ryuNHid24fYLqyuzoc82mfL9RrZR9BQMsIiLSkbVOtXdVm2xAmXCjasm289halb75CoItleyBRWRkDLB0pKpYXbVKtvDD9JwPJXZjpggCQJ2jYHkrWFoAyhRBIiLSk9ICdU5uk40AEDVNMJZW0Yf2oBpgra1ggEVkZAywdKRSW8FKtvDD1JwfJQZsMhxSX2bHwMTcoqpKyZhPESzhChYREemHEAI2s4LrweiVBGNxYAoVYmq+RHuTs3DVxkhEq48Blo4UWs0ospqSX8Hy+I29glVmhzcQnO8BkqyRGQ+sJsXQwSUREeWmErsZwyiDSxZhg+hJfAcAe5RrAIBLci2KbWYUcX4jMjQGWDpTU2rH0GTiAMsfCMLtDaDYZuA9WA61DG2/K7U0wZEpLyqLrRDCeA2WiYgotzkKrAAE2mJUEozmbcoZTMkCnA5uQr0jcZErItI3Blg6U1Nqx8Bk4oBjxhMAAEOvYNVrXer7JlIrdDE642GBCyIi0qUqrc9jW7BhSS+sWO5ULuCF4C3wwYxm7r8iMjwGWDpTq+1LSmRyzgcAKDZwgFWnnaXrT7GS4Mi0hwUuiIhIlxq0ue26bESFmEpYSdCJSaxRhvFacAMAYH01e2ARGR0DLJ2pKbVjaGoOwWD8wg/THj8AGHofUkWRFVazknIlwdFpL1ewiIhIlxq09PfXg60AgNu0/VWxbFduAADOyxYAQGM5C1wQGR0DLJ2pKbXBF5AYd8cv/DA1pwVYBu6DJYRQe2GlEGBJKTE67WWTYSIi0qU1Wi+sc7IFbmnDfuVS3OO3iw4AwIVgM4CF7A4iMi4GWDpTW6p+sSbahzXtMX6KIKBWEkwlRXBsxgtvIIjaUgZYRESkP7c0lAIA/DDjdHAj3qRcjnv8FqULncEaTENduQqtgBGRcTHA0pmaMjXAGkwQYC2sYBk7wKovK0BfCgFWKJ2wtowTEBER6c/6qmKYtCK3Lwe3YItyE+WYjHn8RtE735gYUE88EpGxMcDSmfkVrIn4pdrnAywD78ECgKaKQvRPzsHjDyR1fKgACCcgIiLSI7NJQb22j+rl4FYAwD7lStRjLfCjWQzgqhZgldrNhk79JyIVAyydqSqxQYjEKYITs2qKYGmBsb+ImyuKICVwcyy5Vax+raQ7AywiItKr1kp1H9b5+X1Y0dME14l+WEQA14JqgLWhpiRjYySi1cMAS2csJgWVxTYMJij8MDHrg82swG4xZWhkq2NthXqWr2t0Jqnj+yfmYFYEqwgSEZFubalXAyWftg8rVqGL0MrWRdms3q+OARZRLmCApUM1pbbEK1huHxyFxl69AjDfULFz1J3U8QMTc6gptcOkiNUcFhER0bJtDFuJircP617lDG4Ea9Au6wGo+7eIyPgYYOlQbak9YZEL16wXZQZPDwQAR6EFJXZzSitYTA8kIiI9a9JKtQPAc8EdAID7TacXHVODMbxZuYgTwT0A1JOGLQywiHICAywdqim1J7UHy1FgzdCIVo8QAs0VRcmvYE3OoZYBFhER6Vgo/R0Azst1uBJcg982/WL+OhMC+CvLt6FA4tuB+6Lej4iMiwGWDtU7CuBy++D2+mMeMzHrN3yBi5C1FYVJrWBJKdE/McsVLCIi0rWKIius5tBPLIF/DdyDW5UObBFdAID3mJ7DO0yv4v/6H0aPrNKOUud/IjI+Blg61FiufsH2jMeurDfhzo0UQUDdh9UzPgtfIBj3uIlZH+Z8QfbAIiIiXRNCoMGxcDLw3wN3wCPN+Kj5PwEAb1POoldW4KuBh+aPqSuzw2LizzKiXMBPsg41av0zesZjp81NzOZGkQtAXcEKBCV64wSUANDnYg8sIiIyho21C4UuXCjBscA78R7T8/iK5Yt40HQKvw7sQGjvFQCsrSiK8ihEZEQMsHRojTP+CpYvEMSMN5A7K1hav5AbI/HTBAcm1deDe7CIiEjvIisCfsH/XvyD/524WzmHXlmBfwocXHQ7918R5Q5ztgdAS1UV22AzK7g5Fn0FK9RkOFcCrI3V6lm+KwNTeOvm6pjH9WorWPVMESQiIp2LXJEKwITP+N+Pz/jfh/CVq5B965wZGhkRrTauYOmQEAKN5QUxV7DGZrwAAGeR8asIAkBZoQUNjgJc7l/aIyRc9+gMbGYF1SVsMkxERPrW5Iy1IhW9j+Md6ytXbzBElFEMsHSqsbwQN2PswRqZ9gAAKopzI8AC1O71iQKszlE31lYUQmGTYSIi0rk1MQOspdZVFqK6lOnvRLmCAZZOrXHGXsEamVZXsKqKc2clZ0tdKTpGZjDnC8Q8pmt0ZlHzRiIiIr2qLbXDnOSvrK31Zas7GCLKKAZYOtVYXgiX24epOd+S20bnV7ByJ8DaXFuKQFCibXA66u3BoETXqBvN3ARMREQGYFIEGsqTm7M215QkPoiIDINFLnQqvBfWlrrFxSxGpj0wKQKOHClyAagpggBwuX8S2xuXnskbmJyDxx/E2kquYBFRcoQQRwB0AHACgJTyWDqPJ0pkTXkhukZjt1wJ2VxXmoHREFGmcAVLp9bM98JamiY4Ou2Fs8iaU3uR1lYUocBiwqUY+7CuDU4BADZWF0e9nYgonBDicQAdUsrjWqDUKoQ4lK7jiZKxPsk5q7WKJw+JcgkDLJ0KVR/qjNIbamTai4ocqSAYYlIEttaX4o0eV9Tb5wMsplEQUXIOSymPh10+AeDRNB5PlNCuJkdSxzWUs/0IUS5hgKVT5UVWOIus6BhZuidpZNqDyhzafxXypnVOnO+ZwIzHv+S2qwPTqC6xoTzHAksiSj8hxO4oV48BOJCO44mStWtNecJjqktssJlNGRgNEWUKAywda6ksQvvw0hWswck51ORgOdf9LRXwByVOd40vue1y/yQ21XL1ioiS4oQaIIVzAYAQItqSQqrHEyVljbMg4QnRRq5eEeUcBlg61lpVjI7hxStYvkAQg5NzOZlOsKe5HBaTwEvto4uun/H4cXVwCreu4e8cIkpKtC+LUADlXOnxQojDQojTQojTw8PDyxwi5QMhBPasjb+KlWylQSIyDgZYOtZSVYSRaS9cbu/8dQMTcwhKoMGReytYhVYzdjY68HLH4gDrjR4XAkGJ3U2JUy2IiKCuPkUGRqHLkStVKR8vpTwmpdwjpdxTVVW1ooFS7tvTHH/u4goWUe5hgKVjoZS4y/1T89f1udSqgvWO3PxC3t9SgfO9E5gM6/91ulNNGUx2szAR5b0xLF2VcgCAlDJaJZ1UjydK2m0JVrB2NLDJMFGuYYClY1vr1b4Yl8NKl/dN5HaA9bYt1QgEJX52YWD+ul9cGcLOxjI4ClnggogSk1KegbaHKowTwMl0HE+Uii11pTDFaauyb120rFUiMjIGWDpWXWJHZbF1UYDVq/XFqi/LzQBr1xoH1lYU4gdnegAAQ5NzeKPHhXu31GR5ZERkMMci+lgdBHA0dEEI0RJxe9zjiZbLbjFhQ4x+WJtqSlCRg1WBifIdAyyd21JXivO9E/OXrw1Oo8FRgAJrbpZ0FULg/fua8HLHGF6/6cK3X+oCALxzR12WR0ZERiKlfAxAixDikBDiCID2iD5XBxDW5yqJ44mW7ZYYaYAfvH1thkdCRJlgzvYAKL69zU58/uQ1TLh9KCu04FL/JLbU5Xa58g/sX4snn+vAB558GXP+IN5+Sx1aqqKf/SMiikVK+USc244BOJbs8UQrceeGShx/rWfRdTsby/DwbY1ZGhERrSauYOncvnVOSAmc7hrDnC+AjuFpbK0rzfawVlWxzYwnP7QHa5yFeNM6J/76Xbdke0hERETLdmBLDeyWxT+5/vjARtgtuZmNQpTvuIKlc7euccBmVvCrq8NwFFoQlAvFL3LZrqZy/PSP78r2MIiIiFasyGbGg7fU4d/P9s5fFyttkIiMjytYOme3mHBgSw3+63w/fnKuHxaTwO2tldkeFhEREaXgg/ub5v+7usSGqhIWtyDKVQywDOC9tzVgdMaLb77QiTvWV6KswJLtIREREVEKblvrxB+9dT0A4N4t1VkeDRGtJqYIGsDbNtfgE29bj1dujOF/vWNLtodDREREy/DJ+zfh9+5Yh/JCniglymVJBVhaydoOqI0XQ9WXlnW81mekBcBxAGMADgM4LqXsWMb488af3rcp20MgIiKiFXIWWbM9BCJaZQlTBIUQjwPokFIe1wKl1ohmjKke7wTwOIB2ADe0YxlcERERERGR4SWzB+twRLPFEwhrzrjM48sBtEopy9nIkYiIiIiIckXcFEEhxO4oV48BOLCS46WULgCuJMdIRERERERkCIn2YDmhBkjhXAAghHBogVLKxwshDmvHOQE4pJRPLGPsREREREREupIowHJEuS4UQDmxdBUqmeNPAhgLC7aOCiEORyucoQVihwGgqakp8mYiIiIiIiJdSbQHywWtEmCY0OXIlaqkjpdSdkSsfJ0A8Fi0Py6lPCal3COl3FNVVZVgqERERERERNmVKMAaw9JVKQcwv48qpeOFEA4hhBRChB/jglq2nYiIiIiIyNDiBlhSyjNYmgbohJrmt9zjH4sIzloAnElqtERERERERDqWTJn2YxF9rA4COBq6IIRoibg95vExVr0eBvDp5IdMRERERESkT4mKXEBK+ZgQ4ogWNLUAaI/oXXUAapB0PMnjjwkhjkBd6WoFcJS9sIiIiIiIKBckDLAAIF4Zda3637GI6+Id7wLAsuxERERERJRzkkkRJCIiIiIioiQIKWW2x5AUIcQwgK4VPkwlgJE0DCcX8bWJjq9LdHxdouPrEl06Xpe1Ukrd9evg3LSq+LpEx9clNr420fF1iW7V5ibDBFjpIIQ4LaXck+1x6BFfm+j4ukTH1yU6vi7R8XWJj69PdHxdouPrEhtfm+j4ukS3mq8LUwSJiIiIiIjShAEWERERERFRmuRbgHUs8SF5i69NdHxdouPrEh1fl+j4usTH1yc6vi7R8XWJja9NdHxdolu11yWv9mARERERERGtpnxbwSIiIiIiIlo1STUaJuMSQhwCsFdK+ViU244A6ADgBOabRid9O1E+EkIclVI+GnEdP0tEKeDcRJRenJv0JW8CrHx7EwkhDgDYDeAg1OcdefvjAE5JKY+HLgshDoVfjne70WnvBwDYC/V5PhHl9rz6UhJCOAAcBuAC0AoAkT9+8vF1Cad9LlqiXJd3nyXtB3ILgOMAxqC+d45LKTvCjsnr90si+fj8OTfFx7lpKc5NiXFuWqCbuUlKmfP/ADwO4FCsy7n8T3uuR6NcPx5x+QCAE8nebuR/ka8HgNcAHEn2/ZKr7ycAj0d5XQ7n++sS9nxatOd0IuL6vPwsQZ20pPZvPPL/63x/vyTx+vH5c26KfO6cm2K8V6K8LpybFp4P56bFz0MXc1PWX4gMvdg5+SZK8rkvmcSgnj2MfE12A5DJ3G7kfwAcUb6sDwNoT/b9kqvvJwDtEZPWUwCeyvfXJeJ9Evmc8/mzdFj7PLXEuD2v3y9JvH75/vw5Ny1+HpybYr82nJvivz6cm5a+Hlmfm3K+yIUQYneUq8egvmD5ygn1NQjnAuaX4hPdbmROAEeEEC0R17cAid8vOf5+OigXL4O3ADgF5P3rEkpr+n6Um/L5swQppUuGpV2E5Pv7JZF8f/5x5PPniXNTbJybYuDcFJ0e5qZ82IMV900kpXRlfkhZF+3DE3qNnEncbtjXTErZIYS4LeKDdxDASe2/V/SlZOT3k1ycn7xbuy6U/5+3r4vGIaV0CSGWXB/l2Lz4LAGAEOIw1OfjhPoa8f2SnHx//rHk7eeJc1NsnJvi4twUhR7mpnwIsHL6TbRMLmgb98KELo8lcbuhSSnPhP5b+0AdAHCbdlW+fyk5APwWgIcBfDTsprx9XRJs+s3nz9JJAGOhCUcIcVQIcVg705y375ck5fvzjyWfP0+cm+Lg3LQU56aYdDE35XyKIHL7TbRcY1j6JnIA6rJqErfnkqcA3Bt2hiyfv5RCy+rHpJQHATypnQUC8vR10dJ14r3n8/azJKXsiHgOJwCEKnvl5fslBfn+/GPJ289TFJybwnBuWoxzU2x6mZvyIcDK2TfRcmlnySKfuxNaKkKi23OFVqL0sfCzhsjjL6UoeddHtX9A/r4uuwG0CCEOaxP6o2GXW/L1sySEcAghZMR7xoWFMsH5+n5JVr4//6jy9fMUiXPTYpybouLcFIWe5qacD7By9U2UBse0XgEhB7HwhZXM7YamPbcToQksLK87X7+UDgAYj7W5NV9fFynlce2s6TEtveAEgNCZ1NCZ5Xz9LD0WMeG0ADgD5O/7JVn5/vwTyNfPEwDOTZE4N0XHuSkuXcxNOR9gaXL1TRSTEGK31ijtEIDfEkIcCa+OItUmfS1CiEPace3hubyJbjcy7QvbCeC0drajBcAjYYfk45fSaQBPRHwpHYTaqC8kH1+XedpZwoehfi6OhCb8fPwsxTiT9zCAT4ddzuv3SxLy8vlzboqNc1NUnJsS4Ny0QE9zk5BqjfecJxa6MrdAi/KzPCTKAu2LZzzKTcellA+HHRf3/ZKL7yftR84BqGdvWoH5L+DwY/LudaHotM/SYSy8X05FTs58v8SX78+fFnBuio1zE6VCL3NT3gRYREREREREqy1fUgSJiIiIiIhWHQMsIiIiIiKiNGGARURERERElCYMsIiIiIiIiNKEARYREREREVGaMMAiIiIiIiJKEwZYREREREREacIAi4iIiIiIKE0YYBEREREREaUJAywiIiIiIqI0YYBFRERERESUJgywiAxGCOHI9hiIiIjCcW4iWsAAi2iFhBAtQojHhRDjQogTcY47JISQQoinhBAHlvF3HEKIpwCMr2jA6mMd0f49JYQ4stLHIyIifTHi3BTxuEfT+XhEmWTO9gCIjE5K2QHgMSHEKIDHhRAOKaUryqFO7X8/GuP2RH/HBeBhIYRcwXAhhDgqpXw07PJrQghIKZ9YyeMSEZF+GG1uCieEeBxAS7oejyjTuIJFlD4dAI4DOBx5gxBiN4DTwPxklBVaCkfk3z8K4NEohxMRkfHpfm4KJ4RgYEWGxwCLKL1iBStOqJNctjkBHIkygXFCIyLKXXqfm8IdABAzpZHICJgiSJRGUsqTQginEGK3lPJMouO1FaXDWJjgWiJT9bQ9UqHbl5xh1B7jfwI4BTVQOiOlPBljfB1CiNu01JGQgwCiHk9ERMan97kp7D4HAHwfwJ5EYyTSMwZYROl3DOqZwkcBdcLQJrdoFZaeAXBvKDVDCHEgfI+UtjH5sdCEGCN14jUAB0NBkxCiXQuioqZ7hE+u2pgOALhtmc+ViIiMQddzk8YhpXQJIZb7HIl0gSmCROl3FFFy3SOFqjWFTzba2b3DWlWm3VDPGp4Ju70j4jEORbn+DNSgKRlPQZ1E9ZYiQkRE6aXruUkIcUhKeTzJ50Kka1zBIkozLQ3vjDbBnAQwFuPQ3TFuc0FNj2hBlLSLCC0AXBGldU8lcb9QlabHkkkXISIiY9Pz3KStgOmiyAZROjDAIlodoQ3Frjg55x1YKI8bzgG1qtMYgMcT/J0zAB6J+BsJ91NpE+yJsPSOpPLyiYjI0PQ6N+0G4BRChFbYDgJo0S6fZJYFGQ1TBInSZz4HXUp5DGoqxJLc9lC+eygVIjx3XQt8jkspXVrA06GlY4Ru3x3+WKHJK+IxHJHHRfz9A1Anz9PasS0AHknxuRIRkTHofm6SUh6XUh4L/YNaRdClXWZwRYbDFSyiFdImkMeg5qdXSCkf0256AtoZOy2oCZXIfVzbLHwGwL0A/qcQ4hTUoMchpXw47OFDt4fSJxza4z2FhaaQ4Y8BYGGCjDJWBxbK3x4Nu4l570REOcRIc1PEuA8DeBjqCtYRAMf00qOLKFlCyrQ13iYiIiIiIsprTBEkIiIiIiJKEwZYREREREREacIAi4iIiIiIKE3SUuRCqy6zN2wDZbxjjyCsBKhWLYaIiIiIiMjwVrSCJYQ4oAVMjyJKyc8oxz8OoCNUjhNAa6jbNxERERERkdGlpYqgFjg5pJSPJjhuXEpZHnb5AIDHpJQHE/2NyspK2dzcvOKxEhGR8bz22msjUsqqbI8jEucmIqL8FWtuylgfrBjN5cagNrxLqLm5GadPn07voIiIyBCEEF3ZHkM0nJuIiPJXrLkpk0UunFADqnAuYKF7OBERERERkZFlMsCKFkSFAi5nBsdBRERERES0KjIZYLmwNJAKXY5c2QIACCEOCyFOCyFODw8Pr+rgiIiIiIiIViqTAdYYlq5iOQBASumKdgcp5TEp5R4p5Z6qKt3tbSYiIiIiIlokYwGWlPIMtD1XYZwATmZqDERERERERKtpVQMsIURLRJ+rYxGXDwI4uppjICIiIiIiypQVlWnXSq8fAHAIgFMI0Q7gpLZaBe22hwEcBwAp5WNCiCNakNUCoF1KeXwlYyAiIiIiItKLFQVYWiB1BsATMW4/BuBYxHVRjyUiIiIiIjK6TBa5ICIiIiIiymkMsIiIiIiIiNKEARYREREREVGaMMAyEClltodARERkCP5AkPMmEWUFAyyDkFLiJ+f6sz0MIiIi3QsEJe77/K/xUvtotodCRHmIAZYB/Oe5frztc8/if/37ecz5/NkeDhERkW5JKfGlZ9rQMTKDE5cHsz0cIspDDLB0rn9iFn/8r2dxY2QGk3N+/OW/X8j2kIiIiHTr2uA0vvhMGwDg+Gs9+MLJa1keERHlGwZYOvftl7oQCEp84m3rAQAnLg9leURERET69ey1hXlyas6Pp88PZHE0RJSPGGDpmJQSP36jD3dvrMLgpAcAMDHrw80xd5ZHRkREpD8j0x784LXeRdddG5rCxKwvSyMionzEAEvHbozMoGd8FndvrMLPLi2cgfvnl7tYGYmIiCjCv566iauDU4uukxL4zNOX8WL7SJZGRUT5hgGWjj1/XZ0MCm0muNwLZ9++/vwNjEx7szUsIiIiXYqV4fHdV2/i0/91JcOjIaJ8xQBLx17vdqG6xIbLfYvPxvmDEp0j01kaVWa4vX58/LtnsedvTuDvfnk928MhIiID6I6TQn91cAq+QDCDoyHKrhsjM9keQt5igKVjr/e4sKPRMb+SFe5c72QWRpQ5n3n6Cn5yrg9VJXZ89mdX8dML7AFGRETxxQuwvP4g2odz++Qk5bdgUOJs9zh+dXUIbo8fx37dnu0h5S0GWDo1OedDx/AMpJRoG1o6IZzpGs/CqDLj5pgb//RyFz60fy1+8vE7sL66GJ/7+TXuOyMioph8gSD6J+biHvPBr72CXtdshkZElDkX+yZw8PPP4t1//yJ+55un8I4vP4+fXhjA0+f7+fspCxhg6dS1ATUt8Jkr0cuyXx3M3RWs77zSDUUIfOyeVpgUgcN3tqBtaDqng0oiIlqZzpEZBILxf0iOTHtxvmciQyMiyoxrg1N437GXMeMJoLzQAkBNDxx3+/D73zmDB7/4HP74e2ezPMr8wgBLp64Nxk9j6Bp1I5hgIjGiUGn6ezZWoa6sAB3D07gyMAWzIvD913qyPTwiItKplztGkzruQi8DLModHn8Af/idM7CaTfjG7+7FuHtpS4IrA1P4z/P98Pq5BzFTGGDpVNvQFBQR+3ZfQOJSf+6tYl3sm0Svaxb331KLwck5fPy7Z/GtlzoBAL+6yibLRJQ8IcQRIcQhIcRhIcThBMceFUK0ZGpslH4vticXYL16Y2yVR0KUOd98oRNtQ9P47MM7MBEluArxBSSuR9lyQquDAZZOtQ1OwxQvwgLwkW+dwtRcbjVPDAVR926uxtnucVzsm0QgKOEPSgxOetA9yibLRJSYEOJxAB1SyuNSymMAWoUQh+Lc5QCAdiGEjPgXNzAjfQgGZdIrWK92juG5tuFVHhHR6hue8uArv7iOA1uq8dZN1TjTHX8rxeUcPDGvVwywdKp9eBq+QPwUwIFJDwYn42/oNZoX20expa4UFcU2nOl2Lbn9pQ42iiSipByWUh4Pu3wCwKNxjj8J4DYArWH/ntCCM9K5q4NTUVOjYvn5xcFVHA1RZvzdL69jzhfAX7x9CwDgdGf81dl/PXUz4T5FSg8GWDo05wtgIEElpJChSc8qjyZz5nwBvNY1jttbKgAAr0UUtbCYBM5GCbqIiMIJIXZHuXoM6ipVLI9LKc9IKTuklB3asZ9elQFS2r2UZHpgyOs31bmE1dXIqEanPfjeqW68a1cDWqqK8Q/PtuN0Z/wVrFc7x7jdIkMYYOlQz7gbyX7lD07lzgrW5f5JePxB7FtXjjlfYEmlJ39QJvzyICIC4IQaUIVzAYAQwhHtDlpQBe2Y3VDTC3lihdjsAAAgAElEQVRGxyAu9KVWuOJy/yQu90/ii8+0rdKIiFbXt17qwpwviI/d3YL24Wl85ukrmPL4E97vV1eZHpsJDLB0qHMk+X1GubSCdV6r7LS90YE3brrgDSyudiMlcH14GjNJfIEQUV6LFkSFAi5nEvd/VEp5MtaNWtGM00KI08PD/LGiB20JKu9G8gclHvzic/iP1/tWaUREq2fOF8A/vdSJg1trsL66BF9//kbS9z1xaZC/ozKAAZYOdY7OJH3sYC4FWD0TqCiyor7Mjn870xvzuFdvpJYKQkR5x4WlgVToctxNCkKIAwDa4x0jpTwmpdwjpdxTVVW1/FFSWgSDy6+OdmNkBlcHpuALBHGxbwIvto/gJ+f6mDpIuvaziwMYd/vw4dubMTLtwfEU2tgMTM7hUz+6uIqjIwAwZ3sAtFRXCgHWUA6lCJ7vncAtDWWY8Qbwozdin1V8o2cCb91ck8GREZHBjGHpKpYDAJJI+3sUwL+uxqBodfSMz2LWF1j2/R/6yvO4Y30lnr02DJMQ2LmmDGZF4J5N1bBbTGkcKVF6fOeVbqytKMSbWyvwd7+8nnJ/qx++3osjD2xGVYltlUZIXMHSoc4USpHnSorgrDeAtqFp7Ggsw3+e64s7WV5hmVEiikNKeQbanqswTqiVAhM5BKAj4VGkG08+t7L/u7z+IH5xZQiBoIQ3EMSZbhf+/lftOJWgIhtRNlwfmsarN8bw23uboCgCT18YSPkxfAGJF66zKvNqYoClQ32u2aSPzZUy7Zf61X5XRTYzPn8i/qbjVAJQIspbxyL6Xh0EcDR0QQjREtkXK6wABotbGMgPziSfHpWMQFDiXM8EfnmF++tIf773ajfMisCh2xoRDEp0jCw/PZZWDwMsHRqaSn5Vang6N1awLmgFLsZnPBhIEDSmEoASUX6SUj4GoEUIcUgIcQRAe0RfrAOI3herAwn2aZF+uL1+uL3LTw+M59lrLGdN+jLnC+D4mR7cv60WVSU29E3MYs6XWnpgSCr7/Sl13IOlMx5/AFNzyVd3cXsDmPMFDJ8nfmVgEo5CC8ZnEjeKnJzzY9rjR7GNb18iik1K+USc244BOBZxnQtqg2EyiNFp76o9dvvwDD5/4hp+583NKC+yrtrfIUrWzy4OwOX24X37mgCo79Hl4grW6uIKls7EajB82PRj/ND6l0CUDlmjM6s3wWTK9aFpbKwuQe9EcqtTy60YRUREuSPe/GeHB06sbM/uF59pw88upr7HhWg1/EtYcQtA7ee2XDeGZ1gtcxUxwNKZPlf0AOsvLN/FrUoH7lAuLLltJIWUQj2SUqJtaBqt1cXoGU8uwLo2OLXKoyIiIr0bjZEm78QkXrR9HM/b/jv+1Px9FGL5+5VPXmaqIGVf+/A0XgkrbuHxB/DtFzuX/XhTHn9OtfrRGwZYOtMfYwVnShYAAP7M/BQEFufbjhh8H9bojBcutw+tVUVJ76+6NsAAi4go38VKEfyw+edwimkUCg8+Yf4h3mN6btl/4/WbLp7pp6z77isLxS0A4MX2UfTFyHpK1lWerF41DLB0pj/Kh6UCEygRs7gYXItdynXcqZxfdLvRA6xQup9JCPgCyU1i57WiGERElL9GZpbOfwqCeLfyHJ4L3IIfB/YDAB4x/RKHTT9GKVJPLx+Z9qz4hyzRSsz5AvhBWHELAHipfXTFj8uT1auHAZbO9LlmoYjF121RugEAX/a/GwCwXdxYdLvRl3jbtADrQl/yQROr3xAR0cjU0hWs95p+jSZlGP8SuBcf930CX/H/JrYrnfgLy3fxQdMzy/o7b9xk5X7Knp9dHMB4WHELAHixfeV9rK4wwFo1DLB0pn9iDkIsjrB+3/QjjMtivBC8BV3Barzb9DwaxUJOePeYsYON9qFpFFlNePp8f9L3SabaIBER5ba2oaU/EH/H9DOcDzbj6eA+AMAX/O/Fn3h/HwCwV7mCaMWiErnArAnKon95pRtNzoXiFh5/AFf6Vx4cnevhiYPVwgBLZ/onZhEMLnz5V2McbzFdxJP+d2AKhRhBGdYrfXjS8rn5YzpWUKZTD9qGplBaYIE7hV4O3kAQU3MMsoiI8pXb68crHYtblpViGltEN04E9gBQT1b6Yca/B+/Ed/z34q2mN/APli+k/Lcu9q2sGiHRcoWKW7xvn1rcAgDaBqfhD658X2Db0DRcbuNXotYjBlg60++a086tSfyG8gLuNr0BAHgpuBUAcDxwFwBgnVgoG5ts5T29uj40vaw+XjfHjP28iYho+V69MQZvYPGJub3KVShC4pXgliXHfy/wVgDAA6ZTsCK1E3QMsChbvvfq4uIWAHAxhS0ViZzpHk/bY9ECBlg64vEH4JpVv/TXi158yfp3+KxF7YN5Sa4FAHw3cC++7H8XzAjADLUh8ci0B/7A8jp5Z5vbq5YJFYkPXeKmwVMjiYho+c73RP7IlPio+b8wLovxulzaL/q8bMFh758AAHaK9pT+1si0B//4wo3EBxKl0ZwvgOOv9eC+bTXzxS0AtYJgupxb8jmidGCApSPh5WbXi775/341uAkeLHSR7wzWwiyCaBTDAICgBK4NGrPxbveYGwDg8ccOEIvhjnr9ZW7OJCLKW5GrSutFL/Yrl/Fl/7sXzZnhXg1uhl8qeNT84yUtTxL56rOpBWVEK/XTC2pxi/fvWzt/3fWhafzojb4490rNSpoVU2wMsHQkvNx6qxZg3en5PD7q/bNFx3XKGgBAsxicv+7j3z2TgRGmX9eoGjxF2091p3IO37H8v7hg/wiOWz+F90dUf7rKACsvjM942YOGiJa4FPHDsEWohZJOBzfGvI8LJXjC/wgOmM5it2hL6e8NTnowPGXsqr1kLN9+qRMtlUXzxS0A4EzXOOJNiWb40Sz68W7lOXzL8pn5bKdYLqehWAYtxQBLR8K/uFuVPvTKCtyUNZhA8aLjrssGBKVYlOLQ5zJmj44urdz65NzSL4DPWo7iLaaLAIA9yjX8reXri27vGGGKYD5435Mv49ivO+YDapZLJqJpj38+AyKkSauu26WdhIzl37S9zPuVy3iv8mtYEvwADZfOvS9E8VzoncCZbhc+uH/tfHELQC16EctucQ3X7R/Cr2x/hs9bv4q7TeewX7kc9+90j7kxavB+qnrEAEtHBuYbGUpsFzfQHqyPetwEinFGbsA7TC8jVG521heA25v8JKEXnaNulBWYl1xvhh9liB9ADbLxY84LBCXah6fx6aev4PMnruGVjlF8+RfXsz0sIsqyaBkMa8UgJmThkpOSkUZQhkHpwJ9bvo/PWf8BDyivJv13WeyCMuWfXupCgcWE94YVtwDiB1hvN72y5LonLEexWXTH/VuffvrK8gZJMTHA0pGb4+rZuPuU09ig9OLHwdtjHvt0YB82Kr34ouXv5q+L1nBR77pH3SgvXJorv010okB48QfeT+Buz/9Fj6wEANixcJZlcs7H1LEcdn1oCv0Ts/AF1P+PT14exEe+dRqvdY3x/3eiPHdtMHqAlWj1KuSZwK75/96tJJ8qGJmWSLQaJtw+/McbvXjXrgaUFVgW3dYepzXPbqUNs9I6//4elqUohAc/tf0P/ND6/2BTjEDr5xcHOK+mGQMsHQml+d2hXMCkLMS/Be6Meew3Aw/gWrABu8JyyEdmjLfE2zk6A5OytIbgPkU9m3IquBldshZP+B4BgPnCHoBa3GPKY7xVO0rOL68M47WuhfKx/qDElMePcbcP14eMWdSFiNIj2gpWsxhIOsD6P/4PYdfcP+ClwFb8rvln+E3leawNa38SC1OUKRP++ZUuzPmC+NDtaxddf31oGp2j0QOsUsxgh+jA1wMP4iO+P8Of+w7jDs+X8HbPp3HU/w7cqrTjsPk/o953cs6PPmYFpRUDLB0ZmFTf3HViFL2yEgHE7g0VhIJfBW9FtXAhlCYYXoXQCLz+IPpcs5iOEiTtU66gI1iLYTgAAD2yCsDiAAsAesaiVxgk47s2OIUfvR69UtJLHekrUUtExhO5glUMN5qUYVwONiV1/znYMI5S/CJ4KwDgi9a/x7O2P8V7lF+jAcMx79czHn3OIkqXWW8A33j+Bu7ZVIUtdaWLrv+r/7gQtcCFCQH8d/O/wSyCeCawGxIKngrcAw+s6EMlPu3/AE4EduNWETvF/hLTX9OKAZaOhDYZ1otR9MmKBEcDQ9IBu/ChVCtjbrRNij3jbgTl0tRGBUHsVa7iVHDz/HWdshZBKXC7cmnRsVdYSTBntQ1N49lr0X/ovHB9BAAwMZtas1Aiyg2R+1BCe0wuy7XRDo/pycA7/n/2zjw+krLO/++nunPf9z3JZGYy9z0DM4DcoIKicqkoi/5UvHd1XWE9dtXVXRdvF10FBUUFQUAUEJdzOOZghrnvTO776hydpJNOH/X8/qi+j6Q76SSdTL1fL15Mqqu6Kkmn6vlenw/XTtyDQ2rLoR8l/pLXkr5IlUuRMBQHmwaivFqdeMKpSk+QfKR1kNfDPGfmi8feaqXfYuOzVyz32/7bvc1h/a++bHyMjxn/zrBMDekBB3BUXc4ypYtMQneA6AFWbNEDrDhicExbLJaIfrpk7pT790qtulMgtJaFfsvCqmC5JdqdAemYzaKObGFht7rOs22ATP6iXswdhhfYJrzDmHUh+vB1Fj5vNvZzumsYhxq6J3xvQz/mcTu/fqNxjq9MR0dnvhmx2ukZ9k8orlFaADitRhdggeCcrKBm4nd8zvZ5nnHuwChULlTCD/0/fKAl2kvWiSOaTBaaTRaGxmzc+Iu9fPS3b7G7zsQfD7Rim8STcy6wOVTuf72RC6py2V7lvw482Bw6sK8SXXzM8Hda1EI+YrsLGWZp/6a6GoBPGJ8L+fpJXSEzpugBVhwxanWQzAS5YjSiCpa7fa7QFWAtNH+O9sHg9r5y0cu/JfwBmzTwqqt1w8137bfRK7P594Tfe7Y19+stgouRH75QO+mDbsTq4IE3GnniUDsP7m6awyvT0dGZbxpDDPlvUJowyUx6yJnWe6ooPKvu5PP2zzMiU7gn4Vdcp7wZct99DbrQzkLmVKeZ9sFx3mzsR0qtovXhB/bzlT+f4McvnZvXa3vycDudZiufucK/CqWqkoM+M8m+fMn4ODaM3GT7FodleA+4Q3Ilf3ZewicNz5AZQqX5VIceYMUSPcCKE8ZsDmxOlRKhZSi6ImwRBChE+6PrW3AtguP46ltkYuG5xK+ySWngYefVjJDqt38f2exW11MivCXyzqHxubpcnTliwuHkWPvUN/pf726iy2zl0bcml5/V0dFZXISSqd4qajmsrgCCRZOiQ3ierf+W8IeQe4xOODjXowvtLFROdpjpGBoP2W53/+uNdMzTumLc5uQnL51j85JsLqsp8Hvta385GbIlfo1o5t2GN3nQ+U5MZE15jt87riFROLlSORL0WqfZuuBGTeKZmARYQoi7hBA3CyHuFELcGcH+d/r8d1csrmGh455DKhJasNRNJC2CWqZuwVawhsYxGrwfwWrRRaYY459tn+JbjjtCHtNHFrmMoKBVNxZaUKkzNac6hyNq0xizOQEtmz3fbR06OjpzR6CCYB5mlio9HFTDZ++j4Yv2z9Atc8jHTBqhF9vPnQg/o6UTv/QMW/nz4Q7aB8fYFyLAcqqSXWd75+HK4ME9TfQMT/DV61YjhDdR4HCqPHWkPeQxNxnewCoT+JXj+ojOcVQuo00t4EvGx8knOJGpJw5ix4wDLCHEPUCjlPIJKeX9wDIhxM2T7H+XlPJ+93/AS3qQBX2jmoJgLtqQ4YDMmPKYEVIYl4kLNsBqGxjD7rMwLhOacMEpWRX2GJPMwiAkuWgPWPOYLnKw2Ii2TcGhyrCytTo6OouPMwEB1npFm8U8oq6Iyfsfl8v4ov0zJAgnOwKEldw8czy0wqlO/NI+OMYNP9tNv8XGsbYh6sLYfYQTV5pNOobG+fmueq5ZUxQ0e3W2ewSrPXQScYPSwEm5lGHSIjqPROGz9n+kRPTzsRCzWG0hRjd0pkcsKlh3Simf8Pn6ReCTk+z/ft8vpJSHge0xuI4FTZ+rgpUrtAfHgMycbHcXWitDwQINsFoHxvDtYi91BVidLlPhUPS7fi75QluEj9uds3Z9OvND7TSES45H0FKoo6OzODgbYPa7QnQAcE6Wx+wch9QaxmUilygnQ77e2GfR/fgWGD984ZxHHOVwa3g/s5OuJN/JOZxJ+ubTp1Cl5N/ftSbotSOtoWevDDhZJ5o5rlZHda7jchkvqNv4gGEXBvzXULr1TeyYUYAlhNgSYvMAcPUkhw0IIR73eY87gcdmch2LgQGXAmCOqzIzSHpEx/WSTSHajWJ0wsGYbWH4c1jtToYCqk9lwsSwTA2avfLFJLUeY3eApUoY0z1JFhXnuqNftMxHxlFHR2fuGbDY6A1IJi4XnfTJTMwRPjcjwUYC+9XVfNT4PNtFaEXB+Wol04meY21DPHWkI6J9u8xWeoatfPmJ46hhlGxjyV+PdvDi6R6+cHUNFbn+6x8pJY8dbAt53AXKWVKEjaNqaFn2yXjRuZUcMUpVgLl226A+1x4rZlrBykULqHwZAhBCZIc55pPAFiHEoKs1cCCgAnZeMjjmrWANy1QcGCM6rldme1oEYeFUsUINkZYJEx1TiHu4hzh9e4enU/HQiU+klNP6fb5+rg/nHDwIdXR05pdQAhfLlQ7q1dhVr9z8yXkZAP+a8Meg1/LSEnm9Tk/sLBReOtMT1f5/O97Fma7hqI+LlpZ+C1976iTbKnP4+CVLg14/1m7mZEdof6qvGB+hQ+bxoro16vPWygoAVgn/4K1Nr2DFjJkGWKGCKHfAFVKlQUrZCNwHNAL3MEl7oEsE46AQ4mBf3+K+kZlcYg25YoT+MPNXaYmGoG29MscvwArM7MUrHQFZki3iHBcqZ2iWxZMeF1jBgrkt4+vMLvW9o9MyDzaP2+ky65k3HZ3FTmNAgJWInRWinXpZGvNzPafu4D7H9awTTSTif1/KT0/iQNMAVr1NfUHQZbZGtf+zrhm72RQzMY/Z+cTvDqII+MkHNvmJfrl5JUyVdJnoYIPSxP2OdzFOctTnrpdlOKTCSsVfhVefwYodMw2whggOpNxfh3REE0LcBxyWUm4FbgHu9G0Z9MUlhLFNSrmtoKAg1C6Lhl5XX3AOIwwSHGAlJyh8LER2o09mkynGSEKrgC2UClarT5YkDzMPJn4fk8ziPx0fmvS4YVIZlOmsVrxGjy26F9ai4aUz02+5aTbpnwMdncVOo8lf0Oadyn4yxTgvqNvCHnNpzfTXD4fVFSQJB2tFs9/2BKNgwqFyoCm0+atOfNEzHF2A5Z7Rau4fw+FUY+57ZrU7+cTvDtJksvDLD2+lPCf0aMRrtaGfiW9XDgLwvDP8534ybCTQJEuCKlg9wxN60iBGzDTAGiC4ipUNIKUMmiB0z2xJKV9y/f8JYCsQVnXwfMEtN54nhj1CDr7UFGXwoR2VQVWsXo/ZsDYEGe1NZL7wbQNbpzSTLSx8zfEx2mXhFEcKXlE3caVy1DOcuVCCSp2pee3c9AOsJl1JUEdn0dMUYDJ8reEg7TKf3eq6oH0r81L5/JXLubymAIMQZKckRH2+wy5lwi1Knd/2MZuTRIPC6/r8Z9wjpYy6guWmud9Cbc/ItI8PhdXu5LMPH+ZA8wA/unUTFy0PLezVbLKE9YTcoZzmjLqEbqb2TA1HrSxnpQie72rX57BiwowCLJcCYGAglQu8FOaQXKAh4D0agfN+Bqt/dIIkbBSKQQZDtAiuKs6gKDOZj7/NXy2mS2oFw1JXwdCtkBPvNPqoL7mDwzYZWZbxFecWcsSoJ6NosiyM71lnchxOlWNt02/3bDbpAZaOzmLmZIc5SP2tSAzRohYhQyxnLl9ZwAuneviPZ0+zrSqHF754KZ++fBnZqZEHWn3k0C7z2RwQYHWbrWytzGFfY7CXkk784FQl+xr76ZlmgDQ0Zue1c31B3mvTxTxu5x8eOMArtb18573rePfG8K2tjx8KLW4hUNmk1HNohrYEtWoFlUovqfj/bPQ5rNgQC5n2+wN8r65Bm7ECQAhR7X7dVbnym7lyiWE0xuA6FjTmcTtfMj5OHiPsUjf5vZZkVLhmjTabFOiP0Oqq+CxRtEHM3pGFUcHyzZAUu4JDt3HyVDS4eu3LhZY5HLToXliLgdqekRnJ7ofzNNHR0VkcPPZWm2de2U0BQ/S5xI8CeWhvC+N2J//7oS08eucOCjOTufsdq7hmdVFU5z2srghZwdpQnsXprmGGrfHxDHqzsT/mrWwLnSaThccPtjMyA7Xhvx7p5Gz3yIx/tr3DVt5/3z6OtA3yPx/YzId3VIbd1zQ6wUN7W0K+tkJ0kCnGZ+z75ha6qBH+Jsb6HFZsmHGAJaW8G6gWQtzsUgVsCFAFvBp/X6y7hRD3uAQs7gRudb3Hec2w1cEK0c4pWcnf1QsBSEnQ2gGvW1/CNWu0B8LqEv/qVpfMwyEVKoTWWtW7QCpYvg/JYjFIv8zARmRZxU5X1a5EaJnD6Ygi6MQfRybxJYmEvfWmoMWXjo7O4sFtZ+JFUiDMIZNzBgFfu241L/7zpVy3vgQhhOe12y5cQkFGUsTnPaIup1QMUIC/H1FFbipSwqGW0D5Fc82vXm/kzUZ9JsyXU53mGQtV1PaM8NIZrRI6XVr6Ldz8y320Dozx4Ee2T1q5Avjz4XZGwwSF/8/wd+zSwD412DMrGs7KJQB+M+0Arfpce0yIRQULKeX3pJRPuP5/f8Br90spr/H5ulFKebdr+/2B+5+PWO1ObA6VfGH2qOQBfHjHEoyKYGWxN6jKS0/iHWu9SnsOjHTKPCrdAdYCqGDZHCoWm7dSUSQG6JEhRSdDMkwaozKZUqE9SMLdhHQWFuHUIDMZ9Yi4TIZDlTx7rDPWl6WjoxMnBCZQ0hknVUzQJ4MrWJ+7cgWfuLSaJGOw+u7mJTl88tLIzVndmf4Vir+PUmPfKEZF8FYcCF0MWmy8UW/iV280hghEz18ONg8y4VBn/D6HWgZ5aG8z3dNoNaztHuGmX+xjxGrnkU/s4G0rJh+HeOZYJ8+d6A75WjIT3GJ4jUecV9JJ6NmtSGmVhfTKbHYoZ/y2t+gtgjEhJgGWzsxwG+7miWG/AGtHdR6XryzwC7AA7r1tM8WZXlnOFlnEewx7KWJgWn/8c03gNRaLQbojbA/UEHTJPEqFCWDBmCvrTM6JEAFWuejjePKdfD/hPipFN5cpxziQ9BlyCO0LsrdBn4fQ0Vms9AcEDgUuu44+GewYc8u2yX2x3O32+emJU563Ti0DYLnwD7Ae3t/K2tJM3mqevwCryTV7+tu9zdgcKq+c7eXqH70WJGd/PmIes/Pnw+1T7xghqoR9jaaojjnZYeYD9+/DoMDjn9rJpopwFrFe/uflOo62he7oWCa6MAjJfnV1VNcRGsEb6jouUU4g8Aah+jxzbNADrDhAyzZJ8hj2GOmCphz4uStXsLLIP8BKMChU5XslPc9IrY/3n4x/ZtjqiPuKTsuA7x+vpEyY6I6iggXQKfM8LYJ2p8QWgwyVzvwx4XByLoTB8McMzwFwg2EfryX9Mw8l3kOhGGKbci7k+xxoHkDVDYd1dBYl/SHmr4CgGayqvNSwstdu1pRm8sELlvDDWzdNup/2/tkMy1RWBARYEw6VmqIMjrWZ51Ta+nTnML/f18xbTQM8tLcZq93J7/Y1e14fsNh46khHuMPPGw40D/h1y8SCfQ39Ea+xznYPc9uv3iQ10cifPrmT5YWhPU59kVLSORRexW+Z0Lo06mVZZBc8BXuc68gTI35zWC0DY/pzNAYY5/sCdGBwzEYmFpKEA5NLor00K5my7BQqckM/JJbmp3l6re9xfICbDK9T5FLjax8cY1VxsNR7vHCq01t9qBQ95IhRTshgjy/QzJUr89I43eVfseiQ+axXGgEJCPotE5RkpcziVevMJrvrTNid/jf0Dxle4h2Gt0LuXyPaeZFg/4+hMTuNJgvLC9Nn5Tp1dHTmB4dTZXDMf97W/cwzBbQIblkydUdEgkHhuzeuZ8zmwKgIHJMuKAX1spQ1SrDoQH56EjanyvF2MxcsjS5ROB1+s6eJbz1z2nVVkJWSwITDGfSzOdwaH3Nh88lsjEz85UgnAxY7v75jcv+pzqFxPvLgWyQnGHj0zh1h13KBDFsdkwaFy5QOnFLQLIvD7hMNx+QyANYrTdQ6tZksm0Ola9hKWba+ppoJegUrDhiw2DytDu4HxX23b0NRRNhjKvPSPP92YuCkupQ813u0DcS3h0FttzdY2ia0SsRBdWXQfikJBv7+T5fyg1s2Upadgs+MMifkUnLFKEtcs2e6F9bC5sE9TX5fJzPBfyY8SIkY4HXnel50bvG8NiqTg4ZyfWnS2xt0dBYdgQEEwBqlBZs0BC02N1dG3nKemmjkGzesJdE4+XLoBec2tip1bBL1ftvdj+kDTbPfnryvoZ9vPXOaa9cU8fKXLqMyL5WhcTt/PBAs53283XzeKwrOhm2Nzamyp940acVy2GrnjgcPYJlw8ND/uyDi4KquZ4QTYXyvAPIxc61yiFZZGLEo2FQ0yRIsMol1wv8ZHOg3pxM9eoAVBwyO2ch3zZS4WwSXFqRNdghbAx4gJrLIF9p7xLuHgW8AuFWpxSxTqZfBijobK7JYkpfKquIMPnpxFQXpXtWnQ2qNdrwrQNMDrIWLedzOvoDZqWXCq/p0WlbxCfu/8EHb1/iQ7Su8oa5ns1Lv1zPuS5NJnz3Q0Vls9IfwO9wkGjgjK5nAO0clBFy5airDen9u31HJxy9Zyoby0HLvAL9zXotVJvAuwz6/7W2D49QUpXOgeXYrRk5V8vW/nKAyL5WffmAzVXlpTNjDt8aPWB00n+dqcL3DszOTPm538q57d4cMYFVV8s+PHaPJZOG+f9jK6pLIu2LKC8YAACAASURBVIn21Jt4YHdo1yIDTn6V+EOqRDc/cLx/2tceiIrCKVnlarv3fj9v1OsG2jNFD7DigM6hcU/1qV9mkZ+eSHrS5N2b2ypzqMrzZkVMMpN8zICMexfuXp9gaKtSx2F1RUiTSHcQqSiCOy6qosSnXF0nyxiWKWxWtGzigThQcdKZHvsa+gnszlnmM+vgVgjbp65lj7qeZ507KRP9/JfxAf4n4V58HwoAjXrmTUdn0XE8ILOvoLJeaeSousxv+0XL8qbV2nTXO1bxqcuWhX19jGTOyiWsEf7V8/reUbZV5XKkZRDnLM6tPH2sg4Y+C1955ypSEg0caBqga4oAwi0fH+9J19miJ4IAy4CTy5WjESnV+lLfOxoysfu/r9bz0pkevnb9ai5aNrXKn6pKPvqbAwxYbOxp6GdXbejAZrOoY7NSz787PsLf1B1RXetUPO28iHVKM+9UDni2vXCqJ6bnOB/RA6w4oGNwnGyhLQoHZTpLIignCyF48tMXkZGsBWImmUWysJOGlfY4N4kbGtNuZJmMslJpD9keCHCpj5RpgkGhLNurnChRaJbFVArtJvD3kzPzudCZP95sDG6tqVG8A7f90j8D+IK6jV6ZzQeNu7jBsI8fJvySbLwCGXqApeNGCHGXy6PR7bs41f7ZAcdsmeoYnbkh0MtoueggXVg5qi732761cvpzUJfVFPCFq1eE9cg6rVa65rC8gVSjaZStS3IYmXBQ2x0s1BMrfr+vheqCNN7usmnZF+K+Gcibjf04nCqvnjs/qxFTtQjeatjFoaRP8dvE7/F04tfZn/QZfp7wEzKIbA3VGNCOvrfBxA9fPMd7N5XykYuqInqPTvM4u2r7uOSeV3jxdPig5m2GEzil4Hnn9infMzctkaJM7TMciUrmI86r6JK5fjPPTSaL7is5Q/QAKw7oHraShfaHaiYtogALNE+skiwt6HAvQvOFOaKszXziHuDcotQBcFgGu5FnpSQEtUGWBohYdMh8ylxS7SPW+FZO1AnPkQA52pWilU8anqVWLecztn/kr+pFfq/bMfJH5xWer28yvMHNhtc9Xx/vGJpTRS+d+EQIcQ/Q6PJovB9YJoS4eZL9s4GX3b6Ors1fmYtr1ZkcVZVBbcSbXN0L7iF9N76dHdGSlmTkC1fXhF0cn5JVZAsLpXivxWpXKc/Rnk2HWmank+Js9zCHW4e47YIlHsPkUImpQPY19HO2e4TW/vMz6dQbZnTg3cpebje8wAcNu8gWFg6oK0lhgmPqMq5VDvGjhP+N6P0b+yweif4Rq50vP36cqrw0/uvG9X7G1pNR16O1tI9NImyRj5kbld0ck8sYZvLxESHg0Tt38MAd21lbmslXr5tazl1F4ai6jPXCvz0xlLKvTuToAVYc0D9qI0tYmJAJWEmcUl7WlyKXH5Z7diuPYbrjOMAaszk8bRRblTocUglq8QC4ZEU+RoP/x7M0OzjAKhX9gJz05qQTv0w4nJzp9FeIvMGwlwTh5B/tn+M5dUfI9tHfOa7lSefb+KNDC7SqhNeU0WpX9ZZRHYA7fQIlgBeBT06y/z3Afe4vXEHZJ2bp2nSioNM8HmQWu0k0YJapNAUIXFTlT74AjYQ1YeZmTquaJcpapdlvu8XmoDAjiYMtszOH9eiBNhINCjdu0by9pJSTiiG46Rga587fHcQ0ev4ZDx9sHghbgbk38Wd8O+G3bBAN/NRxI7favsGltp9yp/1L3Ot4H9cYDlPuEtCajIf3t/DzXfUMjdn4r+fO0GUe5we3bCA1MXKB7rreqYOYO43PUiQG+C/7bVPue1lNATVFGawry+Lr16/h+g0l3L6jcsrjTqjVVCvdZOINxut79XnmmaAHWHGAedxOFqOYSQMEeRGUdN24A6x+15xKgRiib2QChzM+faG6fPwdtolznJJVjONt/SvKTGJndR47qvOCjr1gaa6fkmCHzCdVTJDDCDaHet4rJi1ETnaYsQV8VrcrtRxRl1Mrl4Q9rp8svmT/NF9xfIL96iq/lkLQDYfPd8K09g0AV09y2J3AS74bpJSh3T515pRmU3DL1ialgWPqsqAEzNK8mQdYq0pC+xWdlRWoUgTNYdV2j7KtKoeDsyB04VQlTx/r5Jq1ReSmaWuDnuEJxiOs0nearedlq9dv9jSH3J6KNwFtEJI9zrV+rz/hvBSAbxh/z8cNf5v0HKc6h9ldZ+LqH73GHw+08YlLqyNuUe02WznWNsRjbwUrQAayTanlqFzOQblq0v0uXJrLnZdWe77euSyPJKOBb793Hb/88NagriBfjkntOHdlGPQK1kzRA6w4wGJzkCUsDEntweC+iUZCsSvA6pHaH06hGEKV0BenN9Szrj9YA042Kg0cVv3bA9+5roRvvWctO6uDb1LryrL41g1rMbh0cTulNkBaJkxIiLmhoM7s88h+/4dLInY2ikbeCjOXF4pzajkrRRu+cxH1EWQFdRY1uWgBlS9D4GkF9EMI4V6VVPvMX901y9eoEyFNAS1uKVipEW0cDWgPzEw2kp06c/nq4sxkaoqCvfTGSaZJFgf5YZ3sNLO1MpeOoXG6zLEVmTrePsSAxca1a4o82xqjVEo9H1V2G/pC/4zW+8iRj8kkjgSMKHSST7NaxDWGQ3w94WG2itpJz+NQJaZRG+U5KXzx6pqIrk1VJe+6dzc3/mIvDVPMDCdhY51o4rA6+Xt//srlPPbJnWGFNd6xrpj7bt8a9vhDag0T0sglyknPNnf7os700AOseUZKyYRDJdtTwYouwHIPMvaTgUMqHuPFbnN8tgkebdXaGqpEN6lighOqv8FwaXYyNUUZYR3P/2FnlSeobPcJsAAGzsM2iIWMlDJInGS56CBJ2DmuVoc5KphTsoosMcZyH+XBqR5aOoueoCAKb8AVKsXs+cD5zGy557iCcAVgB4UQB/v6zk8BgbmkOUBMYJ1oxijUIIGLpflpEc++TIYQgj9/5mJCWVGelpVBFaxTHWa2uaoDsa5ivVrbhyL8RZ9CVfQm43xrEZRS0hpGOfFqwyHPv/erq7AT3M5XJ8s8//608emIzrm9KpfkBMOk+7jHI052mjGNTkSkOrlFqSNRODmkBs+qu9lYnsUXIgju8tOTWFUcem1lJYm31JVcqhz3bNOfozNDD7DmmTGbEylxVbC0jFlOavQtghKFXrIpIr4DrLMuk2Gt4kBQG1hJ1tTyum5VnA5XgFXuCrBmw7VdZ/YYnXAEzc65PxdnZUXE77PLuQmAa5WDnm2tA2NMOPSK5nnMEMGBlPvrUAN67m0Hfba9BISsYkkp75dSbpNSbisoKAi1i04MCVTG3aBow/jHAuZ3l8Zg/spNepKRmqLgxehptYoKpc9vVqW5f4yK3BRSEgweafRY8WptL5sqssnxSbw2hqnOhGPAEtlifrFgGrWFnMvOxMIthtd41nkhbzjX8bjzspDHt0vv3/QVylGKmbrl/GyAgmRrCA+y/3m5jo6hce564njQa+G4QdnLqEzmDXV92H3uescqT2fPVFwxiUfcYbmCFaIdI5pomGl0AnMIg2+dyNADrHlmwKJllrKExaMOE80MVmGmd36pV2Z7K1hxKnTR4rrprFTacEoRZDAcKGQRijyX4fAQ6YzJJJfQxfnr9bFQCdW2slJpY0IaaQ4YXJ+MHnI5plZzmcH70HKqMuQDTue8YYDgKlY2hJ2ragzxWtiWQp25pTtAbnup6GJAptOPvzFwLAQufNm8JPhXf0pqggGBbYIt/WNsqsjmYAyVBE2jExxrN3PFSu+ieMzm4K/HOqN6H1WeX8/H1oHQlZevGR8mnXF+4biB2+1f5bkwflLjaGuMRx2XYxCSuxMeZbs4O+k5z3QN89s9TR6p/udPdfu9frpzmHtfqeMbfz0ZFIyFIxE71xn287y6DSuhrQNy0xJDzqyH45+uWkF1mL+TdlmAQUiKhfczXB9lMK/jRQ+w5pl+16xUFtOrYBX6+HX0yhwKhLY+iNcAyz1su1K00yyLmcD/ey318boKh9fXQfhJtbfFucGyjj+hJHTXiBYaZBmOEG0bk3FGXUK18F90dAzpn4fzFSnlYVwBkg+5BIhY+Ow/BAz5zGLB5AGZzhzSE9CRUSl6aAmRhIllBQsIuXA9rVYBBLUJ1vVoQhdnukawTMTGNuR1l3/V5T4B1qMH2qY1U+XuHjkfONUZ/L1mMcr7DG/wB+fVnJJLQxzl5deO63jCeSn/5bgNq0zgfYY9PJ70H1Oe95vPnOZHL2ozW4EB1iMHWlAlvHRmanVCN5crR8kSYzztvDjsPtesLoq4egWQnGDggxeEFpByV+7cXUEADbqS4LTRA6x5psM8jhEHGWIcs0wjLdEwZR+vL/np3gCrR+bE9QzWhMPpKdtXi07qffqcd1Tn8tGLqyjMmDrAyvP5nrUAS3sIxWtQqROawEWCEQdblDqOBMxVREKzLKZADJPuYxDZO4XJpM6i5/4A36tr8JFhF0JUB7z+XfxVBt8P3D27lxjfxIMyq8OpBrV/V4kemmVR0L7V+cHCFDPhilWFJBj8F68msuiTmdQIf4Geut4Rtlbm4FQlR9tiE5Pvqu0jPz2JtaWabLyUkt+/2TLFUaE503V+CP/YnSr3vdYYtP3dhn0kCid/cl4+5XsMkMm/2D/FMOn045XsNzB12/nB5kHGbA4Otw7SNjDG//vtW7QNjPHU4Y4pjw3kPYY9mGQmu9V1IV/PS0vkrndELgjl5qat5SwrCE5GeMcuvHOlZ86jwDzW6AHWPNMxOE6hK9HaS/ak/bGhSDQqXulWmUOuGCURO11xGGA1uQaVFVQqRQ9NssTz2tWri/jGu9dGlInJDwqwtGyL6TxUSlrIBAZYG0Qj6cIa9mEyGe6WwkrR49kW74bbOrOLlPJuvKqAdwENAb5YV+PjiyWl/B6QLYS4y7V/v2vbeYllwhEXarSmURu+40OJ2CkVJloCAqxEg0JNcWwDrMzkBN69sTRoe7ss9LSmuznXM8qWyhyEwGM+OxMcTpXXz/Vx+coCFNdzccBi8zxHo+VM1/mxUG7pt4TsXrjR8AZn1QpOy6k9oXxJ85F1vyfhVyQweXWy32Ljsw8fRpXwi9caeOVsLzf9Ym/UKscZjHG1coRnnTtwEjrp/uEdlX4J50jJTUvkx+/fFLS9S+ahSkEZ3grW+fK5mQ30AGue6TJbKXHdqLtkHj+6NfhDPxXuNsFe18hBoRiKy8Wlu2xfKkwkCYefQWRR5tSVKzf5PjNqXTKXXDFKEjbPPJvOwiCwRfBi5SSqFOxT10T9Xu4Aq8onwArVgqhzfiGl/J5LFfB7bmVAn9ful1JeE2J/z39ze7XxRd/IBG0D899mG9iZUCl6MAhJs+rfIri6NJMkY+TdH5HyH+9ZR6AwYYfM8yT23DSZLGQmJ7CyKCMmQhfH2ocwj9v95q/aZ9AGH6ptbjHSFEJhsVz0sUWp5ynnJUB0KpMPOd/u+ffNhtd5v2HXlMfsqtUqQI8f1Kqc03kWvdewmyRh56+TtAfesq086vd1s6E8m/Vl/jOMNhLoJduvgnW6czguKtkLET3Ammf6RiYocwVYluRiEo3R/0oK3AGW2wuLQbrM1rj7ozjRrlXqlgqtN7lJnV6AVeCTsRlCy1hmMM7QuB5gLSQC234uMZzktKxkiNAyspPRLIuwSQMXKac82+IxyaCjsxCQUtI7MhGk3jcfdAZUI7Yp2oxLoAfWxnL/xWKsSE8ysiQ31f+aPJ0T3mds++AYNofKtqocjrQOzVi1b9fZPgyK4JIVXl+jthn8PjqGxs8Lw+FASX/AY+ERjb+im584bmSd9dc86bwEgI8Znov4WLtzep8Bgconjc9yUK3hiAzdMl9dkEZ5TmrI1yJlRwi/0XZZ4Jc8GLY64iLRshDRA6x5ZsBi81SwnBnBrQiR4J5b8jUbtjlUzOPxJa/pzixVC837yLeCVRxFgLWlMoeMJE0EYVhqN5hMYWHUGpvB4njG7lTn+xJiRteQNwBKwcpmUTet9kDQPDyecF7KzYbXyUPzWtMrWDo606PJZHFVsOY/wApUXLtQOUOvzA5SGl0Zxt8nFqwo9G897JR5JAs7uXivTZVakLWtMpfRCceMRSV21faydUkOWSle4+SZVLAATrSbZ3T8QiDQlBrwtHN2ysjV9txIFEZJ5Uv2z/At++0sVXpYJqKfp4qG1aKVcmHiEceVhKu4XRzGUDga1pcHq2S2y3y/ChbAvkZT0H46U6MHWPNM/6iNUmHCLFPJyArlfzk1buU9d4DlFrqItwCrw/VwWCnaGJTp9PmoKBdmRt5HnJxg4Nq12sN1BFeAxVhI34vFgvt3+a9PnmDMtjgCyS6zd7GwXjSRKJzsV1dP+/0edl5DkrBzheEooFewdHSmy2vn+ugdscZF5jpwBmSrqOOAupLAhWesBS58CTS+dy/USwPaBJv7LWx1GQ7PpE2wd9jKqc5hLl/l77E204rikRiJb8QzoSpYpcKEQyr0kjOj996rrgXg5aQvs1Y0zei9wnGxcoLnkr4KwD7X+QJJNCjccVHVjM+1oSy46tsh8ykRAyh4k7l7G6b2AdMJRg+w5hnzuI1S0U+nzKMoI/phRYDKPE0NZpB07NLgCbCG4swgzt2eUKO0c06W435AZqUkRKWcCLDSNczsW8GyOhZPdceXAYuN3+5pxuFUefZ4J8fbzXHX/hktUko6fYRYVimtAJxWoxtA9uWUrKRHZnO5cgzQZjes9sUbdOvozBb7GwdoHRjj5bO9/HxX/bxey2mf2aEkbJQJE+fUYCPyUKposaKmyD94c6utlQUIXTSZxijPSaEoM4m3mqcfYL3qlmev8Re96phhBetQDD264hFVlZzoCK7SlYp+uslFneGS95ws9zyjrjEcmtF7heNK5ajn312ErrhdtrKA5YUzTyhU5qV6uoHctMsCEoSTIryf35MhfqY6U6MHWPPM6ISDIjFIj8yNqorjS1WeFmRIFHrJjssKlqpKhq12QFIj2qj1eUCWZEXeHuimOEszJHabM2cytqja53xp7Bvlsbdaae63MOFQefpYJ//65In5vqwZ0W+xYfMJiFeJVgZlOj0hMozuz7ebsrBm1ILd6jouUDRDSCmhQTdJ1NGJmvahMfY19GManeD7z9dyqnN+FlgjVrufItxS0Y0iJI0+CrSgzUkVTDNBGQnbKv27S8JVsJpMowgh2FaZy6EZKAm+WttLUWYSq0v8K2czVQc+0jq0aJ+TAI2mUUYCRgX+wfA8Nxp2Y5KZYY6KHInCdbbvckyt5gvGP3OL4dUZv2cgGS6rkRsmvh12n8CW1ekihGB1qf/PxZs88LYJTsd3TUcPsOYdq12lUAzRK7P9xBuiwde9vkfmUIKWVYunAKt3ZAJVQjEDZIpxVwVLY0VR9L3z7qDMW8EaQ0pN2nax0dA3SqfZypMuH41H9rfy2ME2Ghdw8OA/uC7ZoDRxRl1CqH7z/3jPOvLTk8hMNpKSYOCOi8JXuc6pFRSKIc9Dql43SdTRiZrOIavf7NO+hn5ere3l1drITVJjQUu/f0uc20w8MMCqKUpHBEr9xZCKXK0q5WaQDMZlYpBUe2Of1p52wdJcOs1WWvujb+mzO1XeqDNxxcrCoO9pMq/HTEZ5I/Gf+KDh5bD7jNmc1HYvXj+sw63BLZD/YvwTAAkReFhFyuPOywD4QASKgtEgUCkVJo6qyzgeIOLiSyyqV27WBgRYbrPhJcL7tz5sdejdINNAD7DmEVWVOFUn+ZjpJZvs1MSpDwpBXloimyq0eaZWWUiFK/MQTwGWe97G/UBy/xHD9LIxngDLM4OlPdgWo9lwg+uh/ft9/gaTL57uCbX7gsB3WPtDhpdZpzTzkro15L4byrNYV5bJRy9eypWrCllTEl4trEFqQjHuhVhdjx5g6ehEypmuYcZtziDLi121vdz95HGePd41p9fTHCBYcJ3hAOAvkARw1epg0+FYIoTwzFa5ttAp80JUsLTrvXi5VgV4o95fLCASDrcMMmJ1cPlK//krq905adv/x43PUaH08d2EB/iS8U+sEc0h91vMvkbuANeNQEVBYpFJ3G3/RMzO8wfnNTzquJwlIrbP4OcT7+YSw6kpxThiGWAFSrW3yUIcUmGp0u23/XxQoIw1eoA1j/SOWMllBKNQ6ZPZZKYYpz4oBEIIfvvR7YAWYJUKE0YccRVguUvMpR7PL2/LxXQCrMKMZISAcZKwSwMZQssUHgmRwVroHHUNJo9O+Lc+vF4X/cM7XnAPgCdh4x+Nf+ZNdTW/8fEbAS2IzkgykpWSwPu3VXDNmiJu3lrO0klmLdyZ7WWuAOu43juuoxMxv3i1gbd9Lzgrv6e+n57hCV4528sbc3jf8a1gbRNneZfhTfY41zKOf1v5VasLAw+NOYEiGprJvX8Fq8tsZczmYFlBGiVZyeyui159bVdtH0ZFeII0N5OL9khuMbxOu8xnQKbzeeNf+EXCT0gkeA1wehEHWIE/o6Wim3Rh5ZuOOzgpq2N6rnpZRoEY5iolNrNYuQxTo2hdKn0ydBIxOUHh/tu3sqIwdoqZl9YUoPgUSu0YaZWFniSlG71NMHr0AGseaeobo0C4JKVltp8ca7RkpSSQaFBok4UYhKRE9MdVgOWuLPmaKrtZXRJ9b3SiUSE/PQkQDJNKpqslbLENYw5b7RwOo0a1kA0A32zUPgeXK0cpEkP83PEeZMDt6PKVhSx3tf5cs6aI1SWZvG1FPiWZySQnhL51tcpC7NJAjdIOwFtNA36zXjo6C4ER8wD7H/0u+x/9LmOjc3dPaxkYmzRTPWCxzanoha8inDujfrcjuBIxmwqCbirzAr2w8oJaBAGaTWMIIbhkeT57G/qj9sN6tbaX7VW5ZCR71wOm0Ymg6gxAInbyMLNONFEiBvix/WYun/gxX7d/lEqll7crb7n29F7DYjYc7g6YUdui1AFwTA3fbjdd6mUZAA8k/pCKGVSy0hhng2jgah/RjHQRWszktgsquXZtMSmJsTPUzk9PYke1f8WsUZZ47HTc6LYn0aMHWPNIU/8ohS5BipkGWEII8tMTaZNaJm+J6MUcRyqCLS4PrBIxwKhM9rT2XbI832+GLBo2u9ois7Bwu/Eltomz1PYsrv7yl0734AjzgB4csy/IlsjnT3V7sqg7ldOMyST2qWuC9ltemM7VrtYfo0HBoAiMBgVFEXzm8uUkGRXWlfkH5w6MHFRXco1yCJCM250caZ2+mpeOzlxj6m5j4Kdv48Kz/82FZ/+bnh+9jdHhufkMt4bwEArEXVWaqc9TJPjOgblVzXqlvxBOfnoiicbZX8oEPqdaZRGFYsjju+fG3Q5/yYp8zOP2kKp24egyj3O2eySoPbCl38IvX2sI2v8/jQ9wKPnTfMCwC4dU2KVuYpg0HnFexYBM5wrDUW43vEBz8odIdyUhGxbxXGrg8/Ai5RQmmUmdKxiKJcfUaiak1nX0u4T/Jp/pJUK+ZnyYp5P+je8l/Io+mcmTzrfxM8f7Qu57/YbikNtnSmC1tEmWsFR0I3yk2vUKVvToAdY80jY4TqHQ2r/6yCYzefoBFkB+RhKtqk+AFUcVrLYhd4DV76peaTXp928PltuNlPds0m6a7mDtUsPxaQ0VxyvH2ob49rOnJ93nVMfCy0b+6IVzuAtvO5XTHFRrcBDcHltdkMY1a0LPVnz+yuX84eMXcuu2CjYv8TdLfEbdyTKli1WiDfDORejoxDtSVWl/6OMUOXs4efXvOXbpfSxxtnLqoS/M+rnN43YGI0jKdZk1+4O/HOmcct+ZYBqd8AtOisUAAzIdG/7PycKM6FVop0NgBes1dSOAx3fPjVvp75Ll+QhBVMIgr9Zq7ZdXrPJveewZnmB/U7Aq4S3G1wH4sPFlnle3MYCWcFJReE3dyGXKMb5sfAzQkpugKbhqir6LCyllQAVLcpFyin3qmqDuCF8SDIKvXreKL19bw/KCdJKNChU54ZRqvQySycqJ33FcXcpSpYfPGP86ret2W5T8yH4z75n4Dl+yf5qmABEXgDUlmWyumJmPVzjcM/xuTqlVJAs763zm+HRfyejRA6x5pHNonAJX1qNPZpE5gwoWaGIX3eRikwaWiF4Gx2xTHzRHuG98WoClzV8JoT2EpssFS7X3udn2TQDSmGAojoLKmfLVp05MueDZNceqXjNFSkmbyyzzCuUIK5V2Xla3BO2XkWxkRWF62Pk8IQTbq3J5x7pivvlufzPGN9R1AGxStFamnmE986azMDi191k2jb/J0RWfZd0lN7Dxyg9wsOBGtpieoaPxzKyeu7438up/c7+FZ451okbZ/hYNe+r955fcdiaBFE/D5mM6FKQn+XWZnJKVdMpcrlCO+O3nrmDlpSexrTKH509F3j724ukeynNSgu57ga1voAk7qVJLVDql4BeOG/xe3+XcTJ4YIdPVbubulgEWVSLSzbDVwbiP0l0mForFIMfV8LNXQsCbX7mKj168lH2NAzT1W/jFh7fyr++M3PD+47Z/oV4t9XRNREul6OERx5X8j/NGOgm/HvrujetRlNlRytxQnoWvYOUb6npAa+F3o1ueRI8eYM0jvcMTFIpBRmQKqjE1arPdQPLTk1BRaJcFVIg++uJI9aV/dAKBynLR6REiWFeaRU7a9JQTQQsoEw0KjbKUVrWAXDHMWIAQxEKmdWDqh+Bfj3ZiWUDf84DFxphNewjeZniFdpnPI86rgva778NbKc9JnVJ6uTAjmdUlmSQYvPu1ywJGZTKrhJYZ7BlZmJm3fQ39fPaRw9z2qzf5yUvnFmXWWccfdfdPMJHNppvu8myrvvHfEUhaX/zZrJ77/052T72Tiy8/fpyOoXFMltl7xgRWnovEIN0yOINflDk3AZYQgstqfFv3BEfU5awR/uquXUPe+83b1xZzpms4ooDGMuFgd72Ja9YUq6iBZAAAIABJREFUBd33Qt3DrlIOowjJnbYvsnHiV0EiDq+pGzwBGECxj3FsoDrjYiAwCC12BZTdIYJyN2tKMslNS+Tf/nKS3fUm/vvG9VyxqpALq7Vjbt1WHvZYN73k8GvndVQofawXTVFdcyYW8sQIzXJyFcyMJCPrysKr586UjOQErlrlvYZ+sjiuLuUixdtBc05X5I0aPcCaR/pHJyhweWDNtHoFWosg4AqweumZoSlhLDGP26kQfaQLK2ek5mO0ZhriFr4oivBkL/vJIo9hrA51VrOqc4V5zB5kmBiK0QkHD+1rnvXriRVtPvLsRWKAerUMe0B7YIJBsHlJ5K0QiUbFb8hdonBOlrNK0VoEexdgBevnu+r54K/eZH9jP5YJBz99uY7rfvqG3u64iKk/tocN1kPULf0wySneeZ+C0ipOpO2gpusZHPbZ6UqQUvLcicgDLHfr3mz+bQUO1ReLwZCLZV9/qtkmUK3wnFpBpeglGe+1+poBv32tNjPz/Kmpf7Zv1PVhc6gh26JDPctvN75Ig1rCi+pWRkkNet1MOn9Xt3u+LvKpYDUvwvtIS0DQWOxqiewKE2AlGhV2VOdx/+uNPPpWG5+7Yjm3bNNGFvLTk1hTksmX374KQwRVo+ecFzIuE/mU8WkUVAQqtxte8PgxBrJTOcXfEr/C8WRNsKVFTj5btbkyJ6LrmAlfuHqF39cn1aWsVFpxV+WaTRZdMCpK9ABrHhkat1MgzPQxM4ELN26j4lZZyBLRi8XmZCQOst5SSsZsTla7Mn2aoWxsvBzcflj9MoM8oc0jLYZMfyTVKzdPH53dWYhY0ubzfRWKIXpCZKTXl2VFrZIUOId1Vl3CStcMVu8Cq2A9frCN7z9fy3s3lbL77iv56+cu4YlPXcSYzck/PLifQUv8tP7qxI6BV3/OmExizQ1fDHpNrr+VPMzUvvXSrJz7TNcIHUOhlcsmI1TrWqzwHaqvFN0UiiGPz50vZdlTz8vEisBZlVpZgSIky0WHZ1tLv8Wj7lqRm8qakkyeOzm1f9gLp3vISknggqrggCCwzTmHYbYo9TzpfNuk80Wftf8Tl078mGGZ4tcieGYRmg0HmlK7A8pugn+eS/PTuGhZHoUZSdzzf2e5fkMJ/3xNjd8+79lUSkFGEjurJ/ekAhgmjT85L+N6wwEeSPg+VylH+HbCb7nL+KjPXtLVVSH5mOE51ireymetnLxSdumK6Y9SRMrqkkzSk7zJzlpZQa4Y9YyxOFS5KCufs4keYM0jYzYnhQzSJ7NiEmCVuh40rbKQHDFKBmNxMZhosTlRJaxRWnFKQa3UskTLCqenHuiLN8DKIldoD41Ak8yFSDQBVjyJmUyFe/5KQaWAIXrJDtpnQ3nwtql41wb/hVeb628gBeuCqmC1D47xjadPsbM6jx/cstHTNry1MocHP7KdriEr//nc7M7i6Mw91rFRVg+8wqnsK8jKCV5MrbzkfUzIBEaOPjUr53/l7PRkptsHZ2+WxzfAusnwOk4peMa5M2g/9yzuXFCRk+pnEXHOtTBeKdo92zrNVk76iA+9Z1MpR1qHqJtE4dZqd/LS6R6uWlWI0eC/LOsdsXK83d/fcbtSC8B+dapZIUGrLKJb5vpVsALfbzEQuPgvRqtgBapOAmyvyuFty/N5YHcTVXlpfO+mDUHzTe/eqD1Trl1bFFH16JuOO/iO/UNcYTjGJ4x/A/AkfQG+aHyS/0v6V/YmfZ6rDUe4z3E9VdaH2Wm9l+YQohZuEo0KN22ZulVxphgU4ZeodH+2a1ydILA4K5+ziR5gzSNWu5NCMUSvzCF3BrNIbtyZvA6p9YmXChPd5vlfXLoflKtFC02yhAm073V5wczN8kpc3/MAGS65XBmREla8E420bzyJmUyFexYhj2EMQtIrg4Op1SXRfy52LssjxWeGsQ+tX71AmOkbnYjai2a++NGL53Cqkh/cujFoobWpIptPXlbNE4fagwQAdBY2p3Y9SoYYJ2X7h0K+npaRTW3KRopN+2J+7m6zlV/vjm52xM29r9TPWkXVN8C6QKnlmFxGT0A1ojQrmSW5we1xs4WiCD+T11ZZiE0aWKb4dxE8edgbcN20tZwEg+CPB9oIxwunexi2OrgxxEL69/tasNicftsuUM5ilQmciNA8t1vmUia894y2gXGOtS2uICuwglUiBjDJzCDVSYALl+ZxsnOYwTEb9962mbSkYBVbd8J6c0UOa0szg1QkA5EoPOR8O1aZwIXKWQByxQgfN/yNtaKZTxs0lcFSMcDrzvXc73gXIOhi8grZVasKZzSrHg07l3mvpVbVEuFuNV6ILvGrowdY84bNoZKojpMmJuiV2VRP0wvKl9JsrZrj7jkuEf1x4ZPkbiNZo7Rw2jV/lWhUKItACnUq3DdBk8wkUTjJYJyhBRRwhMLmUHniUPiHcSBWu4rV7px6xzjA/RB02xOEDrCin80zKMLvAeh+3wKGcKpyQSgg1XaP8NSRDu64qCps29Pnr1xBTmoC33729II1mdYJxnjyMXrIY83O68PuYynZQZXaxkBvR9h9psOrtb0MTTMp1W+xcXgWfOaklH4BVrXook4NDj62VeVOKYQTa2qKvAGWAyMtsphlwj/AeuRAq0dNMD89iWvXFPPnI+1h79OPH2yjLDuFi5YFL7bPhah8bVdqOSqXhwweQnFaVrJStJGI9/f8gfvfXFDdD1MROJ+6XOkIO3+VnGDgqSMdfPLSZawtnVw8YmVxBjur81hbOvVzyY6RFh/Bih3KGb6e8DB/S/oqicLJ3fZP8EP7zdxhv5t+IhOtCOzOmE0+sH2Jp0I7QCZ9MpMan+qsHmBFhx5gzRPmcbunJ7pPZlFdMPMAKzctkUSDcPlMaRmcjsHo++pjTWPfKJlYKBcmzqhagFWdnxaToU23X8Wg1B56OWJkwRviHW8fwjQaXZC4UB6U7hu012Dbv31DEfhliKPBN8DqcwdYQqsELoRs7b2v1JGeaOTTly0L+fqhlkEee6uNwTE7Z7tH+PNhbaG9GFpiz2ecDgc1Y0dpKrgSxRB+9jBnzRUANB9+Mabnb56hZPepzth78Q2PO7A5tYH6DMYoFEMe9VlfIln0xpoVRf6zw42yhGrhP2Nlc6jsb/T6Vn3owiUMjdn508HgxFn74Bi7603cvLU8pAx3YOCQxjjrRBMH1JURX/MxdRlJwuFRVgUYtzvpnMbcXTxiHrf7zRAuEx1coNTyd+eFQfuuL8vkJy+dozIvlc9duXzK9040Ktx24RLWl2UHGUCH4tfO6zilVvKg4x0A1KtagHREXc5jziu413njpHNzviQnKFyxaupzxorctES/Fv1zagUrfVoEA6uEOpOjB1jzxNCYzTM82EsO1QUzF3wQQlCek0ov2TiloET002Sa/8x9k8niGQI+656/isH3C9oQMcAQ2vtlYZnVweu54GRAe+Athlf5ovFxADIZJYngBfVCaBOccDjpdGV13QpPgSIX66YhcOGmKs+bpHBXsNyB3LE4nznoG5ng/0528/7tFSHbQZyq5Gev1PGNp08BkJ5k4Dt/0yR0nzoS24qGztzS1XyWFGHDULJ+0v2qN1zCuEzE3vBGTM8fqL4WLac6I29njhTfzotqV3UoVIA1nWr3TAn0qGqQpVSKbgz4V6d8F6M7l+VxwdJc/uflesZs/uqw97/eiEEIbt1eEXQupyqDAuBtyjkMQvKWuiriaz6makmbjUqD3/Z4SMDGgrNd/kG+27/pceelQfuuKMygrneUu96+KmJrnMq8ND5yURU/u20LGcnB7YS+PO68nOtt3+UHjlu5ceKbfMD2b9zreC8ftX05wu/Gy6UrCkhNnPx8sabEx1funCxnhWhHoCU79ApWdOgB1jwxNG73a5OKRYsgaKaLTgz0kkOpGKAxDoYS2wfHPQvqTld1LRYVO/DOnZml9n7ZYtSziF+onAzICH8/4X7+yfgUdxie53jynfy78fdBx0y3xWcu6Rgcx93VViH6sEtDkMLThTMYWK/y+RsaIAOHVDwVrLNd8a2a9aeDbThUyQcvXBL02rG2IXZ892V21fZ5to3bVQbH7DxyoIVXF5jZtI4/fY3aYjBzyeQBVmJSMg3Ja8gfOBTT88+0guUr6BArOoa81+SuDsVLgBWoftuglpIonFQI/7/DlgHvs1cIwd3vWIlpdIL7X2/0bK/vHeHRA23cvLU8ZFtw59B4kDT2DYa9jMgU3oqigtVJHn0yi00BAdZCf1a6ORugilglejDLVPrwT+ClJijsbxpgXVkm71w3uTR6ICmJBtKTjFy8LDJFvzGSOSxrMJHFDx23MkT0nRk3bJq79kA3vsbdtbKCNDHhmd9r6bcEJQh0wqMHWPPEoMXmya4PG2MjcgFQ6PLC6pK5FNNPQ+/ovM5qOJwqx9qHgkz/YlXBSk4wUJiRhBltcZ2FZcG3Pfi33Hh/d99KeAiAKwxHgo5ZCAFWp48BZ4XopUPmowbcgnaGmEGIlJ3VeSS6hCEkCiayKERLYrTHcaZWVSV/PNDKzuo8v7+L+t5RPvTrN7nxF3uD2l7doh1ff+qkLp27wLF2ngSgrGbzlPuOFO9gqaMZ80DflPtGgsOpzriC1TE0HnMrBN/KyhLRiyoFbdLfg6osO4WCjLnzwHJTnpNKotF733IHfoFzWIHmwlsrc3n3xlLufaWe/zvZTe+wlc89coTUJAP/8vbQwVJgxSAfM+9UDvCMcwdWovneBUfVZWwUi7SCFRBgVYoev1koN1UF6XQMjfPFq2tCtmNGwkXL81hVPHOBrqkoykzy+KjNJSU+xt3nVLdKptYmqEo40R77ivViRQ+w5om+kQkKhBmbNJCYnhezQV33A6dX5lAohrDYnEGGjXPJq7V9dJmtFIpBJmSCJxBaVxa7zGNFbipmqS1Ms8XovH6/M8WpShp9BBkKCG5tKxUD/Djh5xjxZpIWgrCHb+BbIfpoDVgwpSQYuCjC7GAoqvLT+IedlZ6vO2Q+VYpm8NkzYo1bk8SDLYO0D47z/oAWob8c6WBPff+kCoiqhPaB4Cy3zsIhYaCOLgpIz5zaXDt92U4UIWk7tTcm5/63v55kzBZaeOHnCT/hjwnfieh9jrbGtgXXNyFSofTRQ06QoMNMqt0zwaAIVvoIXTSECbBaBsaC/nb/833rWFuayaf+cIgL/utlGk0Wfn7bFvLTQwdLgQHQF41PYMTBr53hxVDCcUxdxnKl08/8tm0WZfbnksBRiCWil9YQAZZ5zEZ1fhpXrCwMei1SbtlawTfevXbax0fKZTUFJBjmfolenOWtpIayIYj3dvupsNrnzh9WD7DmiW6zlUIxhIks8jNiZ5ToDrCGZBpZQstMds3jTJLbJ6VIDNIjswFBWqKB6vzYVLBAG8x0B26ZWBb00H/n0DgTPovl5S753yFXC+Szzh0AvM+wh88bvZ4453pG417oosMvwOqlXfoP716yIj/invhwvHdzmeffp9VKl7m1REo8ql7xxnMnukg0Kly9xn9BUNcbWVujBBrjYNZSZ3ps/NwjKB9/PqJ9y9dof/+jzTNvE+wdsfKng+1hX7/ecICdhtNBs0WhOBzrACvgXhGYjAHYPk8BFsDGCq8C3DDp9MnMIKGLvpEJPvKbA37bMpMTeOzOnXznvev4wtUreP4Ll3Lx8vBJpfaAbowLlTO8qm6iMYTh8lQclisA2O6SEAdo7Fsc1W9fIRADTsqEiZYQn5mOISt3XFQ17eoVaK2Cm5dkhw2KY8V0/CBjge8M1iiptMt8Py+sY20Lu4J1ssPMq7Wx6QCYCj3Amidqe0YoZJBemR3TNgf3e5lJIwvtpjNgmb+KTpdrWLmIQc+8zbqyrBnd4ALJTE7ARgLjMpEsYcE8bl+wEtaBcuIXiLOoUnCv470APOy8ivdO/AevODdxu+FFTxXrwT1N/GbP9Lxs5gp3BSuNcfLESFDLj6/J4XRZW5pJqesBcUpWkSnGPbMR8dgmqKqSv5/s4vKaAtJ9vFhUVVLfG3nQtLe+X2/dWKAkJCZRVB5aOTKQnPxiuinA2Htyxud9/mT3JNVR73YtSTE5B5r6Z3w9vvhWbkIlY4A5adMKx8aAxW+jLPUkw3wJldxMSTTw4R2VfOHqGpZOMXvt+3NQUKkQvdMKrgAOqTWMy0TeppzwXrfJsmA8AsNhmXDQ42MmXyl6SBBOmqV/e11KgoG0RAM3bZ25aW9ygoFX/uUyP9PpWFKWncKG8shk3GNNSXay39fn1HJW+6hPzoaozVxytG2Ivx3vmpNK1nkTYNltEwz2dWG3zX/7mFOVvNnYT4EYoi/WAVa69sdhlmkkCztJ2KKW/I4lXa65myIx6JHkDpS5nSlZKVrryBDpZGPB7pSMTizMQUzfjKIRB7cYX2OPupYHnNdz2cSP2Keu5ahczsPOq8gVo1zi87D0NbeMR9wD1e5+7nOyzO/1mmnKs/sihKDGtfA6pVYBsMk1d9AWhwpIh1oH6Rme4PoN3gH+vpEJvv2301FJ4j5/spu7nzw+G5eoE2d0pdZQaDk79Y5TMJmZ+WWK97P0KeMzlDF5xvd4uxlLjO65qiqpc3k/JeCgmEHaQgRY5TlzZzAcSGB14Yy6hFWiFQX/Vt2uofEZJfvafVr4SugnSThoDtH6FgkTJLJfXe0XYNkcalzeF6MhcAZ1i1IHaLLovjhUlbevLfZLZM2EzOQEVhbPjsjK92/ewKpZeu+pKEhPIslnxvAtdRUrlXYK0Obom/vHGJ6jFrvZ4EjbEC+e6eGB3U1h26NjxXkTYJ3Y9Sdyfr6K1rOxVWCaDud6Rhi2OigRA3TJPE9QFAvcwdpwnLTMdbmqFlqLoBZglWTFriUSIDNFu2Gafdoie+LAYHk67G3Q1HouFGfYl/Q5yoWJ3zrfDkCLT0buDXUDE9LIDuWMZ1vbwHhc3/iaTWNsFPU8kfgtAI8nmhtfA8+Z4JZRPi0r6ZHZvM+wG4jPeYMXT/eQaFC4cpW3mvfL1xr4zZ5mHFFklvc3D3C6a3jGggU68Y+1YD3lzk5Gh2dm8HsmjLLmUtHFQ4n3aPuoFbzLsJ8/Jk4+i+VQJQeaBibdJ1JaB8awuBY+y0QnipA0qv4KgikJBvLTYyMMNR0Cs/wn1GrShZWlAW2CFpuTYev0A0/ftupKpQcgpHhDpBxQV7Fc6SQTb3U8mkp5PBIYIG4R5zDLVBoCKn12p+TdMVblWz1LVdSlBWl+QipziRCCshzvGu1VdSMAlxuOebadngXvu7lg2GrnlTO9OFXJD16onfXznTcBljFJy3bZx+f/ZjI0ZieNcbKFhU6ZNzstgq6ZnSwxvwFW+9A4aYyTLqyuGSwozY5dQAneCpaZNLKF9vtdiEIXTSYLL53R2tmuNRykQAzzU8f7eFndGrSvjQRqZQXrhH9bYF3P/H++Q9HaP0bH0DhfTXgERWiBQydexcDkBIXynNgE3m4ZZScGHndexuXKMTKxxKVJ4mu1fWxfmkNGsvYZPtI6yAO7p9/q+bcTXVPvpLOgSVmyWRO6OHNg6p3D4HCqnOsJHWAt8ZEb/7L9k/zEcSNLlD7KRS9ZhL+/vFFnmvb1+HLSpwVpjWgGtHZfX8pzUmImDDUdMpKMpPjMix6X1QBsEI1B+0539tMaYARcJbQAq1mdvrLcUam1ovrKtcdj4ikafNVpATYpjRxVlweZ+aYnGblkknm36XDDxtKYm10rQqsizSe+1eEzcgnDMpX1PmuNwFGGhcITB9sZt2vJm7mYIjlvAqyEFG3RZZ+Y/wzvmM1BidB61jtlfkwDrJzUBFITDX7Gu6bR+Qk2pJT0jlg9HlhuifZYV7DcAdagzCDfZd4cKGu9EDjU4s1IlwkTdWoZP3bcEnb/k+pS1inN+M5L1EcojDDX7HFV5mxSqzZ2yVxAWyC9d1Mpr335ipjN5a3wqYTVqhUoQlIkBuOuFaZzaJzanhEuq/G2P52aYWbwiYPtC36mQmdyylbvBMDceNBvu8Op8pcjHTicUytK1veN+onp+FIu/j977x0e2Vme/3/eM1UjadR7L6vt69312l4XsI0bPQ41AZJAaEkgkPINpMCPNJJAwi+FkAJJCC1fAkkoCRjigrHB9trr9Xq7dqVd9S6NNGpTz/v945Q5U9SnidV9Xb6u1cw5M2PpzHnf+3nu575jcsAhWcXD0WMA/Mj1azzv+qUVTS+euJKewfGLltDY/Uo/y9LJtYQMLCNgPlcQQlDjja3bvbKeoHSwRxlIOnazJlO9kwtYv8otYoygdDDG2m6TK+GM2o4qhSmbBrZ9rImVwCqodIgRumVyaPMduyrT7sp3W2clP3e8Ze0D14mG0gIayzzYc+AeaEV8sVMwIUupELHCRz4WK9dCIBzlH37Yu/aBaURa/opCiA8JId4ghHiPEOI96zi+NOGco+n4HKvB4dYIRySQe4K1EIzQqAe3DcsKar3p6+gIIWivKsqLDtZCMEJUJRaorC8M9emWCOrV//NqC+1iFC8L25JgWatCDWKSYbl6te2sbKNULMbZA3eP5WdlybBxbhYTnFD38Jrgx83nfvmuTmrS+B043BgL7jbm/qqFj/48I1hPXNY2pHdZLINXk+tom4dhPuf4C95mezjlMVenFvni033p/Jg7yDNU1jUzTQm2ifNxj3/lxAC/9u+n+VHP1Jok+7lV5HwGwXow+IfMUsxF2cyc1AiNXajsEsMpz+uZWEiLNNtq7LBf6eOSbE7Ky0v3HO9mUG25Z6koDMsKM5DVisQ8rPUi8V7QKsbpl9VJnZmNYAEPfbKG3RYimNgB2m4YsRDYBjGJS4ST5IEArzyQHFSdDtyzt4b2qtXNStaL+/bV8JobMvM5N4JENckUJVSKWOGjbyr3++iN4vvnx7KubNoywRJCfAK4KqX8DynlZ4EOIcQbVjm+FHhUSvlJKeV/6A//zlY/x1pwFmhfgGhedLCi1Fs6WDUl6W0H76ouNG3LS1nIGcEywm9r9OFIYwYr3f+/JR6NYD0n96AIyY3KlW0pEbQuqA1iak2C9cOopo1+QIlVsp/tS6+bV7pwZWIeJ2EaxSTPqPuYQnNIaq3w0JXmzZKiCN54TKtgTurvU8Ucs0vhvLKyf7x7kroStzkzFomqK1qzuwjxmPM3edT1W9xnO8W7bN/lVuV8ymMfOjeWsc+8g9xDCMGIs42S+Z64x7+ry0P/89QwH//OxVSnmni2L/X8lpsgdyhnuabWcFpqJgEqCj8d+kN+L/yLANygrFwFfubq1u8/RsfHToQbRC+n1WSHxdfekN5Zms2gOkF5MiSr4rp/BhJDcNeLRAlnixhPcsbbDK7KujhL+eHt3sGyfH6j2NirJpOUe/YmG6WkA1XFLv7vu4+n5bXu31/DG25M7r5lG60V8YRxSnpNdRBszw7Wf51KXRjKJNLRwXqPhSgBPAy8d5XjPwH8o/GDTsrenYbPsSpcHk02pOYBwVoMahLBiFSYUcqoLEwv4eisLo7rYE3nyEXQp4ff1ogYwar1unHZt5Z1lAhDIviC2klEKhxWehjP08yj1WBsrgsIUC4W1iRYI1TygtrJg7Yfme5V54b9ede9k1JyZWKBZjGOTci4xe/v33ZjRmYpDMv3CX3ur1q/BvNlODeqSp7qneKlu6rM//93f/EkZ1JYrd+jPM+3nR+hVR9yv6C20KqM83+dH2e/6ON1yhNYZaJXxue3bUzBDtaHBe8uGsN9SFWT650enOW5Pq0r9d8vjvCVE/0ruvr9zn+d5fvnU5PwD9u/ykGljwDxBhJXZT1fid7DrCzkZmVl8vbM1a0bXRhuo/tFHwUixEl1d9zzTeUF7K/PjYW1FYld9yFZmbKDdWlsc/ccq1x4jxhgjzKYJoJVT5sYQ+hrxnYnWGOWDpZBsHoSHGpbKzwUuuKDqtOJGq+bw02bjxlpryzkI6/ay20dlWta92cDxhyzgSlZQqVFItg3vYi6jaToA9NLaZMwbwRbIlgrSPtmgHtXOe09wCPWB6SUGY+GduszWGoo98x7MRilgjl8FFPpLUxrJhRAR1UhfgpRpaBMzOesg+XTO1i1Yga/LGAJN3vq0u+643U7uLGljCBOfBRTxZyZv7VdEImqppTkZcppgJTZL4n4l8jL6VKGea3ylPmYIT3LF0zMB5kPRMyqqTFP4bQrGcuyOdBQghCwQAFL0kWVvjgYm9Bc4+KoH38gwq0dmtHH2FyAH3RPMm9xHKtnij+xf45/dn6KajHLN6K30xr4Cv8UeYV5zHdcv8v/7/yHODdJ31I4p9EMO8gCqvfiEUEmB6+wHIry3i+djJvXCUZUvvh0cn5VIBzlv18cIbTC/NXLbc8B8DeR16V4VvCt6G08qPzYNJ9IxErGGeuFlNLcMN+o222fVLvijklHnEM6kCjtH5ZVVAk/buILXN1j8xvejKqq5JRlJvd7rt8GSBm4bMV7XtpOmcfBS3ZVYt1WlHli5OKqrMMtwjToKprJ+SDLGbarzhSiqmTcUlDsECNMy2Jmib9Gfvbm5ox/lg/c07n2QSvgG++7nXe9pD2Nn2ZraK0oxGa5gKZkCSViCSfani4YUTfdmc0FvvrcQFZMLRKx1Q5WORqhsmIWTClgHIQQxhXUbpm/+tAWP8O64C7Uv3D5QLBCEcrEAj5ZFDcomy60VxWhotAvq+kQIyyHozm5gc7qHax6MW0aXOytS3+2Q6nHwa/dq6XU+2QRZWKe8bn86uKsheHZZX2DJPl9x79yXm3hUfXImuf9t3orfunhiL4ZAXj00nimPuamYEgfYwRLq8LWeF0ZcwIrctn1OSzBpCwx5wDTZSW9VRhSqlvate/FiYSg1mKW+Jbro7zF/gOeV3dxPPi3/Hr4fYCgWyZvFmoTbsNb3ejuIL9RWqctpcNDffzHqaG4oFUDn/lBD4Fw/H3/qd6pFTMCG8UkdWKGPwj/HA935ldPAAAgAElEQVSpt6Q85tOR12ETckV5as/Ewpa6p7NLYcJR7fx9Sj8TspRxPaDeQEd17uevQOukWTGkKw4Su1hLoSgXRjfWxeqdXDDt3R16mHxUCr4dvW3Fc1orPPzuK/fy1G/fw5feeQufeP0h87mX7IoV63pVTV7ZaZmlezIH1f10wLcUips37FRGUs5f3b1ndWKaDrxsTw0f/+kDGz6v2G03VTj5AqddocViJDONtm8rJ3Ydp0MOnGnMLYV5YcDHD3NUdN4qwUrVEzVW+vIUz5kU3TKzZcxxJUEnYCeFECcnJ7f2C3I63USlQIbzgGAFI5SLeXwUU1uSXstygGb9i3FJNpsJ3NOL2SccxgxWs5gwszsy0bFwO2xmW91Hsfa7XdpeFfw+vXvVKCapEn6+Er2XRdZjBiKYkcWUipj09YnLU+tyEssWDILVJsaYkKUsoF2fNcXpv/atMKxmJyg1nSzPDs/lhXzumasztFZ4TEfN3oSB9iPKFarEHL8c+iBvCH2MoEWydV628Kuh9/Ou0G+aj7Uq8ZKvc6uEyO5g+6OhUlt6R6b9nB1KLQBZCEZM6/S55TD/c2aEhy9MpDwW4CahhRc/re5f8ZgpvCxIt2nSlIi55fCWFBNWx709YoBLavI8SkeaDAW2ikQnQyOnsE0kyy8fOrex+IQXBmN/03r9d/2h8HvNfMtUONqizTgXODUJ/htubORQYwkep41jrTHnQcNhz9qF3K5zm4ly+A4xYhJIAy67Ys65ZhpvubmZ2zs1VcJ6i+cNpek1/UoXrGqjKalJcq0ywXxRg6yG718Y47NPXN2yO+9msVWCNUsykTJ+TvXbNx6z+ss+AqTsYkkpPyulPCalPFZVtbUBRaEoLONG5AnBKmVBsxXPQN6B22GjyGXnktpMqxingEBOZIIzi0FA0izGGdSlDenOjDBg/B5nZDGlLLAQjOTFRnq9MFx5btBzVM6obes+d5Yiyoh1LBaCEZOw5QMMd8Q2ZdTsXkHyDEO6YVwTF9QWDoprONFMLnJtgBJVJc9em+Z4eywHrHcyfjZ0v9DkXT9WD6RwDRP8t3obj6g38rrg7zMrC+OyiyDe8n8HP3nwFmqb+5HpObpXyb4zjC++/Ew//+frL644ewVwWOlhQbq5LBtXeWfBkKxKOWtkIPFa3giMTCYbUXaJYS4mdGuFgN21mVlDNopEgtWjd05SuSw+sgqxTQVrgcT4bq8lDzzaHG/fLoTgtTfU01ldFOcK56eQPrWGV9tOUK0bUJ1ZgaTnO6wEqww/FWI+qYPVUVWUtcw0IQRv1E0q3n7b2mu4lv+Y28iBlXCrZX0akdq/mywmLtthdu/HPVM5LR5slWDNkNzFKoUV56qupnhuRUlhuhEQLkQk9xfFfDAmESzzZCaNvrLIySWpZQB1ihGmc0CwRucCVOKnUATplzUUOm20VWamkmSQSp8solzMo0rt97xdYGS/HFSuEpT2lDKwleCTRZSI+E3NZgerMwGTYIkxrqnZI1hGvtyP1IN4RJCjuoyyO8facWP+Kp5gxTbJ77b9Dx92fJWwtK1asQY4Jbs4r7bSmlA1PzXg21YFhh1sEDZNUjTum+fKKnLQ/z0/xnIoyiMXxwmE1VULbUeUHi0naY1twbCsXLGDBdC9hXvPVZ2ctYoxXCJMd0IH67dfvmdLZgLphNftiJttWsDDiCynUxlKOrZ7fB7fBtbgVARrcIWZXCHApgju31eT9NwrDtbxtuMt1Cd0SQZkNfuUfv7a8RnttWeWt2V+npVgGRL0ngSCdUtbKjFV5nBLezmKgJ+9uSkujNoKIeDb77+dZ37nHjqq86Mjm4hbO2ImWz2yAVUKdiuD5mNTeWamlQrWyIdcYEsES0p5Cp0gWVBOgomF5fhZYNYyiwWrE7K0Iihc2CK5r+zPL4coQ5MIlhdmhmDVet2mZKFJTDCTg6H3cX+AZj19fkBWs7++JG5wMt2oLNJMLkpZACSzi/ljyb0anrg8yTde0KqeHWKEq7KOMPa4YxItga1I7GABXBrNnxmcnokFXISoEnNxxh2ZmD+0orJI+249re4DYhKoXBOsUwNa1diQ7YSjKtf0DmYhy/ye49+A2OdeCz2yni4xhJ1YQWFqIbThuY+fRGwko1E/7kNCiHZLVmP+TJ5bYdOu7QnfPEurzNcuhqK8/fPPcnpw9eXVRYi9YsC0Zl8NQ7KSDjHCN5z/H3cpLyQ9f3pw8/LUy+PaNWtUyg1puYGOqvyYvzLQnNjFUhtWzAl7dp2Sqqgquajfv52Eea3tKZalk/EUAcNOm8Kv3t3JKw/WxeVyGWgoLeBNx5qSCNZXo3cD0KVvmENRlbFtZgwFxKkROhTdoj2BYD1wYOvOixtBXUkBf/nmw5R6nBxsKOHl+7X3v62jgm++73aONJfykVft41BjKaUeZ1qDitOJjqpCSvUCQhCnlp8mLARrIZT3RbzNhnynC+mwaf9sQu7VfVhs2PXFyvr8nxLvMvhm4MNp+BxrIiTc2KK5v4lEludxiKjWwcoQwaorLTBtvhvFZE4kgmNzAQ4q1wBtE7gvQ/JAA5VFLnyyGIeIUswys8vbYw7r0pifoO7q1SbGkqx460vcvPrQyrkvs7IobgYL4PxIfszgzAfCjPuDZu6b1Xo+E/OHVhgdrAU8jMpy0+b8ao5DEk/1+6gudpna+6d7p82//2/avw7A+0If4NfC71vX6z2r7qVIBOhx/zyHRCyj6H/ObGzu4ycNG81oRCsOfgLoBa7p517NwkfdOHSCJaNr3+NOXJtZ00HrgLiGQ0R5QV2bYA3IalwizBGlh3faHkp6/sUtyM2MwlCq+wVAS0V+yan2JdjF98naOBmVFes1Bbg6ucCybk7yEuUMtyiX+JPIW1IGDN/SXs4v39XJp954w6qv6XU7qCiMddu+qx7n85EHTAMNgP5tGB5r7WB1ihGC0sGwpYgnSJZOZgM/dVizif/cLxzjr3/2ME3lBbzxWCOHm0r5xq/czjvviMkH81UiKIRgn8WUrFs20SVi3dlQVMW/nL8qoagqc1402DLBklJ+mJgr4IeA3oRcrHux5GJJKT8JGNXBDwHT+mMZR0hxY4vmXiJoC2gVbB/FcRKDdKKlooB5PMzKQhrFVE4kguP+IK+0naBbbWRQ1iRp1tONiiInPqkNZpaJedMmPt9hLBIKKk1iIolgddYUc58u//iHtyUnI8zKIrxiCRuxSvbz/b68yKkwJD/GzMaIZcPUniG5qIEqy3zjgKw2u6mDM7ntYr8wOMuR5lKEEEgpze6lnQhvtT3K1yMv5TvqcWZYX0HihLrX/PebbY+b//5h9/Z0BksjNprRCFAGdEgpyxLOzS/oEkHrBnkrOKxoocWn10Gw/iv6EjP8dyJFV6VnYmFFp8K1MKB/NxvEJGFpS3r9TK8hG8XhpniC5aOYEhbNXEIrnu5dH8GyDuR36rlO34renvLYVx+qo8Bpw2lfeyt3pDleKjciK/CKZYrRfufP9fmSXCfzHRPz8RlYV2VtnMS1xONY1+8mUygpcOCy2/j7t97IKw4khx/nO6wEq0c20CrG4pQSkwv5KxOcnA/mXPaalitPSvlJvUr4ScMZ0PLcZ6WU96U43vwvHZ9hPYgobhx50MFyhrQKXyZnsIzN65CsoklMMJXlL0I4qhJanucm0c331JuAzEvCygudzOj5FxX4TZv4fIchc6gXU7hEJIlg7aou4khzKc3lHl5+oC7JEcmH9rMmjdTgD0TozgOrbsNB0HDCGiZGsNoy7AZWZZFV9qm1tOizDP0zuavUTi0E6Z9e4mhzGYFwlLd//jmTYLWIcVwivG5poPmalPBvEU3yo9lna4tKz8QC4Txyk8wmNpnRiJRyNm+7VlboHSyHSM+G+E7lDANqFZMpjYHj4cPLg6E/4qzaSgWpZag9Eysbb6yEcX+ARV3u2CCmGJPlcZvlGq8L9wozLbnCDQnzYLOyEEVIk7RYcWlsfl3yZOv8VYcYYUKWppzFLC90mp2S9cAIXzcwkmAr/5ePXM65fHqjsMZRdIhki/b6DKsk1osDDSV5d+2uB1bV0YCsxiYkdSJWKMj2vnIjMALLc4ncUfscIGwrwKHmlmD5A2FKglpVakxWZGwGa3eNRjQGZRWNYorxLLdKR2cDNIkJFCG5rA8qJwYzphveAgcTUltEqsWsaROf7xjV3XheozwDwFU1vtK1v96L22Hjbcc14wsjO8nArN61M7KeDJzMAyc5w7yhQUwRlYIxqVWka7wuilz21U7dMqwSxH5ZTbWYpYAAI7OBnBGP0wPa3+hwUymPd0/G5XMYsxuru7ilxu9G3s3vhX+RdmXMjGYIRdU484zrDBvKaDSgz2plNaNxU9AJlhH8uRXsEkO81HaWf9fnctaLSVlKhUgtRV7NeGMlnB2KvVa9mGaEirjnDyTI8fIBu6qLcVk6JLNSL3aJ1N+7B/7qiTUNiM5Z5N0dSrLtuIHbOio2tGm/sSW+G2jIL+sthiW5iHPZLALhqOlYaSNKo5jM+5m97YbdllgdY37aKoHNZ4J1cY0Z5DYxijI3kNHPcF0RrKi9AKfMLcE6NzTHbmWIqBT0yPqMdbCM7sCYLKdWzCTlRWQaAzNLSfaymXaN87odjOuBxjViZtsQrJHZAC5C/Ib96zwaPcLzsst8bm+dl9fcoC2wb75JI1i/fm8XH7hnl3nMlC4l+7bzI3Ebrgs5yn6wom9aWwAPimv0yVoiunlHpuWBAMVuh9ntG9AX3mYxQVSVjM7m5j5wasCHXRH0TC7EZePsEkP8g/OvAE2KsRpeeTD10PZ3orcQljZeb3vCfGytReYnGBvNaATNnOlrCTNbKY0x0pnRuCnoEkFnGiSC77J9l2Xp5CvRezZ03rT0UiHS18E6a+ncNIlJM7jXwNvy0AzApgi6amKb0NkUaoJEfOWZ1Js6KSVSxgwuQOpdmdTSso3OFh1uKo0zmTI2zNaIh6kcmGFtFpfG5k0JWJ2YwS5UMw7GwIGG/CPl2wkdVUUYl4zxu7USrOeu5WcWVjAS5Z+fvLbqMb9u/w/Kv/bTGf0c1xfBshXgVnPbNjwzPEeXGNRkYHaXGQqYbjjtNhQBk7KEYrHM7Fx2TQ+uTS/GOQgCVGdYIlhS4GCaYsLSRq3wbZuw4enFIO1iFIeI8o3oHaYs5mOv2cffvfUoDpv2s5H2XlHk4tfv3WWGKz+r7tEGlkWUV+ldMMiPzfXwbIACAtyunOeHamwQO9PyQANG1daobLbq12SuZIKnBnzsq/fy454pvnV6xHz8bbaHARhQqwiQ+nvy1lua+cTrD/KZtxyl2J3c/ZulmP9Rj/M22yM06ovgnz10idE8kErkABvNaERKeTXBzfZhVjBgSmdG46ZgSAS3SLA8BHjQ9iP+I/pSZtlYCPwUJbpEMHnO4dImpGZG56aQZerETFznxmET3LGrcqVTc4o9liq/0cEqW6GDBSubgDxzdYZzw37mlrUiWQV+SsVikuzNwOHmjdnVux029lnDY/Hilx7T3hxgehsRLGscgHG/S7SyT5Rw7mBjcDtstFRoa/WoLCciFZoshPwLT/fnfKY5FX7hX55d0czqj+3/zBccf8ZdyouEa49k9HNcVwRLdZVQLHMrmemdWKBLDHFZNlLjzWyCt92mMIVWwbEtTxOMZG+A9cLIHM1iAr/0MEchZR5t2DOTKClwIFGYoJQaMUPfVP7LowLhKMthlU5dHnbF0r141aE6k0QlQgjBG49pUrIIdv4g8vMMqlXcb4tleF8a8+d8yHN0dpmblW5cIswP1MOAJg9sX+H/K90wzEH6dZIfM7rIPumIRFXODM1xpKmUsTj7WMl9tud5MnqAB0N/lHTeu+5o4zsfuIMPvXwPb76pGSEEHVVFKR3VPhV5E24R5gHlWUAzmvnu2dwFLeYQG8po1G3ZZYJ8cBbIT5t2u0bCt0qwdotBXCLCE+qhDZ87Jb24RARvinmjp3qnNqya6Ne73R3CsNuO3QvbKgvNQlO+YY/FCMDoYJWs0sG6NDafUqL8zNVpPv3YFfPn2O8hmWC9ZFclhxs3Th7ujcvKEvTKevN9AKbzWPKViCFLxlGTmRUW38FqKM3sHut6QFeNdk1HsTEsK80ipYF8k6EvBiM815d6PKKIJd5mf5Q7bWfwiqUdgpVWFFZRIEIsLeTOwtofCNMgphiU1bRmeJPpsitMS+3mXynmsioTPDs8R5OY1CtKIuPyQNBmsADGZRm1+OiZzH/b2Svj2s2pUxkmKgXXdDmIwyaoLFy943dnl7VaJ7gsG+NufoGwykgO09ZDEZXJhSD7RR8Qcyj7qcMNKxLHdOOevTXcu7caP0X4ZBEtOexgdY9rmUVHW8oY98e+i7XMUC9m+L56U5xzYGWRk4//9AF+6a4O9teXmB1M0KrmH7TIRA0MySompTcui+fhC9cfwdpoRqOODyeQr3bgVLo/W1qg2JAoOMTWCNYeRZOrXdxAsLmBaakV76xD7wbCUck3XkgO3F0NE/p3wig2WQNjd1VvrLuWTXRYuvGzUvt3YmyGFaGImlJC+czVaf73Quz+beY6pZjBev/dnSibyJR8MMEUo1fW065YOlg5cBveLIYta1ujmEKVglEZm9tz2RXq8sTkYjvDKoG9LJvYK/rjnu+fzq8O1vP9vhULy3cqZ+J+DtdsvLC0EVxXBEsp1qobs5O5y4dZWAriFmEWZAEtGbac9ThsTOmLYIXwZ83oIqpKrowvUC78TOqmE1WrBOWmC8YG1Jg7G/YtZ7Vrtxm8OKRVWjrECAOymhDa/0NtiXvNBbSrphi3I/YV7pc1eocmdnPJpY3quD+AlLBP6WdQrWIeD5VFTu7orMwawYJYzki/rDbnDXIhazDCXg81lMTZCxvuhonukb9waytvvaWFyqLk787rjjZy//5aXHaFvXXxdu5X1Ea6lNjmNh9m8XKEdWc0rhB0/0a03Ma8hKo4cLL5+1sBAd5t+w5L0pWUN7UenFD3EpR23mH7Xsrn12tLDtqaMR/QyOIuZZiQtMUZFuyqyV+zAqt1/JzewfoDxxfMbnkqnOybiYvReKp3ihMJ8ywdYoRl6Uwy+/C67UmGFetFS0UhhZaxhKtqHXVihkI0spLPpgWJsBYPW8QYI1QQJiadPtpcij1Pu57bCVaCdV620CbG8BBbv4w563yBdZYzEQ/YnmNKerkt8Df8XeS1hBuOZ/SzXFdXn6tEq/jPT4+scWTmEFnWNjuLuDMemljotpsEq1LMMbOYHdOH/ulFghGVUhaZ1e1lq4szX0kqsXSwqsUsEhjIs+pKIk5c1RbVVjEet8GuW4d81GFT4py1+mUNhSJIpcU6eSrL5iZWGCnqe0U/F6Q2oN5eVcShxpKs5tkY5L5f1urEQ5p5O9nEueE5SgocFLvthKOxzVWLonWY+hIcsFbbRN3UWkaRy85v3t/FzyUM/1+RDXoXQHsPfyDC3DYxfEknNprRiEbIPqQbWHwC+Md8zsJSFceWJIK/af867coYL6odKUNshVhdYjVKBd+I3sGrbc8gUuQ+ndxAFt/0QtAsC+0VA/TKBtMQB6CzOn8JVkNpAUKvhVlt5VcingBPXpnij75zgQ9+9QXmA+GUA/ldYoheWZ/0t3nvnR1bIg7WfYdBYo0Zpu1kcmHtYHWJYa6o8d25e/bWJJ6yg00gjmCprShCskfEjFryrYM15Ev9eRxEuEs5zSPRo4xQyScjP8Mz/ZktPl5XBKugVJNfLc9NrHFk5hANaMO/CxTQWpHZKn6J22HOYFVmMRfqnF4xLxUL5tBvpg0uQKvsgdbBKhbLFLKcd1/+RJwf1YbEm8W4udg5bILG8vVpx29sjW3CE+eMILcdrP7pRVyEaBVjXNIlSB1VRZR6nFmdpzAChx+P3kCt8HFMdNM/tYSU2Z1POzfs50CDl9G5+L9JixgnLG1x8pYbmkpXHdAW+o7u3S9ppz3BMOSybMIrlmkgZr+cC0KZD9hIRqOegfVJ/fEP5zO5gq0RLA8B3mx7nPNqCx8Ivy/lMY1lBXz9l27F47SxUjP9edlFkQjEGSUYmA9EuLbO6nZssyw5oFzjrNoW97x1k5dvcDtscREk/xJ5OQD3KKdIZQAC8FTvNF97bpBvnR7h7x/v5cmeqaRj9ioDXFTjpZtlHgfvu3vtMOjVcNjiPjickIU1Mruc9fviZhBVpTnHaiNKhxhJire4pW0ls9AdbARtlYXY9RvAebUVgP1Kn/l8vs1grbTWvUp5Bq9Y5iH1FvOxP3voUkZVTtcVwSoq1zoE4bmVW/eZhhrUCNaidFOf4QHMskIHQZzMywIqxZzpTpRpnB+ZQ0HFy5IpmahKIXNKN7ymRFBbQGrFTN5LHib9QcqYxyuWTSvx2zsr+fiDB9d1vnUO64qqLTD32mJjI9m257fi+X4frWIMm5DmHIHVxSpbMDpY31dvYkm6eJXtBPPBSFZJRyii0j02z4GGEr7+/GDccy1igiFZSRRNunO8vZxv/sptFK4jJ0wIkVSoOacvggeUWFX8eiVYP8mQKQhWCQsUs0RNaqNEE0eVKxSLZf408hYmSd0p7awqor60gId/46UpXSsBzqqaB8gBkdoSeXxufbL0M7qzXi0zVAo/Z2WMYNmU5Gs832DtyP9h5Of5w/DP0axMrhjEvBCMmKHKf//DXkKR+A5gJXNUiTkuyvjudDpyne7ojMlBh/WiTr0+Rze3HN4WXayphaCpAjAC2o28TQO78piUbyc47QqHGrVC/QgVzMgic64atLVlMbj1uIh0YaW17p3279KtNvKEGttbfeL1hzJqvnZdEazSSo1gRRaSq0XZgJQSGdDY/gJuKooyk4FloEI3SZiW3qwSrAsjfopZQhGSOX3oNxsdLIdNochlZxwjC8uX1wQrqkoWgpGkvLCjzWXrtu8/1lJubn6GqeK/onfwTttDeNEqx7n8/3+2b8asbBtZLvtzkEtizDAt4eaMbOew0gtoHaVs4fL4PKGoSmtFIf/+nJVgSQ4rPVyWsc3BB+/pMjtU60F1sStuFu+SbCYsbRzcIVg/0ZCKA6fF5OKVyjO86H4PZ93v4oT7/bzJ9oMVzz0selCl4EW1Y8VjDFne492TzC2n3kBdkQ0EpIMDloq2FRPrLPCcHtDmJgzTjQtqjFi0Vnhw2vN7q9KcIHk2DDqsDn0rIVXDaK+iGQkkmo+kg2DdaLF3n6KEoLTTaAkbzreORCrEywO1edNuSwfLZVc2FMK8g9Vx/35jfEFwXm2N62BJublYhkwgElUZSZFx2SgmOKj08fXonXGSW2uQciaQ33etNMNTVMKSdCEWcxAMCSyGoniEdmNYlAWUehxrnLE11JZoG0sjryRbwbvDs8tmkr3hqpSNGSyAu3ZXxTpYzOR1NW5Knzu423YaiOnhj2wg38RpV/iN+2LBxF+N3I1LhLlVOQ/kroM1HwhzdXLRJFjXZB2KgL213jXOTD+sBitn1Hb2iX7sRFYdhk03jPe6NOonaKlW3ywu0SimeFTV7GL313u5taMi5WusBCUh7DSIk8uykRtEr/nYdtg07WBjUG1Os4PlIsQfOP417vmP2b/ITeJSynMPKz30ynrmST0L6bIrdNUUE4qofPrRnhVnoKLYuCwb2S0GUz5vNXNZDd3jWrHD2OgPWOy289lB0ECiaY/RsTecADcKY8YlUSLYUb31Tl61121KPiUKI7KCBkt47GZCorMNa1B8lxhClSIuoL2iMLPF6+sNt3fEup7nZStdYiiue54PmZsAg77llA6C9ynPA/CwemNWP891RbAAZpUSbIH1uxulE/7lMEW6+0rY5sl4LlR9iSZBnJIlVIo5ZrPUwZpeCJlJ9kYuSE0WOlgArz/ayLgpEczvDtawb5lK5viA7Rs8Hr3BrHputKpyu0XycUruYl4WmHakuSJYRuW6XRlhRJazhJuWisKMBWuvhooipzmEflZtwyXCdIkheiayV3U7OzyH123nYYsN8x4xwJecf8qydPJY9CigEazNINEQ4xl1Hzcr3RTpGUXdeVJh3EH6YJUI3qqcp0r4eXvot/jP6B18JPwOpqWXjzq+lHSegwg3Kd2cUpNt/g384h1tvPFYE985O8KYP8D/ub+LxrICbm5Nnmu5LJviXCutmPCv7/5jVJ3rxTQhaTNnh2Hz34lsIpFgjVDBsnSuq4OVCnuVAUZleVL4czrIphCCMk+MgAzLSlNFAVp+Yr7DGp7epQwyIKvjAtqzaaJ0PcBapOyRDbhEJI6UXxnPj/Xl9GDq/Kt7lVNcVhvoT3DqzTSuO4K1YCvFFVxdn54p+ANh0w5VujLvitShVx2npZcK4c+KRDAcVZlbDps5ILOyiPJCZ5KEIlNoKvewjBu/9FCT5zNYF0b91IspFCH5UvReJAoFDtuG59WsndAIdk6qXRxVtMDKvhyZfBjErkOMcFXV5IGNZbkJfXTYFI63aV0hQ3LTKYbjgiozjXPDc7RUFDJimUn5fccXWKCA14d+39xQbnaY/1hLOa8+VGf+/N3ozbhEmJcpWnf08vg8kRThpjvYvpC2GMF6mXKaJeniaXU/vxn+Fb4cvY9/ir6SQ8o19ok+7lZeoIYZPAT4svNPKBFLfE+9acXXNiJEvvbcEC0VHh7YX8uX33kLR1qSu+uX1QZqhS9luO56JYL+gLY2NYgpRmVFnIxnf8P2I1gShR5ZzxGlZ1Ovt1f0J3WvAHMWZqtosNyLX5Qd7BP9pvX2Uz25KUBvBFYZ2G4xlGRwkRhdsYOtodzSEexXNaWNlZRfyxMzsef7kwmWlwVuUS7ySJa7V3AdEqxlRxmecGqWm2n4lyMUCu3GYHdn/gZwU2s5dkUwRQnlzDO/mPkNpU93KjQW2zkKOd5evqGZkq3AuBFMyhIqhJ/pPJYIXhiZo1ZoZH9MapXh5nLPhn9XpXwkALMAACAASURBVAXxcogLsoUOMYKTMDOLoZyQTO09Je1ilKt6Zy5XBAvgjce0BXhQVqNKQZsYY8iXHcescFTl0ui8ZY5Eckj0cly5yL9EXsEF2Woeu9nB7Pv31/CnrztovscpuQu/LOCY0g1AMKLmXV7JDrYIxYmTCK1ilDfYnuAx9TBBYveCb0ZvJygd/L7jC3ze+eeccL+fj9i/zC3KJXyyiB+pKxvpNJd7GPcHePrqNK8/2qiZqVQWpuygGPODqWSC65EIXhydw1D11IspRhIyuaxRFPmKVCYc34zezo3KFfavYACyEpyE6RQjSfNXzeUeKtJkFrXPQkCeVvfjEFFu0u8VV6cWc5ITuBEYHSw7EVrFWBLBOrKKA+sONg6nXTFnvQdMt+IYweqbyo+15WRf8t7+LuVF7ELl4egOwco4Qq5yiqOpMiUzjzmLRNBdlHmCpUkBHExJL4qQyOXMd+5m9CT4Mn0Ga04WpZSVZAolBQ4UAT6KKWMhrztYZ4fnqBbatTihyxqbN5GN5rQrceGRF9UWHCJqylMu50AeNjkfpIo5vGKZXp1grZapk2kc1hfcIFpwZ4syzkIwkpWurmFwYTgtHRE9fNv1UQAeVw+bx336Z49waJMmIA6bQrHbYbpKShS6ZZNpGgDw2KXcxVPsIP2QNicOonzE/mUiKPxx+G1xz/sp4iH1Jm7WN84Ab7E/xsPRo9wZ/Mu4UFYrnHaF5goPj1zU5KyvOBCT1exKMYt1RncSTNWtGVuHi+A//vCq+e96Mc0wMYJ1a3sF1d7szO9uBQVOGx0JcQlfj95FVArusz2/odc6LHpwiCin1Xg79nTajt9kea2TahdRKTiqXDYfOzOUvfnUzcDIWKwVMzhENC6UGqAzj4OptyuMubYJSglIRxzBGvItJTlhZhvDs8tJZhv3Ks/zN87P4JNFnJYrG/pkCtcdwYoUVFAm55Bq9i+GcX+AQrFMRCqUZIFgAZQVOs2wYftS5t0TZ/SOUZOYYFk6maaYo5tMnd8MbIqg1OPEJ4soEwv4lsKE81AaJaWkd2KRGuEjIhWm0a6Hlk1KKUstmnqj8rlXaE5U3TnQR08tBM0B76vSkAjmThffVO7BYdM6g/1qDa1CC/fNhkzwnG5wMajLKNp0449pWcx53Ya51uvmVQfrKNvicPZrbqg3/92tNrFHDGJk8Xz12dRGBDvYnpA2B7uVAe61vcA/RF7DGMnmKJ+KvJEnogf5TOS1ZhDrR8PvwM/KZgm/cV8XdSUFPHxhnJYKT5zBRVdNMa4ER78ZvPSqddykJBtq9M8ssbCGhfNTvZokzUmYWmbMbCaAX33Z1jKfsonbOuI7b34K6ZX1K1rYr4RblQuoUnBC3WM+Vlnk4mOv3Z+WzwnEFXICuBilIm7DnO+mOON+jWA16XNAQ7Iq7vl8t/XfjjC6pxKFAVlNiyVvU5UwuELAb7bw2MXE+CXJXzr+DoD/jR5LGaaeaVx3BEsUVuEUERbms9/FGvcHKCTAIu6s2JaD5t5nECx3aJqlUGbzCqb0DlabGKNP1uC029mTZee4Mo+DWVlEqdCIhS9LAcsbweDMMkvhKDX4mKAUFYV79lTzwXtXHjxfDdY5rGuyLk4elovFcmo+ZDoIGjNYDTmUCDpsCi36otsna83FIRtB1GeH5yhw2lgMa7k3tUKTMdwR/GtAI303tZWjrJTmugHcu7farDReks14xRK7xDCgSX98i/n3XdjBJmFzUq4rBaydUCsGZQ0/H/4d/jzyM7wl9HvcHfxUSiJmvqQieNcdbQTCUZ7qmebevTVxkuUCp4179lYnnfecuptjymUSg3WljBUYUkFVpakyaBOj2ISkR40VCdqqts9G+bYU7p9nZTuHlGusFDicCrcoFzkvW/ATI7aHGksoWkcu3nrRXOHBpgiTLA+q1SZZgfx2ElRVac72GQHJVlLucdrWlSG4g43BOofVK+vpSpAE9+b4mnnmWrxC66jQsv4+H3mAP468bYWzMovrjmDZirRKx9zk5tx9toJxf4AillmggMYsmT40lhUwTix491qGtbIz+mLZKsa4Jus40FCS9QyT8kKnKRGEmGwxn/Bsn3YzqBUzpjxwT10xxe7NWfdbXaFUFE6o+7hdt2rP9N88FSYXgrSLEZalJslzO5Q43X8uYEh4+mQNFWIeL4tZccw6O+ynrCD2d60WPvxSM2Mx0JQm8ulx2nnvnZpk63H1MHPSw2ccf41A6+Lme2V6BxuAYi2qrO2ONUkp12TdqsfUet3YbQpPXpkkFFW5d29N0jF3704mWGdkB6VikUaRHIFihAinwpg/YM5fGYUAw27baVOoyVK8RzrQkUI+eVZto1rMUs16C7qSA0pfUj7Z3jQHtLvsNprLY/liA7J623SwphaDphV3o5hElYJRGSO39TmUov8ko9KS23pWbadNGcdrMba5kmOCdXog/jt2g553+beRB1eMo8g0rjuC5SrRFowF31jW33vMH6RFGddyJ7J0E2ip8DAqK1CloIGpjG+2R/0BbERpFhP0yVr2ZDjILRXKC53MyiIKRAgXobw0uvjRFW0j0iCmGNEXh61Y8JYkZKr9WN1PizJBPVNcncw+weqb1jKwrsk6JAr37KnJeVWxrVLbABl6/RYxvmp1PR0IR1UujvpZ1rtXoHWwjKw2A+mUTx7TZx6HZBUfDb+DLmWYlyhngfyuTO9gY5A2bcMzJCvjyPpWUF+qvc7TvdN4nDaOtSbLu1Ndq0Yw8D5dlmzFqf6VycWLg7HnOpVholLEJMXlBWnp6mYLtSXJf4NLulzbOgu5GhqYwiuW4oxvIDOueB1VhWbI8aCsolrM8kbb4wBcnVxETZEnlA+wWv83MMU4ZXHzhF0781cZQUVhTHX1otSKeIcsYfa5tGqfnA/GhU+DZsIxLwvM8Ytc4LojWAVl2uZqOQcEa3JuiX2in/Nqa9aqLPWlBYSxM0EpjWIy45vtCyN+WsUYDhHlqqzbtO30VqB1sLSbbBnzTOdhB+tkvw8XIVrFGFd0B6SVwjzXg7IEgmUMSB9QrjE6F8i4NNSKpVCEa1OLmkW7vlm6c3fVGmdlHi26gUifXu1vFWOcG8lsB6tnYoFQRMVnCfmuFTOma6SBdMonrdfRQ+otzMpCXqE8a36eHfxkQNg1gmVIcNMBY116rs/H0eYyHLbkLUJdCiLRLRtRpWCvSCYSz/bNrOjWacxfAewSQwzKatMJsSmHM5ubQbHLHmc2BHBJXdlhMRX2KRpBNQgrwLvuaOOlXem/f7ZXFZnrwqA+w/Tnjs8CsByOJm1Y8wVW45R6MW0WKA0cbcrezPf1hHaLXPes2gbAPtFnPnZ5PHdry/+cSVakNYsJBmU1hgw/FTJdvrnuCFZxhbYYhf3Zd9Ry+PspEgEuyJaszaNU6xKLYVlJg5jiagZb/1JKzg7PcVy5CGjuRKlcpzKN8kInPqkRuzKxwHSeOQlKKZnwB+gQI9iE5LKqEaz2Lcwb3LevNm7jc0k2EZXCXLDf8fnnsuby0z02j0OGaRSTpoNgPtjmGgYihs1sixhncj6YUafJZ68lO3fWCJ8Zhm0gnRb2XrfDvBbC2OmV9ebMWS4MT3aQGTgWtE3FC3Jzc5up0FpRiD8Q5tKYPym82kCqTs0ybq7KOg6ncBKcWQzxvXNjKUmWIZUGOCD6TNMXIGvZiemCEIKahN/NLMWMy1J2rxDEnIh9op+oFFzSre8BbuuswLtJ6fhq6KgqNOWZj6lHiUptu2nIifO1GDPmjxGsmhRqgMPN+W/rvx1hnaX3U8SCdJvzxBArJmYbUko+84Pk+06LGKdfJsuZDdgVETdXlglcdwSrtFIjWOpC5h31rAhFVOqCmh1tt2wxB9EzDSOBe0hW0SCmMuqaNjy7zOxSmOPKBcZkGX2yNid2qbUlBczqHaxSsZB3M1gLwQihqKRLaItut2ykssiFx7l5Cd2dXVX86stiG60ALq7JOlOyc+LaDFensrNgXhj1s1sMYhOSbrURt12hvSr3sg3DAj+Ai1FZTpuimXBkUjb7g+74Qk67GKFOzJhzJgBCpN/C3trFGpRV5gD7ueG5rGR/7SDzEFKTnX4lck9aXq/W6+Y9L23nhYFZVKnlKKaC22FL6pgD/EA9zG3Kebwkf59++SuneLo3PsBWSsk1XVFRwgItygTndMt32FpHP1dI2d1Tm0xH17WwT+nnmqwjQEyO1V6Zmd9Dh+WePI+HP4m8FYBitD3C5Twtxljv19XCZ84wG2ip2H7XzXZAZ3URdotkd0KWmjEzACFdDp9taEXS+D2eQKVJTJrF1FRoKvdgT9GhTyeuO4LlLihkQRbAUvIwbiYxuxyiQne18zsqsxa8axCsYVmpZYzMZG4zqQ05So4rF3la3YddUahKUzDiRlBf4mZaatWWKmbzTiJoWMx2KCNEpaBP1tJcvvUN9isPxg+6X5JN7BKxyml3lvKwfnBpgiPKFQBeUHfRVVuMLQ9mKepKCkyr9gtqC4eFNgSbya7uxQQJ4s/b/pegtPOf0Zeajx1uKsXtsCWeuiVYZx8HZTV1YhobUXxL4byV/uxgY5h+4DO8KfhRJkiPJOqGphIKXXZO9s1gUwSHm1fuOteWJN+vvhu9BZeIcJfyYspzvvJsvHxwYGaJkB6hcUCf5Tgj28znc6F+2Cpqvcm/lxfkLvaIAYpZ27F0n+jngqWL57QpGQto70goes3KWFEScm9asBIMVYCHAF6xHKcGsAkRZ8awg/TBaVfirplJSqkS8fOVLwwkB/1mGj0p1u+j4gouEeaS2pziDA0tm8gc3SiuO4IFMKd4sQcyH7prxexS2KzsRRzZG7rzuu3YFMGkLMEhoiwvzGSsjduvz91UiTmeVvdRUuDIGpG0orbETb+sISIVdinDeScRHNeHdOvEDOOUEcFOUxrkMCUFjrgZgHFZHldhSgzhywTmA2GeuDzFEaWHMVnGKOXc0Jh7eSBoFtRGEO/T6j46lFGq8WVsLjESVZm0XHvFLPEG2xP8j3orU8RkLC9L4cq2VVjlHIOyCrtQqRNaB+H5/uwvgjtIP6S3kWfl3rS9XmulJlE+2edjX513VVvwhtLkTs052UZUCjqU4ZTnPHpxPC4T68krsSKnGYquxqRx2zEstilFoewZdS82IbnREvicCq9VnqJJmeSiZf6qtTJzVfayQmdcJ3JWz0Yr1Z3hcuE+uxb8gTDnRzRjompdnmYlWCWe3Ow5rhdY9ykTspRq4teSkzlYW3oT1u/7lJP8p+sPWJBuvqfelPKcd93RllRgyASuS4K1YCvDFZxe+8A0wrcYwiuWCEo7Nlf2tOVCCIpcdmaMmSTm44ZE04m+6SVuVS4A8IxOsHKB+pICQji4JuvYIwaZWw6vfVIWMazLNGuZNu1l0zHQLYSIm+2blCUUiiAetL/34EzmM5+evTZDKKqyRwzog7AiIw5Ym8XHXqOFdT6t7gPguHIxY5Xa758fw2rE9SrbMxSJAF+I3G8+9vbbWvmF21vT/t576uI7WIBpw/zpx3qI5GH49g42hnR3hdsqCglHVV4Y9KV0D7QilelCGDsjspJWkRj4qSEQVvnrRy6zFIrw454pTlyNFTmrxSxhaWNKd/zyuu05UT9sFbtTmDq9oHYSkA5+3vawOd+UCAcRPu74ZwB+qB4yHz/anFnDho6qIpw6gbPOLQP0T+cfwbo6uWjeU2t06/txSwc3lURzB+mDtZs6IcviCrigmdZk230yMX/rrbZHAfjjyNtSuqvuq/Pye6/ay9tva834Z7suCdayswxPJLtBw76lMCUs4sdDkTu7dtWlHgezxAjW0GxmNtp904vsEkPMSQ8DsjrJOjxbKPU4cDsUumUTXWKQ2aX8IlhXJrROUp2YYVR3k9uVpmqt1Z3S6JJUCq3iZ4QzZhKGfKNW+EzyuLs2fyrRTeUeaopdXNFdz9rEKI9dmuDx7vSb3iQO3t6rPM+AWsUZ3eLWZVf4wD27MjLAbtXLGy5znUbO0MQCF0fzc75iB+uHPc0Eq7WykPMjfgJhlWMtqeevDLziQB0HGpILJ32yxjRUSYXPPXmNu//icf7lR9firsEafExRgtS3JDc0lW7LTsSeFMWkAC4+GfkZXmY7bWYTJuJG5TLFYpn3hH49zqL9lvbV/w5bRUdVEVIPQZ7TO1glegdraiHEfCC/1k5rUHpNig5We+X2CabejognWKUUiiCFxCTnM4shzmfYmTcRz1yNNUsKWeZW5Tyfi7ySr0ZflvL4997ZjhAiLaqhtXBdEqyQqxxvNLsEa245hFcs4peFFGc5D6iyyBXrYIl5s4OSbvRPL1Ep5piUpYDIWQdLCEF9SQGX1UZalAkCS/lVidMkaZI63a77eHs5rzlUn5bXtpolaH8HqEQjWJNZIFjP9c3gIkSZWDAXvs4t5HtlArd2VBDCwRhlNCmaTOnHPek1vembWuSCZQPpIsQdyjkeVY9imMPe1lGRMRcjl93GrR0awR2nDJ8sYo/FQvtkf3Yl0jtIP9KZEVVX4mZ3TTEndVe/tTpYVcUu/vjBg0mPD8gamlchWKBJpM+PzDHoixX6qsUsEzImJV6L4OUrmss9uB3J26qvRO8hIB3co5xKed4DynOEpI0fqwfiHl/JaCRd6KguJBzVCFbiDBZA31TmVQ8bgW8pRrDa9Rlma8hwJuzsdxCDNQPPcG9MNHA5vUqweLoxOLMUN/qwWwziEhFToZIIh01wT4rw9EzhuiRY0YJKSqUfqWZPJuNbCuNliXk8eLNMPGq9bnx6B6tczGekkyGlZGR2mUrhN4PdckWwQJvDGtOlA/ZAdh0j18Kgbwkvi3hEkFFZzsGGkrRtlupLCzAKv5NS62AZg6gT/sxIQ63om16KvR+leJy2nF4HqXBTm7ZpGZTVNOmyuXS7aybOOe0XfbhFmKfU/eZjt3dWpvU9E3H/fsP0RNAtm9ijxLJ4cqGV30F6YUtjh+eTbzhEWaGTk30+mss91HjXllqlchLskzWUiwW8rC67HfMHCVpmgZMI1hoEL19hU0RKuXcQJ0+p+3mH/fu8z/bNOKlgFbP8rO0xvq3eziKxAllFoTPt7qKJsM6hzJrZkbG/XbacZ9cLqyPwjeIy3bKZJYsM7GV70j/PuoMYrB2sx9SjjMtSfsvxtbhjerLoPvnDy/FmdXVCKxCNyNRr681t5avOlqYb1yXBEoWVOEQU/2z25rB8SyFKxCJzspAyT3ZdbhrLCvDJWPBuJmaw/IEIwYhKJXPmxj7XBGtK/xyF4cwZe2wGk/NBGnTDgTFZQV0KR67N4lfu6uAXbm3V3sckWFoHazEUZTGYucDhUERlZjFELdpNbkyW56Um3gi/HpJVJsFKt7Ne91i8TOKIng90Wu0A4B23t/LqNHUtV8ItbbHq90W1WavuoW1QLmfJUXIHmYPNlh6CVei0cUtbBVJKTvbPrJvclKZYxy7qDngHlL4NfYYqMWvabQsBhxq3b5bRSiMAfxV5PU9GD/Bbjq/xgHLSfPx+20ncIsw/RF4dd/yBhpKMyyStBCuKDb8siOtgXciB7fZqMOT+NqIcUXo4qXaZz7ntChXbcG5vO8HqvDePh29Fb+eQuBpXMMhm4PCJhJxJw8hpRKbu/D54uCHl45nCdUmw7MValWNuKrXbUSYwuximmCX8eDIebpaIlgoPi7gJSjvlYsG0CU8nJue116wScyaxKc0hwaovKTA/R5WYyyujC38gYtoSX5JN1Kdw5NoshBAcb9ckEzN4UaUwCRZkdg5relF77Rq9gzUuy7Li1LNRdOmSxQG1mlp8OAmntYM1txROkkncoPQyLCuY1LuqR5rLUga2phOtFYXmnM73ojdTKIK82fYDAPpnlrI+jLyD9CJdHazbOytx2hX6ppeYWgitW5ZmONRacUbPsToskoM/V4KDCJXCb3aw2ioLKc7AXGK2sFKF/Izs4O3hD+OXBbxEOWs+frtyjiFZGZeNB6SccUs3GssKErKNyswuAMDZoblUp+UMM7pEsFlMUCQC5jwrkLOZ7+sJxW5HXAB4v6yhQISoJrbeZcvef8If4Nlr8U2SejHNonThJ3kWz+u285obMlvUTMR1SbBcJRrBWvStrhVPJ4wOll8WUpnlKkt1sRsQ+CimlHnGM7DJnvAHcRLGK5ZMYpNtKaQV1g5WZR4RLH8gTFSVHBa9+KWHq7IuZabMVnBcH4yOYtPmjETMwCGTMsEJv0GwYsPH++vzx0HQQInHQZHLRo9sQBGSLjHIzGIobd293/ja6QQTCcktykVOqbEg6Np1SLC2Cqddob1KW2hOyD2cV1t4le0EoHUbx7IgGd1B5rCai+Av3dnOf/7ybRSvw1DJmNV7zpi/allfB0sIkSQT9FNIr1rHYaV3Xa8BsarzKNp962DD9u1ewcoEC7R78nPqHo4rF3iH7SE+5/gUr7Q9y4+jBzBmMw1YoxYyBbtNiRv2vyZraRFj5s9n8yyYfFYnWLU6CRy2SMG2o+vkdoR1Te+T2jyT1Tl0aiHIVBaicd76TyfMyBsDtWJGn8lLvje+ZFdV2vMm18J1SbA8ZdpsQmB2bI0j04fJ+QBeFpmjkPLC7BKPaq924/HJIirEfEY22RPzQSrQ5ASGe10uJYJ1Je6Yix5zzC3nR9jwwLQ2NHxY6eFFtR2JQn2aOxmlHqeplb6sNrFbxGZvMrmpNkw0WsUYflnAHIXsrs0vgwsDzeUeXlA7gZh8byANNvZLoQg/6J5gPhAja51imBoxy5NqzBQgGwQLYnJIELyodtAlhkB3DevLQxvmHawfqQhWpx7Ou6u6mBtbynjHGlbE9+6t5pY2jWCd7Juh1OPYUNc5lUzwtOzQCdb6NuaG+YqRgbUvj2IdNoPCNWY8nlL306GM8jHHl7jP9jzfi97EX0TelHRcZ5aClrssDrb9skbfLGt/u/lAJK+CyX2LWqHUkKFbHQQb0xB1soO1YSVY/VLbS7co8XvpMxk2upBSplSd1ItpRiymJ1bcsSuzM8+pcF0SrOIKzbY45J9c48j0YW5uDqeI4pceilzZN7kALXi2TkwzMR9MuzxoYj5g2oFPS+0LmO1OnRV1ehbWnPTkVQfr9OAsBQTYLQY5LTtx2ERGfk8H6jVyeVk20ilGUHSNdCYXS0N+uFsZpFs2AYKDeRIynIhdNUWMUMG4LOWocgUgLYHD54b9JH617lDOAehVag1G0SPT+MU72nDatdt8t2yiTCxQpcs5+qfzyyFsBxtDKongX735BoSIFQt+7tZWHDaRsqtyz55q/u6tN7JHL4Kc7PdxrKVsQ4Y7qYwuXlQ7qBaz1LE+p0qjAHRZNgLESZC2I9Yaov929Dbz378aej+/HP4gk8TfJ4XQpJLZgJXI9cnaJMlXPgUO+8wOlqaSGLPM2nRU7Vi0ZwPWzuqIrCAkbbSJeIL14mBmpaUziyGWw9G4x9wE6RTD9MnalOfc1pGaeGUS1yXBKq3UCJa6kB2CparSfK9pvGtWuNKNyiIXQkC/rKZZjBNVVaYW09vCnfAH2a27lF3TL/Bczt9UFWsb2ClZQqWYMytfucbpQR8HxTXsQuW02kFTmSetdssGjHDfy7IRlwib2TSZsugHo4Ml2SMG6FabcNnT351LF3bXeAHBGbWDA6IPgN7JhS3LYbpTOCjdrpzjmlrDMJqFcJnHkTWpwtHmMj7wMq1Tp5FeTDfBnixp5XeQGSTeN+7orORAQyltFYV06yYmVcUu3n/3Lv72LUeSFAX37avBaVdQFMH0QpCrk4sc26AteMoOlt4ZPqysbw5rtzJEv1ptusFlI58mk1iLYE1SyqcjD/LJ8Jv4b/U2M/vLisaygqzdI6zrdL8u+bJumNNReEoXDJVEjZjBLwviHATzKdD+JxlWVYqKwjVZR6cYiTvm9GBmO1iDKfYx9ygvUCQCPKTenPRcZZErJ4Wb65JgOV1u/HhQlrJj3z29GKJUaox+SpasSxefTiiKVsEckDV4xTJlzJvzMulCz+QCN4he/LKAXlmP26HQUJZZi9nVUKpXVqcooUrM5Y0c6vL4grnxOK12ZqxKebBRJ1iqVhXu0qvEIxnqYP3g0gSfe/IqtcxQIpa4JJtpKC3I27DQlgrt994r62kRYyio9Ews8M3TWzO+GUi4zl6pPMN9tlNx+Tb1GbZeTsSbjmnEKvFauJhnDmE72DisBgWGRfXeem+c+9sH793FXbur+ekj8SYKt1oquoZt/3rnrwyk6mBdks0EpIOblO51vILkqHKZ85Zw3VQ259sJ6ymgfiryJv4u+uCKz++uyZ60ut1CsC6pzQAcVK6aj+VLB2tuKcz0YqyDNZ7gFHewaXvP7m0XNJQW4HHGyP9l2chuS8YiaDElkWjmnJuHfMnqi5+y/ZhxWcoJdW/Sc8daynKyF7kuCRbAnCjFHsiOTfu4Pyafm5IlWe9ggZapYVSnWsREWq3apZScGZrjsNLDGX2uqL2yaNUh7EzDYVMoctqYlCVUMpc3m8lh3zJdyjCjspxpSjJGsG5uq0ARcEV3ptJmbzInEXz44jgLwQgvsWnuWC+onXldUTTsZntlHU4RpVFM8ny/j09+r3tLXSyr7E5B5e+cfwPA/6rHzMdfdahu06+/GVQWuXDaFWbwMilL2K1fCxdH/Xk1wL6DjcPaxTJmDPbVeRmYWcIfiO/a378vFrDZWV0UV9E92TeD065wcIP26KkcB0M4eFbdwx0Wp7yVcEBco17M8Jh6BIBit33bu8GtZNO+Ebz8QPbuEe0Wad0kpfSpNXHkuHcyPzrdvZZMrloxYwbdgmZp0LzNifl2gaIIdlkKAN1qE83KJB5ie8qFYCSjFv+JXdUSFrhLOc23o7ehpqA1t+dg/gquY4K1aC/FHVyfRnyrsBKsaemlsii7Nu0ADWUFJsFqFuOMz6ePYA35lpldDNAlTbAqJgAAIABJREFUhjgn2wDywtygrNDJlNQ6WPGubrlBJKriWwpRjc/UjrdmiGAVuey0VxaxjJt+tZrdik6wfMsZ2VQ/1aN1g1+uPMegWsV52ZrXYaFtlYXYhOCqqm1k2sUIw7PLjM4FtmR2YT23U2jdsI+G384T6g2AliT/Zr2jlC0oiqBR75pdUptMKa9vKcyH/uNMVj/LDtILYw5rX52XXfosjWEScSnhnndTWzkv7ari1+/t4g9fuz+uonuy38cNjSW47BuTpb36UD3FKQqGT6oH6VKGqVljDuulinb9PRrVCNZ2714BFLlsW4pisSuCB/bXrH1gmuB1O+L2JCflbo4p3RhGF5ezGBy7GnotkuY6Ma27xWnwuGx5q5b4SUSHZd9izE4aRVwDT17JnELshQFf3M8vVc7gFFG+Ez2edKzTpvCaLBc1DVy3BGvZUYYnklmdqIFxf8xhL+Aqz0nGR0dVEQNSk5C0iHHG09jBeuTiOPViGpeIcE1qF/KrDubmgraivNDJpCzVrONn55IqutnG5fEFVAnVYtbMfGmtyNxg7pFm7T16ZAOvtj3DTytPshiK8rvfOJfW94lEVfqml3AS5nblHI+oRwHB3bur0/o+6UShy86x1jLzev1X559TiraRODe8ucqblDKug2VIQX9kcQ+8Z09NTsIwDbnuZdlElxgyTU++/vwQCxkMn95BZmFIBD/66n3mBnOf7vJ1YSR+0NxhU/jiL97MB+/dxW2dsYrucijKueG5Dc9fARQ4bRxNISs0ZDpH1pjD6lBGGJYV+NA+866a/MvN2ygKnXbeeGPjps/vqCrK+h5hV3UxBj85r7ZQIeYp1++H4/6gaY+eS1zVpYouQtSIWQZllflcLg21rkc0WrrfRn5bmxiNO+brJwczkrUopeSFhBmvY0o3C9LNWb3Ab8V772xPOSuaDVy3BCvkrsCrZodgTc4HqRRz+KWHMm9uZFOtFYUEcTImy2hRJpLyAzaLQDjKX3y/m2bdRKFf1lBV7OKu3VVrnJl5lHqcplV7BX5zQDZXOD2oVV1qhM8kWJmcU7ulTdsw/VA9BMA77Q8B8NC50bR2sYzwx8OiB7cI82P1AEJkrjuXLvzU4Xpm8PJw9CgAB5Q+ILVRxXpwasAX52x0n/I8U9Jrmr4AWQ86NGBYGD+n7qZAhPiY/Qvmc5k0Prkw4ufFDA88X89QFMFLdlXGzVNVF7uoKHSuW6Lz4tAs4ajkpk12nA+lkBVeks2EpI1DllmeVGgTY/SrsW5NNrKfMo0it52XH6g154A3ilyoPzqqC83koJjSJZafeGks912sPp1g1eu5aUMWgrXdnSe3G5os+5ZBWU1UCtqUeILVN73EuZH0uwmeHZ5jdim+WH6TcplT6i6ixHfg60rc/Nq9XWn/DOvFdUuw1IIKSqUfNRpd++AtYnIhQJWYY0p6aSrPjfFDne7m1i9raBbjactDujQ2z2IoagbN9as1vO5oA3Zb7i+t8kInU4ZlvJjDt5jbKtyJazM4CVMmFkyCVZdBl73j+qbri9EH+HzkAdrEKAKV2aVwygyJzWJqXvu9HlcuokrBs+puCrIc6LcZGDNiHwu/HYBGoTl9Xt7kZuLfTsTyxvaLPu6zneILkfsxQg+F+H/snXd8G+d9/9/PYXGDew9xSdS2tSxvO94j207SOEmbUTsdaZvGjZuke/1i55emv2bVdtM2s0ns7GXHsuNYtrwkWbIsUZOUxL1BcIIA7vn9cYcDQIAbJA7kvV8vvV7C4Q6CSOCe57s+H7iyYeWlYiG8AXlC3c1PglfwdtvzCEO6f/nk2vef6VuWRdZCw6aIqOAKNAPgTdOELmbj5ZZBhICd1QuvYAFsi2PFMIWD07KKrWL2AGud6I6SVd5YlvzW8qWS7XLQWJLNjurFBaxNSfgZ1BdloUrIcChGp0t1hHnsKRMEWKHugNB9OtJkONW901KNSKVPP3baZVGMVDvAwfNDMceWyheeOh31OIdRmsRFDqobYs59+6UVSdUCSP4uOEmIrCJsQjI82Dv3yUukf2SKArz046ZihRXEQpTp/+5FtZga0ZMwkYvj+uapRnTjkw66yeOWzfF9CFaa3AwH/VLLrhYJj6FAlCxOdnkpFlo2v4c88jOdyyrFW5GbTujeckLWkCl8hlz70QQaAQ7okv8NSgdtsggvWeQm0WR6voSUBHvIIyAVKoTWM77QmYNJvWr1UktYNOeP7T/CKzP4evAW49jWCnfSWhUaDa8bwXPBbeSICRr1GbHlrGCZRYFstWJTBLVx2ow3ledwqnvE+GzOxost/Wwqy1m0uMRMQdFxdR1NysW4z4G2McoXo5yX4QqWmYVx5ktdUSZZLvuig8WmJFSwQkqCpe50ozIUWcFK9vdYSmnMt4YCrMgK1p7axSUHLBbHdCuFVlnGungB1oXE6hwMjk3x7Oloe6XLlJMoQvKiuinm/MvqkpPQDLFmAyx7tvbl9A50zXHm0ukb1VoE+6U7ab3CkRWsEuFhaDgxG+zjnVqWtFr00iaLkChJCyKnk5fhNAKsQuFNegWr3TNJMVpGp1fmLmv1CrRMdoZTG0Bv1uV3N+pyqonMSA6Maj/XYuGhBy1rW2JS/6tI8jIcOG0KQWx0yQJj4W4dGKN3ARXeI20ejncOGwqNafi4WTnI/wavx0t487vYjHYiiGw7OiwbAQyD5eX0w2qxAqxlxSaEkSiIZFdNPv6g5FjH7NXDSX+Qwxc9XL6EjUiZOx1nnI6FNllEkfDiIv59t16f2QjNQRZluyjOTv1ZmpBK8GLbHUMm8StJyKRXCJjERY/MNZJxwJKEfxLB4NiUMStaKfrwS5ux1gBsTsLPbC1TmpNmGNiD5n1aK7qNrogQRy4mtj18/5k+pk837FWamZQOjsr6mPMbi5M707lmA6w0t5Y1Gx2MjboTTX9EgFWSk5yNZ8hsOFT+z/Z1M5aA4fZQO1WZGKBTFiCEJglvBkpz0hjQh6fzGDFmhZLByKSfMV+AEhEKsPIocy9/IBoyFw393kNVmkRuqvtHtQpWEWHxjpoU6IkXQlCco23oOig0fjZSwpPH539faB+a4NHnwq1Q60U7NiE5rDZGnbe1InmbgIrcdDJ175JWWcqITGeD7of17ZcvxqgyJYL+UV/SM9+rHZsiDMuBSHbqwhOvnp89g/zaRQ9TATWmzXCh76E6znvo1FXeykR8O5QtSisAb6jaYPrWCveqUoJbTAWrMMtFcRL2COXudNIcCkFdlKBVltGghM1jk+0jeSEiwKsQ/XTJfGPeRghWRWCeStgUQUOEf9opWUWWmDSSlCE6hycZSaC42Mutsfezy5UTHFTXM0V0BT7TaVv2JPZcrNkAKyNPa2Ob9PTMcebS8YyMkSdGGZA5SfuF2xRBTprDMOcrFYN0DS+9NSi0gaoQA3TIQgoyXaaYvwLYUuFmEidT0kaOGGdwNHkB1vl+bYEIbeLbZSHlucv/WQjJ73rJZFy6KBXaDepMQgMs7edaJDz06QHWehPI9M+HUIarXRZFtcQ8/FzLvIOD9qFxfvZ6uBK+UW+LOimro87bksQAS1FExKyM4IIsMVo6AqrkE48dxZ9gY8jf++9Xki4ss9opz02L66uYn+mkriiTQ3PMQLzUMoAiNAn3pbAuToDVRSjAih/kbVda6JM5dKH928n8fiwHtYVZUYas82FLRXJaJBVFUFeYhS+g3QOa1Wo2iDZDbbR9cMIIvpJBZBtzpeiPag/Mdtmj/OAsVobIVtYTag0Am8SFmPNO9yRur3F22mu59fmrl+K0BzaUZCc9YWOOnXASyCnU2hICI8sbYI1PBXBNaWVSbQYreRF1QZbTWMxKGaLTs7Q5rJCzuhM/RWKYTllAkYkySY0lWdgVBS+Z5DCW1ArWmV6t0lch+hmR6XjJXJF5g3CVTNAt8yjVK2jn+8eYCiRmQ90/6iMNHzliwgiwLqmKHXw3I9es1xbqFrWUUjFEJtpC3j40wdcPnJ/Xa7QPhTcf1ypHedDxKBCuGgJkOG1GG06yuP+WsJrS+YgACzTjxp8e6Yx32aKQUnKu16peLTc3bZrZL2l3TT4HLwzNKpX8wtl+tlS4yVmiLHi8NsWQCEEoqTSdraKFY2odIRGYZLfzJBqbItgeRwBkNnYmsY24vjjLaMM7IWvIiJjZnQqqCUnILpbImfFK0RcVYJlpz7GWiBRjOSWrCErBJiU2wDqTIB81KSWne6Nfa69yAkVIXtJtISLZYwIfzjUbYOUWlKJKgRxZXpGLHq+PIt1kuF+6KU1iybI0J40e3f28VAwuWeiiVW8bCFVFuigwVaneYVOoKcjAKzPIEeNJncH60WuaoICWfSsExIq0jK0rDGeWe2Q+JfrvKqDKhMxhSSl5pXWQIl28o5fUCrCu1P2AzklNPv142ofZI5oBePbU/O4N7UPh9pU7lRcB+GbgRmTE7XVnTV7SK7s7qvOMltHzspRK0Y+dcJvw44faZ7p0wfSN+KIk65OFEOKTQoi7hBD3CiHuXeC1Dy/X+0oUb9leMeNzO9flMTzh51xf/Axy/6iPwxeHeFPT0v3qNpTEVqxDZurlxGsRlNSIHuN7B6uzzWtnHI+w2bguid6BjcVZjEzqAZa6DoiuSCSy62GhhFSPnfgpFUNRAdZqMKdORRqLw995H07OyfK4FaxESfwPjE3FyLPfYjuIR2ZyRDZEHd9ZkzfrvXGlSMiKn4qLmN3hxCOyEeN9c5+8BLo8ExQaAVZOUkyGQ1TkpuPDyaDMolQM8lrb0uYuWvu1G27Il6JDFppukSzP1apFbsboG01Ou9LwhN9wNa8Q/XTIQpx2hfVxNiWJpq4wnBXuIj+qXefFlqU7rb/W5uHi4DjXKq8DmniH0xYW1zA7jcVZOGwiaqP3Ttt+QPPxeODx12e9/pfHujjaFhISkFxhO84vg3v468CHos7bm2Q1I9BmzkJVgguyBIcIRlUXXm/3JKwN6PxAcofiAYQQDwItUsrHpZSPAPVCiLsWcG3dsr7BBDBbwm6Pbhx84Fz8GahnmntR5exVsPmyoya+VHu7LOQypTnmuVxGSRN+umT4e1FosrUjEdy5vWzebYKFWS42lydPRTFyPTqnC4/URFS5m+cp+78chJLB5REt9iEaVlnlM1Uom9aNdULWxK1gzdcuYi6mf/4cBLhROcSTwd0ECO83NpRk8/37Lk9au20kSw6wUnkRG1bycE4ufZM5Gx2eCQrQNmCDJHeIN2T82iPzKRWDPH6onU7P4sv+IaGEUKtRuyxM+lDhdEpyXEYF68LAeEINdudLpCJdheijQxbSVJodpcKzXESq+fXIPIoZMpR+nj8bf+M1X/xBlb//6XEymeCv7d8E4KxaQb5JRE7mgxCC8tx0LkZIRddHDHc/1Tx7C/H/HDhvVGpKGaRCDPBynHaFvXXmkBFuLNE2I2fUSgBD6AJgbCpotLIulRa9avIW5QCXnPwCTCReRGMe3CulfDzi8VPAfXNdJIQwfWA1H9YVZrKuIGPGSuyvT3RTkZueEA+husIsctJikyr/HbiVK23H2SGivWtCc4pdMvy9WI2tXk2lObx7d9W8zr19a2lSZ4kiZ2omcTEgs6mIECg52ZU8L6xQe2KdrjwZ2X69KYlB6VqmdJoYywm1hgoxQC7Rn5PmTu+sbcrzQUrJC9P2K1tFCzligmfUS6OOX7ehCJsikj5/BYmpYKXsIjbmyCNjKrE6/dPp9EwaFaxhW3J7QkODyF16gOUPSr5/sG2Oq2YmFGBdIs4yJLNok8VxTSeTSUVuhjGDNTIZSIoXVmjQ380objFOmyxm4yIlfBdK5E2wW+bjFEHy9Rvg/jN9HF6CetzB80McbR9mp3IalwjwkalP0EmhEcinCk0l2Uzh4GuB27igFrNdnMOJ1oowODaFN44K0qnuEZ473cfRtrAMbSgwOy0ro87NcNpM871o0Ns6mmU1AalwuXICR0Sb4OvtiTEFfrFlgEKG+Xfnl9jc+t+wzLOu0xFC7IhzeBC4cR6X34i2jqU8120o5sC5gRjF2DFfgP1n+rl5c0lCNiKKIuKKVHwveB0BqXCD7bBx7O3Kfv7X+c9AuI3QZVfIjiPWsRqYb6fCW7aXz33SMlKVnxElt98hC6Mq3MmsYPV4tTU0ZDMSKSBUV2RVsJKBO92BKyJJfEKuA4ipYo34ArQNLa2j4X8OnOf5s+FuszR8fMj+BACvTjMYNlOiZkkBVqovYpOuQrKDy5tZ7fRMUCi8TEoHfntye4VDZsOa2IEWWP706OIG272T/nCApZzjqFoPiAX3nC835blpRgULkmOYGGpNrBfaz7pFlkUNiC4nkRLO3REKkqDJkf/ocMeiX/u5M9oNb49ykoBUOKBuBsJzTalCqJXgHwPv5/OBd+EQQWpFWBXwot7u5g+qxjzLV589y6d/dMxQ3YJwdvWcGt4oOWyC6zcU4zCJsuZ6vYLlw4mHLD5of9KoPoImfrJUgqrkudN9xuf9mV1fheKmJb/uAslHW4si8QAIIWaMdoUQNwLfX8b3taLcsa0MX0Dl1yeibQd+8XoXvoDK7VvLEvZvxUusjJLBa7KBq5Q3AFBQ+YTjMeP5kJR7UbbLFBnn5SD0nZuNzeU5SV87bYqgMi9sHdIpC42WPIBzfaOMTy3d2mWhqKqkR+8C2ahc4KJaxCjhdS3yPVusHEKIqI6l19VapqSNG5TXYs79x583L6n9/GvPt/JGRzjA/7DtV9xpe4kRmc4g0cnqZNgczMRSV/2UXsQC6YXkqok1QptO5/AEBWKYftykO5KboSt3hwKsAoqEFwcB2gcnFtw21z/q4+9/eoILA+Pk4WW9aOeIrKeuMJM8k7WHFWenMaxXsEDS2peEAEuvYNUp2ga8RZatiIIgQJrDZrTudEcInIRYbGZJVSW/1r2itojznJJVjKPd2K6sT60Aa1tVnuHddkqGWufCgg8hD5hvvniBb754AX9Q5enmXtqHottr60QXozLNEPoAbfbqS++NbmFIJpGGw6+p2mDwTbZDxrELCZidOtLmYWjcb1T0hrOS0qwQb/0JffBn69fMlVIu76KwguyszqMyL53vvRruVJBS8s2XLtBQnMWuBG7qZ/K+ezq4g+1KC/uc9/OC60+ojNi09+m/psIs82SdE01D8dzJtLt3VpoiwKyLUDrtlAV6BUvbH6gSTnSufBWrf8xHQN+cbxQXjUoJgGIi3821SKSvq5csnlR3807bc1FdEQD7mnv49sux81nzYdIfpGPaKMsGRbuf3e+PbZYzkw7AUgOslF7EZGYxGcLH2MjyvZUe7yRFaCbDWUlugSjKdqEI6NYd0EvEEFNBNUaZZS6eOdnLDw63E1Alb7G9iCIkTwT3mLJUX5jlwiszcYkALvxRim8rRWQFa0raaJPFrIsja7xcVOgZvtBAeUiqHeDi4OJ+Hk8193BOD1aLhceojgHUpliL4LXri9hWqbU3tcoyAlKhUQkHWJ978hT7z/Tx6xPdPHOyl5+/3slIHJPuJtFGiywjJDsNmpqiGTZOIYqyXORlaEI7n/TfS7NaxaQMC+8kwlB0X3MPdgJcpxxhXLoYT1u6iMIi8BC7BoUex+0LF0LcNa3dfUZ0QaeDQoiDfX3LK5S0FBRF8IHLa3ipZZBDF7Tv/b7mXo51DPPhq2oT+tmMJ9UO8J/B23kkcAeVoo8yMciXA2/hO4E30S3zUPUtiJnaehKNO91B+RyzybvWmWNGM7LNs0MWkil85EXM1CSqhXgh9HpD4lSSKtHLeVlqPJed5jDV/XWtMV1kZ19wB7lijGoR2xL+g0Wq1Gqz89HHKkQ/B4KbeFLdE3P+agqwUnoRs+doC7+nb/FtUnMxNO6nUHjplzm4M5KnIAhaC4A73WFshkv0X1HvAs1AH4uY27rd9jIn1BpOyuqodjSzUJTtwqu3E7gZwzu58i0OffoCUSe6uChLUIWNgqyVy7qFHNf7cROQiiHVDpqH02IGUH8eYaxbILQEAkC6w0Zukj/niyHUnjOFg1ZZxqXijPHchYFxHt3fyqELQ1wcHOfj3zsac/1GcYHLbSd4Vt0edfzSanPMXoUQQhhVrCFy+I16KRWi3zAUXaoQTFCV/OpYF++x/YabbYfokbkgktIeOUhsAjAXIF5yT58JnnemTUr5iJRyl5RyV1FR0dwXJJF7LquhONvFJx8/ytPNPXz6R8eoL8rkrp2Vc1+8ACItISIJYOdfAvew2/dVPjR1P58LvJtPBz7CXt+XjXPiybyvJjbPYsmR6bRFCUwkk0h7jWZ9zmm70mIcO56EClZIQTCXUZwiSK8Mv8eVXEctYrllc2nU41ZdfbIuosU+xBud3kW1mB7vjA3qq0UPF2T8xN1qahFM6UXM5dY+HCP9iTPYjERKiWd8ytiAmqGUXZKTZgRYIcnuHu/8/bBOdnt59byWCbUTYLs4xwHdRXudCQOsgiyn4ZnRqLTHFSxYbjr1BWK9aOOUrCQ/w7miMzm7a7XgQUWhj1w2iwvGhnoqoC5Yvl5VJc/r81cClQK89Ot90OsKMlIyo3j1+vD95afBy7nKdpwN+kA1wHOn+/AH4wce99p+xr87voRP2vnPwO3GcXe6wxTy7NP55ocvo1b/rrbLIpwiSAnad3rUF+DbL1+c7fJZ+fnrnZwfGGeraAXg04GPLP0NLwIp5WFi15p8YN8Ml+wA6iKsRu6LeJx0QaalkOmy82/vuYROzyQf/vpBgqrky/fsSPg9aF1BplEdjccIGTyj7iCywhsinkDGamJrhXtGufa9dQVJ98gL0RQhvvSa2oBf2titnDSOnZ3BU205CXlghfxEIwOsuSqDFsvLbVtKo34HoepibZwAK6hKfnmse0GzWGO+AP/yy5NRxzKZoEh4o5R/Q2Q4bUnvFItkSd/qVF/EMvK1aHt8qHuOMxfHqC9AIBjUN6BuU7RB1BVmxogdLKSCtf90uH9+g2gnTfh1gQuoXsG2t/nisCkcU5oISIW9SjPeiZWtYD11ooeXWwbIYJIa0ctJtXrFPwdXNYSDhyGZzQ2213iv7Wnj2NkFGkie6hlhSG8rzWUUu1CNClZ9inqSRGbQvxW8EY/M5EuOLxpqgjMhUPm0439pVDpoltV4Cf//P3B5jSn9wBw2hUv1il2bnnwI9bQDPPirk4uqag6M+vjHn58AoE7p5GW1iRd14ZMk8cg0y5CbAMN3UQhRF3o+ZDMS+oMmwOTRH7eQ4lxRX8ivP34NX37vDp76+DVRG+lEkeaw8btXrFvUtaEW3dXKteuL+Nd3bY/73Nt3JN8QNURJjgu7LhU/QRpvyFp2KWGJ/XO9oytuddJrBFjaVrMvIsDabhJ11rWKECJqzfeSSb/MoVbE31Pf/9hRjrbPfyTnwLkB+qclgEPB2/k4AdZ1G8zVTZCItEnKLmLuIu3G5h9engDLM+6P2oBO9w1IBhvLcvCSwahMMyRYe0fmX8F6uTXsRbBdOQfAEakFWDMNOScbJS2b12Ude5UTK17BeqllAAmsF+0oQnJSrnyAVVuYacjv/lPgHgAuV44bzz9/dmFecKd7wj35hUJrGTECLBPO4c2HNIeNNIf2Mxoih7/0/z6NSgdX6OpnMxGq/ABRZsXudAcfudq8hY9Lq7UA63W1jj7p5guOr1Co+/WN+AKcWWDQDfDLN7rpH9VsEOpEF+fUxCnULQYp5QNoCby7hBCfBM5Na0+/kTiWInry72792k/OJtiUSlTlZ3DHtjIKllFQYjFKeMXZLtP5Jyaa7VW53LixhKr89KiMf3aanRs3JmVGMS5CiCgfwzNqBTUR8zSjvoAhmb5ShCpYxXouP1JEaOsqD8xTgenz5K2ylAZl5rGbZ0/G9+WLx/4zsaNBu5VTABzRRZpCuOwKf/eWpCb0YlhygJXKi1huobYBUJfJo2VofIoCfQM6IHMoz02+nKgmpSu4IEuMG2fH0PzMhgNBlZdbw/M7jaKdMemiTRZjU4QhpmA2ctOdnFUrqBD9eCdWNsAKtV+GKgQnZdWKB1hCCG7fqpXuD6hb+Flwb1Rf/bOnFjbfGFnxCnm89aMtdJEqVKlGSGUT4Bn1UkZkOv/j/BxNYuaWuVolnJzpkGH1xKsaCnGnm3cWbYtuzjlMFu+Z+isymeAv7N8znn/mZO+CZXWfO619jnIZoUCMGAHnd1+5SNsixVSWipTyIT2x95Ce1It87hEp5U1xrnlESnmTlDJPvy7pgkypQmXewpNse+sKUrKteKHYbQq/vf96/vfevYBmD/H+vTWkOeK3DiaLqkipdgooxhOlCpcoM/L5ElKQC1ewwkHVYj5vFoll+uz9UbWeraJ1xu6PJ453z6sKGlQlT52I3ZvvVk7RphbRRXT7/bt2VVGcba5ETUIaf1N1EXM4XQyRjTK+PCpQQ+N+o2+4HzdVJrgZVOlVpvMRAdbTzb1ztgRJKTnS5mEkQiSiVnTrQ42Citx003j9TKcwy8kgORQwwsgKB1ghBaR1opspaaNDFiWlVTTSo+aIWk+l6DcqFie7vYz6ArzSOrvptpSSU90jnOmJCLD01wgteiupjphotpSHF+4pHHwn+CYA7rb9dsZrQsO8X/C/ky8H3mYc31S+MjL8i6WuMFxpPCcr+HbwRt5h208pWoX6wSdO8p1X5jeL9aPX2tn9z/uMAOsSvbLdLGsAONbhnXH+xGJ1UZ678A2OGecUlwtFEdQUZLJ7XR4fvbaev7hlw9wXrTDbI4QuOmUBipCURCjPRvoRrQSh9aZIDDMhnYwSDgCrTNo1s5aYvua/ojaRJvxsFfGb0k73jPLDwx0MjU3N+Jr9oz5+cLidruHo7qp8vFytHOMldWPMNTdvNk8lOIQ5d8QryLCSi3NyYS1S88UzPhW1AZ1JZWklCWWnLshSqkQvCird3kkOXRyKav2azs9e7+Jrz7dGHasZYj6eAAAgAElEQVQVXbosdWwWw0yU5KQxKLNwCT/+yZUd0u3R2y+rRQ9tshgVJSlZlsjfT8hHpEnRNtBSwtE2D/+273S8Sw2ePdXHXV89wJG2cC5kh3IGn7QbEvDxzEZThS2VOVHB7/8J3MMptZIqEb+lwUGAW5RXGZcu/j34dnyEW2vMHmC5MxxRggRfC96GQwR5q+2AcezR51rmVXn69fEe+kZ8hunyFcpxfNLOIXU9xdkuagoylrUtzcI8uOw2SnIW9rsOGX2vJf757Vu5dn2RKSt310QI/nTqVflywnukYx0rlwsfnvAbM+JlYoAemUdIJCXNoZi6S2CtMH3Nf1XVkgaXKSfjnQ7AJx47ykstAzM+/40XL/DJx1+POX6v/Rek4+Ph4J1Rxx02wa4ac1gdRLLmA6wxez7pU7Nn7hfL4NiU0UI1IHNMoc+fn+nEYdNaBJ0iSLnQPuSHLwzxg0PtTPqDca977eIQv3oj3A7lxE+l6DNkOc0cYFXmpzOEJmLgnBpakqP4QpBS0j2stTfUiF4uymIAKpLQKlqdH74JnlKrANggwsIGPzjUzostAwzPUuG7MDDGiC9g9MQ78fNW2ws8pe5ijPSUX/Aai7O5Y0v03FCbLIobYP2p7Qf8xvXnXGM7xucDdyEjbqXbK91sSwFVtEi/snZZzDm1jD0Ri+LFwXGu+7/P8sPDM/uXfPeVi7wwbYbvCuU4h9X1+HAy6gssai7HInVZaNtWTX7qJmUWy/qSbLLTzHmvjJRq7zIUh8Ob4aNtK+eFFdmOXheR0AXN088i+dQUZBjCKKDNMJ9SK6PWkngc6xiO+v36gyr7z/RxqnuE78xgSnyjcogX1C2cldEWE9sqc0k3YZfEmg+wJl0FZAWWJ8DqH/VRILwEpIJXZKEoyf9xCyEoynLRrGoeFyGxgzc6vRzrGOa1i+HsVEgQ4nTPSEx1q1r0YBOSFlWb7TFza1hNfgYDUsuS5uNldIW8sLyTAXwBCcgo34bKJMyqRQbAg+TQL3NoFOGN88+PdSEls1Yx26fN6t1le458Mcp3gm/CYRMpv1G6vL4gps2gTRZTJfoAyduV/XzV8QWuUY7ycccPqNRFYv4neGvUNV++Z0dKVGymZx5fVpvYrZwyJPxB64N/dH8rUkpDzSvEVEDlb356PMpbLpcRNokLvKCrB45PBa0Aa42xkGRbTpo96f6QFtHkZjhx2bW9SqfemRASxAJtJuqNjpUJss7pG3CBGhNgmWGm3UJTpZ2+lryiNrFTOY2N+Al7gCNtHu79xkH2nejBMz7FUyd6eP/XXuGWf3vOEEuKpII+GpROnlO3xTy32aQdI8nf8ScZf3oReerylLyPdXgpZJgBcrDbzCPXXJGXzuuyjrNqOe+x/QaANzqGOd0zwsHzWrD5uSdP8t5HX6J/1Mdnf3WS0z3RrXWh2ZNQBcvMPiZl7nSGpFbByhcjK6YkGBK4yGeEHDFh+DYkI8AqyHSSHjFMfVqtpClCmntKb+862eUlEFRjrofwsHGI99n2cVSt44C6GYdNMfVnYD6kOWzsXJeHwxbOxrXLIrLEJP/X8TBfcH6V22yv8nnHf0RdFyT8c720OjdlBq+nm5seluvJEeMxHibNXV6+9fJFvvFiOKs46Q9yostrfG5CXK6cQBGSAxHy7DuqrQBrLbG5fP73gRoTJ+bWMoV6gmiCNHplbozs9nznM5dK+5DWolzOAOliKkqp1cxJ3bVGwzT14BfVTWSLCa5Wjs14zYFzA7T0j/GRbxzkS8+c5V+fmn1EYaduF3AgjvXHxjIrwDIlMrOITDHJxFhilXGklBxt81AohhmQbiMjZAYaS7IBwXeD17NTOUOjaKe1f4z+0SkOXxxCSskPDnXwRoeXH7/WwTMne+kbme5FoN1wW2UZNkWY2o8iN8PJAOEK1kKMlZfChQFtcbhMaQY0cYkslz0pbXRCCKryw4Hd67KOTeI8GUT/LI60DfOhrx+M2yoaGWC5GWWTcoGngjsBwfhUkFoTzBguFZfdxqaIm/VpvRXhLttzxrEiMcwPg1cxLDP4B//7o67flULVmunf2TOqZltRF8ck8m9+8oZR3ewb8fHDwx1xe+hvt72MV2oJnKbSbDJdNtaXZMecZ7F62bqAREu1JVJgSiKrkGfVchqUzqjnV6qC1eHR1qc6RbsntajhAKshRT0XVyPTfxdPqbtol4X8of0n87r+P59vndOPc6NykSlp44yM9Y2bniw0C+bZ9ScJW45WVRjqnVm3fzGcHxhneMJPofDSL3PINJG79GZ9A/nD4NVMSRvvjNg8vtbm4Y0OrzFn8+2XYzNVCiqblAv0STcjZLCpLMeU/a8hstPsRgUrT4zw89djN5DLwfn+MQCuVl7HK9M5KuupzEtP2mBzXUQZ/zl1G04RZK9yIuqcH73WznOn+3j0uRYeeiLcQy2ljGoR3KV7UbyqNhnHagtXx4L3lkvCi/h+dSsfnPoL4/EfTv0JzwW38l+BW9nu+0/+K3hb1LWpFExsqXCzPcJHpkXPDteLzphzpYRW/fP8dHMPvz3dyw8ORc9m1Youblde5jvBGwlgJ6hKdlTnYVPMN8hvsXxsLs9hvrc4M8/urmUijdfPygoaRAcQnl1u7RtbEcPhDo+WpAzdkyIrWKlsCbLamP678GPnscC17BKnySYxFh1N4iJnZSUBovfSuRkOq4JlVlxubYbIO5DgAEvfjBQJD33kkmWiAKtW/zIMksNJWR0lduAZ9/POr4aVxEKbqkg+bn+ct9oO4JHahvqyWvOpt0SSnWZnhHR80k6R8PLLYysTYLUOaD+7S5WzHFQ3EMSW1PaxyHacg+oGxqSL222vRJ0T0v/4132n+cqz5wzFwB8f6WAwQlb1JuUQPungiKwntH82g0pmInj37irCMYHgN+ql/IX/Xt7h+zt+qe7lA/5P8YaMbyLcVGrOG308Ml12vvGhy4zHI2TQK3PjVrBAq8g+3dzDP/2imaebe2PMiP/I/hOmcPBo4HayXDbO9Y0ahsYWa4dMl53d6+a3JmwwaeZ5rbOjJlzdPiMryBYTUabqI74AA7PIbCeKzlAFS3ThlRn0E76/WhLt5qE2jnrwK7IJRUijtW+pNCltNMuqmOP3XFZtOi+5EGs+wMrI12aIJgYTu+nuGp5EQaWEIbpkPrkmGuStj+iX7ZSFUQOsAFMzzOCAVr36gO3XAHw9eDMAVzSY28dEU2sStMsiqkQPvSO+WT0YEsUFPcAqFUOGCW0y2+iqI7LFUzh4LHgtb1VeMLyPIgklJ399vJu+ER9/99NwpasID++w7eex4DX4CM92rZae+CyXg9umqQk+FryOw3L9rNfZFZFybSvuDAeZrvDidE4t51323/IW5YWYc6eCKr//jYOM+gIEpilxZjHOW5QX+F7wOgZwU+ZOR5VYAhdrlDu3lc19EqmVkFhLREpen9VbshqU6CR0vORrIlFVSZeuwlsvOvXqVbg0mgw1Xov4xAuwjqj1+KXN6HZZCuX0UyYGeUOtjXnuPburl/z6y8WaD7ByCrWS89RwrGP0UuganqAID3ah0iULyM90zn3RClGc7TLadjqMAGt+5f5d4hRuMc4fT32MbwVvQhHMO1uZLJx2BUXABVlCrW6ufLZvef2wDl0Y4ninFyd+8sQovVLLCCZzqHu6yt/3gtfjEEF2z3ID3Nfcw8e/dyRKvn2PchKnCPK94PUA2G0KxdkuU7XBLpX7ro1foZqNP7q+wdStsjNRmhP2Zfv34NsBeJstNsCCcIUzkiKG+LT9OzhFkF8GtYpYmsOGENGSzxZrhysbCuc8x2ETVpuXSSl1pxl7hLP63FPDtNbh1r7lDbD6Rn34g9oNp06JVhBMcyirar1JdXIznDF73AnSOCMr2SLOL+m1LxFnOZD2J0CswMXudXmmrmSu+QArr0jLzqgjiQ2wOj2TlAlNka9TFkQZmCYbIYRhMtopC8gUPtzM72b5JtsRpqSNZ9XtgNZvb1Y/j0jSHDbOy1JqRDcgDXf45eIrvzmLZ9xPEVqLXS9aJj9epmelmD7v0CLLUKWgXomduQlxumeU56f5HG1VWpmSNk7p5XopZVL/X8vBtsrceQ/rZ6dpC/1dOyvnONOcNEZU3V5UN/PNwI1cqRzHztx2BjmM8WvXA7zX/gwAh2UjAONTATaW5qS0L5rF4qktyJyzLb46PwOHbc1vQUyJEIISfc/SRy5emRFl6wHhFvjlIiSqlIaPMjFIi2p5YJmZ+jjJkhOyhk1KfE+r+XKb7WXj76en+V/NJ5GTTNb83c3pSmOIbJSxxAZY3d4Jw5yvW+ZHZYnNQIn+ftr11rXKaW2CM3GdcoRX1SZG0Tbre+vM3R4YIsNho1WWkil8FOOZU7FmqZzs1hTXioUeYOkVrOl+EStJmTuNSL0BH07aZFFcUYPZ2CxaOSWrmELbPPsC6qoLsAD+6W2xcrDxuKK+gO2V7qTI7yeCt++IXrReVDfhEn5+6fzUnEHWVcox8sQoXw/cxO9OPWAMILcPTbDH5LOZFsuHoog5vWmKs821JlpE02QIBwjOylglwfPL3CLYoYsqlQht9itkegya1YyFudgUR2jihFpDsfBQyOJVJ0OFig9N3Y+cFrKYvQV9zQdYAB6lAOdEb0Jfs2taBctsakk1elk1NBtUJeb+/5fTT5PSxm/US4xjZv+Ah8hMsxs+VNWih27vxBxXLJ6RSb+RfSuKCLBcdoWyJAbadptCQWZ05u+cLKd+BlGDeCiobFNaOBbRC+0LqEkNHJeL7VV5fOjKdXOet7Esh/uurU+aOuRSuWVzaVRw+Gt1F18NvJn1Sgc/cP6dXvWN5VblFb7i/HcCUuEfAh/gt3pV22VX8AVU9tZZAdZaZq4KcHGOVYUwM5GWE2fUSurFys5gdepraEhcI9QFAqml1rpWiOd/1yy1+aiNS6hi1Ykung1u5xl1R9TxD11Za/oWdCvAAkacBWROza+CMx+klHR7JykRg0xKB8Nk0lBsrhtCKDt1Rlbik3Z2KGfmvOY621GAqADLbP+vmchJczCoS7XnijF6vb45rlg8kabMkRWsuqIslCRLVlfkRQd4Z2UFdaITF/MT/dgoLuIW47ysbow6vloELqbzmTs2RRkPx6OpNIdbNpeu0DtaHq5pLDKqmwHsPBh4D08Ed7NdaeHbzn8hjdjvy9ttzwPwxcDbo8yWy9zaZ2xPbWpUty2Wh7kUAq02L3MTqQB6VpZTJLy4Ca9t5wfGUOMNZSaIUIAVWkN7ZPj9bLACLNOxKU7F+oRaoz0nFhdgCVTqRFeUPH+IP72h0fTjKVaABfjSinEHYpXUFsuoL8D4VJACMaIb3ArWmayCdUW9tvnx4eSorGePcnKOK+B65QhtapHxYRekjlFkXoYW6AK4GaNvdPkCrMjMXo3owS9tDJITt0d5pZnuVfWcuo004Z/VcT3EDnGaX7g+DcBL6qao51brsLpNEVGqmyGcdgW7IijOdrGnNj/lvZ4urc6dJmAh+Kj/47xn6q+oFP38q+OrfNf5j4YxtYLKXuUE3w1cx/8LvjPqtYQQrC/JMpWwj8XKM5dCoJnmki1iiTIbDikJRlSxJv0qFwcT43EUj1AXSKhFsEeGqxVmFjZYqzSWZGGftg4Ok0W7LFz0HNY7bfvJED6jEhaiINOJ20TK3DNhBVhAIKOYfOlBDQYT8no9uklvLiN4ZBYCSHeaS/FmS0T7xqvqBraJFv7J/rWYNgANyR/ZfsxNtkN69Ur7EpXnpuO0p8ZHqK4ok2GpB1hijL6R5QuwwouO5DbbK7ygbiGILe5GfaWZnlV+Sd3IsMzgw7Zf8THbD1GIL9FvI8gjzn8F4IXgZnrQ2r/SHJpCY6oE2oshJAdcmOVk9zoti/ql37mUbZVu7r95w6oIJC6tjt9q8ZK6ieeCW7nd9gp7lWa2ilZ2i5N81fFvuMU4L6hbYq7pHp605q8saCzJYra8gxVgmZvI389ZPanaOE2q/fDFIZaLFj1RWSyGmJQOvISTeKk677qacdnj73Ga1RreajvAxgVXsSR/bn+Mg+p6fhS8KuqZVJn5To3d8TKj5JThEEGG+hPjhdWjt5/liVGGZJYplZLSHDbD/+ZVVTOEe5/9ab7k+GLMuZWin79wfB+AZyLaA+tTyPPnfXtrGNGFOdxijPGpIKO+uVXSFkObHmBtFBepFP38QtWkq81Q5anTb0whX7YAdl5RN3K57QSfcDzODcrhuNeViUEKhZe/9H+Ee/yfMY6X5qRRU5BpWqO/RPCu3VXc0FTMZ+7YyF/etpHCLBdvairm0uo8Lq9fHW1wdYVZ5GY4DEXESD7l/wgTUgsiG5V2HnP9A7fYDgLR7cIAl1S5mfAHucxqD1zzpDlsM9pS3HNZtSVyYXIcNoUM3XaiQxYxKR1RFSzQ7EiWg/5RHy26DHyJGNJFoiI8sKwAy5RsLItt3XxJHyf4nvMfqBbzF5PbKC5SLgb5XvC6qBZ0sAKslMKRq8l/enrb5zhzfoQrWKN4yDatN05obuaQGjZQXSe6EajsEicRqOTj5Q9tPwHgueBWXlC3GufWmqztcTYairNBKHhlBjm6JP1yVbFCFazQzeSEuk57bIIqT2jDU5UXfi9H1Hrj7++1PR33ukrRB0CbLIo6rkpSzlx3odyyuZQ/vbGR27aUsbMmjyf/7GrsNoU7t5WtmlYVRRHsWZdvGExH0kERG33/zahM458c/20cP6LWG2qiIUIzmZdZAhcWELc1vjjbxd+8eRPrS1f3fWM1UKBX51UUzsnyGC+sF1sGkPFuGkvk1dZB4++lYoieCIGL3HQHLrs591RrnaY4SoJfC97OTb6HyGSSd9j2z/u1QsneZ4PbY57bkSLialaABWQUaDLFo/1tCXm97lCApVew5vIDSRZXN2oKgiMRm6R0McUf2H7G465/4AuOr/BFxxcNj5s/8f8xfsL/l1RTjnPaFYZlJm6hBVi9+u8p0VwY0AKsCl2mv0Nq2fzKvORvxkNBXmSl4oSsMf6+UzlDPNPpkMpke0SAVZLtotMzseoDLNB8sUJVugJ9OD9yCHw1sKc2f5aqriBLaN+XrwVu4yrf/+MDUw9EneFOd9DjnaS+KNOqTlgA8deIN28vx2W3WZ+RFKAqP1wpOisraJjWItjSN2ZYkiSSI20e4++Voo82WWw8Ls+1qldm5V27quK2/p6RlRyX67jL9hyV81Csvtv2LPc7HuMVdQN9xK6zV9ab2/8qhBVgATlFmmHq1NDC/IBmotfrQ6CSyyhDZJnWbHNHxAZxz+SXebfvrwH4kP1XALzNdoArbceNczxEl39TLcBKd9gYJtMwVV6OAd3hcT/9uoBGmRhgQjrxkEW6w0ZhVvJnddKdNoqn3QBfVDfxi+AeHg3cTo4Y598cXzbEDEJUin5UKeiU4RtbQ0kWAVVGGdVapC5ztfX9lf+DfDtwA/8YeB/tsggv0b/36zcU80rrINesL5rhFSzWGvFaed52SUUS3onFYthWGZ7NPKuWUyn6Y9aGJ4/Ht3FYCiGfSgcByhmI6pwwg1iURXzyM53c0FQc97mX1E1Uin6+7/wH4iVxQxQyzOccjwDws+DlMc83FmdRnSLdU1aABRSUagFWYDgxAVb70DjZjGMTkmFpXjWtjRHl3F7yeEVuwCvTKRRejqj1Ua1j7TI2Y5Bq0tyZLntUBevUMmTeTvWEX7Nc9NMpCwBBZV66aXySagoyGIuoVEzi4o/8f8aP9UHSt9kO8FnHo/yt/euGQWCl6KWbvKgKZshTqzFFpPotZmdTeQ6Zs7Qzfyt4E58JfJjIWYgQxdkuqvPT8QVUrmm0AiwLjXUFmYZIDGjtxFsqZlcXtDAPN20K20+ElATrprUJvt6+eBPZmTjbpwVY5aIfRcioClaqzN+sVWYKfr4euJkhmUW5GGTzLIIXb7W9AMDn/Xfxv8E3xTz/6ds3xhwzK1aABbjSMvCQhTKWGLPhi4Pj5AntBjEksyjKNmeAVZGbHrWhkiic1OUwn1W387PgXgCeCu7gVt9no661KSLllHzc6Y6oCtZytDac6vYaf68QA4aRs5l+VtX5mfR4faRPE6Y4JSs5qWrJhrfYXuSD9if5Y/uPqBcd3Ka8yusRATdoCoIA9cXWgrcasCmCPbX5VOQurHXrvZdVs/+B6xnxBXDaFGv+ysJgZ00ej35gl/H47p2Vpkk0WczNJVW5OHQpyNNSG6XYIKJn1V9vH07oHNakP2gIRVXr7WRtajjAMkOrvcXMzDRr3kER1/s+z5S08QvXp3nI/nDU85+xf4uzrvfx145v8bLaxBeD7yBA9HhNTpo9pTokrABLZ0gpwDk+f4WTmZBSagGWbsg3RDalbvNsriNRFMGWCneUh8/f+X+XP5/6KF8OvI1D6gYA9qtbY4bZP3VbkynVEWcjP8MZVcFajgAr8jXLxABd+vzV+jlMN1eSmoIMur2T7FoX3dscwM6tUw9SP/lN/sX/O5xXS3iP7Tf8h+PfmMTB3/h/zzi3qTSbSX+Qitx0MkxmQWCxeK5uLKLDM8n6kvm3fd68qQSX3caL5wbYtS7P+jxYGGS67Gwsy6YyL507tpbx+1fXJfstWSwAmyLI11vbW2UZE9LJZuV81Dn9oz66hhM3z3xhYNzw5DMCrIgWwcp8c+6nLDRmE/PykM23gjcB8C77b3nQ/ghvV/ZzhfIG99ieZoAcngju5s+m/iju9Vc2FKaU52Rq7ZCXkVFHARlT/Ut+nd4RH5N+lXVC60vukIWUu807zLuzJo9ghMPoCbmOH6rX4MfOEdnADb7P8U39CxGiMMvJh6+qXem3umSKclxckCUUCw+lDNA/6mNiKjHeZwBjvgBPvKH93p34KREevUUQtlXE9xlKBiEDye1V8d9TEBuPBN/Mh/33kyb8NCod/J/Ae+mNGDa9c1sZZ3rHaFzARtzC/Fy7QdvI7K0rmFfV9S9va2JvXQFtg+Oc7B7hug2pk120WBmEENxzWQ3v21uDkkKbIwuNUn3/oqLQLKtjAiyIFqVYKhcGxoy/14ouJqSTLsJV8SqrgmVq5lJLfjDwHr4buA6Ad9uf5QvOr/Id57+QIXx8bOpjfNT/cbqIPw98WYr5K1oBls5kWjHuwMCSXyekIHeJcpYx6eKsrKDaxLNKO+eQuzwnK5DTPiZv3l6ekm0epTlp/FrV2lVu1n18BsYSJ9X+hadOMzA2BUCJ0GRmO/UbxbZK94zXrTQh1b+ynLRZjUDPyQo+77+Lf/Lfw2PBa6OeqyvMpKVvlAYTmCdbJI66wkwq89Lp9Ezy2Xds42Nvapjx3DJ3GvddU0eaw8avT2jV/1s2l854vsXa5XevqEm5zZGFRuQM3XF1nW4YG90SePB84vyw2oYmjL83iE5aZJmxB1GEdt+xMC/udAclOTObiPtw8n8D7445/rpay6tyw6yvvbXSPInq+WAFWDqBzGLy5RBqcGkVjZBE+yXKOY7JOlQUqkw0fzOdxUhNv3tX1TK8k+WnMi+dFlnOebWEK5QTAAyMTiXktTs8E/zn863G43L0AEsWkO2ym2oGq74oC0VAz4iPq+cQJPhi8B38Z/AOpgsbZLrs+AKqVcFaZQghuG5DEQfO9bOnNp9P3LyBGzfGV4W6aVOJkWh58ng3TaXZMxrLWqxtMpx2q3qVokTK6Z+U1eSICcoYjDrn0IXB6ZctmrYIdd960WmIa4AmrGRPsdGEtYYQgivmkFHvx02zWs1/BO5kx+R/8N6pT/M7U38Vk8yPRBGwKY7PlpmxPqk6IrsMpwjiGVia5OjwhB+QNImLHFO1NrqQ2poZyc90Upoz/4xQmkNhg4nmiRZCSDXxjKykVnQBMDiWmADrdE/0PFe50NpNO2UhZblppqr4pTls1BRkcqZnhBs3lSz4epsiGPdriYgGS0Fw1XHd+mLGp4K81KJV9P/2zZtxpztomva9v3Gj9tkZGPVx8PwgN1vVKwuLVUekr9E5WQ5AvRKtJNjcPRI1arAUQgFWGj4qRD/n1HLjuSpr/ioluKJ+dssPgNumPstnA+9lkBwOqFsYY/bfbUNxFumzqNyaESvA0nHmaV9iT2/7HGfOjnfCTy6jpAm/MX+Tk27uoe/pYgezsbXCbapgYSGEsh/nZBnrRA8KquFZtVTO6b4dIcp1k+FOWUDJAgLYlaKxOIvTPSNsKV94RqihKIvz/doiuBZMhtcaVzUWkuWy8/PXtU1UVX4GT/zZ1bxvr2ZI7bQrvHl7uaEW+Ks3ulEl3LJ54cG6hYWFuSnKCgdYZ1WtmtQgog2HpwJq1OzUUmgb0taWKtGHIiStUkvcCLTuCwvzc2VD4o2Ad61LvRZjK8DSycjXbhyjfW1Leh3vhJ9SofUj98g8XHbF9AHJQmQv79hWPvdJJsXlsGETmhqSS/gpF/3GzNRSOdcXHWA1KRfplzn4cEa1WJiFxpIszg+MU1+UtWBVno/d0MDJbi9l7jTTmmhbLJ40h42bN5fwxBvd+AJapbLMnc7m8hzc6Q6+9ru7+OLvXIrLrmUTHzvUTlNpdsq1b1hYWMxNYYTNTD85eGRmTIAFcGZaknExdHomDJPhsogkJWhTX1VzCChYmIPy3PSE+pU5bQqX181dFTMbVoClk1Os+T9NepZmNjw84adED7C6ZT6ZLnNXrwCuXUiAtbVsGd/J8pPutNOqahmxetHFQKIqWH3h7F2DaOcO5WV+pBv3lrrN1yK6viSboCrpHJ6gcQFVqC+991Lu3FZOc5fX2lCvYt68rRzvZID9p8PKqk2lOfzNnZui5vZOdY9wtM3D3buqTJ9IsrCwWDgVuZFBjaBZreFy5QQCNeq8Mz1Ltz351ksXDIn2Ml0oKmR1AlaLYCpx0yLGD2biobu2zavt0GxYAZZOfolmohccTkSApd0YeslLiQx/SU7arKovIe0DqcwAACAASURBVAoynVH92KmIO91uuMKXi/7EiVxEKB9dqRxHEZKvBW4DMGmLoDZPc7pnlFu3zG925pr1Rdy5rZxJf5BzfWPGTJvF6uPKhkJyMxz84HC4ZTrdaeMdOyqizvv+wTYcNsHbLkndyraFhcXM1BRkEJk7+W7wOuqVLq5S3og6779eOM/xzuFF/zune0Z4dH+L8bhMDKBKQS9h5ThLoj11+JMbGinMcs594jy4urGQgqzU23taAZZOWnomHrJQRpdmNjw84acErYLVK3MT9gFbbm6fR2XqratgE5WX6aIPTTK9GI+h+rgUVFXSE/E6G8RFBmUW3bp3hxkDrLqiTBShZR3fdknF3BegSXgDnOkZJahKNi1ifssiNXDaFd6zu5onj3dzcSCs6hVZpfKMT/H9V9u4eXNpSi5+FhYWc5PmsFHuDleOnlD3oErBTuV01HmDY1O8eG7xVjcHzvbjD4aFMkoZpA83AcJdQJVWgJUyZLnsXD6HmuB8yM1wkJ+ZGvvo6VgBVgRDSiHO8aWrCJaKIQZkNlM4FqTQl0zerw+wh/pmp4/l5GU4+Os7N63020o4BZlOAtjpkzmUiCHDt2wp9I/5CEQoKG1U2jilVhOSNp/LeC8ZpDls1Bdl0dzlZV1hJmXuNG6dQwUu1P9+okvLUloVrNXN712xDpsi+K8XWuM+/1/PtzLiC/DH18/slWVhYZH61BWF52l8OOmkgBoRm4yerqa7EFr6o0UyysVAVHugy65QnOIdNGuNPQnwvqsvykrZ9nPzDwitIF5XCdm+pVewisUQvVJT5qswkf/RbNQVZXFZbT7NXV4Afv/qOh5+Llyuv2Fjccp+yCMJ3aB7ZR7FYojO4Qkm/UHSHIuX/+zyhKtXApX1oo3vq9cB2qKwkBmnlWRzeQ4vtWjtrNc3FfN3b97MlQ8+Q99I/Lm0UKB4otNLhtNGjQkDR4vEUepO4y3bK/jeq2189Np6SiMMPgfHpvjvF85z25ZSK9CeB16vl97eXvx+f7LfisUaxeFwUFxcTE7Owr+v6woy2X8mPI/ZqpZSK2KT0ad6Fi90MV0oqlQMGrLwNkVQlZ9heamlGHsSoPyXqr6rYAVYUUxmlFE90byk1wiJXHTrAVYqlbQ/fFUt937zEADv21vD2d5Rnj7ZS4bTxnt2Vyf53SWGslxtk9grcykRQ0gJFwfHWV+yOD+noCrpGg4HWIV4yRQ+Q1p2c3mOaY0Rt1S4+fGRTvpHffzBtfU47Qo7q/N44nj8Km4owGruGqGpNNta7NYAf3pDIz9/vZO/+vEbPPL+nSiKQErJX/34GJOBIH9+0/pkv0XT4/V66enpoaKigvT09FWRqLJILaSUTExM0NGhqf8tNMhaN00R7oIs4Q7l5ZjzzvaMMBVQcdoXvua19EVXsErFIC+oWwBw2IQpO0EsZqexOIvsNDsjk4FFXb+5PId37U7dAMucO78kIbMryMPLxNjiyty+QJBRX4BSMUSPHmClkurNTZtK2FGtDZSe6vYafa+fuHn9qpm3CQ3J9sg8ioUHgNb+xft37GvuoWs4LHBRoRsMd0it93hLhXvRr73cbC7X3tvxTq/R/rezJo8rG2LVenIzHFTlpxNUJSe6vKvm82AxO9UFGXzy1ib2NffwqR8e40Snl0/98Bi/PNbN/TdvoHGRiYm1RG9vLxUVFWRkZFjBlUVSEEKQkZFBRUUFvb29C75+XUF0cNMqS8kTo7iJrjqNTQV57NDCrW7GpwJRicosxskRE3RJrQISCEorwEpBFEVwSVXu3CfOwC0pbl5vBVgR2PO1SLm/syXq+MRUcF7Xv9wyiCKDFDJMD1qAVeZOnQBLCMFX7tlJSY6Lj3zjEI8damddQQYfurKWDOfqKHbW6AtFD3kUMoyNIE/OULGZC39Q5SvPnuNrz4dnVMqNAEuTsjbzohAKkt7oCCs/vW9vDf/xvp3cvbOSz75jq3H8y+/dQYbTzrm+UUZ9AS6pmr85tUVq86Er1/EH19XzvYNt3P7v+/nuq238wXX13HtNXbLfWkrg9/tJT0+ddcBi9ZKenr6oNtWaaQHWBb1DY12cNsH/+O05ghEzyfPh4mD0LHTpNIn2gCotD6wUZUf14vcKN6e4ef3q2DUniPRCTejB03WeqsbtxvHW/rF5Zeyfbu6hCA+KkPTomZfCFFPXKnWn8Zv7r+M3J/sodbsY8wVXVda1rlCbh+qSBdiEpEwM8qPXbPzlbU0LNgT2jPs52uaJOja9glVp4hk8d7qD6vwMTnR6jWPpThtg43N3a5//58/2k+6wGc7sRy5q/99LqxeflbJILYQQPHBrE++4tIJjHcNsq3TTUGxVrhbCarqHWqQui/0cVuZpUu1Sj5vOS23jWyN6OCqjRW7aBif47ele3tQ0/83x+f7oACvsgRWe4TFzstJiZjaWLXytyHbZKXGnsSHFOySsACuCvDItIzsxcCHq+Lm+0XkFWMc7vYbJcI/UNqC5KeCDNZ0Mp507tmmy7eoCM1Fmp0CXzb+gLxBVopd2tYj2oYkFB1hD47EeWuViAK9MZwRtMYg2aTQfWypyeGMW75LPv2s7DiVc6H6tbYicNDu1BYlzabdIDRpLslOuJVAI8UmgBTTPBCnlI7OcmwvcC3iAev38B1bgbVpYmJqQVHuHR2uHb5PFqFLEFboA2Ne8sADrwkB0m36Z0OTeuwm3q1sBVmqymPn2t15azh9c15DyiSmrRTCCwvJ1qFIQHIruIZ4+fDkTfaM+SvUAq1vm47QpKS8EkOrvfzpCCGxCGGbDIanZnuGF+2ENjsUGWJWiz6hegflVJLdW5HJhYJyB0fjKgS67Leoz8NpFD5dU5626z4XF6kMI8SDQIqV8XA+s6oUQd81yyaeklA9JKR/RA6sbhRD3rsy7tbAwN7WFcaTalfiqyy+c7Y97fCbOT7NLKdcDrNAsO6TWPLtFmJqCTLLT7DHWP7Nx6+YyKnJT//dtBVgROF1pDAo3tpGOqOMdnvF5zWH1jfiMGZwuWUCac/HS3xbLh8uh0CkL8Esb1UIb+F2o4bAvEGQoToBVLzpplVr1L91hIy/D3BXMPbXaAvbq+aE5zx3zBTjdM7KkoVULixXkXinl4xGPnwLum+X8u6YFVC3ATcvyziwsUoza6UqCagl1oivuuRcGxo1q13wI2cOE2ClOc0qtxK83WeVmOFbNHPhaw6YI/ueDu/nbN2+e89z6okyubCjgivpYoa1UxAqwpjFoLyZtIrrsPRVQaR+a3ZB2zBdgfCpItehlTLoYJJsslxVgmZGSnDRUFNplIdV6BWuhAdZjB9sZmBZguZiiRvRwRlYCUJ6bZvoS95YKN067wqvnB+c892i7B1Va81cW5kcIsSPO4UHgxlkuu2laC2Ed8GpC31iKc/jwYYQQ3HfffTz00EM88MADCCG4++67jcd5eXk89NBDyX6rFgkm0mwYoFlW0yQuYie+BPerrXOvKVJKBsemONoenmVOZ5I9ykmeU7cZx6pSyO7GIpadNfncqY+dzERpThr7/vxavvXhy1ZNh4wVYE1j1FWKeyq67O1XJf2jsdWKSHp1c9ZK0cdFWQwI3Ck4f7UWaCrVeoLbZREVoVaEBbYI/vi1Do5ME7ioE13YhOSMWgFAeQqUuF12G5dU5c4rwHrx3AA2RSxJFcjCYoXIRwuoIvGAMWsVg5TSkI8NBWhSSitSiGBwcJDHHnuMhx9+mE9+8pM8+OCDANx3333G49bW1jlexSIVmV7BOqI2kCb8NImLcc9/5fwgqirpnSV5ebzTy8f+97AhngFwiXIOlwgYHljx/m2L1KMgy8Unb93AZbXxzYdv3FSMEML0SemFYAVY05jKKqco2IdUVeOYP6AyMBZ/RiVEnx5gVYte2vX5Hmso05yEWtz6cVOIJvDQNTyJlPMT9PAFghxp8/DMyWg/kXfZngXgtF7BKslZmGhGstizLp/jnV7GfLObAe4/08/2SreVOLBIBeIFUaGAK/4KjxZ86W2CDwK/P8t59wohDgohDvb19S3tnaYQHo+Hu+6abYwNcnNzyc21qtyrjfqirKjHr6maeuClytm45+870cMPX+vg+Vnmsc70jvDC2YGoY6G2w1Nq2GB2ug+XRWryh9c18HtXrKMg00lDcRYOm2BzeQ4NxVnctTN1DYVnwgqwppNTQYbw4R0KL5oBVcYVNIhEC7AkVUYFK2zkamEuQq0OfTKXQjEMSF5uHeQD//XKvK4/3z8e85moE5180P4kB9X1nJPlAJS5UyPA2l2bT1CVHL448xzW8Lif19s9XNVYtILvzMJi0XiIDaRCj2cs10opPbrIxU3AozOJXOjn7JJS7ioqWjvfibq6+Xmf7dq1a9bnPR7PrI8tzEdFbjqZEXPlHRRyUS3iJuVQ3PN7R3zc/9hRzvaOxn0e4FR37HO1oosJ6aSbSIELK8BaLdy2tYzvf/RyLq8r4DO3b+Rjb2rkWx++bFXOdlsB1jSchtlwuM3BH1QZmKNFsMc7iZsxMoSPTt0cb31J1qzXWCSHkPlzv8whXUyRhTaMu/9MPy19My8GIeItGFuF1l30Gf+HCKItQqlSwdpVk4fTrvCbkzNn4g+c60eVcHVj4YznWFiYiEFiq1i5oAVR8S6I0zr4sP7HQmfHjnijbbEMDg6yc+dO7rvvPh5//HHuvvtuHn/8cfbt28fOnTu5++67AS2wuu+++8jLy4sKsjweDw888ACPP/44Dz30EPv27VuW/4/F/FEUMc2mQfAT9UquVN4wOkHicWaWAOtMz0jMsVrRzXlZiozYnlrdQKuL+qIsLq3O5Y5t5dy6pZTSFElGLxRLlmUaWSW1AIz0tMLWvYAeYM3RItg+NEGu0G4kQ1ILrErd5p/BWYuEKkv9UqswFophRqV2A2/uGqGuaPbA+FycIGyLcp5J6eCsrIj5d8xOpsvO1Q2FPHm8m7++c2PcHuj9Z/vJctlXZZbJYvUhpTwshJgeSOUDcXfqQogbgaeEEHkzBWCJ5O9/djzK4DsZbCrPmZey12K48cYbue+++3jwwQd58MEHjcrXjh07+NSnPsXDD2txa25uLg8//DCPPBJtT7Zz506eeuop47r6+noOHTpktR4mmabS7KjZ433BHXzM/mN2Kqd5Ut0d95p4QRTAz452xm0frBVdNMvqqGPVVovgquOWzaVkulZ3CGJVsKaRX6oFWL6B8OBmIDh3i2D70Di5aBtvD3qAlSIVjLVGfqYTRWgzWEBU9u3i4OxqkRC/grVFnKdZ1hjVK0idChZoN7sOzwTH42z6gqrkqRM9XNVQiMNm3TIsUoZHpvle3URERUoIURfx/EHgoWnB1U1ApMy7xQLIz8+nrq6O3NxcduzYYVS/4gVJkccef1z7kUe2I+7YscOqYpmAjWU5UY9PySpUKdgg2ma4QvO4ujAwhqqGZ5xVVfLgEyfxBdSocxVUqkQfF2SpccxlVyjJTp211GJ+rPbgCqwKVgz5JZVMSRvqcLtxbD4tgu1DExQKzZB4WGYigMIs53K+VYtFIoQgN8NJ37i2qBcKL+j3/ouDc5tKxwuwGpR29gV3Go+zXHYailOnRfSGjcUoAp483s2Wiv/f3p1Hx3md9x3/3hlsBAliABALSZAgBly1awhatuVVGrpeGseOAdF102M3OSTSxs1yekpYOYkbnzqHAZyeOOlxWkBN66RtUppoUjuJ7ASg3RzHcmyCI8u0REkWR9wkUlyAIUVSXIC5/WPeGczyzmCwEbP8PufgEPO+9x28c/nO3Hnee+9zU+cO/uDVy1x88xY/8+C6ZTo7kbmz1vYbY/Y7QZQfOJG2LlYQ6AVGrLURY8xBY8x+YvO3uogtUty/FOe2VD1HhWY+PU7hcBifz5cSUO3atUu9VwWge1NqBtmbVHPStrLdcxpyLBX6n779Ch4Db+ts4mMPreNzf3GMs5OZ62S1MkmlmeY1GxuKbohlECyVtN1SXhYlwHIapTDOJOK0tUSylQfYBRwppFS4Hq+XS541VF57PbHtzrTl6s1bfO3IGZ7Y5Z7p5OzkDTYT+3IeYRUrqyuo0N3+gtVcV82l67FAojlpJNGpy7l7sKajNmOI4Gqu02yuErYz6zw8tr2FmsriWQetaVU1j3Q28fUfvc6vBbfiTWrQDh45Q111BY9tb1nGMxSZu1xti9NODSc9DgGhu3Fekip5/lUgEODgwYMEgzNLliX/Lstne9tq6qoreDMp4+xLdgM7zKmcx40cjd2w/tr4WS5du5V4nG69ic0DjgdYFV6Tkb1QpFgsOAIwxgwQu9M34jRYXWnDMtLLD1lrB52fXmBPUsBVECYrW1n1VnKAFeXVS9f5y2dfcy1/5a07XL05xepED9YqGmqVyrqQrauv4RKruWUr2WBmkju8eul6znTtZydvZAxr6HTSyr6aFGAVYzKITz2ykdMTNzh8fGYduHNX3uLpY+fo6W5nRVXxBIwiUpj8fj/hcGLJMUKh1Jg2Hkwll4lEIhnl5O7zegwPps3DfS7aRafnDZrJnoU22Zf+9qWs+9ab2Jyss06ANTVttQaWFK3F6GLZlzbsYhTocyvoZGlKn0A8lK38crle286aOzMB1pQzdvj1K5ld2jAzZCw+B+sKK1lTV73EZykL0dG0EouHU7aFTeZ8Yvu5Kzd5Kcuk3DvTUY69lpktyZ8IsGbGjaePVS8GH7yvjY6mWr70ty9x2wkiv/StlzAYfuHRzmU+OxEpJIODg4lsgP39/QwODiaColAoxNDQEGNjYwwODqb0UPn9fnp6ehgeHk7Mt/L5fPT39yfKHT58mKGhIUZGRhLZB/PNYChLqyMt4cR3o/cD8C7PT/I6fjqa/QZmPMCK92BZtMiwFK8FDRGMr3afZoLY2HY3jcB+pxcrnLQ9v8U17pJpXwdrIk/z1vU3WbGyLvFl81zkJtGozRgPfPxcLDFAvbnOdVvNHSoSqcClMMUXLjxp21ICLICv/+h1tn8wFiCdvnyDjU21WGv5lT9/lm/+5Hzmc3nOM20Np20rAB5DUc2/iqv0evj8P72HX/yTcT77ZyE6mmr5i2df47Pv36x1SEQkxf792QeeBAIBRkdHs+4fGBhIeTw5mdr74fP5MspIYUhvC16wHUzYVbzD8wJ/GX33gp673Vzksq3jLWaSWnQ2K8CS4rTQHqxGMhdtjIDrmiI4QdXOtOBqN1lS5y6XyuYuAN44HevKnorGAqzb01EuuaRrf8EJsHxc4wqxD4MNjQqwClk87eurto0OcwHDzLC/Q+NnE0H1V585mdjmFlwBrOMyF2jgjnO/wt+8qqjmXyV7fEcrv/Hh7Xz7xQs89d1X+fjD6/m14JblPi0RESkA6WtSWTwcj3aw1eM+rypfHqI85v0RP4puTtnuVw+WFKmFBlhuaX3iAVej2wHORGIgEYQFyT6kcJ8xZtwYM37xYvZFUBfb6rWxL5SRsy8DsXHAca9HbqaUtdbynLMuRL25zhVnDayuNcXXg1FONjTM9GBVmzsp87CSJ+H+/csXeOXCm3zreffgCqDVTPKGncmutKmpuBuEfe/p4pknH+O7+9/P7+95SMlaREQEmGk7k71i19FlXieRjnce3uP5MW1mkv8zPdMLtrqmAl+tsjFLcVroN6cImYFU/HF6z5abQ8DjaT1aCdbaYWttt7W2u7m5eQGnOTfNG7YBcPPiCSDWcxX37OnUoQxPHzufWDuoyVwl4gRY7Q3qwSpk7U4j8Uw0li75w54fpOw/8M3jvHV7mnNXbvLNY+cZP5n9cm4zE5y3M2+DYllgOJeWuhoNCxQRkRTpPVgAP7Xt1Jm3aMvra5+7X6r4K87ZRsaiM8udbFLvlRSxhQZYE2T2YvkA0hZszOBkH+xP7tEqFL6mVt60KzCTJ4HUHqy//vG5lLL/6wex9KReptlhTvOijaVxbyuBL9mlbEWVlxWVXk7ZNo5Gt/Bhb2qA9ebNKZ45cYkbt6f56jMnuXpzKsszQZuZ5HxSD5b+70VEpBTV11byeNqSHa/Y9QB8quLwvJ6zkau83XOc/zEV5DYzGZi3FOFcZpG4BQVYTnCUHkg1MsucKieN+2g8uMqSLGPZGI+HCxVrqbl2Gohlj4s7emqSm3emE7//8NXYHZst5jVqzS1+FI3N31rnUw9WoWtyFoJ+PropZYhg3NPHYsMCL1/Pvsj0Cm6y2tzgjRLrwRIREXHT292e8vhodCvHopv4rPfrrOZalqOyiyeaOm47Urb7tQaWFLHFmFwxnLbu1W5iqdcBMMb4k/cbY4LEgrBxY4zPGOMH9izCeSyqKzXr8d16HWttIk173NnJt7h07Raf+M/PJPY96IkNJ3zOdlFb5S3aJAflJB4IXbT1NJhrVJLaSzX6QvZ5VwAd5jwf834PILUHa7UCLBERKU2bW+pSHt+hgi9PfQKPsXSZc1mOym6juQDAaZvaM9alDIJSxBYcYFlr+wG/MabHWTD4RNq6WIkkFk5Si1FiAdik83OCAkvTDnC7biNt029w63bm0LAzkzd4OW2tpI3mDe5YL6dsK40rNSmzGMSTUVyiHoAmUte4yjUsEOBLlUMcqPxjILaafZyGCIqISKna2FhL2mo1hO06YGZdyLnY5DlP1BrOpAVYnUoWJkVsQetgxVlrB3PsGwaGnd8jgMlWtpCYxk6qz9/h5GuZ+TfOTtwgfa28FiJcpB6LR0PEisSW1tiH90Ubm0bYbK5w3jblfXw1dwD4g6mP84LdlNiuAEtEREpVVYWHDY21nLp8I7HtjG3mjvXS6TlH0qonedloLvA6TSnzryBzUWORYqL8y1msXL8dgMjLz/CFiv9OLTPp2c9MvsVPXkvt7WgxkcQXda08Xhx2tMUWE75oYz1YzSZnXpYMNdzmW9O7+P2p3sS2tfU11FYtyn0LERGRgpT+PWeKCk7bFh4wYeaarn2TOc+paGvKtvoVlZpqIUVNAVYWbV0PArAl9EU+XTHKZ7zfSuz75k/OMRJKXVSvxUS44ARY250v7lLYOpwhgvHAeI25kqt4hjXmCpds6v/1ZmU9EhGREtfhkq79G9Pv5D3eY3zU88ycnmujucCptOGB63waCSLFTQFWFk0t7VyllpW3LwEzkzABzky8hU27QdOc1IO1Y23qBFApTOt8NRhm5mD9C+8oXqbzOtbLNA1c47JzbFyXsh6JiEiJc1sn8Q+nP87x6Eb+VcU3yLcXaxU3WGOucsq2pWzvbNJIICluCrCyMB4P5yo2Jh6vN5eylq1gijXmKhecJcG0QGtxqPB6qK3ycptKTkZbud9zkg94xvM6Nug5isfYxPBCiK3Zcf/6+hxHiYiIFL/2hszvORYPfzq9mx2eM2w3Z/J6ng7n5vUpmzpE8F61pVLkFGDlcHVVZ+L37Z7TWcutcbLPXbANGGBtvdbAKhYNTsbH4O0vcd1W87j32VmP6TDnGar6MgCXkgKsD97Xxid2tmc7TERE5iESmdv82FI9h0KyodH9e84/RO8DIOD5aV7P0+GsgZUeYD22rcWtuEjRUICVw3TjlsTvzeYq1bgvONtmJgF4w/qorfLiTc9fKgUrnvFxigoORwO81/PcrMd80vudxO9XmBnGoOyBIlLKwuEw/f39GGPYuXMng4ODDA4O0t/fT29vL6FQaFH/XiQSobe3l4aGhpTtfX199PX1Lerfmus5lLtsI3XO2BYu2np2el7O63m2es4StSYlwPIY6NJ8ZilySneWQ83aHZCUpb3NTGSMEwZoNxeB2AdL/YrKjP1SuDqaajlyMhYgPxft4qPe79PAVSbJnqjkPZ4fc8XW8opdz/PRTYnt69RzKSIlzO/3MzAwwMjICHv27GH//v2JfeFwmK6uLo4ePUogEFiUv+fz+Th06BDGpN60nGtwNTw8zL59+xb1HMrd6ppKGldWMXE9/cazIRTdQsDkF2DtMi9x3G7kBjM3KJvrqqmq0P1/KW66gnNo6rwfgLN2DQBrzYRruQ1OgPWaXUPravViFJNtrTOBVNiuBaDTGbLgpoIpNpvX+PPpx/jE7S9wVT1YIlJmfD4fPp8vZZvf7ycQCHDgwIEl//uBQGBOQdzRo0eX8GzKV7Y5x0ejW+j0vEETuTPzPlX5ezzqfZ4fRrenbPdrgWEpAQqwcljbsY1Ju4rvTcfGFLfhHmC1m4tM2FVcZwXtWcYlS2HatWlm2Ec8wOryvJ61/CZznmozxYvRjRn71IMlIuUsEonQ2Ni45H8jFArlNRwxEonQ19fHxIR72y0L82B7tgBrKwD/teo/8meVX3Qt4yHKbm/s//Dp6UdS9j2wQQkupPhpiGAOFZVV7K37Ci9fusWeiv/HOnPZtVy7uchZ2wxokeFis33tTA/WWdvMbevN2YO1w8SSnbxkN6RsX1HpZfUKvZ1EpDyNjY0BMDAwkHjc399Pd3c3u3fv5uDBg+zZs4eenh4ikQgHDhxg165dhMNhAoEAwWAw8VyDg4P4/X6AjJ6yiYkJDhw4QCQSYXR0NLG9v7+fXbt24fP5iEQi9PT0MDY2xsTEBKFQiMHBQXw+X2Ko4ELOIV0oFGLv3r34/f7E8MVQKITP5yMYDCaCwdHRUYaGhhLH5TqHcDicclxfX1+i187t742OjtLV1TXvoZDz8eAG93r5iY0lCHvY8woAq+7c4Bqpc7bWOZmZ++/s5YhN7cF6tGvNYp+qyF2nb4SzaFm7kfFL54jYldzneRWmLZA6FrvdXEx84d6mRYaLSk2ll+oKD7emokzj5aRtY4c5lbW835wDZnq74jqaajVGX0Ty883Pwfljy3sObffDh3533oePjo7S2NjIxMQEkUgEn8/HiRMnEvuDwSB9fX0MDAwwMDCQCFYAdu7cyejoaGJbfO6Wz+dj9+7dDAwMJIKJcDic8nfjQUU8kAMyjmloaMDv99PT05MokzxfbKHnkC4QCPDkm0CjNwAAFfxJREFUk0/S39+P3+/H7/cTDAYxxnDo0KHEeQwNDTEyMpJ4nOscent7efLJJ+np6SEQCLBz504mJydn/Xt3M8B6Z9caVlVXcO3WVMr2W1Txq7f/NX9Q9UdArN38se1KKdMVb0ujqW0pwIPtuQNakWKgAGsW965bzdPHznFw+n30VfwN754+xnejDyT213CLTeY8fx19BwDtPg0TKzaNK6s4d+UmAD+Mbudnvc/gZZppvBllN3guct42cIuqlO0dTVr7TETKx65du1ICGDeNjY34/X58Pl8iWBkZGQFICbgCgQBjY2P4/f5ET05ccjk3oVCI8fHxlGOOHj2a87jFPgeY6eVKL5v+PPHhirnOoaenh8OHD2c8ZzgczuhVS/978WD3blhR5eWD97UxcvRsxr6vR9/F87c2MVa93zXA2mxix6TfrKyp9FBfq2RhUvwUYM3iAWeM8R9N/Sx9FX/DVnOG7zITYG0zZ/AaywvRDgB8+mAoOl3NKxMB1jPRe/n5isM8YMI8a7dklN1gLnDGGQ6abJNWnReRfC2g56jYpH/ZD4fD+Hy+xJBCIDG0b3x8fM7Bwfj4eEaQMVtAtNjnkO3v+ny+rHPScp1D/NixsTHC4XDW53D7e3fbQxt8rgEWwGnbyrQ1dHrOQXRm+xZzlv0VX+PVaCuX0zL2Nq+qXsrTFblrFGDN4v51sQDrCiu5alckMgbG3eOJDSd73joB1orUng0pfMEdbfzDK7H5dc9E72XKenjcG+LZqcwAq91c5AfRHRnbOxRgiYjMKhAIcPDgwZT5TvHfQ6EQ/f39c3q+7u7uvI8Jh8NEIpFFP4f5yHUOEBv22Nvbmxjyt3fv3iU/p/nYnGO9qttUctK2ca85CcRG/NykyllL0vLPbv8m6VMuNmkeu5QIZRGcxerEulaG12xzYs2ruLd5XuSKreWsbcYYqKtRzFpsfvbhdYnfI9Tx/eg9fMTzj3iZ5gEzM6fgvZ7nWG8uu/ZgaYigiJSLSCQy72OTkzgkP18oFCIQCOD3+1MyBM6WLTB+THJPUHKCiPiQv/j29EQSi3EOcenZCnPVU65ziA97TJ5PFX+u+NDCuf69pdLVnDul+vei9xH0PstHPd/jxZp/yaGqL/CLFd/k29GHOU9TRvkdazWPXUqDAqxZeDwGj3OD5YxtTunBqucaH/b8kG9MvxMwrK2vweNRooNi01BbRXXSooZ/FX0HnZ43+M2K/8k3qn+LneYlPu39W/6kKjap+pXo+oznWKs1sESkxIXDYQYHBwmHwwwNDTE4OJi1bCgUYmhoiLGxMQYHB1O+/B8+fDiR8GFkZISxsbHEXKXDhw9z8ODBxPZ4ANLb25sIQAYGBhgfH2d4eDhxzKFDhxgeHmZkZCRlDlUgEKC7u5vh4eGUYGYh5+D2WgcGBhLZCiORSKIXrL+/n3A4nHiueJ3kOodAIMATTzzB4OAgY2NjieMGBgbw+Xx5/b27Zc2qKupXZJ8a8Z3oQwD8YdVXANjleZlT0Ra+eOfnXcvv6ljaNP8id4ux1i73OeSlu7vbjo+PL8vf3vH5b/HW7Wk+X/Gn7PF+h3tv/TfA8IT3OwxWPsVHbv0Oz9tOPrCjleFPdy/LOcrC7PqdMS6+eQuAWm7yg+pfps68BcCJ6Fq6POf4UdTPF+/8PCG7lWjavYnnv/BPWFmt3kuRpWKMOWqtLbgP2NnapuPHj7NjR+awYpHlsBTX4y989QjffvGC674Kpujz/jXbPGf4qPf7APy7O/s4NP0+1/KH/+17Z+0VEykk2dom9WDlYVVVLJvcsWgnK80t3u45jiHKz3n/gbN2Dc/bTQBsW1u3jGcpC9FaNzOx9gY1jEVnMj91ec5xx3r55O3fYtxuzwiu6qorFFyJiEhZ+uC9bVn3TVHBV6Y/xq/c+Te869aX+fOp9/NX0+9wLVtb5aVT85mlRCjAysMq58vz09FHmLCr+JT3ML9d8Se83XPcWYE8Niww12RPKWzpc6iORFMXPnzOdnET9+xGLauV9UhERMrT+7Zlzkt2c9a28OTU3qxt6Tu7mjTNQkqGbrvnYUVVrJpuUcX3o/dwvwljjeGV6Dp+b+qJRLn2Bq2BVazaG1MDrPHoVgCORzdyk6qsd9wAWldr/pWIiJSn5rpqVtdUcPXm1OyFc/jMo52LdEYiy08BVh5WVM0sOPuKXc9HvD8EYPDOE9xmZnJnS52+aBerppWp6fV/atfzlamP8n+n38VPbXvOYxVgiYhIuTLG0NWyimdPzz+LYZXXw6NdmVkFRYqVhgjmoaZypppOJGWQO2ZTF/lrrtNQsWLVuDL1/87i4UtTn5w1uAItMiwiIuVtoYkp/M0rMUbDA6V0KMDKw4rK5B6smTWTno1uTvzuq62kJqmcFJemVfNbILq7o4HPPLppcU9GRESkiDy80beg43dtUnp2KS0KsPJQU5k6RPAH0e3su/3rXGNm3k6Leq+K2paWVdy7bu4LHH71F96Wcw0QERGRUvfPH+ngA/e0zvv4t3U2LOLZiCw/BVh5SO7Buk0le25/nr+L7kopo3k4xa29oZbPvn/z7AWTrKzyJjJMioiIlLPO5vkPl+9coyzMUloUYOUhOclFNpp/Vfwe3ji3O2it9QqqRUREADoa5x9gpS+VIlLsFGDlobZq9l6K9T6laC92bfU1rJ1D0NSqrJEiIiIAbJpnkFS/ooK6Gg21l9KiACsP79m6ZtYyWgOrNNyzNv95WG3qwRIpaMaY/caYHmPMPmPMvjzL7zfGHDLG7L8b5yhSKjbOM8Da0KjeKyk9CrDy8PbOJtbN8mW6vUEfEKVgc2v+48BbVmtYqEihMsYMAGFr7Yi1dhjoMsb05Cg/ZK0ddH56gT0KskTyt65+Bb/y2NzmMoNGAElpUoCVB4/HcN/6+pxl1INVGra21OVV7jc/soOfeWDd7AVFZLnss9aOJD0eBfrcChpjfED6KqlD2crL3RWJzH8BW7l7PB7Drwa3znk+1XqfblBL6VEKtDxtba3j7154w3WfMbC2XgFWKdjaOnuA1bSyil98V6cWRRQpUMaYgMvmCSCY5ZBGYL/TixVO2u7PUn7BNn3ub5bqqfNy8nc/Mu9jR0ZGOHLkCAMDA4t4RpkikQh79+5lZGQEa+2S/i1ZHF6P4UP3reW//P2JvI/RDWopRerBytOWHEPH1q6uoapCVVkKtrSuwuvJHTg90F6v4EqksDUSC6iSRSDRW5XCCap2pgVXu4Extyd35nSNG2PGL168uEinXPjGxsYYHBxkaGhoUXqVhoeHc+73+XwcOnRowX9H7q77Zxnxk05zsKQUqQcrT1tyDB3bPofECFLYaiq9bG2t4/i5q1nL3N++sBXrRWTJub1J4wFXI5nDAbHWhuK/O0FYENjp9uTOnK5hgO7u7rLpWgkGgwSDQS5fvrwoAdbRo0cX4ayk0Ny3fm7fieZaXqQYqNslT9va6mhcWeW6b8fa/ObtSHF4sD333bd79P8tUugixAKpZPHH6T1bbg4Bj6f1aMkiiUQi9PX1MTGRz3+FFJuNjbWsrsnv/n1zXTVtq5WRV0qPerDy5PUYHtvewsjRsxn77lk7t+5wKWwPbfDxv4+cybp/nTIeiRS6CTJ7sXwA1tqcXS9O9sH+5B4tmb/BwUECgQCRSIQjR46wZ88ewuEwExMThEIhBgcH8fl87Nu3L+UYvz82/c3n04iBYmOM4cENPr7700s5y9VVV/Dxh9dryL2UJAVYc/C2zkbXAOvBDQqwSsmjm3Ove6a7bSKFzVobMsakB1KNZJlTFeekcR+NB1fGmIACrfkbHh7G7/cTDMZyi8SDpZ6emWz5+/enZsLfvXs3AwMDBAKxPCXhsDoRi9FDeQRY29fW8Rsf3nGXzkjk7lKANQebmlZmbNvaukprYJWYDY21dK5ZyauXrmfs83oMTau0/pVIERg2xvQkpWrfTSz1OgDGGD8QiO83xgRxgjBnDlYjsAdQgDVPfr8/MRQwPn8rl1AoRDgcTgRX8eeQ4hPY2ED9ikrW1tfw4vk3XctsbMz8TiVSKjQHaw42uazt8P7tLctwJrLU3ru12XV7S131rFkGRWT5WWv7Ab8xpsdZMPhE2rpYQZx1rpyAapRYADbp/JxgCdO0l4NgMMjQ0BCjo6N0dXWxc+fOnMkxxsfHNSSwRLxvWzMjv/SOnGuIun2nEikVCrDmoLmumhWV3pRtH7indZnORpZStsC5VcMDRYqGtXbQWjvi/Ductm/YWrvb+T1irTUuP73Lc+alYWxsjGAwyKFDh7DWEgwGXVOzh8NhQqEQ3d3dGhJYIowxbGmtyxlEdaxRD5aULgVYc2CMSVmhvGllFQ9taFjGM5Kl8khnI9UVHlZWzQTUq6or2JbHQsQiIhIb8jc2NjPtbc+ePYnf/X5/IpiKDwsMBAL4/X5CoVDKc0jx6nCZWgGx708PzHG9LJFiojlYc/TuLWsS44mf/PAODRcrUTWVXro3NdCzs51fP/gcn3pkIx9/eD3dHQqoRaQ8xQOmkZERJiYm6OrqIhgMpsyZSubz+QiHw4yMxEZmhsPhRFKLQCBAd3d3Ro/W4cOHOXDgAOFwGJ/PlxhS2Nvby1NPPaUhhEXGbe46wH/42H1sUg+WlDBjbXGskdjd3W3Hx8eX+zSI3LhN9xfH8NVW8sPfCOJRgFWyvnbkDL3d7Xxy+B/57Y/eyw4tKC2ybIwxR6213ct9Hulma5uOHz/Ojh3KlCaF4W5fj2/dnubBL/wdt6ejiW01lR5Cv7Wb2ird45fil61t0hDBOfLVVrGtrY53dq1RcFXifi4QW5/jl9+/WUMDRURE5mhFlZeHN8Z6Hd+9ZQ3GwB9/epeCKyl5CrDm4aENPh7foeyBpa7CG3t7vGdrs4JpERGRefjQfW3Ur6jk3//MPTy+vWXWtSZFSoFuIczDE90bcqYeFRERERH4zKOdfObRTgA+9yENl5XyoABrHh7coEm2IiIiInOxuWXVcp+CyF2hIYIiIiIiIiKLZFF6sIwx+4Ew0AixBRwXs7yIiEixstZijOZxyvIqlqzRIqVgwT1YxpgBIGytHXECpS5jTM9ilRcRESlWFRUVTE1NLfdpiDA1NUVFhWaGiNwNizFEcJ+1diTp8SjQt4jlRUREilJNTQ3Xrl1b7tMQ4c0336Smpma5T0OkLCwowDLGuC3fPgEEF6O8iIhIMWtububixYvcuHFDQ7RkWVhruXHjBpcuXaK5uXm5T0ekLCy0r7iRWICULAJgjPFZayMLKW+M2QfsA9i4ceMCT1VEROTuqqmpobW1lfPnz3Pr1q3lPh0pU9XV1bS2tqoHS+QuWWiA5ZavPB5ANeIET/Mt78zRGgbo7u7WrT8RESk69fX11Ndr7UQRkXKx0DlYEZxMgEnij9N7quZTXkREREREpGgsNMCaILNXygfgMjxwPuVFRERERESKxoICLGttiMxhgI3A2GKUFxERERERKSaLkaZ9OG0dq93AUPyBMcaftj9neRERERERkWK14ADLWtsP+I0xPcaY/cCJtHWugiStc5VHeRERERERkaK0KEt6W2sHc+xLZALMp7yIiIiIiEixMsWy8KEx5iJwaoFPswa4tAinU4pUN+5UL+5UL+5UL+4Wo146rLUFt0qq2qYlpXpxp3rJTnXjTvXibsnapqIJsBaDMWbcWtu93OdRiFQ37lQv7lQv7lQv7lQvual+3Kle3KleslPduFO9uFvKelmMJBciIiIiIiKCAiwREREREZFFU24B1vDsRcqW6sad6sWd6sWd6sWd6iU31Y871Ys71Ut2qht3qhd3S1YvZTUHS0REREREZCmVWw+WiIiIiIjIklmUdbCkcBljeoBdzgLP6fv2A2GgERJrluW9X6QcGWOGrLV9adv0XhKZA7VNIotLbVNhKZsAq9wuImNMEAgAu4m97vT9A8ARa+1I/LExpif5ca79xc65HgB2EXudgy77y+pDyRjjA/YBEaALIP3LTznWSzLnfeF32VZ27yXnC7IfGAEmiF07I9bacFKZsr5eZlOOr19tU25qmzKpbZqd2qYZBdM2WWtL/gcYAHqyPS7lH+e1Drlsn0x7HARG891fzD/p9QEcBfbne72U6vUEDLjUy75yr5ek1+N3XtNo2vayfC8Ra7Ss8zOZ/n9d7tdLHvWn16+2Kf21q23Kcq241IvappnXo7Yp9XUURNu07BVxlyq7JC+iPF97RiNG7O5hep0EAJvP/mL+AXwuH9b7gBP5Xi+lej0BJ9IarUPAoXKvl7TrJP01l/N7aZ/zfvJn2V/W10se9Vfur19tU+rrUNuUvW7UNuWuH7VNmfWx7G1TySe5MMYEXDZPEKuwctVIrA6SRSDRFT/b/mLWCOw3xvjTtvth9uulxK+n3Ta1G9wPHIGyr5f4sKavuewq5/cS1tqITRp2EVfu18tsyv3151DO7ye1TdmpbcpCbZO7QmibymEOVs6LyFobufuntOzc3jzxOmrMY3/R1pm1NmyM2Zn2xtsNjDm/L+hDqZivJ5s6PjngbIuP/y/benH4rLURY0zGdpeyZfFeAjDG7CP2ehqJ1ZGul/yU++vPpmzfT2qbslPblJPaJheF0DaVQ4BV0hfRPEVwJu4liT+eyGN/UbPWhuK/O2+oILDT2VTuH0o+4AmgF9ibtKts62WWSb/l/F4aAybiDY4xZsgYs8+501y210ueyv31Z1PO7ye1TTmobcqktimrgmibSn6IIKV9Ec3XBJkXkQ9i3ap57C8lh4DHk+6QlfOHUrxbfdhauxt4yrkLBGVaL85wnVzXfNm+l6y14bTXMArEM3uV5fUyB+X++rMp2/eTC7VNSdQ2pVLblF2htE3lEGCV7EU0X85dsvTX3ogzFGG2/aXCSVHan3zXkDL+UHIZdz3k/ED51ksA8Btj9jkNel/SY3+5vpeMMT5jjE27ZiLMpAku1+slX+X++l2V6/spndqmVGqbXKltclFIbVPJB1ilehEtgmFnrYC43cx8YOWzv6g5r2003oAljesu1w+lIDCZbXJrudaLtXbEuWs67AwvGAXid1Ljd5bL9b3Un9bg+IEQlO/1kq9yf/2zKNf3E6C2KZ3aJndqm3IqiLap5AMsR6leRFkZYwLOQmk9wBPGmP3J2VFsbJE+vzGmxyl3Inks72z7i5nzgd0IjDt3O/zAnqQi5fihNA4Mpn0o7Sa2UF9cOdZLgnOXsJfY+2J/vMEvx/dSljt5vcCBpMdlfb3koSxfv9qm7NQ2uVLbNAu1TTMKqW0yNpbjveSZmVWZ/ThR/jKfkiwD54Nn0mXXiLW2N6lczuulFK8n50tOkNjdmy5IfAAnlym7ehF3zntpHzPXy5H0xlnXS27l/vplhtqm7NQ2yVwUSttUNgGWiIiIiIjIUiuXIYIiIiIiIiJLTgGWiIiIiIjIIlGAJSIiIiIiskgUYImIiIiIiCwSBVgiIiIiIiKLRAGWiIiIiIjIIlGAJSIiIiIiskgUYImIiIiIiCyS/w9j7B9Lm90MlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_mean = pred_mean/num_inference\n",
    "\n",
    "# Calculate standard deviation\n",
    "pred_sdev = np.sqrt(np.sum((pred_pca_array - pred_mean[0,:,:])**2,axis=0)/(num_inference-1))\n",
    "        \n",
    "fig,ax = plt.subplots(nrows=2,ncols=2,figsize=(12,10))\n",
    "ax[0,0].plot(test_data[0,0,:],label='True')\n",
    "ax[0,0].plot(pred_mean[0,0,:],label='Predicted mean')\n",
    "ax[0,0].fill_between(np.arange(500),pred_mean[0,0,:]+pred_sdev[0,:],pred_mean[0,0,:]-pred_sdev[0,:],label='1 std')\n",
    "ax[0,0].set_title('Mode 1')\n",
    "\n",
    "ax[1,0].plot(test_data[0,1,:],label='True')\n",
    "ax[1,0].plot(pred_mean[0,1,:],label='Predicted mean')\n",
    "ax[1,0].fill_between(np.arange(500),pred_mean[0,1,:]+pred_sdev[1,:],pred_mean[0,1,:]-pred_sdev[1,:],label='1 std')\n",
    "ax[1,0].set_title('Mode 2')\n",
    "\n",
    "ax[0,1].plot(test_data[0,2,:],label='True')\n",
    "ax[0,1].plot(pred_mean[0,2,:],label='Predicted mean')\n",
    "ax[0,1].fill_between(np.arange(500),pred_mean[0,2,:]+pred_sdev[2,:],pred_mean[0,2,:]-pred_sdev[2,:],label='1 std')\n",
    "ax[0,1].set_title('Mode 3')\n",
    "\n",
    "ax[1,1].plot(test_data[0,3,:],label='True')\n",
    "ax[1,1].plot(pred_mean[0,3,:],label='Predicted mean')\n",
    "ax[1,1].fill_between(np.arange(500),pred_mean[0,3,:]+pred_sdev[3,:],pred_mean[0,3,:]-pred_sdev[3,:],label='1 std')\n",
    "ax[1,1].set_title('Mode 4')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../Figures/NA_TCN_Mean.npy',pred_mean)\n",
    "np.save('../Figures/NA_TCN_SD.npy',pred_sdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed per inference: 0.00583440113067627\n"
     ]
    }
   ],
   "source": [
    "print('Time elapsed per inference:',(end_time-start_time)/num_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
