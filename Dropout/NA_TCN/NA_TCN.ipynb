{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(10)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "params = {\n",
    "    'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "    'image.origin': 'lower',\n",
    "    'image.interpolation': 'nearest',\n",
    "    'image.cmap': 'gray',\n",
    "    'axes.grid': False,\n",
    "    'savefig.dpi': 300,  # to adjust notebook inline plot size\n",
    "    'axes.labelsize': 16, # fontsize for x and y labels (was 10)\n",
    "    'axes.titlesize': 16,\n",
    "    'font.size': 16, # was 10\n",
    "    'legend.fontsize': 16, # was 10\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'text.usetex': True,\n",
    "    'figure.figsize': [3.39, 2.10],\n",
    "    'font.family': 'serif',\n",
    "}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training data that goes from initial condition location to PCA coefficient trajectory\n",
    "num_modes=40\n",
    "locs = np.load('../../SWE_Data/Data/Locations.npy')\n",
    "pca_coeffs = np.load('../../SWE_Data/PCA_Coefficients_q1.npy')[0:num_modes,:]\n",
    "\n",
    "coeff_scaler = MinMaxScaler()\n",
    "pca_coeffs_scaled = np.transpose(coeff_scaler.fit_transform(np.transpose(pca_coeffs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = np.shape(locs)[0]\n",
    "num_ivs = np.shape(locs)[1]\n",
    "num_coeffs = np.shape(pca_coeffs)[0]\n",
    "burn_in = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "raw_training_data = np.zeros(shape=(num_sims,num_coeffs+num_ivs,500),dtype='double')\n",
    "\n",
    "for sim in range(num_sims):\n",
    "    raw_training_data[sim,:-num_ivs,:] = pca_coeffs_scaled[:,500*sim:500*(sim+1)]\n",
    "    raw_training_data[sim,-num_ivs:,:] = locs[sim,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 42, 500)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(raw_training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "from tcn import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 42, 20)]          0         \n",
      "_________________________________________________________________\n",
      "tcn_2 (TCN)                  (None, 42, 88)            227920    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 42, 88)            0         \n",
      "_________________________________________________________________\n",
      "tcn_3 (TCN)                  (None, 42, 88)            233904    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 42, 88)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 42, 480)           42720     \n",
      "=================================================================\n",
      "Total params: 504,544\n",
      "Trainable params: 504,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 9\n",
    "inputs = Input(shape=(42, burn_in))\n",
    "tcn_output = TCN(88,return_sequences=True,activation='tanh')(inputs)  # The TCN layers are here.\n",
    "tcn_output = Dropout(0.2)(tcn_output,training=True)\n",
    "tcn_output = TCN(88,return_sequences=True,activation='tanh')(tcn_output)  # The TCN layers are here.\n",
    "tcn_output = Dropout(0.2)(tcn_output,training=True)\n",
    "output = Dense(500-burn_in,activation='linear')(tcn_output)\n",
    "m = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "my_adam = optimizers.Adam(lr=0.000258365691288, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "m.compile(optimizer=my_adam, loss='mse')\n",
    "\n",
    "filepath = \"NA_TCN.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "earlystopping = EarlyStopping(monitor='loss', min_delta=0, patience=100, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "m.summary()\n",
    "\n",
    "train_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data into windowed input and windowed output\n",
    "input_window_length = burn_in\n",
    "output_window_length = 500-burn_in\n",
    "num_timesteps_per_simulation = 500\n",
    "state_len = 42\n",
    "num_sims = 20\n",
    "\n",
    "training_data_ip = np.zeros(shape=(num_sims,state_len,burn_in))\n",
    "training_data_op = np.zeros(shape=(num_sims,state_len,500-burn_in))\n",
    "\n",
    "for sim_num in range(num_sims):\n",
    "    training_data_ip[sim_num,:,:] = raw_training_data[sim_num,:,0:burn_in]\n",
    "    training_data_op[sim_num,:,:] = raw_training_data[sim_num,:,burn_in:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_mode:\n",
    "    from time import time\n",
    "\n",
    "    start_time = time()\n",
    "    history = m.fit(training_data_ip, training_data_op, epochs=5000, callbacks=callbacks_list, batch_size=batch_size)\n",
    "    np.save('NA_TCN.npy',history.history['loss'])\n",
    "    end_time = time()\n",
    "    \n",
    "    print('Time elapsed:',end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "from time import time\n",
    "m.load_weights(filepath)\n",
    "filename = '../../SWE_Data/Data/snapshot_matrix_pod_test.npy'\n",
    "test_data = np.load(filename)[0:64*64,:]\n",
    "pca_vectors = np.load('../../SWE_Data/PCA_Vectors_q1.npy')[:64*64,:num_modes]\n",
    "\n",
    "true_pca_evol = coeff_scaler.transform(np.matmul(np.transpose(test_data),pca_vectors))\n",
    "test_data = np.zeros(shape=(1,num_coeffs+num_ivs,500))\n",
    "test_data[0,0:num_coeffs,:] = np.transpose(true_pca_evol[:,:])\n",
    "\n",
    "test_data[0,-2,:] = -1.0/2.7\n",
    "test_data[0,-1,:] = -1.0/4.0\n",
    "viz = False\n",
    "\n",
    "mse_val = 0.0\n",
    "\n",
    "num_inference = 1000\n",
    "start_time = time()\n",
    "pred_mean = np.zeros_like(test_data)\n",
    "pred_pca_array = np.zeros(shape=(num_inference,np.shape(test_data)[1],np.shape(test_data)[2]))\n",
    "\n",
    "for inference in range(num_inference):\n",
    "\n",
    "    pred_pca = m.predict(test_data[:,:,:burn_in])\n",
    "    pred_pca = np.concatenate((test_data[:,:,:burn_in],pred_pca),axis=-1)\n",
    "    pred_pca_array[inference,:,:] = pred_pca[0,:,:]\n",
    "    \n",
    "    mse_val = mse_val + np.sum((pred_pca-test_data)**2)\n",
    "    pred_mean = pred_mean + pred_pca\n",
    "    \n",
    "    if viz:\n",
    "        \n",
    "        fig,ax = plt.subplots(nrows=2,ncols=2,figsize=(12,10))\n",
    "        ax[0,0].plot(test_data[0,0,:],label='True')\n",
    "        ax[0,0].plot(pred_pca[0,0,:],label='Predicted')\n",
    "        ax[0,0].set_title('Mode 1')\n",
    "\n",
    "\n",
    "        ax[1,0].plot(test_data[0,1,:],label='True')\n",
    "        ax[1,0].plot(pred_pca[0,1,:],label='Predicted')\n",
    "        ax[1,0].set_title('Mode 2')\n",
    "\n",
    "        ax[0,1].plot(test_data[0,2,:],label='True')\n",
    "        ax[0,1].plot(pred_pca[0,2,:],label='Predicted')\n",
    "        ax[0,1].set_title('Mode 3')\n",
    "\n",
    "        ax[1,1].plot(test_data[0,3,:],label='True')\n",
    "        ax[1,1].plot(pred_pca[0,3,:],label='Predicted')\n",
    "        ax[1,1].set_title('Mode 4')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Plotting some contours\n",
    "        true_rb = np.transpose(coeff_scaler.inverse_transform(true_pca_evol))\n",
    "        true_recon = np.matmul(pca_vectors,true_rb)[:,-2].reshape(64,64)\n",
    "\n",
    "        pred_rb = np.transpose(pred_pca[0,:num_modes,:])\n",
    "        pred_rb = np.transpose(coeff_scaler.inverse_transform(pred_rb))\n",
    "        pred_recon = np.matmul(pca_vectors,pred_rb)[:,-2].reshape(64,64)\n",
    "\n",
    "        fig,ax = plt.subplots(nrows=1,ncols=2,figsize=(12,5))\n",
    "        cx = ax[0].contourf(true_recon)\n",
    "        ax[1].contourf(pred_recon)\n",
    "\n",
    "        fig.colorbar(cx,ax=ax[0],fraction=0.046, pad=0.04)\n",
    "        fig.colorbar(cx,ax=ax[1],fraction=0.046, pad=0.04)\n",
    "        plt.tight_layout()\n",
    "        plt.show()      \n",
    "    \n",
    "end_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean = pred_mean/num_inference\n",
    "pred_sdev = np.sqrt(np.sum((pred_pca_array - pred_mean[0,:,:])**2,axis=0)/(num_inference-1))\n",
    "\n",
    "if train_mode:\n",
    "    np.save('../Figures/NA_TCN_Mean.npy',pred_mean)\n",
    "    np.save('../Figures/NA_TCN_SD.npy',pred_sdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed per inference: 0.05027106237411499\n"
     ]
    }
   ],
   "source": [
    "print('Time elapsed per inference:',(end_time-start_time)/num_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
