{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(10)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "params = {\n",
    "    'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "    'image.origin': 'lower',\n",
    "    'image.interpolation': 'nearest',\n",
    "    'image.cmap': 'gray',\n",
    "    'axes.grid': False,\n",
    "    'savefig.dpi': 300,  # to adjust notebook inline plot size\n",
    "    'axes.labelsize': 16, # fontsize for x and y labels (was 10)\n",
    "    'axes.titlesize': 16,\n",
    "    'font.size': 16, # was 10\n",
    "    'legend.fontsize': 16, # was 10\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'text.usetex': True,\n",
    "    'figure.figsize': [3.39, 2.10],\n",
    "    'font.family': 'serif',\n",
    "}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training data that goes from initial condition location to PCA coefficient trajectory\n",
    "num_modes=40\n",
    "locs = np.load('../../SWE_Data/Data/Locations.npy')\n",
    "pca_coeffs = np.load('../../SWE_Data/PCA_Coefficients_q1.npy')[0:num_modes,:]\n",
    "coeff_scaler = MinMaxScaler()\n",
    "pca_coeffs_scaled = coeff_scaler.fit_transform(np.transpose(pca_coeffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total shape is large due to multiple simulations\n",
    "num_samples_total = np.shape(pca_coeffs_scaled)[0]\n",
    "num_sims = int(num_samples_total/500)\n",
    "pca_coeffs_scaled = np.reshape(pca_coeffs_scaled,newshape=(num_sims,500,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_len = np.shape(pca_coeffs_scaled)[-1]\n",
    "seq_num = 20\n",
    "\n",
    "num_samples = 500-seq_num-1\n",
    "input_data = np.zeros(shape=(num_sims,seq_num,state_len+2))\n",
    "output_data = np.zeros(shape=(num_sims,500-seq_num,state_len))\n",
    "\n",
    "for simnum in range(num_sims):            \n",
    "    sub_data = pca_coeffs_scaled[simnum,:,:]\n",
    "\n",
    "    input_seq = sub_data[:seq_num,:]\n",
    "    output_seq = sub_data[seq_num:,:]\n",
    "    \n",
    "    input_data[simnum,:,:state_len] = input_seq[None,:,:state_len]\n",
    "    input_data[simnum,:,-2] = locs[simnum,0]\n",
    "    input_data[simnum,:,-1] = locs[simnum,1]\n",
    "\n",
    "    output_data[simnum,:,:] = output_seq[:]\n",
    "\n",
    "output_data = output_data.reshape(num_sims,(500-seq_num)*state_len,order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Lambda, Add, LSTM, Dropout\n",
    "from tensorflow.keras import optimizers, models, regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_filepath = 'NA_LSTM_T.h5'\n",
    "\n",
    "def coeff_determination(y_pred, y_true): #Order of function inputs is important here        \n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "class EarlyStoppingByLossVal(Callback):\n",
    "    def __init__(self, monitor='loss', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current < self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0208 21:32:52.453939 140006284019520 deprecation.py:506] From /home/rmlans/anaconda3/envs/deephyper_env/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "at_inputs (InputLayer)       [(None, 20, 42)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 20, 145)           109040    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 145)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 145)               168780    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 145)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 19200)             2803200   \n",
      "=================================================================\n",
      "Total params: 3,081,020\n",
      "Trainable params: 3,081,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_inputs = Input(shape=(seq_num,state_len+2),name='at_inputs')\n",
    "h1 = LSTM(145,return_sequences=True)(lstm_inputs)\n",
    "h1 = Dropout(0.2)(h1,training=True)\n",
    "h2 = LSTM(145,return_sequences=False)(h1)\n",
    "h2 = Dropout(0.2)(h2,training=True)\n",
    "lstm_outputs = Dense(np.shape(output_data)[1],activation=None)(h2)\n",
    "\n",
    "lstm_model = Model(inputs=lstm_inputs,outputs=lstm_outputs)\n",
    " \n",
    "# design network\n",
    "my_adam = optimizers.Adam(lr=0.005232326845556, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "earlystopping = EarlyStopping(monitor='loss', min_delta=0, patience=100, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "callbacks_list = [checkpoint,EarlyStoppingByLossVal()]\n",
    "\n",
    "# fit network\n",
    "lstm_model.compile(optimizer=my_adam,loss='mean_squared_error',metrics=[coeff_determination])    \n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 5000\n",
    "batch_size = 6\n",
    "train_mode = False\n",
    "\n",
    "if train_mode:\n",
    "    train_history = lstm_model.fit(x=input_data, y=output_data, epochs=num_epochs, batch_size=batch_size, callbacks=callbacks_list)\n",
    "    np.save('NA_LSTM_T.npy',train_history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Load model weights first\n",
    "lstm_model.load_weights(weights_filepath)\n",
    "\n",
    "# Testing\n",
    "filename = '../../SWE_Data/Data/snapshot_matrix_pod_test.npy'\n",
    "test_data = np.load(filename)[0:64*64,:]\n",
    "pca_vectors = np.load('../../SWE_Data/PCA_Vectors_q1.npy')[:,:num_modes]\n",
    "\n",
    "true_pca_evol = coeff_scaler.transform(np.matmul(np.transpose(test_data),pca_vectors))\n",
    "test_data = np.zeros(shape=(500,num_modes+2))\n",
    "test_data[:,:num_modes] = true_pca_evol[:,:]\n",
    "\n",
    "test_data[:,-2] = -1.0/2.7\n",
    "test_data[:,-1] = -1.0/4.0\n",
    "\n",
    "viz = False\n",
    "\n",
    "mse_val = 0.0\n",
    "num_inference = 1000\n",
    "pred_mean = np.zeros_like(test_data)[:,:-2]\n",
    "pred_pca_array = np.zeros(shape=(num_inference,np.shape(test_data)[0],np.shape(test_data)[1]-2))\n",
    "\n",
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "for inference in range(num_inference):\n",
    "\n",
    "    testing_inputs = np.copy(test_data[:seq_num,:]).reshape(1,seq_num,state_len+2,order='F')\n",
    "    true_outputs = np.copy(test_data[seq_num:,:state_len]).reshape(1,500-seq_num,state_len,order='F')\n",
    "    predicted_outputs = lstm_model.predict(testing_inputs).reshape(1,500-seq_num,state_len,order='F')\n",
    "    \n",
    "    true_plot_array = np.concatenate((testing_inputs[:,:,:state_len],true_outputs),axis=1)\n",
    "    pred_plot_array = np.concatenate((testing_inputs[:,:,:state_len],predicted_outputs),axis=1)\n",
    "    \n",
    "    pred_pca_array[inference,:,:] = pred_plot_array[0,:,:]\n",
    "    \n",
    "    mse_val = mse_val + np.sum((pred_plot_array[0,:,:]-test_data[:,:-2])**2)\n",
    "    pred_mean = pred_mean + pred_plot_array[0,:,:]\n",
    "    \n",
    "    if viz:\n",
    "\n",
    "        fig,ax = plt.subplots(nrows=2,ncols=2)\n",
    "        ax[0,0].plot(true_plot_array[0,:,0],label='True')\n",
    "        ax[0,0].plot(pred_plot_array[0,:,0],label='Predicted')\n",
    "        ax[0,0].set_title('Mode 1')\n",
    "\n",
    "\n",
    "        ax[1,0].plot(true_plot_array[0,:,1],label='True')\n",
    "        ax[1,0].plot(pred_plot_array[0,:,1],label='Predicted')\n",
    "        ax[1,0].set_title('Mode 2')\n",
    "\n",
    "        ax[0,1].plot(true_plot_array[0,:,2],label='True')\n",
    "        ax[0,1].plot(pred_plot_array[0,:,2],label='Predicted')\n",
    "        ax[0,1].set_title('Mode 3')\n",
    "\n",
    "        ax[1,1].plot(true_plot_array[0,:,3],label='True')\n",
    "        ax[1,1].plot(pred_plot_array[0,:,3],label='Predicted')\n",
    "        ax[1,1].set_title('Mode 4')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Plotting some contours\n",
    "        true_rb = np.transpose(coeff_scaler.inverse_transform(true_pca_evol))\n",
    "        true_recon = np.matmul(pca_vectors,true_rb)[:,-1].reshape(64,64)\n",
    "\n",
    "        pred_rb = pred_plot_array[0,:,:]\n",
    "        pred_rb = np.transpose(coeff_scaler.inverse_transform(pred_rb))\n",
    "        pred_recon = np.matmul(pca_vectors,pred_rb)[:,-1].reshape(64,64)\n",
    "\n",
    "\n",
    "        fig,ax = plt.subplots(nrows=1,ncols=2,figsize=(12,5))\n",
    "        cx = ax[0].contourf(true_recon)\n",
    "        ax[1].contourf(pred_recon)\n",
    "\n",
    "        fig.colorbar(cx,ax=ax[0],fraction=0.046, pad=0.04)\n",
    "        fig.colorbar(cx,ax=ax[1],fraction=0.046, pad=0.04)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "end_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed per inference 0.008150947093963624\n"
     ]
    }
   ],
   "source": [
    "print('Time elapsed per inference',(end_time-start_time)/num_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_mode:\n",
    "    np.save('../Figures/NA_LSTM_T_Mean.npy',pred_mean)\n",
    "    np.save('../Figures/NA_LSTM_T_SD.npy',pred_sdev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
