{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(10)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "params = {\n",
    "    'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "    'image.origin': 'lower',\n",
    "    'image.interpolation': 'nearest',\n",
    "    'image.cmap': 'gray',\n",
    "    'axes.grid': False,\n",
    "    'savefig.dpi': 300,  # to adjust notebook inline plot size\n",
    "    'axes.labelsize': 16, # fontsize for x and y labels (was 10)\n",
    "    'axes.titlesize': 16,\n",
    "    'font.size': 16, # was 10\n",
    "    'legend.fontsize': 16, # was 10\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'text.usetex': True,\n",
    "    'figure.figsize': [3.39, 2.10],\n",
    "    'font.family': 'serif',\n",
    "}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training data that goes from initial condition location to PCA coefficient trajectory\n",
    "num_modes=40\n",
    "locs = np.load('../../SWE_Data/Data/Locations.npy')\n",
    "pca_coeffs = np.load('../../SWE_Data/PCA_Coefficients_q1.npy')[0:num_modes,:]\n",
    "\n",
    "coeff_scaler = MinMaxScaler()\n",
    "pca_coeffs_scaled = np.transpose(coeff_scaler.fit_transform(np.transpose(pca_coeffs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = np.shape(locs)[0]\n",
    "num_ivs = np.shape(locs)[1]\n",
    "num_coeffs = np.shape(pca_coeffs)[0]\n",
    "burn_in = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "training_data_ip = np.zeros(shape=(num_sims,num_coeffs+num_ivs,burn_in),dtype='double')\n",
    "training_data_op = np.zeros(shape=(num_sims,num_coeffs+num_ivs,500-burn_in),dtype='double')\n",
    "\n",
    "for sim in range(num_sims):\n",
    "    training_data_ip[sim,:-num_ivs,:] = pca_coeffs_scaled[:,500*sim:500*sim+burn_in]\n",
    "    training_data_ip[sim,-num_ivs:,:] = locs[sim,:,None]\n",
    "    training_data_op[sim,:-num_ivs,:] = pca_coeffs_scaled[:,500*sim+burn_in:500*(sim+1)]\n",
    "    training_data_op[sim,-num_ivs:,:] = locs[sim,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Lambda, Add, LSTM, Dropout, Bidirectional\n",
    "from tensorflow.keras import optimizers, models, regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_filepath = 'NA_BLSTM_P.h5'\n",
    "\n",
    "def coeff_determination(y_pred, y_true): #Order of function inputs is important here        \n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "class EarlyStoppingByLossVal(Callback):\n",
    "    def __init__(self, monitor='loss', value=0.00001, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current < self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "nat_inputs (InputLayer)      [(None, 42, 20)]          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 42, 290)           192560    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 42, 290)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 42, 290)           505760    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 42, 290)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 42, 480)           139680    \n",
      "=================================================================\n",
      "Total params: 838,000\n",
      "Trainable params: 838,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_inputs = Input(shape=(num_coeffs+num_ivs,burn_in),name='nat_inputs')\n",
    "h1 = Bidirectional(LSTM(145,return_sequences=True))(lstm_inputs)\n",
    "h1 = Dropout(0.0)(h1,training=True)\n",
    "h2 = Bidirectional(LSTM(145,return_sequences=True))(h1)\n",
    "h2 = Dropout(0.0)(h2,training=True)\n",
    "lstm_outputs = Dense(500-burn_in,activation=None)(h2)\n",
    "\n",
    "lstm_model = Model(inputs=lstm_inputs,outputs=lstm_outputs)\n",
    " \n",
    "# design network\n",
    "my_adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "earlystopping = EarlyStopping(monitor='loss', min_delta=0, patience=100, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "callbacks_list = [checkpoint,EarlyStoppingByLossVal()]\n",
    "\n",
    "# fit network\n",
    "lstm_model.compile(optimizer=my_adam,loss='mean_squared_error',metrics=[coeff_determination])    \n",
    "lstm_model.summary()\n",
    "\n",
    "train_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lstm_model.load_weights(weights_filepath)\n",
    "\n",
    "# Testing\n",
    "filename = '../../SWE_Data/Data/snapshot_matrix_pod_test.npy'\n",
    "test_data = np.load(filename)[0:64*64,:]\n",
    "pca_vectors = np.load('../../SWE_Data/PCA_Vectors_q1.npy')[:64*64,:num_modes]\n",
    "\n",
    "true_pca_evol = coeff_scaler.transform(np.matmul(np.transpose(test_data),pca_vectors))\n",
    "test_data = np.zeros(shape=(1,num_coeffs+num_ivs,500))\n",
    "test_data[0,0:num_coeffs,:] = np.transpose(true_pca_evol[:,:])\n",
    "\n",
    "test_data[0,-2,:] = -1.0/2.7\n",
    "test_data[0,-1,:] = -1.0/4.0\n",
    "\n",
    "viz = False\n",
    "\n",
    "mse_val = 0.0\n",
    "num_inference = 1000\n",
    "pred_mean = np.zeros_like(test_data)\n",
    "pred_pca_array = np.zeros(shape=(num_inference,np.shape(test_data)[1],np.shape(test_data)[2]))\n",
    "\n",
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "for inference in range(num_inference):\n",
    "    \n",
    "    pred_pca = lstm_model.predict(test_data[:,:,:burn_in])\n",
    "    pred_pca = np.concatenate((test_data[:,:,:burn_in],pred_pca),axis=-1)\n",
    "    \n",
    "    pred_pca_array[inference,:,:] = pred_pca[0,:,:]\n",
    "    mse_val = mse_val + np.sum((pred_pca-test_data)**2)\n",
    "    pred_mean = pred_mean + pred_pca\n",
    "    \n",
    "    if viz:\n",
    "    \n",
    "        fig,ax = plt.subplots(nrows=2,ncols=2,figsize=(12,10))\n",
    "        ax[0,0].plot(test_data[0,0,:],label='True')\n",
    "        ax[0,0].plot(pred_pca[0,0,:],label='Predicted')\n",
    "        ax[0,0].set_title('Mode 1')\n",
    "\n",
    "\n",
    "        ax[1,0].plot(test_data[0,1,:],label='True')\n",
    "        ax[1,0].plot(pred_pca[0,1,:],label='Predicted')\n",
    "        ax[1,0].set_title('Mode 2')\n",
    "\n",
    "        ax[0,1].plot(test_data[0,2,:],label='True')\n",
    "        ax[0,1].plot(pred_pca[0,2,:],label='Predicted')\n",
    "        ax[0,1].set_title('Mode 3')\n",
    "\n",
    "        ax[1,1].plot(test_data[0,3,:],label='True')\n",
    "        ax[1,1].plot(pred_pca[0,3,:],label='Predicted')\n",
    "        ax[1,1].set_title('Mode 4')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Plotting some contours\n",
    "        true_rb = np.transpose(coeff_scaler.inverse_transform(true_pca_evol))\n",
    "        true_recon = np.matmul(pca_vectors,true_rb)[:,-2].reshape(64,64)\n",
    "\n",
    "        pred_rb = np.transpose(pred_pca[0,:num_modes,:])\n",
    "        pred_rb = np.transpose(coeff_scaler.inverse_transform(pred_rb))\n",
    "        pred_recon = np.matmul(pca_vectors,pred_rb)[:,-2].reshape(64,64)\n",
    "\n",
    "\n",
    "        fig,ax = plt.subplots(nrows=1,ncols=2,figsize=(12,5))\n",
    "        cx = ax[0].contourf(true_recon)\n",
    "        ax[1].contourf(pred_recon)\n",
    "\n",
    "        fig.colorbar(cx,ax=ax[0],fraction=0.046, pad=0.04)\n",
    "        fig.colorbar(cx,ax=ax[1],fraction=0.046, pad=0.04)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "end_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time per inference: 0.016969022512435913\n"
     ]
    }
   ],
   "source": [
    "print('Elapsed time per inference:',(end_time-start_time)/num_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean = pred_mean/num_inference\n",
    "pred_sdev = np.sqrt(np.sum((pred_pca_array - pred_mean[0,:,:])**2,axis=0)/(num_inference-1))\n",
    "np.save('NA_BLSTM_P_0_Mean.npy',pred_mean)\n",
    "np.save('NA_BLSTM_P_0_SD.npy',pred_sdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
